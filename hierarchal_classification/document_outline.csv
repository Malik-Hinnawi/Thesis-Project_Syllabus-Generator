Level,Title,Page Number,Parent Title,Description
0,Cover,1,,
0,Title Page,5,Cover,"OPERATING
SYSTEM
CONCEPTS
ABRAHAM SILBERSCHATZ 
:BMF6OJWFSTJUZ
PETER BAER GALVIN 
$BNCSJEHF$PNQVUFSBOE4UBSGJTI4UPSBHF
GREG GAGNE 
8FTUNJOTUFS$PMMFHF
7(17+(',7,21
"
0,Copyright,6,Title Page,"Publisher    Laurie Rosatone 
Editorial Director   Don Fowley 
Development Editor   Ryann Dannelly 
Freelance Developmental Editor  Chris Nelson/Factotum  
Executive Marketing Manager  Glenn Wilson 
Senior Content Manage  Valerie Zaborski 
Senior Production Editor  Ken Santor 
Media Specialist   Ashley Patterson 
Editorial Assistant   Anna Pham 
Cover Designer   Tom Nery 
Cover art    © metha189/Shutterstock 
This book was set in Palatino by  the author using LaTeX and printed and bound by LSC Kendallville.  
The cover was printed by LSC Kendallville.  
Copyright © 2018, 2013, 2012, 2008 John Wiley & Sons, Inc.  All rights reserved. 
No part of this publication may be reproduced, stored in a retrieval system or transmitted in any form or by 
any means, electronic, mechanical, photocopying, recording, scanning or otherwise, except as permitted 
under Sections 107 or 108 of the 1976 United Stat es Copyright Act, without either the prior written 
permission of the Publisher, or authorization thr ough payment of the appropriate per-copy fee to the 
Copyright Clearance Center, Inc. 222 Rosewood Drive, Danvers, MA 01923, (978)750-8400, fax 
(978)750-4470. Requests to the Publisher for permission should be addressed to the Permissions 
Department, John Wiley & Sons, Inc., 111 River Street, Hoboken, NJ 07030 (201)748-6011, fax (201)748-
6008, E-Mail: PERMREQ@WILEY.COM.   
Evaluation copies are provided to qualified academic s and professionals for review purposes only, for use 
in their courses during the next academic year.  These copies are licensed and may not be sold or 
transferred to a third party.  Upon completion of the review period, please return the evaluation copy to 
Wiley.  Return instructions and a free-of-charge return shipping label are available at 
www.wiley.com/go/evalreturn. Outside of the United States, please contact your local representative. 
 
Library of Congress Cataloging-in-Publication Data 
 
Names: Silberschatz, Abraham, author. | Galvin, Peter B., author. | Gagne,  
   Greg, author. 
Title: Operating system concepts / Abraham Silberschatz, Yale University,  
   Peter Baer Galvin, Pluribus Networks, Greg Gagne, Westminster College. 
Description: 10th edition. | Hoboken, NJ : Wiley, [2018] | Includes  
   bibliographical references and index. |  
Identifiers: LCCN 2017043464 (print) | LCCN 2017045986 (ebook)  | ISBN  
   9781119320913 (enhanced ePub) 
Subjects:  LCSH: Operating systems (Computers) 
Classification: LCC QA76.76.O63 (ebook) | LCC QA76.76.O63 S55825 2018 (print)  
   | DDC 005.4/3--dc23 
LC record available at https://lccn.loc.gov/2017043464 
 
The inside back cover will contain pr inting identification and country of or igin if omitted from this page. In 
addition, if the ISBN on the back c over differs from the ISBN on this page, the one on the back cover is 
correct. 
Enhanced ePub ISBN 978-1-119-32091-3 
Printed in the United States of America 
10   9   8   7   6   5   4   3   2   1 "
0,Preface,9,Copyright,"Preface
Operating systems are an essential part of any computer system. Similarly, a
course on operating systems is an essential part of any computer science edu-
cation.Thisfieldisundergoingrapidchange,ascomputersarenowprevalent
in virtually every arena of day-to-day life—from embedded devices in auto-
mobiles through the most sophisticated planning tools for governments and
multinationalfirms.Yetthefundamentalconceptsremainfairlyclear,anditis
on these that we base thisbook.
We wrote this book as a text for an introductory course in operating sys-
tems at the junior or senior undergraduate level or at the first-year graduate
level. We hope that practitioners will also find it useful. It provides a clear
description of the concepts that underlie operating systems. As prerequisites,
we assume that the reader is familiar with basic data structures, computer
organization,andahigh-levellanguage,suchasCorJava.Thehardwaretopics
requiredfor an understanding of operating systems are covered in Chapter 1.
Inthatchapter,wealsoincludeanoverviewofthefundamentaldatastructures
that are prevalent in most operating systems. For code examples, we use pre-
dominantly C, as well as a significant amount of Java, but the reader can still
understandthealgorithmswithoutathoroughknowledgeoftheselanguages.
Conceptsare presentedusing intuitivedescriptions.Importanttheoretical
resultsare covered,but formal proofs arelargelyomitted.The bibliographical
notes at the end of each chapter contain pointers to research papers in which
resultswerefirstpresentedandproved,aswellasreferencestorecentmaterial
forfurtherreading.Inplaceofproofs,figuresandexamplesareusedtosuggest
why weshould expecttheresultinquestionto betrue.
The fundamental concepts and algorithms covered in the book are often
based on those used in both open-source and commercial operating systems.
Our aim is to present these concepts and algorithms in a general setting that
is not tied to one particular operating system. However, we present a large
numberofexamplesthatpertaintothemostpopularandthemostinnovative
operating systems, including Linux, Microsoft Windows, Apple mac OS(the
originalname, OSX,waschangedin2016tomatchthenamingschemeofother
Apple products), and Solaris. We also include examples of both Android and
iOS,currently thetwo dominant mobileoperatingsystems.
The organization of the text reflects our many years of teaching courses
on operating systems.Considerationwas also givento the feedback provided
vii"
0,Contents,23,Preface,"Contents
PART ONE
 OVERVIEW
Chapter 1 Introduction
1.1 WhatOperating SystemsDo 4
1.2 Computer-SystemOrganization 7
1.3 Computer-SystemArchitecture 15
1.4 Operating-SystemOperations 21
1.5 Resource Management 27
1.6 Security and Protection 33
1.7 Virtualization 341.8 DistributedSystems 35
1.9 KernelDataStructures 36
1.10 ComputingEnvironments 40
1.11 Free andOpen-Source Operating
Systems 46
Practice Exercises 53
FurtherReading 54
Chapter 2 Operating-System Structures
2.1 Operating-SystemServices 55
2.2 User andOperating-System
Interface 58
2.3 System Calls 62
2.4 System Services 74
2.5 Linkers and Loaders 75
2.6 Why Applications Are
Operating-SystemSpecific 772.7 Operating-SystemDesign and
Implementation 79
2.8 Operating-SystemStructure 81
2.9 Building andBootinganOperating
System 92
2.10 Operating-SystemDebugging 95
2.11 Summary 100
Practice Exercises 101
FurtherReading 101
PART TWO
 PROCESS MANAGEMENT
Chapter 3 Processes
3.1 Process Concept 106
3.2 Process Scheduling 110
3.3 OperationsonProcesses 116
3.4 Interprocess Communication 123
3.5 IPC in Shared-MemorySystems 125
3.6 IPC in Message-Passing Systems 1273.7 Examples ofIPC Systems 132
3.8 Communicationin Client–
ServerSystems 145
3.9 Summary 153
Practice Exercises 154
FurtherReading 156
YYJ"
0,PART ONE OVERVIEW,29,Contents,"Part One
Overview
Anoperating system acts as an intermediary between the user of a com-
puter and the computer hardware. The purpose of an operating system
is to provide an environment in wh ich a user can execute programs in a
convenient andefﬁcient manner.
An operating system is software th at manages the computer hard-
ware. The hardware must provide appropriate mechanisms to ensure the
correct operation of the computer system and to prevent programs from
interfering with the proper operation of the system.
Internally, operating systems var y greatly in their makeup, since they
are organized along many different lines. The design of a new operating
system is a major task, and it is important that the goals of the system be
well deﬁned before the design begins.
Because an operating system is large and complex, it must be cre-
ated piece by piece. Each of these pieces should be a well-delineated
portion of the system, with carefully deﬁned inputs, outputs, and func-
tions."
1,Chapter 1 Introduction,31,PART ONE OVERVIEW,"1CHAPTER
Introduction
Anoperating system is software that manages a computer’s hardware. It
also provides a basis for application programs and acts as an intermediary
between the computer user and the computer hardware. An amazing aspect
of operating systems is how they vary in accomplishing these tasks in a wide
variety of computing environments. Operating systems are everywhere,from
cars and home appliances that include “Internet of Things ”devices, to smart
phones,personalcomputers,enterprisecomputers,andcloudcomputingenvi-
ronments.
Inordertoexploretheroleofanoperatingsysteminamoderncomputing
environment,itisimportantfirsttounderstandtheorganizationandarchitec-
ture of computer hardware. This includes the CPU,m e m o r y ,a n d I/Odevices,
as well as storage. Afundamental responsibility of an operating system is to
allocatetheseresourcesto programs.
Because an operating system is large and complex, it must be created
pieceby piece.Each of these piecesshou ld be a well-delineatedportionof the
system, with carefully defined inputs, outputs, and functions. In this chapter,
we provide a general overview of the major components of a contemporary
computer system as well as the functions provided by the operating system.
Additionally,wecoverseveraltopicstohelpsetthestagefortheremainderof
the text: data structures used in operating systems, computing environments,
and open-source and freeoperatingsystems.
CHAPTER OBJECTIVES
•Describe the general organization of a computer system and the role of
interrupts.
Describe the components in a modern multiprocessor computer system.
Illustrate the transition from user mode to kernel mode.
Discuss how operating systems are used in various computing environ-
ments.
Provide examples of free and open-source operating systems.
3"
2,1.1 What Operating Systems Do,32,Chapter 1 Introduction,"4 Chapter 1 Introduction
1.1 What Operating Systems Do
We begin our discussion by looking at the operating system’s role in the
overallcomputersystem.Acomputersystemcanbedividedroughlyintofour
components: the hardware, theoperating system, theapplication programs,
and a user(Figure1.1).
The hardware —the central processing unit ( CPU), the memory, and the
input/output ( I/O) devices—provides the basic computing resources for the
system. The application programs —such as word processors, spreadsheets,
compilers, and web browsers—define the ways in which these resources are
used to solve users’ computing problems. The operating system controls the
hardwareandcoordinatesitsuseamongthevariousapplicationprogramsfor
thevarious users.
We can also view a computer system as consisting of hardware, software,
and data. The operating system provides the means for proper use of these
resources in the operation of the computer system. An operating system is
similar to a government. Like a government, it performs no useful function
byitself.Itsimplyprovidesan environment within which otherprogramscan
dousefulwork.
To understand more fully the operating system’s role, we next explore
operatingsystemsfromtwoviewpoints:thatoftheuserandthatofthesystem.
1.1.1 User View
The user’s view of the computer varies according to the interface being used.
Many computer users sit with a laptop or in front of a PCconsisting of a
monitor, keyboard, and mouse. Such a system is designed for one user to
monopolize its resources. The goal is to maximize the work (or play) that the
user is performing. In this case, the operating system is designed mostly for
ease of use , with some attention paid to performance and security and none
paid to resource utilization —how various hardware and software resources
areshared.
(compilers, web browsers, development kits, etc.)user
application programs
operating system
computer hardware
(CPU, memory, I/O devices, etc.)
Figure 1.1 Abstract view of the components of a computer system."
3,1.1.1 User View,32,1.1 What Operating Systems Do,"4 Chapter 1 Introduction
1.1 What Operating Systems Do
We begin our discussion by looking at the operating system’s role in the
overallcomputersystem.Acomputersystemcanbedividedroughlyintofour
components: the hardware, theoperating system, theapplication programs,
and a user(Figure1.1).
The hardware —the central processing unit ( CPU), the memory, and the
input/output ( I/O) devices—provides the basic computing resources for the
system. The application programs —such as word processors, spreadsheets,
compilers, and web browsers—define the ways in which these resources are
used to solve users’ computing problems. The operating system controls the
hardwareandcoordinatesitsuseamongthevariousapplicationprogramsfor
thevarious users.
We can also view a computer system as consisting of hardware, software,
and data. The operating system provides the means for proper use of these
resources in the operation of the computer system. An operating system is
similar to a government. Like a government, it performs no useful function
byitself.Itsimplyprovidesan environment within which otherprogramscan
dousefulwork.
To understand more fully the operating system’s role, we next explore
operatingsystemsfromtwoviewpoints:thatoftheuserandthatofthesystem.
1.1.1 User View
The user’s view of the computer varies according to the interface being used.
Many computer users sit with a laptop or in front of a PCconsisting of a
monitor, keyboard, and mouse. Such a system is designed for one user to
monopolize its resources. The goal is to maximize the work (or play) that the
user is performing. In this case, the operating system is designed mostly for
ease of use , with some attention paid to performance and security and none
paid to resource utilization —how various hardware and software resources
areshared.
(compilers, web browsers, development kits, etc.)user
application programs
operating system
computer hardware
(CPU, memory, I/O devices, etc.)
Figure 1.1 Abstract view of the components of a computer system."
3,1.1.2 System View,33,1.1.1 User View,"1.1 What Operating Systems Do 5
Increasingly,manyusersinteractwithmobiledevicessuchassmartphones
andtablets—devicesthatarereplacingdesktopandlaptopcomputersystems
for some users. These devices are typically connected to networks through
cellularorotherwirelesstechnologies.T heuserinterfaceformobilecomputers
generallyfeaturesa touch screen , where theuserinteracts with the systemby
pressing and swiping fingers across the screen rather than using a physical
keyboardandmouse.Manymobiledevice salsoallowuserstointeractthrough
avoice recognition interface,such asApple’s Siri.
Somecomputershavelittleornouserview.Forexample, embedded com-
putersinhomedevicesandautomobilesmayhavenumerickeypadsandmay
turnindicatorlightsonorofftoshowstatus,buttheyandtheiroperatingsys-
temsandapplicationsaredesignedprimarilytorunwithoutuserintervention.
1.1.2 System View
From thecomputer’s point of view,the operating systemis the programmost
intimately involved with the hardwar e. In this context, we can view an oper-
ating system as a resource allocator . Acomputer system has many resources
that may be required to solve a problem: CPUtime, memory space, storage
space,I/Odevices,andsoon.Theoperatingsystemactsasthemanagerofthese
resources.Facingnumerousandpossiblyc onflictingrequestsforresources,the
operating system must decide how to allocate them to specific programs and
userssothat itcan operatethe computersystemefficientlyand fairly.
A slightly different view of an operating system emphasizes the need to
control the various I/Odevices and user programs. An operating system is a
control program. A control program manages the execution of user programs
topreventerrorsand improperuseof thecomputer.Itis especiallyconcerned
with the operationand control of I/Odevices.
1.1.3 Deﬁning Operating Systems
By now, you can probably see that the term operating system covers many
roles and functions. That is the case, at least in part, because of the myriad
designs and uses of computers. Computers are present within toasters, cars,
ships,spacecraft,homes,andbusinesses.Theyarethebasisforgamemachines,
cableTVtuners,and industrialcontrol systems.
Toexplainthisdiversity,wecanturntothehistoryofcomputers.Although
computershavearelativelyshorthistory,theyhaveevolvedrapidly.Comput-
ing started as an experiment to determine what could be done and quickly
moved to fixed-purpose systems for military uses, such as code breaking and
trajectory plotting, and governmental uses, such as census calculation. Those
earlycomputersevolvedintogeneral-pu rpose,multifunctionmainframes,and
that’swhenoperatingsystemswereborn.Inthe1960s, Moore’s Law predicted
that the number of transistors on an integrated circuit would double every 18
months, and that prediction has held true. Computers gained in functionality
and shrank in size, leading to a vast number of uses and a vast number and
variety of operating systems. (See Appendix Afor more details on the history
ofoperating systems.)
How,then,canwedefinewhatanoperatingsystemis?Ingeneral,wehave
no completelyadequatedefinitionof an operating system.Operatingsystems"
3,1.1.3 Defining Operating Systems,33,1.1.2 System View,"1.1 What Operating Systems Do 5
Increasingly,manyusersinteractwithmobiledevicessuchassmartphones
andtablets—devicesthatarereplacingdesktopandlaptopcomputersystems
for some users. These devices are typically connected to networks through
cellularorotherwirelesstechnologies.T heuserinterfaceformobilecomputers
generallyfeaturesa touch screen , where theuserinteracts with the systemby
pressing and swiping fingers across the screen rather than using a physical
keyboardandmouse.Manymobiledevice salsoallowuserstointeractthrough
avoice recognition interface,such asApple’s Siri.
Somecomputershavelittleornouserview.Forexample, embedded com-
putersinhomedevicesandautomobilesmayhavenumerickeypadsandmay
turnindicatorlightsonorofftoshowstatus,buttheyandtheiroperatingsys-
temsandapplicationsaredesignedprimarilytorunwithoutuserintervention.
1.1.2 System View
From thecomputer’s point of view,the operating systemis the programmost
intimately involved with the hardwar e. In this context, we can view an oper-
ating system as a resource allocator . Acomputer system has many resources
that may be required to solve a problem: CPUtime, memory space, storage
space,I/Odevices,andsoon.Theoperatingsystemactsasthemanagerofthese
resources.Facingnumerousandpossiblyc onflictingrequestsforresources,the
operating system must decide how to allocate them to specific programs and
userssothat itcan operatethe computersystemefficientlyand fairly.
A slightly different view of an operating system emphasizes the need to
control the various I/Odevices and user programs. An operating system is a
control program. A control program manages the execution of user programs
topreventerrorsand improperuseof thecomputer.Itis especiallyconcerned
with the operationand control of I/Odevices.
1.1.3 Deﬁning Operating Systems
By now, you can probably see that the term operating system covers many
roles and functions. That is the case, at least in part, because of the myriad
designs and uses of computers. Computers are present within toasters, cars,
ships,spacecraft,homes,andbusinesses.Theyarethebasisforgamemachines,
cableTVtuners,and industrialcontrol systems.
Toexplainthisdiversity,wecanturntothehistoryofcomputers.Although
computershavearelativelyshorthistory,theyhaveevolvedrapidly.Comput-
ing started as an experiment to determine what could be done and quickly
moved to fixed-purpose systems for military uses, such as code breaking and
trajectory plotting, and governmental uses, such as census calculation. Those
earlycomputersevolvedintogeneral-pu rpose,multifunctionmainframes,and
that’swhenoperatingsystemswereborn.Inthe1960s, Moore’s Law predicted
that the number of transistors on an integrated circuit would double every 18
months, and that prediction has held true. Computers gained in functionality
and shrank in size, leading to a vast number of uses and a vast number and
variety of operating systems. (See Appendix Afor more details on the history
ofoperating systems.)
How,then,canwedefinewhatanoperatingsystemis?Ingeneral,wehave
no completelyadequatedefinitionof an operating system.Operatingsystems"
2,1.2 Computer-System Organization,35,1.1 What Operating Systems Do,"1.2 Computer-System Organization 7
acorekernelalongwithmiddlewarethatsupportsdatabases,multimedia,and
graphics(to name only a few).
In summary, for our purposes, the operating system includes the always-
running kernel, middleware frameworks that ease application development
and provide features, and system programs that aid in managing the system
while it is running. Most of this text is concerned with the kernel of general-
purpose operating systems, but other components are discussed as needed to
fullyexplainoperatingsystemdesignand operation.
1.2 Computer-System Organization
Amoderngeneral-purposecomputersystemconsistsofoneormore CPUsand
anumberofdevicecontrollersconnectedthroughacommon busthatprovides
access between components and shared memory (Figure 1.2). Each device
controller is in charge of a specific type of device (for example, a disk drive,
audiodevice,orgraphicsdisplay).Dependingonthecontroller,morethanone
device may be attached. For instance, one system USBport can connect to a
USBhub, to which several devices can connect. Adevice controller maintains
some local buffer storage and a set of special-purpose registers. The device
controller is responsible for moving the data between the peripheral devices
thatit controls andits localbuffer storage.
Typically, operating systems have a device driver for each device con-
troller. This device driver understand s the device controller and provides the
restoftheoperatingsystemwithauniforminterfacetothedevice.The CPUand
thedevicecontrollerscanexecuteinparallel,competingformemorycycles.To
ensureorderlyaccesstothesharedmemory,amemorycontrollersynchronizes
access tothe memory.
Inthefollowingsubsections,wedescribesomebasicsofhowsuchasystem
operates,focusingonthreekeyaspectsofthesystem.Westartwithinterrupts,
which alert the CPUto events that require attention. We then discuss storage
structureand I/Ostructure.
USB controllerkeyboard printer mouse monitor
disks
graphics
adapterdisk
controller
memoryCPU
system buson-line
Figure 1.2 A typical PC computer system."
3,1.2.1 Interrupts,36,1.2 Computer-System Organization,"8 Chapter 1 Introduction
1.2.1 Interrupts
Consideratypicalcomputeroperation:aprogramperforming I/O.T ostartan
I/Ooperation, the device driver loads the appropriate registers in the device
controller. The device controller, in turn, examines the contents of these reg-
isters to determine what action to take (such as “read a character from the
keyboard ”).Thecontrollerstartsthetransferofdatafromthedevicetoitslocal
buffer. Once the transfer of data is complete, the device controller informs the
device driver that it has finished its operation. The device driver then gives
control tootherpartsoftheoperatingsystem,possiblyreturningthedataora
pointertothedataiftheoperationwasaread.Forotheroperations,thedevice
driver returns status information such as “write completed successfully ”or
“devicebusy ”.Buthowdoesthecontrollerinformthedevicedriverthatithas
finished itsoperation? Thisisaccomplished viaan interrupt .
1.2.1.1 Overview
Hardware may trigger an interrupt at any time by sending a signal to the
CPU, usually by way of the system bus. (There may be many buses within
a computer system, but the system bus is the main communications path
betweenthemajorcomponents.) Interruptsareusedfor manyother purposes
as wellandarea keypartof how operatingsystemsandhardware interact.
When the CPUis interrupted, it stops what it is doing and immediately
transfers execution to a fixed location. The fixed location usually contains
the starting address where the service routine for the interrupt is located.
The interrupt service routine executes; on completion, the CPUresumes the
interrupted computation. Atimeline of this operation is shown in Figure 1.3.
To runthe animation assicatedwith thisfigure pleaseclick here.
Interruptsareanimportantpartofacomputerarchitecture.Eachcomputer
design has its own interrupt mechanism, but several functions are common.
Theinterruptmusttransfercontroltotheappropriateinterruptserviceroutine.
The straightforward method for managing this transfer would be to invoke
a generic routine to examine the interrupt information. The routine, in turn,
Figure 1.3 Interrupt timeline for a single program doing output."
3,1.2.2 Storage Structure,39,1.2.1 Interrupts,"1.2 Computer-System Organization 11
description vector number
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19–31
32–255divide error
debug exception
null interrupt
breakpoint
INTO-detected overflow
bound range exception
invalid opcode
device not available
double fault
coprocessor segment overrun (reserved)
invalid task state segment
segment not present
stack fault
general protection
page fault
(Intel reserved, do not use)
floating-point error
alignment check
machine check
(Intel reserved, do not use)
maskable interrupts
Figure 1.5 Intel processor event-vector table.
rupts without masking all interrupts and makes it possible for a high-priority
interrupttopreemptthe executionof alow-priorityinterrupt.
Insummary,interruptsareusedthroughoutmodernoperatingsystemsto
handleasynchronousevents(andforotherpurposeswewilldiscussthrough-
outthetext).Devicecontrollersandhardwarefaultsraiseinterrupts.Toenable
the most urgent work to be done first, modern computers use a system of
interrupt priorities. Because interrupts are used so heavily for time-sensitive
processing, efficient interrupt handling is required for good system perfor-
mance.
1.2.2 Storage Structure
TheCPUcan load instructions only from memory, so any programs must
first be loaded into memory to run. General-purpose computers run most
of their programs from rewritable memory, called main memory (also called
random-access memory ,orRAM).Mainmemorycommonlyisimplementedin
asemiconductortechnologycalled dynamic random-access memory (DRAM).
Computersuseother forms of memoryas well.For example,the firstpro-
gram to runon computer power-on isa bootstrap program ,w h ic hth enlo a ds
the operating system. Since RAMisvolatile—loses its content when power
is turned off or otherwise lost—we cannot trust it to hold the bootstrap pro-
gram. Instead, for this and some other purposes, the computer uses electri-
callyerasableprogrammableread-onlymemory( EEPROM) and otherformsof
firmwar —storage that is infrequently written to and is nonvolatile. EEPROM"
3,1.2.3 I/O Structure,42,1.2.2 Storage Structure,"14 Chapter 1 Introduction
trade-offbetweensizeandspeed,withsmallerandfastermemoryclosertothe
CPU.Asshowninthefigure,inadditiontodifferinginspeedandcapacity,the
various storage systems are either volatile or nonvolatile. Volatile storage, as
mentionedearlier,losesitscontentswhenthepowertothedeviceisremoved,
so datamustbe writtento nonvolatilestoragefor safekeeping.
The top four levels of memory in the figure are constructed using semi-
conductor memory ,whichconsistsofsemiconductor-basedelectroniccircuits.
NVMdevices,atthefourthlevel,haveseveralvariantsbutingeneralarefaster
thanharddisks.Themostcommonformof NVMdeviceisflashmemory,which
is popular in mobile devices such as sma rtphones and tablets. Increasingly,
flash memory is being used for long-term storage on laptops, desktops, and
serversaswell.
Since storage plays an important role in operating-system structure, we
will refer to it frequently in the text. In general, we will use the following
terminology:
•Volatilestoragewillbereferredtosimplyas memory .Ifweneedtoempha-
sizeaparticulartypeofstoragedevice(forexample,aregister),wewilldo
so explicitly.
•Nonvolatile storage retains its contents when power is lost. It will be
referred to as NVS.T h ev a s tm a j o r i t yo ft h et i m ew es p e n do n NVSwill
be on secondarystorage. This type of storage can be classified into two
distincttypes:
◦Mechanical .Afewexamplesofsuchstoragesystemsare HDDs,optical
disks,holographicstorage,andmagnetictape.Ifweneedtoemphasize
a particular type of mechanical storage device (for example, magnetic
tape),wewill doso explicitly.
◦Electrical . Afew examples of such storage systems are flash memory,
FRAM,NRAM,a n dSSD. Electrical storage will be referred to as NVM.I f
weneedtoemphasizeaparticulartypeofelectricalstoragedevice(for
example, SSD), wewill doso explicitly.
Mechanical storage is generally larger and less expensive per byte than
electricalstorage.Conversely,electri calstorageistypicallycostly,smaller,
and fasterthan mechanical storage.
The design of a complete storage system must balance all the factors just
discussed: it must use only as much expensive memory as necessary while
providing as much inexpensive, nonvolatile storage as possible. Caches can
be installed to improve performance where a large disparity in access time or
transferrateexistsbetweentwo components.
1.2.3 I/O Structure
Alarge portion of operating system code is dedicated to managing I/O,b o t h
because of its importance to the reliability and performance of a system and
because of thevaryingnature ofthe devices.
Recall from the beginning of this section that a general-purpose computer
systemconsists of multipledevices,allof which exchange data viaa common"
2,1.3 Computer-System Architecture,43,1.2 Computer-System Organization,"1.3 Computer-System Architecture 15
thread of executioninstructions
and
datainstruction execution
cycle
data movement
DMA
memory
interruptcache
data
I/O requestCPU (*N)
device
(*M)
Figure 1.7 How a modern computer system works.
bus. The form of interrupt-driven I/Odescribed in Section 1.2.1 is fine for
moving small amounts of data but can produce high overhead when used for
bulk data movement such as NVS I/O. To solve this problem, direct memory
access(DMA) is used. After setting up buffers, pointers, and counters for the
I/Odevice, the device controller transfers an entire block of data directly to
or from the device and main memory, with no intervention by the CPU.O n l y
oneinterruptisgeneratedperblock,totellthedevicedriverthattheoperation
hascompleted,ratherthantheoneinterruptperbytegeneratedforlow-speed
devices.Whilethedevicecontrollerisperformingtheseoperations,the CPUis
availableto accomplish other work.
Some high-end systems use switch rather than bus architecture. On these
systems, multiple components can talk t o other components concurrently,
rather than competing for cycles on a shared bus. In this case, DMAis even
moreeffective.Figure1.7showstheinterplayofallcomponentsofacomputer
system.
1.3 Computer-System Architecture
In Section 1.2, we introduced the general structure of a typical computer sys-
tem. A computer system can be organized in a number of different ways,
which wecan categorizeroughlyaccordingtothenumberofgeneral-purpose
processorsused.
1.3.1 Single-Processor Systems
Many years ago, most computer systems used a single processor containing
oneCPUwith a single processing core. The coreis the component that exe-
cutesinstructionsandregistersforstoringdatalocally.Theonemain CPUwith
its core is capable of executing a general-purpose instruction set, including
instructionsfromprocesses.Thesesystemshaveotherspecial-purposeproces-"
3,1.3.1 Single-Processor Systems,43,1.3 Computer-System Architecture,"1.3 Computer-System Architecture 15
thread of executioninstructions
and
datainstruction execution
cycle
data movement
DMA
memory
interruptcache
data
I/O requestCPU (*N)
device
(*M)
Figure 1.7 How a modern computer system works.
bus. The form of interrupt-driven I/Odescribed in Section 1.2.1 is fine for
moving small amounts of data but can produce high overhead when used for
bulk data movement such as NVS I/O. To solve this problem, direct memory
access(DMA) is used. After setting up buffers, pointers, and counters for the
I/Odevice, the device controller transfers an entire block of data directly to
or from the device and main memory, with no intervention by the CPU.O n l y
oneinterruptisgeneratedperblock,totellthedevicedriverthattheoperation
hascompleted,ratherthantheoneinterruptperbytegeneratedforlow-speed
devices.Whilethedevicecontrollerisperformingtheseoperations,the CPUis
availableto accomplish other work.
Some high-end systems use switch rather than bus architecture. On these
systems, multiple components can talk t o other components concurrently,
rather than competing for cycles on a shared bus. In this case, DMAis even
moreeffective.Figure1.7showstheinterplayofallcomponentsofacomputer
system.
1.3 Computer-System Architecture
In Section 1.2, we introduced the general structure of a typical computer sys-
tem. A computer system can be organized in a number of different ways,
which wecan categorizeroughlyaccordingtothenumberofgeneral-purpose
processorsused.
1.3.1 Single-Processor Systems
Many years ago, most computer systems used a single processor containing
oneCPUwith a single processing core. The coreis the component that exe-
cutesinstructionsandregistersforstoringdatalocally.Theonemain CPUwith
its core is capable of executing a general-purpose instruction set, including
instructionsfromprocesses.Thesesystemshaveotherspecial-purposeproces-"
3,1.3.2 Multiprocessor Systems,44,1.3.1 Single-Processor Systems,"16 Chapter 1 Introduction
sorsas well.Theymay come in the formof device-specificprocessors,such as
disk,keyboard,and graphics controllers.
All of these special-purpose processors run a limited instruction set and
do not run processes. Sometimes, they are managed by the operating system,
inthattheoperatingsystemsendsthemi nformationabouttheirnexttaskand
monitors their status. For example, a di sk-controller microprocessor receives
a sequence of requests from the main CPUcore and implements its own disk
queue and scheduling algorithm. This arrangement relieves the main CPUof
theoverheadofdiskscheduling. PCscontainamicroprocessorinthekeyboard
to convert the keystrokes into codes to be sent to the CPU. In other systems or
circumstances,special-purposeprocessorsarelow-levelcomponentsbuiltinto
the hardware. The operating system cannot communicate with these proces-
sors;theydotheirjobsautonomously.Theuseofspecial-purposemicroproces-
sorsiscommonanddoesnotturnasingle-processorsystemintoamultiproces-
sor.Ifthereisonlyonegeneral-purpose CPUwithasingleprocessingcore,then
thesystemisasingle-processorsystem .Accordingtothisdefinition,however,
veryfewcontemporary computersystemsaresingle-processorsystems.
1.3.2 Multiprocessor Systems
On modern computers, from mobile devices to servers, multiprocessor sys-
temsnow dominate the landscape of computing. Traditionally, such systems
have two (or more) processors, each with a single-core CPU.T h ep r o c e s -
sors share the computer bus and sometimes the clock, memory, and periph-
eral devices. The primary advantage of multiprocessor systems is increased
throughput. That is, by increasing the number of processors, we expect to get
more work done in less time. The speed-up ratio with Nprocessors is not N,
however;itislessthan N.Whenmultipleprocessorscooperateonatask,acer-
tainamountofoverheadisincurredinkeepingallthepartsworkingcorrectly.
This overhead,pluscontention forshar ed resources,lowers the expectedgain
from additionalprocessors.
The most common multiprocessor systems use symmetric multiprocess-
ing(SMP), in which each peer CPUprocessor performs all tasks, including
operating-system functions and user processes. Figure 1.8 illustrates a typical
SMParchitecturewithtwoprocessors,eachwithitsown CPU.No tic eth a tea c h
CPUprocessor has its own set of registers, as well as a private—or local—
cache. However,allprocessorssharephysical memoryoverthesystembus.
The benefit of this model is that many processes can run simultaneously
—Nprocesses can run if there are NCPUs—without causing performance
to deteriorate significantly. However, since the CPUsa r es e p a r a t e ,o n em a y
be sitting idle while another is overloaded, resulting in inefficiencies. These
inefficiencies can be avoided if the processors share certain data structures. A
multiprocessor system of this form will allow processes and resources—such
asmemory—tobeshareddynamicallyamongthevariousprocessorsandcan
lower the workload variance among the processors. Such a system must be
writtencarefully,aswe shallseeinChapter5and Chapter6.
The definition of multiprocessor has evolved over time and now includes
multicore systems,inwhichmultiplecomputingcoresresideonasinglechip.
Multicore systems can be more efficient than multiple chips with single cores
because on-chip communication is faster than between-chip communication."
3,1.3.3 Clustered Systems,47,1.3.2 Multiprocessor Systems,"1.3 Computer-System Architecture 19
CPU0memory0
CPU2CPU3CPU1memory1
memory2memory3interconnect
Figure 1.10 NUMA multiprocessing architecture.
types of computers. In essence, these servers consist of multiple independent
multiprocessorsystems.
1.3.3 Clustered Systems
Another type of multiprocessor system is a clustered system ,w h i c hg a t h -
ers together multiple CPUs. Clustered systems differ from the multiprocessor
systems described in Section 1.3.2 in that they are composed of two or more
individualsystems—ornodes—joinedto gether;eachnodeistypicallyamul-
ticore system. Such systems are considered loosely coupled .W es h o u l dn o t e
that the definition of clustered is not concrete; many commercial and open-
source packages wrestle to define what a clustered system is and why one
form is betterthan another. The generallyaccepted definition is that clustered
computers share storage and are closely linked via a local-area network LAN
(asdescribedin Chapter19) or afasterinterconnect, such asInfiniBand.
Clustering is usually used to provide high-availability service —that is,
service that will continue even if one or more systems in the cluster fail.
Generally, we obtain high availability by adding a level of redundancy in the
system. A layer of cluster software runs on the cluster nodes. Each node can
monitoroneormoreoftheothers(overth enetwork).Ifthemonitoredmachine
fails,themonitoringmachine cantakeownershipofitsstorageandrestartthe
applicationsthatwererunning on the failedmachine. The usersand clientsof
theapplications seeonly a briefinterruptionofservice.
High availability provides increased reliability, which is crucial in many
applications.Theabilitytocontinueprovidingserviceproportionaltothelevel
ofsurvivinghardwareiscalled graceful degradation .Somesystemsgobeyond
graceful degradation and are called fault tolerant , because they can suffer a
failure of any single component and still continue operation. Fault tolerance
requires a mechanism to allow the failure to be detected, diagnosed, and, if
possible,corrected.
Clustering can be structured asymmetrically or symmetrically. In asym-
metric clustering ,onemachineisin hot-standby mode whiletheotherisrun-
ningtheapplications.Thehot-standbyhostmachinedoesnothingbutmonitor
the active server. If that server fails, the hot-standby host becomes the active"
2,1.4 Operating-System Operations,49,1.3 Computer-System Architecture,"1.4 Operating-System Operations 21
computerinterconnectcomputerinterconnectcomputer
storage-area
network
Figure 1.11 General structure of a clustered system.
ating systems lack support for simultaneous data access by multiple hosts,
parallel clusters usually require the use of special versions of software and
special releases of applications. For ex ample, Oracle Real Application Cluster
is a version of Oracle’s database that has been designed to run on a parallel
cluster. Each machine runs Oracle, and a layer of software tracks access to the
shareddisk.Eachmachinehasfullaccesstoalldatainthedatabase.Toprovide
this shared access, the system must also supply access control and locking to
ensure that no conflicting operations occur. This function, commonly known
asa distributed lock manager (DLM), isincludedinsome clustertechnology.
Cluster technology is changing rapidly. Some cluster products support
thousandsofsystemsinacluster,aswellasclusterednodesthatareseparated
by miles. Many of these improvements are made possible by storage-area
networks (SANs), as described in Section 11.7.4, which allow many systems
to attach to a pool of storage. If the applications and their data are stored on
theSAN, then the cluster software can assign the application to run on any
host that is attached to the SAN. If the host fails, then any other host can take
over.Inadatabasecluster,dozensofhostscansharethesamedatabase,greatly
increasingperformanceandreliability.Fi gure1.11depictsthegeneralstructure
ofa clusteredsystem.
1.4 Operating-System Operations
Nowthatwehavediscussedbasicinformationaboutcomputer-systemorgani-
zationandarchitecture,wearereadytotalkaboutoperatingsystems.Anoper-
ating system provides the environment within which programs are executed.
Internally,operatingsystemsvarygreat ly,sincetheyareorganizedalongmany
differentlines.Thereare,however,manycommonalities,whichweconsiderin
thissection.
For a computer to start running—for instance, when it is powered up
or rebooted—it needs to have an initial program to run. As noted earlier,
this initial program, or bootstrap program, tends to be simple. Typically, it is
stored within the computer hardware in firmware. It initializes all aspects of
the system, from CPUregisters to device controllers to memory contents. The
bootstrap program must know how to load the operating system and how to"
3,1.4.1 Multiprogramming and Multitasking,51,1.4 Operating-System Operations,"1.4 Operating-System Operations 23
1.4.1 Multiprogramming and Multitasking
One of the most important aspects of operating systems is the ability to run
multipleprograms,asasingleprogramcannot,ingeneral,keepeitherthe CPU
or theI/Odevices busy at all times. Furthermore, users typically wantto run
more than one program at a time as well. Multiprogramming increases CPU
utilization, as well as keeping users satisfied, by organizing programs so that
theCPUalways has one to execute.In a multiprogrammedsystem,a program
inexecutionistermeda process.
The idea is as follows: The operating system keeps several processes in
memorysimultaneously (Figure1.12). The operating systempicks and begins
toexecuteoneoftheseprocesses.Eventually,theprocessmayhavetowaitfor
some task, such as an I/Ooperation, to complete. In a non-multiprogrammed
system, the CPUwould sit idle. In a multiprogrammed system, the operating
system simply switches to, and ex ecutes, another process. When thatprocess
needs to wait, the CPUswitches to anotherprocess, and so on. Eventually,the
first process finishes waiting and gets the CPUback. As long as at least one
processneedsto execute,the CPUis neveridle.
This idea is common in other life situations. A lawyer does not work for
only one client at a time, for example. While one case is waiting to go to trial
orhavepaperstyped,thelawyercan workon another case.Ifshehasenough
clients, the lawyer will never be idle for lack of work. (Idle lawyers tend to
becomepoliticians,so thereis acertainsocial valueinkeepinglawyersbusy.)
Multitasking isalogicalextensionofmultiprogramming.Inmultitasking
systems, the CPUexecutes multiple processes by switching among them, but
the switches occur frequently, providing the user with a fast response time .
Consider that when a process executes, it typically executes for only a short
time before it either finishes or needs to perform I/O.I/Omay be interactive;
that is, output goes to a display for the user, and input comes from a user
keyboard,mouse,ortouchscreen.Sinceinteractive I/Otypicallyrunsat “peo-
ple speeds, ”it may take a long time to complete. Input, for example, may be
process 1
0max
operating system
process 2
process 3
process 4
Figure 1.12 Memory layout for a multiprogramming system."
3,1.4.2 Dual-Mode and Multimode Operation,52,1.4.1 Multiprogramming and Multitasking,"24 Chapter 1 Introduction
bounded by the user’s typing speed; seven characters per second is fast for
people but incredibly slow for computers. Rather than let the CPUsit idle as
thisinteractiveinput takesplace,theoperatingsystemwillrapidlyswitchthe
CPUto another process.
Havingseveralprocessesinmemoryatthe sametimerequiressomeform
of memory management, which we cover in Chapter 9 and Chapter 10. In
addition,ifseveralprocessesarereadytorunatthesametime,thesystemmust
choose which process will run next. Making this decision is CPU scheduling ,
which is discussed in Chapter 5. Finally, running multiple processes concur-
rentlyrequiresthattheirabilitytoaffectoneanotherbelimitedinallphasesof
theoperatingsystem,includingprocessscheduling,diskstorage,andmemory
management.We discussthese considerationsthroughout the text.
In a multitasking system, the operating system must ensure reasonable
response time. A common method for doing so is virtual memory ,at e c h -
nique that allows the execution of a process that is not completely in memory
(Chapter 10). The main advantage of this scheme is that it enables users to
runprogramsthatarelargerthanactual physical memory .Further,itabstracts
main memory into a large, uniform array of storage, separating logical mem-
oryas viewed by the user from physical memory. This arrangement frees
programmersfromconcern overmemory-storagelimitations.
Multiprogrammingandmultitaskingsystemsmustalsoprovideafilesys-
tem (Chapter 13, Chapter 14, and Chapter 15). The file system resides on a
secondarystorage;hence,storagemana gementmustbeprovided(Chapter11).
In addition, a system must protect resources from inappropriate use (Chapter
17).Toensureorderlyexecution,thesystemmustalsoprovidemechanismsfor
processsynchronizationandcommunication(Chapter6andChapter7),andit
may ensure that processes do not get stuck in a deadlock, forever waiting for
one another (Chapter8).
1.4.2 Dual-Mode and Multimode Operation
Since the operating system and its users share the hardware and software
resourcesofthecomputersystem,aproperlydesignedoperatingsystemmust
ensure that an incorrect (or malicious) program cannot cause other programs
—or the operating system itself—to execute incorrectly. In order to ensure
the proper execution of the system, we must be able to distinguish between
the execution of operating-system code and user-defined code. The approach
taken by most computer systems is to provide hardware support that allows
differentiationamong various modesof execution.
At the very least, we need two separate modesof operation: user mode
and kernel mode (also called supervisor mode ,system mode ,o rprivileged
mode). A bit, called the mode bit , is added to the hardware of the computer
to indicate the current mode: kernel (0) or user (1). With the mode bit, we can
distinguish between a task that is executed on behalf of the operating system
and one that is executed on behalf of the user. When the computer system is
executingonbehalfofauserapplicat ion,thesystemisinusermode.However,
when a user application requests a service from the operating system (via a
system call), the system must transition from user to kernel mode to fulfill"
3,1.4.3 Timer,54,1.4.2 Dual-Mode and Multimode Operation,"26 Chapter 1 Introduction
take advantage of this dual-mode feature and provide greater protection for
theoperating system.
System calls provide the means for a user program to ask the operating
system to perform tasks reserved for the operating system on the user pro-
gram’s behalf. A system call is invoked in a variety of ways, depending on
the functionality provided by the underlying processor. In all forms, it is the
methodusedbyaprocesstorequestactionbytheoperatingsystem.Asystem
callusuallytakestheformofatraptoaspecificlocationintheinterruptvector.
Thistrapcanbeexecutedbyageneric trapinstruction,althoughsomesystems
have a specific syscall instructiontoinvokea systemcall.
When a system call is executed, it is typically treated by the hardware as
a software interrupt. Control passes through the interrupt vector to a service
routine in the operating system, and the mode bit is set to kernel mode. The
system-callserviceroutineisa partof theoperatingsystem.Thekernelexam-
ines the interrupting instruction to determine what system call has occurred;
a parameter indicates what type of service the user program is requesting.
Additional information needed for the request may be passed in registers, on
thestack,or inmemory(withpointerstothememorylocations passedinreg-
isters). The kernel verifies that the parameters are correct and legal, executes
therequest,andreturnscontroltotheinstructionfollowingthesystemcall.We
describesystemcalls morefullyinSection2.3.
Once hardware protection is in place, it detects errors that violate modes.
Theseerrorsarenormally handledby theoperatingsystem.Ifa userprogram
fails in some way—such as by making an attempt either to execute an illegal
instruction or to access memory that is not in the user’s address space—then
thehardwaretrapstotheoperatingsystem.Thetraptransferscontrolthrough
the interrupt vector to the operating system, just as an interrupt does. When
a program error occurs, the operating system must terminate the program
abnormally. This situation is handled by the same code as a user-requested
abnormaltermination.Anappropriateerrormessageisgiven,andthememory
oftheprogrammaybedumped.Thememorydumpisusuallywrittentoafile
sothattheuserorprogrammercanexamineitandperhapscorrectitandrestart
the program.
1.4.3 Timer
We must ensure that the operating system maintains control over the CPU.
We cannot allow a user program to get stuck in an infinite loop or to fail
to call system services and never return control to the operating system. To
accomplish this goal, we can use a timer.At i m e rc a nb es e tt oi n t e r r u p t
the computer after a specified period. The period may be fixed (for example,
1/60 second) or variable (for example, from 1 millisecond to 1 second). A
variable timer is generally implemented by a fixed-rate clock and a counter.
The operating system sets the counter. Every time the clock ticks, the counter
isdecremented.Whenthecounterreaches0,aninterruptoccurs.Forinstance,
a 10-bit counter with a 1-millisecond clock allows interrupts at intervals from
1 millisecondto 1,024 milliseconds,instepsof 1 millisecond.
Before turning over control to the user, the operating system ensures that
the timer is set to interrupt.If the timer interrupts,control transfers automati-
cally to the operating system, which may treat the interrupt as a fatal error or"
2,1.5 Resource Management,55,1.4 Operating-System Operations,"1.5 Resource Management 27
LINUX TIMERS
OnLinuxsystems,thekernel configurationparameter HZspecifiesthefre-
quencyoftimerinterrupts.An HZvalueof250meansthatthetimergenerates
250 interrupts per second, or one inter rupt every 4 milliseconds. The value
ofHZdepends upon how the kernel is configured, as well the machine type
andarchitectureonwhichitisrunning.Arelatedkernelvariableis jiffies ,
which representthe numberof timer interrupts that haveoccurredsince the
system was booted. A programming project in Chapter 2 further explores
timing intheLinux kernel.
maygivetheprogrammoretime.Clearly,instructionsthatmodifythecontent
ofthe timerareprivileged.
1.5 Resource Management
Aswehaveseen,anoperatingsystemisa resource manager .Thesystem’s CPU,
memoryspace,file-storagespace,and I/Odevicesareamongtheresourcesthat
theoperatingsystemmustmanage.
1.5.1 Process Management
A program can do nothing unless its instructions are executed by a CPU.A
programinexecution,asmentioned,isaprocess.Aprogramsuchasacompiler
is a process, and a word-processing program being run by an individual user
on aPCis a process. Similarly, a social media app on a mobile device is a
process.Fornow,youcanconsideraprocesstobeaninstanceofaprogramin
execution,butlateryouwillseethattheconceptismoregeneral.Asdescribed
inChapter3,itispossibletoprovidesystemcallsthatallowprocessestocreate
subprocessestoexecute concurrently.
Aprocessneedscertainresources—including CPUtime,memory,files,and
I/Odevices—to accomplish itstask. Theseresources aretypically allocatedto
the process while it is running. In addition to the various physical and logical
resources that a process obtains when it is created, various initialization data
(input) may be passed along. For example, consider a process running a web
browser whose function is to display the contents of a web page on a screen.
Theprocesswillbegiventhe URLasaninputandwillexecutetheappropriate
instructionsandsystemcallstoobtainan ddisplaythedesiredinformationon
thescreen.Whentheprocessterminates,theoperatingsystemwillreclaimany
reusable resources.
We emphasize that a program by itself is not a process. A program is a
passiveentity,likethecontentsofafilestoredondisk,whereasaprocessisan
activeentity. A single-threaded process has one program counter specifying
the next instruction to execute. (Threads are covered in Chapter 4.) The exe-
cution of such a process must be sequential.The CPUexecutes one instruction
of the process after another, until the process completes. Further, at any time,
one instruction at most is executed on behalf of the process. Thus, although"
3,1.5.1 Process Management,55,1.5 Resource Management,"1.5 Resource Management 27
LINUX TIMERS
OnLinuxsystems,thekernel configurationparameter HZspecifiesthefre-
quencyoftimerinterrupts.An HZvalueof250meansthatthetimergenerates
250 interrupts per second, or one inter rupt every 4 milliseconds. The value
ofHZdepends upon how the kernel is configured, as well the machine type
andarchitectureonwhichitisrunning.Arelatedkernelvariableis jiffies ,
which representthe numberof timer interrupts that haveoccurredsince the
system was booted. A programming project in Chapter 2 further explores
timing intheLinux kernel.
maygivetheprogrammoretime.Clearly,instructionsthatmodifythecontent
ofthe timerareprivileged.
1.5 Resource Management
Aswehaveseen,anoperatingsystemisa resource manager .Thesystem’s CPU,
memoryspace,file-storagespace,and I/Odevicesareamongtheresourcesthat
theoperatingsystemmustmanage.
1.5.1 Process Management
A program can do nothing unless its instructions are executed by a CPU.A
programinexecution,asmentioned,isaprocess.Aprogramsuchasacompiler
is a process, and a word-processing program being run by an individual user
on aPCis a process. Similarly, a social media app on a mobile device is a
process.Fornow,youcanconsideraprocesstobeaninstanceofaprogramin
execution,butlateryouwillseethattheconceptismoregeneral.Asdescribed
inChapter3,itispossibletoprovidesystemcallsthatallowprocessestocreate
subprocessestoexecute concurrently.
Aprocessneedscertainresources—including CPUtime,memory,files,and
I/Odevices—to accomplish itstask. Theseresources aretypically allocatedto
the process while it is running. In addition to the various physical and logical
resources that a process obtains when it is created, various initialization data
(input) may be passed along. For example, consider a process running a web
browser whose function is to display the contents of a web page on a screen.
Theprocesswillbegiventhe URLasaninputandwillexecutetheappropriate
instructionsandsystemcallstoobtainan ddisplaythedesiredinformationon
thescreen.Whentheprocessterminates,theoperatingsystemwillreclaimany
reusable resources.
We emphasize that a program by itself is not a process. A program is a
passiveentity,likethecontentsofafilestoredondisk,whereasaprocessisan
activeentity. A single-threaded process has one program counter specifying
the next instruction to execute. (Threads are covered in Chapter 4.) The exe-
cution of such a process must be sequential.The CPUexecutes one instruction
of the process after another, until the process completes. Further, at any time,
one instruction at most is executed on behalf of the process. Thus, although"
3,1.5.2 Memory Management,56,1.5.1 Process Management,"28 Chapter 1 Introduction
twoprocessesmaybeassociatedwiththesameprogram,theyarenevertheless
considered two separate execution sequences. A multithreaded process has
multiple program counters, each pointing to the next instruction to execute
for a giventhread.
A process is the unit of work in a system. A system consists of a collec-
tion of processes, some of which are operating-system processes (those that
execute system code) and the rest of which are user processes (those that exe-
cute user code). All these processes can potentially execute concurrently—by
multiplexingona single CPUcore—or in parallelacross multiple CPUcores.
The operating system is responsible for the following activities in connec-
tionwithprocessmanagement:
•Creatingand deletingboth userandsystemprocesses
•Schedulingprocessesand threadson the CPUs
•Suspendingand resumingprocesses
•Providingmechanisms forprocesssynchronization
•Providingmechanisms forprocesscommunication
We discuss process-managementtechniquesin Chapter3through Chapter7.
1.5.2 Memory Management
AsdiscussedinSection1.2.2,themainmemoryiscentraltotheoperationofa
modern computer system. Main memory is a large array of bytes, ranging in
size from hundreds of thousands to billions. Each byte has its own address.
Main memory is a repository of quickly accessible data shared by the CPU
andI/Odevices. The CPUreads instructions from main memory during the
instruction-fetch cycle and both reads and writes data from main memory
duringthedata-fetchcycle(onavonNeumannarchitecture).Asnotedearlier,
themainmemoryisgenerallytheonlylargestoragedevicethatthe CPUisable
to address and access directly. For example, for the CPUto process data from
disk, those data must first be transferred to main memory by CPU-generated
I/Ocalls. In the same way, instructions must be in memory for the CPUto
executethem.
Foraprogramtobeexecuted,itmustbemappedtoabsoluteaddressesand
loadedintomemory.Astheprogramexecutes,itaccessesprograminstructions
and data from memory by generating these absolute addresses. Eventually,
the program terminates, its memory space is declared available, and the next
programcan beloadedandexecuted.
Toimproveboththeutilizationofthe CPUandthespeedofthecomputer’s
responsetoitsusers,general-purposecomputersmustkeepseveralprograms
inmemory,creatinganeedformemorymanagement.Manydifferentmemory-
managementschemesareused.Theseschemesreflectvariousapproaches,and
theeffectivenessofanygivenalgorithmdependsonthesituation.Inselectinga
memory-managementschemeforaspecificsystem,wemusttakeintoaccount
many factors—especially the hardware design of the system. Each algorithm
requires its own hardware support."
3,1.5.3 File-System Management,57,1.5.2 Memory Management,"1.5 Resource Management 29
The operating system is responsible for the following activities in connec-
tionwithmemorymanagement:
•Keeping track of which parts of memory are currently being used and
which process isusing them
•Allocating and deallocatingmemoryspaceas needed
•Deciding which processes (or parts of processes) and data to move into
and out of memory
Memory-managementtechniquesarediscussedinChapter9and Chapter10.
1.5.3 File-System Management
To make the computer system convenient for users, the operating system
providesauniform,logicalviewofinformationstorage.Theoperatingsystem
abstracts from the physical properties of its storage devices to define a logical
storageunit,the fil.Theoperatingsystemmapsfilesontophysicalmediaand
accessesthesefilesviathestoragedevices.
File management is one of the most visible components of an operating
system. Computers can store information on several different types of physi-
cal media. Secondary storage is the most common, but tertiary storage is also
possible. Each of these media has its own characteristics and physical orga-
nization. Most are controlled by a device, such as a disk drive, that also has
itsownuniquecharacteristics.Thesepro pertiesincludeaccessspeed,capacity,
data-transferrate,and access method(sequentialor random).
A file is a collection of related information defined by its creator. Com-
monly,filesrepresentprograms(bothsourceandobjectforms)anddata.Data
files may be numeric, alphabetic, alphanumeric, or binary. Files may be free-
form (for example, text files), or they may be formatted rigidly (for example,
fixed fields such as an mp3 music file). Clearly, the concept of a file is an
extremelygeneralone.
The operatingsystem implementsthe abstract concept of a file by manag-
ingmassstoragemediaandthedevicesthatcontrolthem.Inaddition,filesare
normally organized into directories to make them easier to use. Finally, when
multiple users have access to files, it may be desirable to control which user
may access a file and how that user may access it (for example, read, write,
append).
The operating system is responsible for the following activities in connec-
tionwith file management:
•Creatingand deletingfiles
•Creatingand deletingdirectoriesto organizefiles
•Supportingprimitivesfor manipulating filesand directories
•Mapping filesonto mass storage
•Backing up filesonstable(nonvolatile) storagemedia"
3,1.5.4 Mass-Storage Management,58,1.5.3 File-System Management,"30 Chapter 1 Introduction
File-management techniques are discussed in Chapter 13, Chapter 14, and
Chapter15.
1.5.4 Mass-Storage Management
Aswehavealreadyseen,thecomputersystemmustprovidesecondarystorage
tobackupmainmemory.Mostmoderncomputersystemsuse HDDsandNVM
devices as the principal on-line storage media for both programs and data.
Most programs—including compilers, web browsers, word processors, and
games—are stored on these devices until loaded into memory. The programs
thenusethedevicesasboththesourceandthedestinationoftheirprocessing.
Hence, the proper management of secondary storage is of central importance
to a computer system. The operating system is responsible for the following
activitiesinconnection withsecondary storagemanagement:
•Mounting and unmounting
•Free-spacemanagement
•Storageallocation
•Diskscheduling
•Partitioning
•Protection
Becausesecondarystorageisusedfrequentlyand extensively,itmustbe used
efficiently.Theentirespeedofoperationofacomputermayhingeonthespeeds
of the secondary storage subsystem and t he algorithms that manipulate that
subsystem.
Atthesametime,therearemanyusesforstoragethatisslowerandlower
in cost (and sometimes higher in capac ity) than secondary storage. Backups
of disk data, storage of seldom-used data, and long-term archival storage are
someexamples.Magnetictapedrivesandtheirtapesand CD DVD andBlu-ray
drivesandplattersaretypicaltertiarystoragedevices.
Tertiary storage is not crucial to system performance, but it still must
be managed. Some operating systems take on this task, while others leave
tertiary-storage management to application programs. Some of the functions
thatoperatingsystemscanprovideincludemountingandunmountingmedia
in devices, allocating and freeing the devices for exclusive use by processes,
and migratingdatafrom secondaryto tertiarystorage.
Techniques for secondary storage and tertiary storage management are
discussedinChapter11.
1.5.5 Cache Management
Caching is an important principle of computer systems. Here’s how it works.
Information is normally kept in some storage system (such as main memory).
As it is used, it is copied into a faster storage system—the cache—on a tem-
porary basis. When we need a particular piece of information, we first check
whetheritisinthecache.Ifitis,weusetheinformationdirectlyfromthecache."
3,1.5.5 Cache Management,58,1.5.4 Mass-Storage Management,"30 Chapter 1 Introduction
File-management techniques are discussed in Chapter 13, Chapter 14, and
Chapter15.
1.5.4 Mass-Storage Management
Aswehavealreadyseen,thecomputersystemmustprovidesecondarystorage
tobackupmainmemory.Mostmoderncomputersystemsuse HDDsandNVM
devices as the principal on-line storage media for both programs and data.
Most programs—including compilers, web browsers, word processors, and
games—are stored on these devices until loaded into memory. The programs
thenusethedevicesasboththesourceandthedestinationoftheirprocessing.
Hence, the proper management of secondary storage is of central importance
to a computer system. The operating system is responsible for the following
activitiesinconnection withsecondary storagemanagement:
•Mounting and unmounting
•Free-spacemanagement
•Storageallocation
•Diskscheduling
•Partitioning
•Protection
Becausesecondarystorageisusedfrequentlyand extensively,itmustbe used
efficiently.Theentirespeedofoperationofacomputermayhingeonthespeeds
of the secondary storage subsystem and t he algorithms that manipulate that
subsystem.
Atthesametime,therearemanyusesforstoragethatisslowerandlower
in cost (and sometimes higher in capac ity) than secondary storage. Backups
of disk data, storage of seldom-used data, and long-term archival storage are
someexamples.Magnetictapedrivesandtheirtapesand CD DVD andBlu-ray
drivesandplattersaretypicaltertiarystoragedevices.
Tertiary storage is not crucial to system performance, but it still must
be managed. Some operating systems take on this task, while others leave
tertiary-storage management to application programs. Some of the functions
thatoperatingsystemscanprovideincludemountingandunmountingmedia
in devices, allocating and freeing the devices for exclusive use by processes,
and migratingdatafrom secondaryto tertiarystorage.
Techniques for secondary storage and tertiary storage management are
discussedinChapter11.
1.5.5 Cache Management
Caching is an important principle of computer systems. Here’s how it works.
Information is normally kept in some storage system (such as main memory).
As it is used, it is copied into a faster storage system—the cache—on a tem-
porary basis. When we need a particular piece of information, we first check
whetheritisinthecache.Ifitis,weusetheinformationdirectlyfromthecache."
3,1.5.6 I/O System Management,60,1.5.5 Cache Management,"32 Chapter 1 Introduction
A A Amagnetic
diskmain
memoryhardware
registercache
Figure 1.15 Migration of integer A from disk to register.
becomes the same only after the new value of A is written from the internal
registerback to thehard disk.
In a computing environment where only one process executes at a time,
thisarrangementposesno difficulties,sinceanaccesstointegerAwillalways
betothecopyatthehighestlevelofthehierarchy.However,inamultitasking
environment, where the CPUis switched back and forth among various pro-
cesses, extreme care must be taken to ensure that, if several processes wish to
access A, then each of these processes will obtain the most recently updated
valueof A.
Thesituationbecomesmorecomplicatedinamultiprocessorenvironment
where, in addition to maintaining internal registers, each of the CPUsa l s o
containsalocalcache(referbacktoFigure1.8).Insuchanenvironment,acopy
of A may exist simultaneously in several caches. Since the various CPUsc a n
all execute in parallel, we must make sure that an update to the value of A
in one cache is immediatelyreflectedin all other caches where Aresides.This
situationiscalled cache coherency ,anditisusuallyahardwareissue(handled
belowtheoperating-systemlevel).
In a distributed environment, the situation becomes even more complex.
Inthisenvironment,severalcopies(orreplicas)ofthesamefilecanbekepton
different computers. Since the various replicas may be accessed and updated
concurrently,somedistributedsystemsensurethat,whenareplicaisupdated
inoneplace,allotherreplicasarebroughtuptodateassoonaspossible.There
arevariousways to achievethisguarantee,as wediscussinChapter19.
1.5.6 I/O System Management
One of the purposes of an operating system is to hide the peculiarities of
specifichardwaredevicesfromtheuser.Forexample,in UNIX,thepeculiarities
ofI/Odevices are hidden from the bulk of the operating system itself by the
I/Osubsystem .Th eI/Osubsystemconsists ofseveralcomponents:
•Amemory-managementcomponentthatincludesbuffering, caching, and
spooling
•Ageneraldevice-driverinterface
•Driversforspecifichardware devices
Only the device driver knows the peculiarities of the specific device to which
itisassigned.
We discussed earlier in this chapter how interrupt handlers and device
driversareusedintheconstructionofefficient I/Osubsystems.InChapter12,
wediscusshowthe I/Osubsysteminterfacestoth eothersystemcomponents,
manages devices,transfersdata,and detects I/Ocompletion."
2,1.6 Security and Protection,61,1.5 Resource Management,"1.6 Security and Protection 33
1.6 Security and Protection
If a computer system has multiple users and allows the concurrent execution
ofmultipleprocesses,thenaccesstodatamustberegulated.Forthatpurpose,
mechanismsensurethatfiles,memorysegments, CPU,andotherresourcescan
be operated on by only those processe s that have gained proper authoriza-
tion from the operating system. For example, memory-addressing hardware
ensures that a process can execute only within its own address space. The
timer ensures that no process can gain control of the CPUwithout eventually
relinquishingcontrol.Device-controlregistersarenotaccessibletousers,sothe
integrityof thevariousperipheraldevicesisprotected.
Protection , then, is any mechanism for controlling the access of processes
oruserstotheresourcesdefinedbyacomputersystem.Thismechanismmust
providemeanstospecifythecontrolstobeimposedandtoenforcethecontrols.
Protectioncanimprovereliabilitybydetectinglatenterrorsattheinterfaces
between component subsystems. Early det ection of interface errors can often
prevent contamination of a healthy subsystem by another subsystem that is
malfunctioning. Furthermore, an unprotected resource cannot defend against
use(ormisuse)byanunauthorizedorincompetentuser.Aprotection-oriented
systemprovidesameanstodistinguishb etweenauthorizedandunauthorized
usage,as we discussin Chapter17.
A system can have adequate protection but still be prone to failure and
allowinappropriateaccess.Considerauserwhoseauthenticationinformation
(her means of identifying herself to the system) is stolen. Her data could be
copied or deleted, even though file and memory protection are working. It is
thejobof security todefendasystemfromexternalandinternalattacks.Such
attacks spread across a huge range and include virusesand worms, denial-of-
service attacks (which use all of a system’s resources and so keep legitimate
users out of the system), identity theft, and theft of service (unauthorized use
of a system). Prevention of some of these attacks is considered an operating-
system function on some systems, while other systems leave it to policy or
additional software. Due to the alarming r ise in security incidents, operating-
system security features are a fast-growing area of research and implementa-
tion.Wediscuss securityinChapter16.
Protectionandsecurityrequirethesystemtobeabletodistinguishamong
all its users. Most operating systems maintain a list of user names and asso-
ciated user identifier (user IDs). In Windows parlance, this is a security ID
(SID). These numerical IDs are unique, one per user. When a user logs in to
thesystem,theauthenticationstagedeterminestheappropriateuser IDforthe
user. That user IDis associated with all of the user’s processes and threads.
When an IDneeds to be readable by a user, it is translated back to the user
name viathe username list.
In some circumstances, we wish to distinguish among sets of users rather
thanindividualusers.Forexample,theownerofafileona UNIXsystemmaybe
allowedtoissuealloperationsonthatfile,whereasaselectedsetofusersmay
beallowedonlytoreadthe file.Toaccomplishthis,we needtodefineagroup
name and the set of users belonging to that group. Group functionality can
be implemented as a system-wide list of group names and group identifier .
Auser can be in one or more groups, depending on operating-system design"
2,1.7 Virtualization,62,1.6 Security and Protection,"34 Chapter 1 Introduction
decisions. The user’s group IDs are also included in every associated process
and thread.
In the course of normal system use, the user IDand group IDfor a user
are sufficient. However,a user sometimesneedsto escalate privileges to gain
extra permissions for an activity. The user may need access to a device that is
restricted, for example. Operating systems provide various methods to allow
privilege escalation. On UNIX,f o ri n s t a n c e ,t h e setuidattribute on a program
causesthatprogramtorunwiththeuser IDoftheownerofthefile,ratherthan
thecurrentuser’s ID.Theprocessrunswiththis effective UIDuntilitturnsoff
theextraprivilegesor terminates.
1.7 Virtualization
Virtualization isatechnologythatallowsustoabstractthehardwareofasin-
gle computer (the CPU, memory, disk drives, network interface cards, and so
forth) into several different execution environments, thereby creating the illu-
sion that each separate environment is running on its own private computer.
These environments can be viewed as different individual operating systems
(for example, Windows and UNIX) that may be running at the same time and
may interact with each other. A user of a virtual machine can switch among
the various operating systems in the same way a user can switch among the
variousprocessesrunning concurrently in a singleoperatingsystem.
Virtualizationallowsoperatingsystemstorunasapplicationswithinother
operating systems.At first blush, there seemsto be littlereason for such func-
tionality. But the virtualization industry is vast and growing, which is a testa-
mentto itsutilityandimportance.
Broadlyspeaking,virtualizationsoftwareisonememberofaclassthatalso
includes emulation. Emulation , which involves simulating computer hard-
ware in software, is typically usedwhen the source CPUtype is differentfrom
the target CPUtype. For example, when Apple switched from the IBMPower
CPUto the Intel x86 CPUfor its desktop and laptop computers, it included an
emulation facility called “Rosetta, ”which allowed applications compiled for
theIBMCPU torunontheIntel CPU.Thatsameconceptcanbeextendedtoallow
anentireoperatingsystemwrittenforoneplatformtorunonanother.Emula-
tioncomesataheavyprice,however.Everymachine-levelinstructionthatruns
natively on the source system must be translated to the equivalent function
on the target system, frequently resulting in several target instructions. If the
source and target CPUs have similar performance levels, the emulated code
may runmuch moreslowlythan thenativecode.
With virtualization, in contrast, an operating system that is natively com-
piled for a particular CPUarchitecture runs within another operating system
also native to that CPU. Virtualization first came about on IBMmainframes as
a method for multiple users to run tasks concurrently. Running multiple vir-
tual machines allowed (and still allows) many users to run tasks on a system
designedforasingleuser.Later,inresponsetoproblemswithrunningmultiple
Microsoft Windows applications on the Intel x86 CPU,VMware created a new
virtualization technology in the form of an application that ran on Windows.
That application ran one or more guestcopies of Windows or other native
x86 operating systems, each running its own applications. (See Figure 1.16.)"
2,1.8 Distributed Systems,63,1.7 Virtualization,"1.8 Distributed Systems 35
(a)processes
hardwarekernel
(b)programming
interfaceprocesses
processesprocesses
kernel kernel kernel
VM2 VM1 VM3
manager
hardwarevirtual machine
Figure 1.16 A computer running (a) a single operating system and (b) three virtual
machines.
Windows was the hostoperatingsystem,andthe VMwareapplicationwasthe
virtual machine manager (VMM).TheVMMrunstheguestoperatingsystems,
managestheirresourceuse,and protectseach guestfrom theothers.
Eventhoughmodernoperatingsystemsarefullycapableofrunningmulti-
pleapplicationsreliably,theuseofvirtualizationcontinuestogrow.Onlaptops
and desktops,a VMMallows the user to install multipleoperating systemsfor
explorationortorunapplicationswrittenforoperatingsystemsotherthanthe
native host. For example,an Apple laptop running mac OSon the x86 CPUcan
run a Windows 10 guest to allow execution of Windows applications. Com-
panies writing software for multiple operating systems can use virtualization
to run all of those operating systems on a single physical server for develop-
ment,testing,anddebugging.Withindatacenters,virtualizationhasbecomea
commonmethodofexecutingandmanagingcomputingenvironments. VMMs
likeVMwareESXandCitrixXenServernolongerrunonhostoperatingsystems
but rather arethe host operating systems, providing services and resource
managementto virtualmachine processes.
With this text, we provide a Linux virtual machine that allows you to
run Linux—as well as the development tools we provide—on your personal
system regardless of your host operating system. Full details of the features
andimplementationof virtualizationcan be found inChapter18.
1.8 Distributed Systems
Adistributed system is a collection of physically separate, possibly heteroge-
neous computer systems that are networked to provide users with access to
the various resources that the system maintains. Access to a shared resource
increases computation speed, functiona lity, data availability, and reliability.
Someoperatingsystemsgeneralizenetworkaccessasaformoffileaccess,with
the details of networking contained in the network interface’s device driver."
2,1.9 Kernel Data Structures,64,1.8 Distributed Systems,"36 Chapter 1 Introduction
Others make users specifically invoke network functions. Generally, systems
contain a mix of the two modes—for example FTPandNFS. The protocols
that create a distributed system can greatly affect that system’s utility and
popularity.
Anetwork ,inthesimplestterms,isacommunicationpathbetweentwoor
moresystems.Distributedsystemsdependonnetworkingfortheirfunctional-
ity.Networksvarybytheprotocolsused,thedistancesbetweennodes,andthe
transportmedia. TCP/IPisthemostcommonnetworkprotocol,anditprovides
the fundamental architecture of the Int ernet. Most operating systems support
TCP/IP,includingallgeneral-purposeones.Somesystemssupportproprietary
protocols tosuittheirneeds.Foranoperatingsystem,itisnecessaryonly that
anetworkprotocolhaveaninterfacedevice—anetworkadapter,forexample
—with a devicedriverto manage it, as well as software to handle data.These
concepts are discussedthroughout thisbook.
Networks are characterized based on the distances between their nodes.
Alocal-area network (LAN) connects computers within a room, a building,
or a campus. A wide-area network (WAN) usually links buildings, cities, or
countries.Aglobalcompanymayhavea WANtoconnectitsofficesworldwide,
for example. These networks may run one protocol or several protocols. The
continuing advent of new technologies brings about new forms of networks.
Forexample,a metropolitan-area network (MAN)couldlinkbuildingswithin
a city. BlueTooth and 802.11 devices use wireless technology to communicate
over a distance of several feet, in essence creating a personal-area network
(PAN)betweenaphoneandaheadsetorasmartphoneandadesktopcomputer.
Themediatocarrynetworksareequallyvaried.Theyincludecopperwires,
fiberstrands,andwirelesstransmission sbetweensatellites,microwavedishes,
and radios. When computing devices are connected to cellular phones, they
create a network. Even very short-range infrared communication can be used
for networking. At a rudimentary level, whenever computers communicate,
they use or create a network. These networks also vary in their performance
and reliability.
Some operating systems have taken the concept of networks and dis-
tributed systems further than the notion of providing network connectivity.
Anetwork operating system is an operating system that provides features
such as file sharing across the network, along with a communication scheme
that allows different processes on different computers to exchange messages.
Acomputer running a network operating system acts autonomously from all
other computers on the network, although it is aware of the network and is
able to communicate with other networked computers. Adistributed operat-
ingsystemprovidesalessautonomousenvironment.Thedifferentcomputers
communicate closely enough to providethe illusion that only a single operat-
ingsystemcontrolsthenetwork.Weco vercomputernetworksanddistributed
systemsinChapter19.
1.9 Kernel Data Structures
We turn next to a topic central to operating-system implementation: the way
data are structured in the system. In this section, we briefly describe several
fundamental data structures used extensively in operating systems. Readers"
3,"1.9.1 Lists, Stacks, and Queues",65,1.9 Kernel Data Structures,"1.9 Kernel Data Structures 37
data data data null
 
Figure 1.17 Singly linked list.
whorequirefurtherdetailsonthesestructures,aswellasothers,shouldconsult
the bibliography at the end of the chapter.
1.9.1 Lists, Stacks, and Queues
An array is a simple data structure in which each element can be accessed
directly.Forexample,mainmemoryisconstructedasanarray.Ifthedataitem
beingstoredislargerthanonebyte,thenmultiplebytescanbeallocatedtothe
item,and the item is addressedas “item number ×item size. ”B u tw h a ta b o u t
storinganitemwhosesizemayvary?Andwhataboutremovinganitemifthe
relativepositionsoftheremainingitemsmustbepreserved?Insuchsituations,
arraysgiveway to other datastructures.
Afterarrays,listsareperhapsthemostfundamentaldatastructuresincom-
puterscience.Whereaseachiteminanarraycanbeaccesseddirectly,theitems
inalistmustbeaccessedinaparticularorder.Thatis,a listrepresentsacollec-
tionofdatavaluesasasequence.Themostcommonmethodforimplementing
thisstructureisa linked list , inwhich itemsarelinkedtoone another.Linked
listsareof severaltypes:
•In asingly linked list, each item points to its successor, as illustrated in
Figure1.17.
•Inadoubly linked list, agivenitemcanrefereithertoitspredecessororto
itssuccessor, as illustratedinFigure1.18.
•In a circularly linked list, the last element in the list refers to the first
element,ratherthan to null,asillustratedinFigure1.19.
Linked lists accommodate items of varying sizes and allow easy insertion
and deletion of items. One potential disadvantage of using a list is that per-
formance for retrieving a specified item in a list of size nis linear— O(n), as it
requirespotentiallytraversingall nelementsintheworstcase.Listsaresome-
timesuseddirectlybykernelalgorithms.Frequently,though,theyareusedfor
constructing more powerfuldata structures,such as stacks and queues.
Astackis a sequentially ordered data structure that uses the last in, first
out( LIFO)principleforaddingandremovingitems,meaningthatthelastitem
data null null data data data
 
Figure 1.18 Doubly linked list."
3,1.9.2 Trees,66,"1.9.1 Lists, Stacks, and Queues","38 Chapter 1 Introduction
data data data data
 
Figure 1.19 Circularly linked list.
placed onto a stack is the first itemremoved.The operations for inserting and
removing items from a stack are known as pushandpop, respectively. An
operatingsystemoftenusesastackwheninvokingfunctioncalls.Parameters,
local variables, and the return address are pushed onto the stack when a
function is called; returning from the function call pops those items off the
stack.
Aqueue,incontrast, is a sequentiallyordereddata structure that uses the
first in, first out ( FIFO) principle:items areremovedfrom a queuein the order
in which they were inserted. There are many everyday examples of queues,
includingshopperswaitinginacheckout lineatastoreandcarswaitinginline
at a traffic signal. Queues are also quite common in operating systems—jobs
that are sent to a printer are typically printed in the order in which they were
submitted,for example.Aswe shallseeinChapter5, tasksthat arewaiting to
be runon an available CPUareoftenorganizedinqueues.
1.9.2 Trees
Atreeisadatastructurethatcanbeusedtorepresentdatahierarchically.Data
values in a tree structure are linked through parent–child relationships. In a
general tree , a parent may have an unlimitednumber of children. In a binary
tree, a parent may have at most two children, which we term the left child
and the right child .Abinary search tree additionally requires an ordering
betweentheparent’stwochildreninwhich left
child<=right
 child.Figure1.20
provides an example of a binary search tree. When we search for an item in a
binary search tree, the worst-case performance is O(n) (consider how this can
occur).Toremedythissituation,wecanusean algorithmtocreatea balanced
binary search tree .Here,atreecontaining nitemshasatmost lg nlevels,thus
ensuring worst-case performance of O(lg n). We shall see in Section 5.7.1 that
Linux uses a balanced binary search tree (known as a red-black tree )a sp a r t
itsCPU-scheduling algorithm.
1.9.3 Hash Functions and Maps
Ahash function takes data as its input, performs a numeric operation on the
data, and returns a numeric value. This numeric value can then be used as
an index into a table (typically an array) to quickly retrievethe data. Whereas
searchingforadataitemthroughalistofsize ncanrequireupto O(n)compar-
isons, using a hash function for retrieving data from a table can be as good as
O(1),dependingonimplementationdetails.Becauseofthisperformance,hash
functions areusedextensivelyinoperatingsystems.
One potential difficulty with hash functions is that two unique inputs
can result in the same output value—that is, they can link to the same table"
3,1.9.3 Hash Functions and Maps,66,1.9.2 Trees,"38 Chapter 1 Introduction
data data data data
 
Figure 1.19 Circularly linked list.
placed onto a stack is the first itemremoved.The operations for inserting and
removing items from a stack are known as pushandpop, respectively. An
operatingsystemoftenusesastackwheninvokingfunctioncalls.Parameters,
local variables, and the return address are pushed onto the stack when a
function is called; returning from the function call pops those items off the
stack.
Aqueue,incontrast, is a sequentiallyordereddata structure that uses the
first in, first out ( FIFO) principle:items areremovedfrom a queuein the order
in which they were inserted. There are many everyday examples of queues,
includingshopperswaitinginacheckout lineatastoreandcarswaitinginline
at a traffic signal. Queues are also quite common in operating systems—jobs
that are sent to a printer are typically printed in the order in which they were
submitted,for example.Aswe shallseeinChapter5, tasksthat arewaiting to
be runon an available CPUareoftenorganizedinqueues.
1.9.2 Trees
Atreeisadatastructurethatcanbeusedtorepresentdatahierarchically.Data
values in a tree structure are linked through parent–child relationships. In a
general tree , a parent may have an unlimitednumber of children. In a binary
tree, a parent may have at most two children, which we term the left child
and the right child .Abinary search tree additionally requires an ordering
betweentheparent’stwochildreninwhich left
child<=right
 child.Figure1.20
provides an example of a binary search tree. When we search for an item in a
binary search tree, the worst-case performance is O(n) (consider how this can
occur).Toremedythissituation,wecanusean algorithmtocreatea balanced
binary search tree .Here,atreecontaining nitemshasatmost lg nlevels,thus
ensuring worst-case performance of O(lg n). We shall see in Section 5.7.1 that
Linux uses a balanced binary search tree (known as a red-black tree )a sp a r t
itsCPU-scheduling algorithm.
1.9.3 Hash Functions and Maps
Ahash function takes data as its input, performs a numeric operation on the
data, and returns a numeric value. This numeric value can then be used as
an index into a table (typically an array) to quickly retrievethe data. Whereas
searchingforadataitemthroughalistofsize ncanrequireupto O(n)compar-
isons, using a hash function for retrieving data from a table can be as good as
O(1),dependingonimplementationdetails.Becauseofthisperformance,hash
functions areusedextensivelyinoperatingsystems.
One potential difficulty with hash functions is that two unique inputs
can result in the same output value—that is, they can link to the same table"
3,1.9.4 Bitmaps,67,1.9.3 Hash Functions and Maps,"1.9 Kernel Data Structures 39
17
35
40
3812
14 6
Figure 1.20 Binary search tree.
location.Wecanaccommodatethis hash collision byhavingalinkedlistatthe
tablelocationthatcontainsalloftheitemswiththesamehashvalue.Ofcourse,
the more collisions thereare,the lessefficientthe hash function is.
O n eu s eo fah a s hf u n c t i o ni st oi m p l e m e n ta hash map , which associates
(ormaps) [key:value]pairs using a hash function. Once the mapping is estab-
lished, we can apply the hash function to the key to obtain the value from the
hash map (Figure 1.21). For example, suppose that a user name is mapped to
a password. Password authentication then proceeds as follows: a user enters
her user name and password. The hash function is applied to the user name,
which is then used to retrieve the password. The retrieved password is then
comparedwith the passwordenteredby theuserfor authentication.
1.9.4 Bitmaps
Abitmapisastringof nbinarydigitsthatcanbeusedtorepresentthestatusof
nitems. For example, suppose we have several resources, and the availability
of each resource is indicated by the value of a binary digit: 0 means that the
resourceisavailable,while1indicatesth atitisunavailable(orviceversa).The
01 .. n
valuehash maphash_function(key)
Figure 1.21 Hash map."
2,1.10 Computing Environments,68,1.9 Kernel Data Structures,"40 Chapter 1 Introduction
LINUX KERNEL DATA STRUCTURES
ThedatastructuresusedintheLinuxkernelareavailableinthekernelsource
code. The includefile<linux/list.h >provides details of the linked-list
data structure used throughout the kernel. Aqueue in Linux is known as a
kfifo,anditsimplementationcanbefoundinthe kfifo.c fileinthe kernel
directoryofthesourcecode.Linuxalsoprovidesabalancedbinarysearchtree
implementationusing red-black trees .Detailscanbefoundintheincludefile
<linux/rbtree.h >.
valueof the ithpositionin the bitmap is associatedwith the ithresource. As an
example,considerthebitmap shown below:
001011101
Resources2,4,5,6,and8areunavailable;resources0,1,3,and7areavailable.
The power of bitmaps becomes apparent when we consider their space
efficiency. If we were to use an eight-bit Boolean value instead of a single bit,
the resulting data structure would be eight times larger. Thus, bitmaps are
commonly used when there is a need to represent the availability of a large
number of resources. Disk drives provide a nice illustration. Amedium-sized
diskdrivemightbedividedintoseveralthousandindividualunits,called disk
blocks.Abitmapcan beusedto indicatetheavailabilityofeach diskblock.
Insummary,datastructuresarepervasiveinoperatingsystemimplemen-
tations. Thus, we will see the structures discussed here, along with others,
throughout this text as we explore kernel algorithms and their implementa-
tions.
1.10 Computing Environments
So far, we have briefly described several aspects of computer systems and the
operating systems that manage them. We turn now to a discussion of how
operatingsystemsareusedina varietyof computing environments.
1.10.1 Traditional Computing
As computing has matured, the lines se parating many of the traditional com-
putingenvironmentshaveblurred.Considerthe “typicalofficeenvironment. ”
Justafewyearsago,thisenvironmentconsistedof PCsconnectedtoanetwork,
with servers providing file and print services. Remote access was awkward,
and portabilitywas achievedby useof laptopcomputers.
Today,webtechnologiesandincreasing WANbandwidtharestretchingthe
boundariesoftraditionalcomputing.Companiesestablish portals,whichpro-
vide web accessibility to their internal servers. Network computers (orthin
clients)—whichareessentiallyterminalsthatunderstandweb-basedcomput-
ing—are used in place of traditional workstations where more security or
easier maintenance is desired. Mobile computers can synchronize with PCs
to allow very portable use of company information. Mobile devices can also"
3,1.10.1 Traditional Computing,68,1.10 Computing Environments,"40 Chapter 1 Introduction
LINUX KERNEL DATA STRUCTURES
ThedatastructuresusedintheLinuxkernelareavailableinthekernelsource
code. The includefile<linux/list.h >provides details of the linked-list
data structure used throughout the kernel. Aqueue in Linux is known as a
kfifo,anditsimplementationcanbefoundinthe kfifo.c fileinthe kernel
directoryofthesourcecode.Linuxalsoprovidesabalancedbinarysearchtree
implementationusing red-black trees .Detailscanbefoundintheincludefile
<linux/rbtree.h >.
valueof the ithpositionin the bitmap is associatedwith the ithresource. As an
example,considerthebitmap shown below:
001011101
Resources2,4,5,6,and8areunavailable;resources0,1,3,and7areavailable.
The power of bitmaps becomes apparent when we consider their space
efficiency. If we were to use an eight-bit Boolean value instead of a single bit,
the resulting data structure would be eight times larger. Thus, bitmaps are
commonly used when there is a need to represent the availability of a large
number of resources. Disk drives provide a nice illustration. Amedium-sized
diskdrivemightbedividedintoseveralthousandindividualunits,called disk
blocks.Abitmapcan beusedto indicatetheavailabilityofeach diskblock.
Insummary,datastructuresarepervasiveinoperatingsystemimplemen-
tations. Thus, we will see the structures discussed here, along with others,
throughout this text as we explore kernel algorithms and their implementa-
tions.
1.10 Computing Environments
So far, we have briefly described several aspects of computer systems and the
operating systems that manage them. We turn now to a discussion of how
operatingsystemsareusedina varietyof computing environments.
1.10.1 Traditional Computing
As computing has matured, the lines se parating many of the traditional com-
putingenvironmentshaveblurred.Considerthe “typicalofficeenvironment. ”
Justafewyearsago,thisenvironmentconsistedof PCsconnectedtoanetwork,
with servers providing file and print services. Remote access was awkward,
and portabilitywas achievedby useof laptopcomputers.
Today,webtechnologiesandincreasing WANbandwidtharestretchingthe
boundariesoftraditionalcomputing.Companiesestablish portals,whichpro-
vide web accessibility to their internal servers. Network computers (orthin
clients)—whichareessentiallyterminalsthatunderstandweb-basedcomput-
ing—are used in place of traditional workstations where more security or
easier maintenance is desired. Mobile computers can synchronize with PCs
to allow very portable use of company information. Mobile devices can also"
3,1.10.2 Mobile Computing,69,1.10.1 Traditional Computing,"1.10 Computing Environments 41
connectto wireless networks andcellulardatanetworkstousethecompany’s
web portal(aswellas themyriadother web resources).
Athome,mostusersoncehad asinglecomputerwithaslowmodemcon-
nection to the office, the Internet, or both. Today, network-connection speeds
once available only at great cost are relatively inexpensive in many places,
giving home users more access to more data. These fast data connections are
allowing home computers to serve up web pages and to run networks that
include printers, client PCs, and servers. Many homes use firewall to pro-
tecttheirnetworksfromsecuritybreaches.Firewallslimitthecommunications
betweendevicesona network.
In the latter half of the 20th century, computing resources were relatively
scarce.(Beforethat,theywerenonexistent!)Foraperiodoftime,systemswere
either batch or interactive. Batch systems processed jobs in bulk, with prede-
terminedinputfromfilesorotherdatasources.Interactivesystemswaitedfor
input from users. To optimize the use of the computing resources, multiple
users shared time on these systems. These time-sharing systems used a timer
and scheduling algorithms to cycle processes rapidlythrough the CPU, giving
eachusera shareof theresources.
Traditionaltime-sharingsystemsare raretoday.Thesameschedulingtech-
nique is still in use on desktop computers, laptops, servers, and even mobile
computers, but frequently all the processes are owned by the same user (or a
single user and the operating system). User processes, and system processes
that provide services to the user, are managed so that each frequently gets a
sliceofcomputertime.Considerthewindowscreatedwhileauserisworking
on aPC, for example,and the fact that they may be performing differenttasks
atthesametime.Evenawebbrowsercanbecomposedofmultipleprocesses,
oneforeachwebsitecurrentlybeingvisited,withtimesharingappliedtoeach
web browserprocess.
1.10.2 Mobile Computing
Mobile computing refers to computing on handh eld smartphones and tablet
computers. These devices share the distinguishing physical features of being
portable and lightweight. Historically, compared with desktop and laptop
computers,mobilesystemsgaveupscreensize,memorycapacity,andoverall
functionality in return for handheld mobile access to services such as e-mail
and web browsing. Over the past few years, however, features on mobile
deviceshave become so rich that the dist inction in functionality between, say,
a consumer laptop and a tablet computer may be difficult to discern. In fact,
we might argue that the features of a contemporary mobile device allow it to
provide functionality that is either unavailable or impractical on a desktop or
laptopcomputer.
Today,mobilesystemsareusednot only fore-mailand web browsing but
also for playing music and video, reading digital books, taking photos, and
recordingandeditinghigh-definitionvideo.Accordingly,tremendousgrowth
continues in the wide range of applications that run on such devices. Many
developers are now designing applications that take advantage of the unique
features of mobile devices, such as global positioning system ( GPS)c h i p s ,
accelerometers,andgyroscopes.Anembedded GPSchipallowsamobiledevice
tousesatellitestodetermineitsprecisel ocationonEarth.Thatfunctionalityis"
3,1.10.3 Client–Server Computing,70,1.10.2 Mobile Computing,"42 Chapter 1 Introduction
especiallyusefulindesigningapplicationsthatprovidenavigation—forexam-
ple, telling users which way to walk or drive or perhaps directing them to
nearby services,such as restaurants .Anaccelerometerallows a mobiledevice
to detect its orientation with respect to the ground and to detect certain other
forces, such as tilting and shaking. In several computer games that employ
accelerometers, players interface with the system not by using a mouse or a
keyboardbutratherbytilting,rotating,andshakingthemobiledevice!Perhaps
more a practical use of these features is found in augmented-reality appli-
cations, which overlay information on a display of the current environment.
It is difficult to imagine how equivalent applications could be developed on
traditionallaptopor desktopcomputersystems.
To provide access to on-line services, mobile devices typically use either
IEEEstandard 802.11 wirelessor cellular data networks. The memory capacity
andprocessingspeedofmobiledevices,however,aremorelimitedthanthose
ofPCs. Whereas a smartphone or tablet may have 256 GBin storage, it is not
uncommon to find 8 TBin storage on a desktop computer. Similarly, because
powerconsumptionissuchaconcern,mobiledevicesoftenuseprocessorsthat
aresmaller,areslower,andofferfewerprocessingcoresthanprocessorsfound
on traditionaldesktopand laptopcomputers.
Two operating systems currently dominate mobile computing: Apple i OS
and Google Android .iOSw a sd e s i g n e dt or u no nA p p l ei P h o n ea n di P a d
mobile devices.Android powers smartph ones and tablet computers available
frommanymanufacturers.Weexaminethesetwomobileoperatingsystemsin
furtherdetailin Chapter2.
1.10.3 Client–Server Computing
Contemporary network architecture features arrangements in which server
systems satisfyrequestsgeneratedby client systems .Thisformofspecialized
distributed system, called a client–server system, has the general structure
depictedinFigure1.22.
Server systems can be broadly categorized as compute servers and file
servers:
•The compute-server system provides an interface to which a client can
send a requestto perform an action (for example, read data). In response,
the server executes the action and sends the results to the client. Aserver
server networkclient
desktop
client
laptop
client
smartphone
Figure 1.22 General structure of a client–server system."
3,1.10.4 Peer-to-Peer Computing,71,1.10.3 Client–Server Computing,"1.10 Computing Environments 43
running adatabase thatrespondstoclientrequestsfor dataisan example
of such asystem.
•The file-serve system provides a file-system interface where clients can
create, update, read, and delete files. An example of such a system is a
web server that delivers files to clients running web browsers. The actual
contents of the files can vary greatly, ranging from traditional web pages
to richmultimediacontent such ashigh-definition video.
1.10.4 Peer-to-Peer Computing
Another structure for a distributed system is the peer-to-peer ( P2P) system
model. In this model, clients and servers are not distinguished from one
another. Instead, all nodes within th e system are considered peers, and each
may act as eithera client or a server,dependingonwhether it is requestingor
providing a service. Peer-to-peer systems offer an advantage over traditional
client–serversystems.Inaclient–serversystem,theserverisabottleneck;but
inapeer-to-peersystem,servicescanbeprovidedbyseveralnodesdistributed
throughout the network.
To participate in a peer-to-peersystem, a node must first join the network
of peers. Once a node has joined the network, it can begin providing services
to—and requesting services from—other nodes in the network. Determining
what servicesareavailableisaccomplishedin one of two generalways:
•When a node joins a network, it registers its service with a centralized
lookup service on the network. Any node desiring a specific service first
contactsthiscentralizedlookupservicetodeterminewhichnodeprovides
the service.The remainderof the communication takes placebetween the
client andthe serviceprovider.
•An alternative scheme uses no centralized lookup service. Instead, a peer
acting as a client must discover what node provides a desired service by
broadcasting a request for the service to all other nodes in the network.
The node (or nodes) providing that service responds to the peer making
the request. To support this approach, a discovery protocol must be pro-
videdthatallowspeerstodiscoverservicesprovidedbyotherpeersinthe
network. Figure1.23 illustratessuch ascenario.
Peer-to-peernetworksgainedwidespreadpopularityinthelate1990swith
severalfile-sharingservices,suchasNapsterandGnutella,thatenabledpeers
toexchangefileswithoneanother.TheNapstersystemusedanapproachsimi-
lartothefirsttypedescribedabove:acentralizedservermaintainedanindexof
allfilesstoredon peernodesin the Napsternetwork, and the actual exchange
of files took place between the peer nodes. The Gnutella system used a tech-
niquesimilartothesecondtype:aclientbroadcastfilerequeststoothernodes
in the system, and nodes that could service the request responded directly to
the client. Peer-to-peer networks can be used to exchange copyrighted mate-
rials (music, for example) anonymously, and there are laws governing the
distribution of copyrighted material. Notably, Napster ran into legal trouble
for copyright infringement, and its services were shut down in 2001. For this
reason, the future of exchanging filesremainsuncertain."
3,1.10.5 Cloud Computing,72,1.10.4 Peer-to-Peer Computing,"44 Chapter 1 Introduction
client
client client
client client
Figure 1.23 Peer-to-peer system with no centralized service.
Skype is another example of peer-to-peer computing. It allows clients to
make voice calls and video calls and to send text messages over the Internet
using a technology known as voice over IP(VoIP). Skype uses a hybrid peer-
to-peerapproach.Itincludesacentralizedloginserver,butitalsoincorporates
decentralizedpeersand allowstwo peerstocommunicate.
1.10.5 Cloud Computing
Cloud computing is a type of computing that delivers computing, storage,
and even applications as a service across a network. In some ways, it’s a
logical extension of virtualization, because it uses virtualization as a base for
itsfunctionality.Forexample,theAmazonElasticComputeCloud( ec2)facility
hasthousandsofservers,millionsofvirtualmachines,andpetabytesofstorage
available for use by anyone on the Internet. Users pay per month based on
howmuchofthoseresourcestheyuse.Thereareactuallymanytypesofcloud
computing, includingthe following:
•Public cloud —a cloud availableviatheInternettoanyone willingto pay
for theservices
•Private cloud —a cloud run by a company for that company’s own use
•Hybrid cloud —a cloud that includesboth public and private cloud com-
ponents
•Software as a service ( SaaS)—one or more applications (such as word
processorsor spreadsheets)availableviatheInternet
•Platform as a service ( PaaS)—a software stack ready for application use
viatheInternet(for example,adatabase server)
•Infrastructure as a service ( IaaS)—servers or storage available over the
Internet (for example, storage available for making backup copies of pro-
duction data)"
3,1.10.6 Real-Time Embedded Systems,73,1.10.5 Cloud Computing,"1.10 Computing Environments 45
firewallcloud
customer
interface
load balancer
virtual
machinesvirtual
machines
servers serversstorageInternet
customer
requests
cloud
management
commands
cloud
managment
services
Figure 1.24 Cloud computing.
These cloud-computing types are not discrete, as a cloud computing environ-
ment may provide a combination of several types. For example, an organiza-
tionmay providebothSaaSand IaaSas publiclyavailableservices.
Certainly,therearetraditionaloperatingsystemswithinmanyofthetypes
of cloud infrastructure. Beyond those are the VMMs that manage the virtual
machines in which the user processes run. At a higher level, the VMMst h e m -
selves are managed by cloud management tools, such as VMware vCloud
Director and the open-source Eucalyptus toolset. These tools manage the
resourceswithinagivencloudandprovideinterfacestothecloudcomponents,
makingagoodargumentforconsideringthemanewtypeofoperatingsystem.
Figure 1.24 illustrates a public cloud providing IaaS. Notice that both the
cloudservicesand thecloud userinterfaceareprotectedby a firewall.
1.10.6 Real-Time Embedded Systems
Embedded computers are the most prevalent form of computers in existence.
These devices are found everywhere, from car engines and manufacturing
robotstoopticaldrivesandmicrowaveovens.Theytendtohaveveryspecific
tasks. The systems they run on are usually primitive, and so the operating
systemsprovidelimitedfeatures.Usually,theyhavelittleornouserinterface,
preferring to spend their time monitoring and managing hardware devices,
such as automobile enginesand robotic arms.
These embedded systems vary considerably. Some are general-purpose
computers, running standard operating systems—such as Linux—with
special-purpose applications to implement the functionality. Others are
hardware devices with a special-purpose embedded operating system
providing just the functionality desired. Yet others are hardware devices"
2,1.11 Free and Open-Source Operating Systems,74,1.10 Computing Environments,"46 Chapter 1 Introduction
with application-specific integrated circuits ( ASIC s) that perform their tasks
without an operating system.
The use of embedded systems continues to expand. The power of these
devices,both as standaloneunits and as elementsofnetworks and theweb, is
suretoincreaseaswell.Evennow,entirehousescanbecomputerized,sothata
centralcomputer—eitherageneral-purposecomputeroranembeddedsystem
—can control heating and lighting, alarm systems, and even coffee makers.
Web access can enable a home owner to tell the house to heat up before she
arriveshome.Someday,therefrigeratorwillbeabletonotifythegrocerystore
when itnoticesthe milkisgone.
Embeddedsystemsalmostalwaysrun real-time operating systems .Areal-
time system is used when rigid time requirements have been placed on the
operation of a processor or the flow of data; thus, it is often used as a control
deviceinadedicatedapplication.Sensorsbringdatatothecomputer.Thecom-
putermustanalyze the dataand possiblyadjustcontrols tomodifythe sensor
inputs. Systems that control scientific e xperiments, medical imaging systems,
industrial control systems, and certain display systems are real-time systems.
Some automobile-engine fuel-injectio n systems, home-appliance controllers,
and weaponsystemsarealsoreal-timesystems.
A real-time system has well-defined, fixed time constraints. Processing
mustbe done within the defined constraints, or the system will fail. For
instance, it would not do for a robot arm to be instructed to halt afterit had
smashed into the car it was building. A real-time system functions correctly
onlyifitreturnsthecorrectresultwithinitstimeconstraints.Contrastthissys-
temwithatraditionallaptopsystemwhereitisdesirable(butnotmandatory)
to respondquickly.
InChapter5,weconsidertheschedu lingfacilityneededtoimplementreal-
time functionality in an operating system, and in Chapter 20 we describe the
real-timecomponents of Linux.
1.11 Free and Open-Source Operating Systems
The study of operating systems has been made easier by the avail-
ability of a vast number of free software and open-source releases.
Both free operating systems and open-source operating systems
are available in source-code format rather than as compiled binary
code. Note, though, that free software and open-source software are
two different ideas championed by different groups of people (see
http://gnu.org/philosophy/open-source-misses-the-point.html/ for a
discussion on the topic). Free software (sometimes referred to as free/libre
software ) not only makes source code available but also is licensed to allow
no-cost use, redistribution, and modification. Open-source software does
not necessarily offer such licensing. Thus, although all free software is open
source, some open-source software is not “free. ”GNU/Linux is the most
famous open-source operating system, with some distributions free and
others open source only ( http://www.gnu.org/distros/ ). Microsoft Windows
is a well-known example of the opposite closed-source approach. Windows
isproprietary software—Microsoft owns it, restricts its use, and carefully
protects its source code. Apple’s mac OSoperating system comprises a hybrid"
3,1.11.1 History,75,1.11 Free and Open-Source Operating Systems,"1.11 Free and Open-Source Operating Systems 47
approach. It contains an open-source kernel named Darwin but includes
proprietary,closed-sourcecomponents as well.
Starting with the source code allows the programmer to produce binary
code that can be executed on a system. Doing the opposite— reverse engi-
neering the source code from the binaries—is quite a lot of work, and useful
items such as comments are never recovered. Learning operating systems by
examining the source code has other benefits as well. With the source code
in hand, a student can modify the operating system and then compile and
run the code to try out those changes, which is an excellent learning tool.
This text includes projects that invo lve modifying operating-system source
code, while also describing algorithms at a high level to be sure all important
operating-systemtopicsarecovered.Throughoutthetext,weprovidepointers
toexamplesof open-source codefor deeperstudy.
There are many benefits to open-source operating systems, including a
communityofinterested(andusuallyunpaid)programmerswhocontributeto
thecodeby helpingto writeit,debugit,analyze it,providesupport,and sug-
gest changes. Arguably, open-source code is more secure than closed-source
code because many more eyes are viewing the code. Certainly, open-source
code has bugs, but open-source advocates argue that bugs tend to be found
and fixed faster owing to the number o f people using and viewing the code.
Companies that earn revenue from selling their programs often hesitate to
open-sourcetheircode,butRedHatan damyriadofothercompaniesaredoing
just that and showing that commercial companies benefit, rather than suffer,
whentheyopen-sourcetheircode.Revenuecanbegeneratedthroughsupport
contracts and the sale of hardware on which the software runs, for example.
1.11.1 History
In the early days of modern computing (that is, the 1950s), software generally
came with source code. The original hackers (computer enthusiasts) at MIT’s
TechModelRailroadClublefttheirprogramsindrawersforotherstoworkon.
“Homebrew ”user groups exchanged code during their meetings. Company-
specificusergroups,suchasDigitalEquipmentCorporation’s DECUS,accepted
contributions of source-code programs , collected them onto tapes, and dis-
tributed the tapes to interested members. In 1970, Digital’s operating systems
weredistributedas sourcecodewithno restrictionsor copyright notice.
Computer and software companies eventually sought to limit the use of
theirsoftwaretoauthorizedcomputersandpayingcustomers.Releasingonly
the binary files compiled from the source code, rather than the source code
itself,helpedthemtoachievethisgoal,aswellasprotectingtheircodeandtheir
ideasfromtheircompetitors.AlthoughtheHomebrewusergroupsofthe1970s
exchanged code during their meetings, the operating systems for hobbyist
machines (such as CPM) were proprietary. By 1980, proprietary software was
the usual case.
1.11.2 Free Operating Systems
Tocounterthemovetolimitsoftwareuseandredistribution,RichardStallman
in 1984 started developing a free, UNIX-compatible operating system called
GNU(whichisarecursiveacronymfor “GNU’sNotUnix! ”).ToStallman, “free ”
referstofreedomofuse,notprice.Thefree-softwaremovementdoesnotobject"
3,1.11.2 Free Operating Systems,75,1.11.1 History,"1.11 Free and Open-Source Operating Systems 47
approach. It contains an open-source kernel named Darwin but includes
proprietary,closed-sourcecomponents as well.
Starting with the source code allows the programmer to produce binary
code that can be executed on a system. Doing the opposite— reverse engi-
neering the source code from the binaries—is quite a lot of work, and useful
items such as comments are never recovered. Learning operating systems by
examining the source code has other benefits as well. With the source code
in hand, a student can modify the operating system and then compile and
run the code to try out those changes, which is an excellent learning tool.
This text includes projects that invo lve modifying operating-system source
code, while also describing algorithms at a high level to be sure all important
operating-systemtopicsarecovered.Throughoutthetext,weprovidepointers
toexamplesof open-source codefor deeperstudy.
There are many benefits to open-source operating systems, including a
communityofinterested(andusuallyunpaid)programmerswhocontributeto
thecodeby helpingto writeit,debugit,analyze it,providesupport,and sug-
gest changes. Arguably, open-source code is more secure than closed-source
code because many more eyes are viewing the code. Certainly, open-source
code has bugs, but open-source advocates argue that bugs tend to be found
and fixed faster owing to the number o f people using and viewing the code.
Companies that earn revenue from selling their programs often hesitate to
open-sourcetheircode,butRedHatan damyriadofothercompaniesaredoing
just that and showing that commercial companies benefit, rather than suffer,
whentheyopen-sourcetheircode.Revenuecanbegeneratedthroughsupport
contracts and the sale of hardware on which the software runs, for example.
1.11.1 History
In the early days of modern computing (that is, the 1950s), software generally
came with source code. The original hackers (computer enthusiasts) at MIT’s
TechModelRailroadClublefttheirprogramsindrawersforotherstoworkon.
“Homebrew ”user groups exchanged code during their meetings. Company-
specificusergroups,suchasDigitalEquipmentCorporation’s DECUS,accepted
contributions of source-code programs , collected them onto tapes, and dis-
tributed the tapes to interested members. In 1970, Digital’s operating systems
weredistributedas sourcecodewithno restrictionsor copyright notice.
Computer and software companies eventually sought to limit the use of
theirsoftwaretoauthorizedcomputersandpayingcustomers.Releasingonly
the binary files compiled from the source code, rather than the source code
itself,helpedthemtoachievethisgoal,aswellasprotectingtheircodeandtheir
ideasfromtheircompetitors.AlthoughtheHomebrewusergroupsofthe1970s
exchanged code during their meetings, the operating systems for hobbyist
machines (such as CPM) were proprietary. By 1980, proprietary software was
the usual case.
1.11.2 Free Operating Systems
Tocounterthemovetolimitsoftwareuseandredistribution,RichardStallman
in 1984 started developing a free, UNIX-compatible operating system called
GNU(whichisarecursiveacronymfor “GNU’sNotUnix! ”).ToStallman, “free ”
referstofreedomofuse,notprice.Thefree-softwaremovementdoesnotobject"
3,1.11.3 GNU/Linux,76,1.11.2 Free Operating Systems,"48 Chapter 1 Introduction
to trading a copy for an amount of money but holds that users are entitled to
four certain freedoms: (1) to freely run the program, (2) to study and change
thesourcecode,andtogiveorsellcopieseither(3)withor(4)withoutchanges.
In1985,Stallmanpublishedthe GNUManifesto,whicharguesthatallsoftware
should be free. He also formed the Free Software Foundation (FSF)w i t ht h e
goal of encouraging theuseand developmentof freesoftware.
TheFSFuses the copyrights on its programs to implement “copyleft, ”a
form oflicensing inventedby Stallman.Copyleftingawork givesanyone that
possesses a copy of the work the four essential freedoms that make the work
free,with thecondition that redistributionmustpreservethesefreedoms.The
GNU General Public License (GPL) is a common license under which free
software is released. Fundamentally, the GPLr e q u i r e st h a tt h es o u r c ec o d eb e
distributedwithanybinariesandthatallcopies(includingmodifiedversions)
be released under the same GPLlicense. The Creative Commons “Attribution
Sharealike ”license is also a copyleft license; “sharealike ”is another way of
stating theideaof copyleft.
1.11.3 GNU/Linux
As an example of a free and open-source operating system, consider
GNU /Linux. By 1991, the GNUoperating system was nearly complete. The
GNUProject had developed compilers, editors, utilities, libraries, and games
— whateverpartsitcouldnotfindelsewhere.However,the GNUkernelnever
became ready for prime time. In 1991, a student in Finland, Linus Torvalds,
released a rudimentary UNIX-like kernel using the GNUcompilers and tools
and invited contributions worldwide. The advent of the Internet meant that
anyone interested could download the source code, modify it, and submit
changes to Torvalds. Releasing updates once a week allowed this so-called
“Linux ”operating system to grow rapidly, enhanced by several thousand
programmers. In 1991, Linux was not free software, as its license permitted
only noncommercial redistribution. In 1992, however, Torvalds rereleased
Linux under the GPL, making it free software (and also, to use a term coined
later, “open source ”).
The resulting GNU/Linux operating system (with the kernel properly
called Linux but the full operating system including GNUtools called
GNU/Linux) has spawned hundreds of unique distributions ,o rc u s t o m
builds, of the system. Major distributions include Red Hat, SUSE,F e d o r a ,
Debian, Slackware, and Ubuntu. Distributions vary in function, utility,
installed applications, hardware support, user interface, and purpose. For
example, Red Hat Enterprise Linux is geared to large commercial use.
PCLinuxOSis a live CD—an operating system that can be booted and run
from a CD-ROM without being installed on a system’s boot disk. Avariant of
PCLinuxOS—called PCLinuxOSSupergamer DVD—isa live DVDthatincludes
graphics drivers and games. A gamer can run it on any compatible system
simply by booting from the DVD. When the gamer is finished, a reboot of the
systemresetsitto itsinstalledoperatingsystem.
You can run Linux on a Windows (or other) system using the following
simple,freeapproach:"
3,1.11.4 BSD UNIX,77,1.11.3 GNU/Linux,"1.11 Free and Open-Source Operating Systems 49
1.Do w n lo a dth ef r eeV irtu a lb o x VMMtool from
https://www.virtualbox.org/
and installiton your system.
2.Choose to install an operating system from scratch, based on an
installationimagelikea CD,orchoosepre-builtoperating-systemimages
that can be installedand run morequickly froma sitelike
http://virtualboxes.org/images/
These images are preinstalled with operating systems and applications
and include many flavorsof GNU/Linux.
3.Bootthe virtualmachine within Virtualbox.
An alternative to using Virtualbox is to use the free program Qemu
(http://wiki.qemu.org/Download/ ), which includes the qemu-img command
forconverting Virtualbox imagestoQemuimagesto easilyimportthem.
Withthistext,weprovideavirtualmachineimageof GNU/Linuxrunning
theUbunturelease.Thisimagecontainsthe GNU/Linuxsourcecodeaswellas
toolsforsoftwaredevelopment.Wecoverexamplesinvolvingthe GNU/Linux
imagethroughout this text,as wellasina detailedcasestudyinChapter20.
1.11.4 BSD UNIX
BSD UNIX has a longer and more complicated history than Linux. It started in
1978asaderivativeof AT&T’sUNIX.ReleasesfromtheUniversityofCalifornia
at Berkeley ( UCB) came in source and binary form, but they were not open
sourcebecausealicensefrom AT&Twasrequired. BSDUNIX ’sdevelopmentwas
slowed by a lawsuit by AT&T, but eventually a fully functional, open-source
version,4.4BSD-lite,was releasedin1994.
Just as with Linux, there are many distributions of BSD UNIX , including
FreeBSD,N e tBSD,O p e nBSD,a n dD r a g o n fl y BSD. To explore the source code
of FreeBSD, simply download the virtual machine image of the version of
interest and boot it within Virtualbox, as described above for Linux. The
source code comes with the distribution and is stored in /usr/src/ .T h e
kernel source code is in /usr/src/sys . For example, to examine the vir-
tual memory implementation code in the Free BSDkernel, see the files in
/usr/src/sys/vm .Alternatively,youcansimplyviewthesourcecodeonline
athttps://svnweb.freebsd.org .
As with many open-source projects, this source code is contained in
and controlled by a version control system —in this case, “subversion ”
(https://subversion.apache.org/source-code ). Version control systems allow
au s e rt o “pull ”an entire source code tree to his computer and “push ”any
changes back into the repository for others to then pull. These systems also
provide other features, including an entire history of each file and a conflict
resolution feature in case the same file is changed concurrently. Another"
3,1.11.5 Solaris,79,1.11.4 BSD UNIX,"1.12 Summary 51
1.11.5 Solaris
Solarisis the commercial UNIX-based operating system of Sun Microsystems.
Originally,Sun’s Sun OSoperatingsystemwasbasedon BSDUNIX .Sunmoved
toAT&T’s System V UNIXas its base in 1991. In 2005, Sun open-sourced most
of the Solaris code as the OpenSolaris project. The purchase of Sun by Oracle
in2009, however,leftthestateof thisprojectunclear.
SeveralgroupsinterestedinusingOpenSolarishaveexpandeditsfeatures,
and their working set is Project Illumos, which has expanded from the Open-
Solaris base to include more features and to be the basis for several products.
Illumosisavailableat http://wiki.illumos.org .
1.11.6 Open-Source Systems as Learning Tools
The free-software movement is driving legions of programmers to create
thousands of open-source projects, including operating systems. Sites like
http://freshmeat.net/ and http://distrowatch.com/ provideportalstomanyof
these projects. As we stated earlier, open-source projects enable students to
use source code as a learning tool. They can modify programs and test them,
help find and fix bugs, and otherwise explore mature, full-featured operating
systems, compilers, tools, user interfaces, and other types of programs. The
availability of source code for historic projects, such as Multics, can help stu-
dentstounderstandthoseprojectsandt obuildknowledgethatwillhelpinthe
implementationof newprojects.
Anotheradvantageofworkingwithopen-sourceoperatingsystemsistheir
diversity. GNU/Linux and BSD UNIX are both open-source operating systems,
for instance, but each has its own goals, utility, licensing, and purpose. Some-
times,licensesare not mutuallyexclusiveand cross-pollination occurs, allow-
ing rapid improvements in operating-system projects. For example, several
major components of OpenSolaris have been ported to BSD UNIX . The advan-
tages of free software and open sourcing are likely to increase the number
and quality of open-source projects, leading to an increase in the number of
individualsand companies that usetheseprojects.
1.12 Summary
•Anoperatingsystemissoftwarethatmanagesthecomputerhardware,as
wellas providingan environmentfor application programstorun.
•Interrupts are a key way in which hardware interacts with the operating
system.Ahardwaredevicetriggersaninterruptbysendingasignaltothe
CPUto alert the CPUthat some event requires attention. The interrupt is
managed by the interrupthandler.
•Foracomputertodoitsjobofexecutingprograms,theprogramsmustbe
in main memory, which is the only large storage area that the processor
can access directly.
•Themainmemoryisusuallyavolatilestoragedevicethatlosesitscontents
when poweristurned off or lost."
3,1.11.6 Open-Source Systems as Learning Tools,79,1.11.5 Solaris,"1.12 Summary 51
1.11.5 Solaris
Solarisis the commercial UNIX-based operating system of Sun Microsystems.
Originally,Sun’s Sun OSoperatingsystemwasbasedon BSDUNIX .Sunmoved
toAT&T’s System V UNIXas its base in 1991. In 2005, Sun open-sourced most
of the Solaris code as the OpenSolaris project. The purchase of Sun by Oracle
in2009, however,leftthestateof thisprojectunclear.
SeveralgroupsinterestedinusingOpenSolarishaveexpandeditsfeatures,
and their working set is Project Illumos, which has expanded from the Open-
Solaris base to include more features and to be the basis for several products.
Illumosisavailableat http://wiki.illumos.org .
1.11.6 Open-Source Systems as Learning Tools
The free-software movement is driving legions of programmers to create
thousands of open-source projects, including operating systems. Sites like
http://freshmeat.net/ and http://distrowatch.com/ provideportalstomanyof
these projects. As we stated earlier, open-source projects enable students to
use source code as a learning tool. They can modify programs and test them,
help find and fix bugs, and otherwise explore mature, full-featured operating
systems, compilers, tools, user interfaces, and other types of programs. The
availability of source code for historic projects, such as Multics, can help stu-
dentstounderstandthoseprojectsandt obuildknowledgethatwillhelpinthe
implementationof newprojects.
Anotheradvantageofworkingwithopen-sourceoperatingsystemsistheir
diversity. GNU/Linux and BSD UNIX are both open-source operating systems,
for instance, but each has its own goals, utility, licensing, and purpose. Some-
times,licensesare not mutuallyexclusiveand cross-pollination occurs, allow-
ing rapid improvements in operating-system projects. For example, several
major components of OpenSolaris have been ported to BSD UNIX . The advan-
tages of free software and open sourcing are likely to increase the number
and quality of open-source projects, leading to an increase in the number of
individualsand companies that usetheseprojects.
1.12 Summary
•Anoperatingsystemissoftwarethatmanagesthecomputerhardware,as
wellas providingan environmentfor application programstorun.
•Interrupts are a key way in which hardware interacts with the operating
system.Ahardwaredevicetriggersaninterruptbysendingasignaltothe
CPUto alert the CPUthat some event requires attention. The interrupt is
managed by the interrupthandler.
•Foracomputertodoitsjobofexecutingprograms,theprogramsmustbe
in main memory, which is the only large storage area that the processor
can access directly.
•Themainmemoryisusuallyavolatilestoragedevicethatlosesitscontents
when poweristurned off or lost."
2,1.12 Summary,79,1.11 Free and Open-Source Operating Systems,"1.12 Summary 51
1.11.5 Solaris
Solarisis the commercial UNIX-based operating system of Sun Microsystems.
Originally,Sun’s Sun OSoperatingsystemwasbasedon BSDUNIX .Sunmoved
toAT&T’s System V UNIXas its base in 1991. In 2005, Sun open-sourced most
of the Solaris code as the OpenSolaris project. The purchase of Sun by Oracle
in2009, however,leftthestateof thisprojectunclear.
SeveralgroupsinterestedinusingOpenSolarishaveexpandeditsfeatures,
and their working set is Project Illumos, which has expanded from the Open-
Solaris base to include more features and to be the basis for several products.
Illumosisavailableat http://wiki.illumos.org .
1.11.6 Open-Source Systems as Learning Tools
The free-software movement is driving legions of programmers to create
thousands of open-source projects, including operating systems. Sites like
http://freshmeat.net/ and http://distrowatch.com/ provideportalstomanyof
these projects. As we stated earlier, open-source projects enable students to
use source code as a learning tool. They can modify programs and test them,
help find and fix bugs, and otherwise explore mature, full-featured operating
systems, compilers, tools, user interfaces, and other types of programs. The
availability of source code for historic projects, such as Multics, can help stu-
dentstounderstandthoseprojectsandt obuildknowledgethatwillhelpinthe
implementationof newprojects.
Anotheradvantageofworkingwithopen-sourceoperatingsystemsistheir
diversity. GNU/Linux and BSD UNIX are both open-source operating systems,
for instance, but each has its own goals, utility, licensing, and purpose. Some-
times,licensesare not mutuallyexclusiveand cross-pollination occurs, allow-
ing rapid improvements in operating-system projects. For example, several
major components of OpenSolaris have been ported to BSD UNIX . The advan-
tages of free software and open sourcing are likely to increase the number
and quality of open-source projects, leading to an increase in the number of
individualsand companies that usetheseprojects.
1.12 Summary
•Anoperatingsystemissoftwarethatmanagesthecomputerhardware,as
wellas providingan environmentfor application programstorun.
•Interrupts are a key way in which hardware interacts with the operating
system.Ahardwaredevicetriggersaninterruptbysendingasignaltothe
CPUto alert the CPUthat some event requires attention. The interrupt is
managed by the interrupthandler.
•Foracomputertodoitsjobofexecutingprograms,theprogramsmustbe
in main memory, which is the only large storage area that the processor
can access directly.
•Themainmemoryisusuallyavolatilestoragedevicethatlosesitscontents
when poweristurned off or lost."
2,Practice Exercises,81,1.12 Summary,"Practice Exercises 53
•Free and open-source operating systems are available in source-code for-
mat. Free software is licensed to allow no-cost use, redistribution, and
modification. GNU/Linux, FreeBSD, and Solaris are examples of popular
open-source systems.
Practice Exercises
1.1What are the three main purposesof an operating system?
1.2Wehavestressedtheneedforanoperatingsystemtomakeefficientuse
of the computing hardware. When is it appropriate for the operating
system to forsake this principle and to “waste ”resources? Why is such
a systemnot reallywasteful?
1.3Whatisthemaindifficultythataprogrammermustovercomeinwriting
an operatingsystemfor a real-timeenvironment?
1.4Keeping in mind the various definitions of operating system, consider
whether the operating system should include applications such as web
browsers and mail programs. Argue both that it should and that it
should not, and supportyour answers.
1.5Howdoesthedistinctionbetweenkernelmodeandusermodefunction
as a rudimentaryform ofprotection(security)?
1.6Which of the following instructionsshould be privileged?
a. Setvalueof timer.
b. Read the clock.
c. Clearmemory.
d. Issuea trapinstruction.
e. Turnoff interrupts.
f. Modifyentriesindevice-statustable.
g. Switchfrom usertokernelmode.
h. Access I/Odevice.
1.7Some early computers protected the operating system by placing it in
a memory partition that could not be modified by either the user job or
theoperatingsystemitself.Describetwodifficultiesthatyouthinkcould
arisewithsuch ascheme.
1.8SomeCPUsprovideformorethantwomodesofoperation.Whataretwo
possibleusesof thesemultiplemodes?
1.9Timers could be used to compute the current time. Provide a short
descriptionof how this could beaccomplished.
1.10Givetwo reasonswhy caches areuseful.What problemsdotheysolve?
What problems do they cause? If a cache can be made as large as the"
2,Further Reading,82,Practice Exercises,"54 Chapter 1 Introduction
device for which it is caching (for instance, a cache as large as a disk),
why not makeit that largeand eliminatethe device?
1.11Distinguish between the client–server and peer-to-peer models of dis-
tributedsystems.
Further Reading
Many general textbooks cover operatin g systems, including [Stallings (2017)]
and[Tanenbaum(2014)].[HennessyandPatterson(2012)]providecoverageof
I/Osystemsandbusesandofsystemarchitectureingeneral.[KuroseandRoss
(2017)] providesa generaloverviewof computernetworks.
[Russinovichetal.(2017)]giveanoverviewofMicrosoftWindowsandcov-
ers considerable technical detail about the system internals and components.
[McDougall and Mauro (2007)] cover the internals of the Solaris operating
system. The mac OSand iOSinternals are discussed in [Levin (2013)]. [Levin
(2015)] coverstheinternalsofAndroid.[Love(2010)] providesanoverviewof
the Linux operating system and great detail about data structures used in the
Linux kernel. The Free Software Foundation has published its philosophy at
http://www.gnu.org/philosophy/free-software-for-freedom.html .
Bibliography
[Hennessy and Patterson (2012)] J.HennessyandD.Patterson, Computer Archi-
tecture: A Quantitative Approach, Fifth Edition, MorganKaufmann(2012).
[Kurose and Ross (2017)] J. Kurose and K. Ross, Computer Networking—A Top–
Down Approach, SeventhEdition, Addison-Wesley (2017).
[Levin (2013)] J. Levin, Mac OS X and i OSInternals to the Apple’s Core , Wiley
(2013).
[Levin (2015)] J. Levin, Android Internals–A Confectioner’s Cookbook. Volume I
(2015).
[Love (2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library (2010).
[McDougall and Mauro (2007)] R. McDougall and J. Mauro, Solaris Internals,
SecondEdition, PrenticeHall (2007).
[Russinovich et al. (2017)] M.Russinovich,D.A.Solomon,andA.Ionescu, Win-
dows Internals–Part 1, SeventhEdition, MicrosoftPress (2017).
[Stallings (2017)] W. Stallings, Operating Systems, Internals and Design Principles
(9th Edition) Ninth Edition, PrenticeHall (2017).
[Tanenbaum (2014)] A. S. Tanenbaum, Modern Operating Systems ,P r e n t i c eH a l l
(2014)."
2,Bibliography,82,Further Reading,"54 Chapter 1 Introduction
device for which it is caching (for instance, a cache as large as a disk),
why not makeit that largeand eliminatethe device?
1.11Distinguish between the client–server and peer-to-peer models of dis-
tributedsystems.
Further Reading
Many general textbooks cover operatin g systems, including [Stallings (2017)]
and[Tanenbaum(2014)].[HennessyandPatterson(2012)]providecoverageof
I/Osystemsandbusesandofsystemarchitectureingeneral.[KuroseandRoss
(2017)] providesa generaloverviewof computernetworks.
[Russinovichetal.(2017)]giveanoverviewofMicrosoftWindowsandcov-
ers considerable technical detail about the system internals and components.
[McDougall and Mauro (2007)] cover the internals of the Solaris operating
system. The mac OSand iOSinternals are discussed in [Levin (2013)]. [Levin
(2015)] coverstheinternalsofAndroid.[Love(2010)] providesanoverviewof
the Linux operating system and great detail about data structures used in the
Linux kernel. The Free Software Foundation has published its philosophy at
http://www.gnu.org/philosophy/free-software-for-freedom.html .
Bibliography
[Hennessy and Patterson (2012)] J.HennessyandD.Patterson, Computer Archi-
tecture: A Quantitative Approach, Fifth Edition, MorganKaufmann(2012).
[Kurose and Ross (2017)] J. Kurose and K. Ross, Computer Networking—A Top–
Down Approach, SeventhEdition, Addison-Wesley (2017).
[Levin (2013)] J. Levin, Mac OS X and i OSInternals to the Apple’s Core , Wiley
(2013).
[Levin (2015)] J. Levin, Android Internals–A Confectioner’s Cookbook. Volume I
(2015).
[Love (2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library (2010).
[McDougall and Mauro (2007)] R. McDougall and J. Mauro, Solaris Internals,
SecondEdition, PrenticeHall (2007).
[Russinovich et al. (2017)] M.Russinovich,D.A.Solomon,andA.Ionescu, Win-
dows Internals–Part 1, SeventhEdition, MicrosoftPress (2017).
[Stallings (2017)] W. Stallings, Operating Systems, Internals and Design Principles
(9th Edition) Ninth Edition, PrenticeHall (2017).
[Tanenbaum (2014)] A. S. Tanenbaum, Modern Operating Systems ,P r e n t i c eH a l l
(2014)."
2,Chapter 1 Exercises,83,Bibliography,"Chapter 1 Exercises
1.12How doclusteredsystemsdifferfrom multiprocessorsystems?What is
requiredfortwomachinesbelongingtoaclustertocooperatetoprovide
a highly availableservice?
1.13Consider a computing cluster consisting of two nodes running a
database. Describe two ways in which the cluster software can manage
access to the data on the disk. Discus s the benefits and disadvantages
of each.
1.14What is the purpose of interrupts? How does an interrupt differ from a
trap? Can traps be generated intentionally by a user program? If so, for
what purpose?
1.15Explain how the Linux kernel variables HZandjiffies can be used to
determine the number of seconds the system has been running since it
was booted.
1.16Direct memory access is used for high-speed I/Odevices in order to
avoid increasing the CPU’s executionload.
a. How does the CPUinterface with the device to coordinate the
transfer?
b. How does the CPUknow when the memory operations are com-
plete?
c. The CPUis allowed to execute other programs while the DMA
controller is transferring data. Does this process interfere with
the execution of the user programs? If so, describe what forms of
interferencearecaused.
EX-11.17Somecomputersystemsdonotprovideaprivilegedmodeofoperation
in hardware. Is it possible to construct a secure operating system for
these computer systems? Give arguments both that it is and that it is
not possible.
1.18ManySMPsystems have different levels of caches; one level is local to
each processing core, and another level is shared among all processing
cores.Why are caching systemsdesignedthisway?
1.19Rank the following storagesystemsfrom slowestto fastest:
a. Hard-diskdrives
b. Registers
c. Opticaldisk
d. Mainmemory
e. Nonvolatilememory
f. Magnetictapes
g. Cache"
1,Chapter 2 Operating-System Structures,85,Chapter 1 Introduction,"2CHAPTER Operating -
System
Structures
An operating system provides the environment within which programs are
executed.Internally,operatingsystemsvarygreatlyintheirmakeup,sincethey
areorganizedalongmanydifferentlines.Thedesignofanewoperatingsystem
is a major task. It is important that the goals of the system be well defined
beforethedesignbegins.Thesegoalsfo rmthebasisforchoicesamongvarious
algorithmsand strategies.
We can view an operating system from several vantage points. One view
focusesonthe servicesthat thesystempr ovides;another,on the interfacethat
it makes available to users and programmers; a third, on its components and
theirinterconnections.Inthischapter,weexploreallthreeaspectsofoperating
systems,showingtheviewpointsofusers,programmers,andoperatingsystem
designers.Weconsiderwhatservicesanoperatingsystemprovides,howthey
are provided, how they are debugged, and what the various methodologies
are for designing such systems. Finally, we describe how operating systems
arecreatedand how a computerstartsits operatingsystem.
CHAPTER OBJECTIVES
•Identify services provided by an operating system.
Illustrate how system calls are used to provide operating system services.
Compare and contrast monolithic, layered, microkernel, modular, and
hybrid strategies for designing operating systems.
Illustrate the process for booting an operating system.
Apply tools for monitoring operating system performance.
Design and implement kernel modules for interacting with a Linux kernel.
2.1 Operating-System Services
Anoperating system providesan environment for the executionof programs.
It makes certain services available to programs and to the users of those pro-
grams. The specific services provided, of course, differ from one operating
55"
2,2.1 Operating-System Services,85,Chapter 2 Operating-System Structures,"2CHAPTER Operating -
System
Structures
An operating system provides the environment within which programs are
executed.Internally,operatingsystemsvarygreatlyintheirmakeup,sincethey
areorganizedalongmanydifferentlines.Thedesignofanewoperatingsystem
is a major task. It is important that the goals of the system be well defined
beforethedesignbegins.Thesegoalsfo rmthebasisforchoicesamongvarious
algorithmsand strategies.
We can view an operating system from several vantage points. One view
focusesonthe servicesthat thesystempr ovides;another,on the interfacethat
it makes available to users and programmers; a third, on its components and
theirinterconnections.Inthischapter,weexploreallthreeaspectsofoperating
systems,showingtheviewpointsofusers,programmers,andoperatingsystem
designers.Weconsiderwhatservicesanoperatingsystemprovides,howthey
are provided, how they are debugged, and what the various methodologies
are for designing such systems. Finally, we describe how operating systems
arecreatedand how a computerstartsits operatingsystem.
CHAPTER OBJECTIVES
•Identify services provided by an operating system.
Illustrate how system calls are used to provide operating system services.
Compare and contrast monolithic, layered, microkernel, modular, and
hybrid strategies for designing operating systems.
Illustrate the process for booting an operating system.
Apply tools for monitoring operating system performance.
Design and implement kernel modules for interacting with a Linux kernel.
2.1 Operating-System Services
Anoperating system providesan environment for the executionof programs.
It makes certain services available to programs and to the users of those pro-
grams. The specific services provided, of course, differ from one operating
55"
2,2.2 User and Operating-System Interface,88,2.1 Operating-System Services,"58 Chapter 2 Operating-System Structures
or herself to the system, usually by means of a password, to gain access
to system resources. It extends to defending external I/Odevices, includ-
ingnetworkadapters,frominvalidaccessattemptsandrecordingallsuch
connections for detection of break-ins. If a system is to be protected and
secure, precautions must be instituted throughout it. A chain is only as
strong asitsweakestlink.
2.2 User and Operating-System Interface
We mentioned earlier that there are several ways for users to interface with
the operating system. Here, we discuss three fundamental approaches. One
providesacommand-lineinterface,or command interpreter ,thatallowsusers
todirectlyentercommandstobeperformedbytheoperatingsystem.Theother
two allow users to interface with the operating system via a graphical user
interface,or GUI.
2.2.1 Command Interpreters
Most operating systems, including Linux, UNIX, and Windows, treat the com-
mand interpreter as a special program that is running when a process is ini-
tiated or when a user first logs on (on interactive systems). On systems with
multiple command interpreters to choose from, the interpreters are known as
shells.Forexample,on UNIXandLinuxsystems,ausermaychooseamongsev-
eraldifferentshells,includingthe Cs h e l l,Bourne-Again shell ,Korn shell ,and
others. Third-party shells and free user-written shells are also available. Most
shells provide similar functionality, and a user’s choice of which shell to use
isgenerallybasedon personalpreference.Figure2.2 shows theBourne-Again
(orbash)shellcommand interpreterbeing used on mac OS.
Themainfunctionofthecommandinterpreteristogetandexecutethenext
user-specified command. Many of the commands given at this level manipu-
late files: create, delete, list, print, copy, execute, and so on. The various shells
availableon UNIXsystemsoperateinthisway.Thesecommandscanbeimple-
mentedintwo generalways.
In one approach, the command interpreter itself contains the code to exe-
cute the command. For example, a command to delete a file may cause the
commandinterpretertojumptoasectionofitscodethatsetsuptheparameters
and makesthe appropriatesystemcall.In thiscase, thenumber of commands
that can be given determines the size o f the command interpreter, since each
command requiresitsown implementingcode.
An alternative approach—used by UNIX, among other operating systems
—implements most commands through system programs. In this case, the
commandinterpreterdoesnotunderstandthecommandinanyway;itmerely
uses the command to identify a file to be loaded into memory and executed.
Thus, the UNIXcommand to deletea file
rm file.txt
wouldsearchforafilecalled rm,loadthefileintomemory,andexecuteitwith
theparameter file.txt .Thelogicassociatedwiththe rmcommandwouldbe"
3,2.2.1 Command Interpreters,88,2.2 User and Operating-System Interface,"58 Chapter 2 Operating-System Structures
or herself to the system, usually by means of a password, to gain access
to system resources. It extends to defending external I/Odevices, includ-
ingnetworkadapters,frominvalidaccessattemptsandrecordingallsuch
connections for detection of break-ins. If a system is to be protected and
secure, precautions must be instituted throughout it. A chain is only as
strong asitsweakestlink.
2.2 User and Operating-System Interface
We mentioned earlier that there are several ways for users to interface with
the operating system. Here, we discuss three fundamental approaches. One
providesacommand-lineinterface,or command interpreter ,thatallowsusers
todirectlyentercommandstobeperformedbytheoperatingsystem.Theother
two allow users to interface with the operating system via a graphical user
interface,or GUI.
2.2.1 Command Interpreters
Most operating systems, including Linux, UNIX, and Windows, treat the com-
mand interpreter as a special program that is running when a process is ini-
tiated or when a user first logs on (on interactive systems). On systems with
multiple command interpreters to choose from, the interpreters are known as
shells.Forexample,on UNIXandLinuxsystems,ausermaychooseamongsev-
eraldifferentshells,includingthe Cs h e l l,Bourne-Again shell ,Korn shell ,and
others. Third-party shells and free user-written shells are also available. Most
shells provide similar functionality, and a user’s choice of which shell to use
isgenerallybasedon personalpreference.Figure2.2 shows theBourne-Again
(orbash)shellcommand interpreterbeing used on mac OS.
Themainfunctionofthecommandinterpreteristogetandexecutethenext
user-specified command. Many of the commands given at this level manipu-
late files: create, delete, list, print, copy, execute, and so on. The various shells
availableon UNIXsystemsoperateinthisway.Thesecommandscanbeimple-
mentedintwo generalways.
In one approach, the command interpreter itself contains the code to exe-
cute the command. For example, a command to delete a file may cause the
commandinterpretertojumptoasectionofitscodethatsetsuptheparameters
and makesthe appropriatesystemcall.In thiscase, thenumber of commands
that can be given determines the size o f the command interpreter, since each
command requiresitsown implementingcode.
An alternative approach—used by UNIX, among other operating systems
—implements most commands through system programs. In this case, the
commandinterpreterdoesnotunderstandthecommandinanyway;itmerely
uses the command to identify a file to be loaded into memory and executed.
Thus, the UNIXcommand to deletea file
rm file.txt
wouldsearchforafilecalled rm,loadthefileintomemory,andexecuteitwith
theparameter file.txt .Thelogicassociatedwiththe rmcommandwouldbe"
3,2.2.2 Graphical User Interface,89,2.2.1 Command Interpreters,"2.2 User and Operating-System Interface 59
Figure 2.2 Thebash shell command interpreter in macOS.
defined completely by the code in the file rm. In this way, programmers can
addnewcommandstothesystemeasilybycreatingnewfileswiththeproper
program logic. The command-interpreter program, which can be small, does
not have to be changed for new commands to be added.
2.2.2 Graphical User Interface
Asecond strategy for interfacing with the operating systemis through a user-
friendlygraphicaluserinterface,or GUI.Here,ratherthanenteringcommands
directly via a command-line interface, users employ a mouse-based window-
and-menu system characterized by a desktop metaphor. The user moves the
mouse to position its pointer on images, or icons, on the screen (the desktop)
that represent programs, files, directories, and system functions. Depending
on the mouse pointer’s location, clicking a button on the mouse can invoke a
program,selectafileordirectory—knownasa folder—orpulldownamenu
thatcontains commands.
Graphical user interfaces first appeared due in part to research taking
place in the early 1970s at Xerox PARCresearch facility.The first GUIappeared
on the Xerox Alto computer in 1973. How ever, graphical interfaces became
morewidespreadwiththeadventofAppleMacintoshcomputersinthe1980s.
The user interface for the Macintosh operating system has undergone various
changes over the years, the most significant being the adoption of the Aqua
interface that appeared with mac OS. Microsoft’s first version of Windows—
Version 1.0—was based on the addition of a GUIinterface to the MS-DOS
operatingsystem.LaterversionsofWin dowshavemadesignificantchangesin
theappearanceofthe GUIalongwithseveralenhancementsinitsfunctionality."
3,2.2.3 Touch-Screen Interface,90,2.2.2 Graphical User Interface,"60 Chapter 2 Operating-System Structures
Traditionally, UNIXsystemshavebeendominatedby command-line inter-
faces. Various GUIinterfaces are available, however, with significant develop-
ment in GUIdesigns from various open-source projects, such as K Desktop
Environment (orKDE)a n dt h e GNOMEdesktop by the GNUproject. Both the
KDEandGNOMEdesktops run on Linux and various UNIXsystems and are
availableunderopen-sourcelicenses,whichmeanstheirsourcecodeisreadily
availablefor readingand for modifi cation underspecific licenseterms.
2.2.3 Touch-Screen Interface
Becauseaeitheracommand-lineinterfaceoramouse-and-keyboardsystemis
impractical for most mobile systems, smartphones and handheld tablet com-
puters typically use a touch-screen inte rface. Here, users interact by making
gestures on the touch screen—for example, pressing and swiping fingers
acrossthescreen.Althoughearliersmartphonesincludedaphysicalkeyboard,
most smartphones and tablets now simulate a keyboard on the touch screen.
Figure 2.3 illustrates the touch screen of the Apple iPhone. Both the iPad and
the iPhone use the Springboard touch-screeninterface.
2.2.4 Choice of Interface
The choice of whether to use a command-line or GUIinterface is mostly
one of personal preference. System administrators who manage computers
and power users who have deep knowledge of a system frequently use the
Figure 2.3 The iPhone touch screen."
3,2.2.4 Choice of Interface,90,2.2.3 Touch-Screen Interface,"60 Chapter 2 Operating-System Structures
Traditionally, UNIXsystemshavebeendominatedby command-line inter-
faces. Various GUIinterfaces are available, however, with significant develop-
ment in GUIdesigns from various open-source projects, such as K Desktop
Environment (orKDE)a n dt h e GNOMEdesktop by the GNUproject. Both the
KDEandGNOMEdesktops run on Linux and various UNIXsystems and are
availableunderopen-sourcelicenses,whichmeanstheirsourcecodeisreadily
availablefor readingand for modifi cation underspecific licenseterms.
2.2.3 Touch-Screen Interface
Becauseaeitheracommand-lineinterfaceoramouse-and-keyboardsystemis
impractical for most mobile systems, smartphones and handheld tablet com-
puters typically use a touch-screen inte rface. Here, users interact by making
gestures on the touch screen—for example, pressing and swiping fingers
acrossthescreen.Althoughearliersmartphonesincludedaphysicalkeyboard,
most smartphones and tablets now simulate a keyboard on the touch screen.
Figure 2.3 illustrates the touch screen of the Apple iPhone. Both the iPad and
the iPhone use the Springboard touch-screeninterface.
2.2.4 Choice of Interface
The choice of whether to use a command-line or GUIinterface is mostly
one of personal preference. System administrators who manage computers
and power users who have deep knowledge of a system frequently use the
Figure 2.3 The iPhone touch screen."
2,2.3 System Calls,92,2.2 User and Operating-System Interface,"62 Chapter 2 Operating-System Structures
user programs. From the point of view of the operating system, we do not
distinguishbetweenuserprogramsand systemprograms.
2.3 System Calls
System calls provideaninterfacetotheservicesmadeavailablebyanoperat-
ing system. These calls are generally available as functions written in C and
C++, although certain low-level tasks (for example, tasks where hardware
must be accessed directly) may have to be written using assembly-language
instructions.
2.3.1 Example
Beforewediscusshowanoperatingsystemmakessystemcallsavailable,let’s
first use an example to illustrate how system calls are used: writing a simple
program to read data from one file and copy them to another file. The first
input that the program will need is the names of the two files: the input file
and the output file. These names can be specified in many ways, depending
ontheoperating-systemdesign.Oneapproachistopassthenamesofthetwo
filesas partof thecommand—for example,the UNIX cpcommand:
cp in.txt out.txt
This command copies the input file in.txtto the output file out.txt .As e c -
ondapproachisfortheprogramtoasktheuserforthenames.Inaninteractive
system, this approach will require a sequence of system calls, first to write
a prompting message on the screen and then to read from the keyboard the
characters that define the two files. On mouse-based and icon-based systems,
a menu of file names is usually displayed in a window. The user can then use
the mouse to select the source name, and a window can be opened for the
destinationnametobespecified.Thissequencerequiresmany I/Osystemcalls.
Once the two file names have been obtained, the program must open the
inputfileandcreateandopentheoutputfile.Eachoftheseoperationsrequires
another system call. Possible error conditions for each system call must be
handled. For example, when the program tries to open the input file, it may
findthatthereisnofileofthatnameorthatthefileisprotectedagainstaccess.
Inthesecases,theprogramshouldoutputanerrormessage(anothersequence
of system calls) and then terminate abnormally (another system call). If the
inputfileexists,thenwemustcreateanewoutputfile.Wemayfindthatthere
is already an output file with the same name. This situation may cause the
program to abort (a system call), or we may delete the existing file (another
systemcall)andcreateanewone(yetanothersystemcall).Anotheroption,in
aninteractivesystem,istoasktheuser(viaasequenceofsystemcallstooutput
the prompting message and to read the response from the terminal) whether
to replacethe existingfile orto abort the program.
When both files are set up, we enter a loop that reads from the input
file (a system call) and writes to the output file (another system call). Each
readandwritemustreturnstatusinformationregardingvariouspossibleerror
conditions. On input, the program may find that the end of the file has been"
3,2.3.1 Example,92,2.3 System Calls,"62 Chapter 2 Operating-System Structures
user programs. From the point of view of the operating system, we do not
distinguishbetweenuserprogramsand systemprograms.
2.3 System Calls
System calls provideaninterfacetotheservicesmadeavailablebyanoperat-
ing system. These calls are generally available as functions written in C and
C++, although certain low-level tasks (for example, tasks where hardware
must be accessed directly) may have to be written using assembly-language
instructions.
2.3.1 Example
Beforewediscusshowanoperatingsystemmakessystemcallsavailable,let’s
first use an example to illustrate how system calls are used: writing a simple
program to read data from one file and copy them to another file. The first
input that the program will need is the names of the two files: the input file
and the output file. These names can be specified in many ways, depending
ontheoperating-systemdesign.Oneapproachistopassthenamesofthetwo
filesas partof thecommand—for example,the UNIX cpcommand:
cp in.txt out.txt
This command copies the input file in.txtto the output file out.txt .As e c -
ondapproachisfortheprogramtoasktheuserforthenames.Inaninteractive
system, this approach will require a sequence of system calls, first to write
a prompting message on the screen and then to read from the keyboard the
characters that define the two files. On mouse-based and icon-based systems,
a menu of file names is usually displayed in a window. The user can then use
the mouse to select the source name, and a window can be opened for the
destinationnametobespecified.Thissequencerequiresmany I/Osystemcalls.
Once the two file names have been obtained, the program must open the
inputfileandcreateandopentheoutputfile.Eachoftheseoperationsrequires
another system call. Possible error conditions for each system call must be
handled. For example, when the program tries to open the input file, it may
findthatthereisnofileofthatnameorthatthefileisprotectedagainstaccess.
Inthesecases,theprogramshouldoutputanerrormessage(anothersequence
of system calls) and then terminate abnormally (another system call). If the
inputfileexists,thenwemustcreateanewoutputfile.Wemayfindthatthere
is already an output file with the same name. This situation may cause the
program to abort (a system call), or we may delete the existing file (another
systemcall)andcreateanewone(yetanothersystemcall).Anotheroption,in
aninteractivesystem,istoasktheuser(viaasequenceofsystemcallstooutput
the prompting message and to read the response from the terminal) whether
to replacethe existingfile orto abort the program.
When both files are set up, we enter a loop that reads from the input
file (a system call) and writes to the output file (another system call). Each
readandwritemustreturnstatusinformationregardingvariouspossibleerror
conditions. On input, the program may find that the end of the file has been"
3,2.3.2 Application Programming Interface,93,2.3.1 Example,"2.3 System Calls 63
Example System-Call Sequence
Acquire input file name
  Write prompt to screen
  Accept input
Acquire output file name
  Write prompt to screen
  Accept input
Open the input file
  if file doesn't exist, abort
Create output file
  if file exists, abort
Loop
  Read from input file
  Write to output file
Until read fails
Close output file
Write completion message to screen
Terminate normallydestination file source file
Figure 2.5 Example of how system calls are used.
reachedorthattherewasahardwarefailureintheread(suchasaparityerror).
The write operation may encounter various errors, depending on the output
device(for example,no moreavailablediskspace).
Finally, after the entire file is copied, the program may close both files
(two system calls), write a message to the console or window (more system
calls), and finally terminate normally (the final system call). This system-call
sequenceis shown inFigure2.5.
2.3.2 Application Programming Interface
As you can see, even simple programs may make heavy use of the operat-
ingsystem.Frequently,systemsexecute thousandsofsystemcallspersecond.
Most programmers never see this level of detail, however. Typically, applica-
tion developers design programs according to an application programming
interface (API).TheAPIspecifiesasetoffunctionsthatareavailabletoanappli-
cation programmer,including theparametersthat arepassedtoeach function
and the returnvalues the programmer can expect. Three of the most common
APIs available to application programmers are the Windows APIfor Windows
systems, the POSIX API forPOSIX-based systems (which include virtually all
versions of UNIX,L i n u x ,a n dm a c OS), and the Java APIfor programs that run
ontheJavavirtualmachine.Aprogrammeraccessesan APIviaalibraryofcode
providedbytheoperatingsystem.Inthecaseof UNIXandLinuxforprograms
writtenintheClanguage,thelibraryiscalled libc.Notethat—unlessspecified
—thesystem-callnamesusedthroughoutthistextaregenericexamples.Each
operatingsystemhas its ownname for eachsystemcall.
Behind the scenes, the functions that make up an APItypically invoke the
actual system calls on behalf of the application programmer.For example,the
Windows function CreateProcess() (which,unsurprisingly,isusedtocreate"
3,2.3.3 Types of System Calls,96,2.3.2 Application Programming Interface,"66 Chapter 2 Operating-System Structures
code for 
system 
call 13use parameters
from table  Xregister
load address X
system call 13X
X: parameters
for call
operating systemuser program
Figure 2.7 Passing of parameters as a table.
registers are used. If there are more than five parameters, the block method is
used. Parameters also can be placed, or pushed,o n t oa stackby the program
and popped off the stack by the operating system. Some operating systems
prefer the block or stack method because those approaches do not limit the
number or lengthof parametersbeing passed.
2.3.3 Types of System Calls
Systemcallscanbegroupedroughlyintosixmajorcategories: process control ,
fil management ,device management ,information maintenance ,communi-
cations,and protection .Below,webrieflydiscussthetypesofsystemcallsthat
may be provided by an operating system. Most of these system calls support,
or are supported by, concepts and functions that are discussed in later chap-
ters.Figure2.8summarizesthetypesofsystemcallsnormallyprovidedbyan
operating system. As mentioned, in this text, we normally refer to the system
calls by generic names. Throughout the text, however, we provide examples
of the actual counterparts to the system calls for UNIX, Linux, and Windows
systems.
2.3.3.1 Process Control
A running program needs to be able to halt its execution either normally
(end()) or abnormally ( abort() ). If a system call is made to terminate the
currently running program abnormally, or if the program runs into a problem
and causes an error trap, a dump of memory is sometimes taken and an
error message generated. The dump is written to a special log file on disk
and may be examined by a debugger —a system program designed to aid
the programmer in finding and correcting errors, or bugs—to determine the
cause of the problem. Under either normal or abnormal circumstances, the
operating system must transfer control to the invoking command interpreter.
The command interpreter then reads the next command. In an interactive
system, the command interpreter simply continues with the next command;
it is assumed that the user will issue an appropriate command to respond to"
2,2.4 System Services,104,2.3 System Calls,"74 Chapter 2 Operating-System Structures
resourcessuchasfilesanddisks.The allow
 user()anddeny
 user()system
calls specify whether particular users can—or cannot—be allowed access
to certain resources. We cover protection in Chapter 17 and the much larger
issue of security—which involves using p rotection against external threats—
inChapter16.
2.4 System Services
Another aspect of a modern system is its collection of system services. Recall
Figure 1.1, which depicted the logical computer hierarchy. At the lowest level
ishardware.Nextistheoperatingsystem,thenthesystemservices,andfinally
the application programs. System services ,a l s ok n o w na s system utilities ,
provide a convenient environment for program development and execution.
Some of them are simply user interfaces to system calls. Others are consider-
ably morecomplex.Theycan bedividedinto thesecategories:
•File management .Theseprogramscreate,delete,copy,rename,print,list,
and generallyaccess and manipulatefilesand directories.
•Status information . Some programs simply ask the system for the date,
time, amount of available memory or disk space, number of users, or
similar status information. Others are more complex, providing detailed
performance, logging, and debugging information. Typically, these pro-
gramsformatandprinttheoutputtotheterminalorotheroutputdevices
or files or display it in a window of the GUI. Some systems also support a
registry, which is usedto store and retrieveconfiguration information.
•File modificatio .Severaltexteditorsmaybeavailabletocreateandmod-
ify the content of files stored on disk or other storage devices. There may
also be special commands to search contents of files or perform transfor-
mations of the text.
•Programming-language support .Compilers,assemblers,debuggers,and
interpreters for common programming languages (such as C, C++, Java,
and Python) are often provided with the operating system or available as
a separatedownload.
•Program loading and execution . Once a program is assembled or com-
piled, it must be loaded into memory to be executed. The system may
provideabsoluteloaders,relocatableloaders,linkageeditors,andoverlay
loaders. Debugging systems for either higher-level languages or machine
language areneededas well.
•Communications . These programs provide the mechanism for creating
virtual connections among processes, users, and computer systems. They
allow users to send messages to one another’s screens, to browse web
pages,tosende-mailmessages,tologinremotely,ortotransferfilesfrom
one machine to another.
•Background services . All general-purpose systems have methods for
launching certain system-program processes at boot time. Some of these
processes terminate after completing their tasks, while others continue to"
2,2.5 Linkers and Loaders,105,2.4 System Services,"2.5 Linkers and Loaders 75
run until the system is halted. Constantly running system-program pro-
cesses are known as services,subsystems , or daemons. One example is
the network daemon discussed in Section 2.3.3.5. In that example, a sys-
temneededaservicetolistenfornetworkconnectionsinordertoconnect
those requests to the correct processes. Other examples include process
schedulers that start processes acco rding to a specified schedule, system
errormonitoringservices,andprintservers.Typicalsystemshavedozens
ofdaemons.Inaddition,operatingsystemsthatrunimportantactivitiesin
user context rather than in kernel context may use daemons to run these
activities.
Along with system programs, most operating systems are supplied with
programsthatareusefulinsolvingcommonproblemsorperformingcommon
operations. Such application programs include web browsers, word proces-
sors and text formatters, spreadsheets, database systems, compilers, plotting
andstatistical-analysispackages,and games.
The view of the operating system seen by most users is defined by the
applicationandsystemprograms,ratherthan bytheactualsystemcalls.Con-
sider a user’s PC. When a user’s computer is running the mac OSoperating
system,theusermightseethe GUI,featuringamouse-and-windowsinterface.
Alternatively,oreveninoneofthewindows,theusermighthaveacommand-
lineUNIXshell.Bothusethesamesetofsystemcalls,butthesystemcallslook
different and act in different ways. Further confusing the user view, consider
the user dual-booting from mac OSinto Windows. Now the same user on the
same hardware has two entirely different interfaces and two sets of applica-
tions using the same physical resources. On the same hardware, then, a user
canbe exposedtomultipleuserinterfacessequentiallyor concurrently.
2.5 Linkers and Loaders
Usually, a program resides on disk as a binary executable file—for example,
a.outorprog.exe .T orunona CPU,theprogrammustbebroughtintomem-
oryandplacedinthecontextofaprocess.Inthissection,wedescribethesteps
inthisprocedure,fromcompilingaprogramtoplacingitinmemory,whereit
becomes eligible to run on an available CPUcore. The steps are highlighted in
Figure2.11.
Source files are compiled into object files that are designed to be loaded
into any physical memory location, a format known as an relocatable object
fil.Next,the linkercombinestheserelocatableob jectfilesintoasinglebinary
executable file.During the linkingphase, otherobject files or librariesmay be
includedaswell,suchasthestandardCormathlibrary(specifiedwiththeflag
-lm).
Aloaderisusedtoloadthebinaryexecutablefileintomemory,whereitis
eligible to run on a CPUcore. An activity associated with linking and loading
isrelocation , which assigns final addresses to the program parts and adjusts
codeanddataintheprogramtomatchthoseaddressessothat,forexample,the
codecan call library functions and access itsvariablesas it executes.InFigure
2.11,weseethattoruntheloader,allthatisnecessaryistoenterthenameofthe
executable file on the command line. When a program name is enteredon the"
2,2.6 Why Applications Are Operating-System Specific,107,2.5 Linkers and Loaders,"2.6 Why Applications Are Operating-System Specifi 77
ELF FORMAT
Linux provides various commands to identify and evaluate ELFfiles. For
example, the filecommand determines a file type. If main.o is an object
file, and mainis anexecutablefile, thecommand
file main.o
will reportthat main.ois anELFrelocatablefile,while thecommand
file main
willreportthat mainisanELFexecutable. ELFfilesaredividedintoanumber
ofsections andcanbeevaluatedusing the readelf command.
executable files. One piece of information in the ELFfile for executable files is
the program’s entry point, which contains the address of the first instruction
to be executed when the program runs. Windows systems use the Portable
Executable (PE) format,and mac OSusesthe Mach-O format.
2.6 Why Applications Are Operating-System Speciﬁc
Fundamentally, applications compiled on one operating system are not exe-
cutable on other operating systems. If they were, the world would be a better
place,andourchoiceofwhatoperatingsystemtousewoulddependonutility
and featuresratherthan which applicationswere available.
Basedonourearlierdiscussion,wecannowseepartoftheproblem—each
operatingsystemprovidesauniquesetofsystemcalls.Systemcallsarepartof
thesetofservicesprovidedbyoperatingsystemsforusebyapplications.Even
if system calls were somehow uniform, other barriers would make it difficult
for us to execute application programs on different operating systems. But if
you have used multiple operating systems, you may have used some of the
sameapplicationson them.How isthat possible?
Anapplicationcanbemadeavailabletorunonmultipleoperatingsystems
inone of three ways:
1.Theapplicationcanbewritteninaninterpretedlanguage(suchasPython
orRuby)thathasaninterpreteravailableformultipleoperatingsystems.
Theinterpreterreadseachlineofthesourceprogram,executesequivalent
instructions on the native instruction set, and calls native operating sys-
temcalls.Performancesuffersrelativetothatfornativeapplications,and
theinterpreterprovidesonlyasubsetofeachoperatingsystem’sfeatures,
possiblylimitingthefeaturesetsof the associatedapplications.
2.The application can be written in a language that includes a virtual
machine containing the running application. The virtual machine is part
ofthelanguage’sfull RTE.OneexampleofthismethodisJava.Javahasan
RTEthat includesaloader,byte-code verifier,and othercomponents that
loadtheJavaapplicationintotheJavavirtualmachine.This RTEhasbeen"
2,2.7 Operating-System Design and Implementation,109,2.6 Why Applications Are Operating-System Specific,"2.7 Operating-System Design and Implementation 79
oftherun-timestack,thebinaryformatofsystemlibraries,andthesizeofdata
types,just to name a few. Typically,an ABIis specifiedfor a givenarchitecture
(for example, there is an ABIfor the ARMv8 processor). Thus, an ABIis the
architecture-level equivalent of an API. If a binary executable file has been
compiled and linked according to a particular ABI,i ts h o u l db ea b l et or u no n
different systems that support that ABI. However, because a particular ABIis
definedforacertainoperatingsystemrunningonagivenarchitecture, ABIsdo
littletoprovidecross-platformcompatibility.
In sum, all of these differences mean that unless an interpreter, RTE,o r
binaryexecutablefileiswrittenforandcompiledonaspecificoperatingsystem
on a specific CPUtype(such as Intelx86 or ARMv8), the applicationwillfail to
run. Imagine the amount of work that is required for a program such as the
Firefox browser to run on Windows, mac OS, various Linux releases, i OS,a n d
Android,sometimesonvarious CPUarchitectures.
2.7 Operating-System Design and Implementation
Inthissection,wediscussproblemswefaceindesigningandimplementingan
operatingsystem.Thereare,ofcourse,nocompletesolutionstosuchproblems,
but thereareapproaches that haveprovedsuccessful.
2.7.1 Design Goals
Thefirstproblemindesigningasystemis todefinegoalsandspecifications.At
thehighestlevel,thedesignofthesystemwillbeaffectedbythechoiceofhard-
ware and the type of system: traditional desktop/laptop, mobile, distributed,
orrealtime.
Beyondthishighestdesignlevel,therequirementsmaybemuchharderto
specify.Therequirementscan,however,bedividedintotwobasicgroups: user
goalsand system goals .
Users want certain obvious properties in a system. The system should be
convenient to use, easy to learn and to use, reliable, safe, and fast. Of course,
thesespecificationsarenotparticularly usefulinthesystemdesign,sincethere
isno generalagreementonhow to achievethem.
Asimilar set of requirements can be defined by the developers who must
design,create,maintain,andoperatethesystem.Thesystemshouldbeeasyto
design,implement,andmaintain;anditshouldbeflexible,reliable,errorfree,
and efficient. Again, these requirements are vague and may be interpreted in
variousways.
Thereis,inshort,nouniquesolutiontotheproblemofdefiningtherequire-
ments for an operating system. The wide range of systems in existence shows
thatdifferentrequirementscanresultinalargevarietyofsolutionsfordifferent
environments.Forexample,therequirementsforWindRiverVxWorks,areal-
time operating system for embedded systems, must have been substantially
differentfromthoseforWindowsServer,alargemultiaccessoperatingsystem
designedfor enterpriseapplications.
Specifying and designing an operating system is a highly creative task.
Although no textbook can tell you how to do it, general principles have been"
3,2.7.1 Design Goals,109,2.7 Operating-System Design and Implementation,"2.7 Operating-System Design and Implementation 79
oftherun-timestack,thebinaryformatofsystemlibraries,andthesizeofdata
types,just to name a few. Typically,an ABIis specifiedfor a givenarchitecture
(for example, there is an ABIfor the ARMv8 processor). Thus, an ABIis the
architecture-level equivalent of an API. If a binary executable file has been
compiled and linked according to a particular ABI,i ts h o u l db ea b l et or u no n
different systems that support that ABI. However, because a particular ABIis
definedforacertainoperatingsystemrunningonagivenarchitecture, ABIsdo
littletoprovidecross-platformcompatibility.
In sum, all of these differences mean that unless an interpreter, RTE,o r
binaryexecutablefileiswrittenforandcompiledonaspecificoperatingsystem
on a specific CPUtype(such as Intelx86 or ARMv8), the applicationwillfail to
run. Imagine the amount of work that is required for a program such as the
Firefox browser to run on Windows, mac OS, various Linux releases, i OS,a n d
Android,sometimesonvarious CPUarchitectures.
2.7 Operating-System Design and Implementation
Inthissection,wediscussproblemswefaceindesigningandimplementingan
operatingsystem.Thereare,ofcourse,nocompletesolutionstosuchproblems,
but thereareapproaches that haveprovedsuccessful.
2.7.1 Design Goals
Thefirstproblemindesigningasystemis todefinegoalsandspecifications.At
thehighestlevel,thedesignofthesystemwillbeaffectedbythechoiceofhard-
ware and the type of system: traditional desktop/laptop, mobile, distributed,
orrealtime.
Beyondthishighestdesignlevel,therequirementsmaybemuchharderto
specify.Therequirementscan,however,bedividedintotwobasicgroups: user
goalsand system goals .
Users want certain obvious properties in a system. The system should be
convenient to use, easy to learn and to use, reliable, safe, and fast. Of course,
thesespecificationsarenotparticularly usefulinthesystemdesign,sincethere
isno generalagreementonhow to achievethem.
Asimilar set of requirements can be defined by the developers who must
design,create,maintain,andoperatethesystem.Thesystemshouldbeeasyto
design,implement,andmaintain;anditshouldbeflexible,reliable,errorfree,
and efficient. Again, these requirements are vague and may be interpreted in
variousways.
Thereis,inshort,nouniquesolutiontotheproblemofdefiningtherequire-
ments for an operating system. The wide range of systems in existence shows
thatdifferentrequirementscanresultinalargevarietyofsolutionsfordifferent
environments.Forexample,therequirementsforWindRiverVxWorks,areal-
time operating system for embedded systems, must have been substantially
differentfromthoseforWindowsServer,alargemultiaccessoperatingsystem
designedfor enterpriseapplications.
Specifying and designing an operating system is a highly creative task.
Although no textbook can tell you how to do it, general principles have been"
3,2.7.2 Mechanisms and Policies,110,2.7.1 Design Goals,"80 Chapter 2 Operating-System Structures
developedin the field of software engineering , and we turn now to a discus-
sion of someof theseprinciples.
2.7.2 Mechanisms and Policies
One important principle is the separation of policyfrom mechanism .M e c h a -
nisms determine howto do something; policiesdetermine whatwill be done.
Forexample,thetimerconstruct(seeSection1.4.3)isamechanismforensuring
CPUprotection,butdecidinghowlongthetimeristobesetforaparticularuser
isa policydecision.
Theseparationofpolicyandmechanismisimportantforflexibility.Policies
are likely to change across places or over time. In the worst case, each change
in policy would require a change in th e underlying mechanism. A general
mechanism flexible enough to work acro ss a range of policies is preferable.
Achange inpolicy would thenrequireredefinitionof only certainparameters
ofthesystem.Forinstance,considerame chanismforgivingprioritytocertain
types of programs over others. If the mechanism is properly separated from
policy, it can be used either to support a policy decision that I/O-intensive
programs should have priority over CPU-intensive ones or to support the
oppositepolicy.
Microkernel-based operating systems (discussed in Section 2.8.3) take the
separation of mechanism and policy to one extreme by implementing a basic
set of primitive building blocks. These b locks are almost policy free, allowing
more advanced mechanisms and policies to be added via user-created kernel
modules or user programs themselves. In contrast, consider Windows, an
enormously popular commercial operating system available for over three
decades. Microsoft has closely encoded both mechanism and policy into the
systemtoenforceagloballookandfeelacrossalldevicesthatruntheWindows
operatingsystem.Allapplicationshavesimilarinterfaces,becausetheinterface
itselfis built into the kerneland system libraries.Applehas adopteda similar
strategywithitsmac OSand iOSoperatingsystems.
We can make a similar comparison between commercial and open-source
operating systems. For instance, contrast Windows, discussed above, with
Linux, an open-source operating system that runs on a wide range of com-
putingdevicesandhasbeenavailableforover25years.The “standard ”Linux
kernelhasaspecific CPUschedulingalgorithm(cover edinSection5.7.1),which
is a mechanism that supports a certain policy. However, anyone is free to
modifyor replacethe schedulerto supporta differentpolicy.
Policy decisions are important for all resource allocation. Whenever it is
necessarytodecidewhetherornottoallocatearesource,apolicydecisionmust
be made. Whenever the question is howrather than what,i ti sam e c h a n i s m
that mustbe determined.
2.7.3 Implementation
Onceanoperatingsystemisdesigned,itmustbeimplemented.Becauseoper-
atingsystemsarecollectionsofmany programs,writtenbymany peopleover
alongperiodoftime,itisdifficulttomakegeneralstatementsabouthowthey
areimplemented.
Early operating systems were written in assembly language. Now, most
are written in higher-level languages such as C or C++, with small amounts"
3,2.7.3 Implementation,110,2.7.2 Mechanisms and Policies,"80 Chapter 2 Operating-System Structures
developedin the field of software engineering , and we turn now to a discus-
sion of someof theseprinciples.
2.7.2 Mechanisms and Policies
One important principle is the separation of policyfrom mechanism .M e c h a -
nisms determine howto do something; policiesdetermine whatwill be done.
Forexample,thetimerconstruct(seeSection1.4.3)isamechanismforensuring
CPUprotection,butdecidinghowlongthetimeristobesetforaparticularuser
isa policydecision.
Theseparationofpolicyandmechanismisimportantforflexibility.Policies
are likely to change across places or over time. In the worst case, each change
in policy would require a change in th e underlying mechanism. A general
mechanism flexible enough to work acro ss a range of policies is preferable.
Achange inpolicy would thenrequireredefinitionof only certainparameters
ofthesystem.Forinstance,considerame chanismforgivingprioritytocertain
types of programs over others. If the mechanism is properly separated from
policy, it can be used either to support a policy decision that I/O-intensive
programs should have priority over CPU-intensive ones or to support the
oppositepolicy.
Microkernel-based operating systems (discussed in Section 2.8.3) take the
separation of mechanism and policy to one extreme by implementing a basic
set of primitive building blocks. These b locks are almost policy free, allowing
more advanced mechanisms and policies to be added via user-created kernel
modules or user programs themselves. In contrast, consider Windows, an
enormously popular commercial operating system available for over three
decades. Microsoft has closely encoded both mechanism and policy into the
systemtoenforceagloballookandfeelacrossalldevicesthatruntheWindows
operatingsystem.Allapplicationshavesimilarinterfaces,becausetheinterface
itselfis built into the kerneland system libraries.Applehas adopteda similar
strategywithitsmac OSand iOSoperatingsystems.
We can make a similar comparison between commercial and open-source
operating systems. For instance, contrast Windows, discussed above, with
Linux, an open-source operating system that runs on a wide range of com-
putingdevicesandhasbeenavailableforover25years.The “standard ”Linux
kernelhasaspecific CPUschedulingalgorithm(cover edinSection5.7.1),which
is a mechanism that supports a certain policy. However, anyone is free to
modifyor replacethe schedulerto supporta differentpolicy.
Policy decisions are important for all resource allocation. Whenever it is
necessarytodecidewhetherornottoallocatearesource,apolicydecisionmust
be made. Whenever the question is howrather than what,i ti sam e c h a n i s m
that mustbe determined.
2.7.3 Implementation
Onceanoperatingsystemisdesigned,itmustbeimplemented.Becauseoper-
atingsystemsarecollectionsofmany programs,writtenbymany peopleover
alongperiodoftime,itisdifficulttomakegeneralstatementsabouthowthey
areimplemented.
Early operating systems were written in assembly language. Now, most
are written in higher-level languages such as C or C++, with small amounts"
2,2.8 Operating-System Structure,111,2.7 Operating-System Design and Implementation,"2.8 Operating-System Structure 81
of the system written in assembly language. In fact, more than one higher-
level language is often used. The lowest levels of the kernel might be written
in assembly language and C. Higher-level routines might be written in C and
C++, and system libraries might be written in C++ or even higher-level lan-
guages.Androidprovidesaniceexample:itskerneliswrittenmostlyinCwith
some assembly language. Most Android system libraries are written in C or
C++,anditsapplicationframeworks—which providethedeveloperinterface
tothesystem—arewrittenmostlyinJava.WecoverAndroid’sarchitecturein
moredetailinSection2.8.5.2.
The advantages of using a higher-level language, or at least a systems-
implementation language, for implementing operating systems are the same
asthosegainedwhen thelanguageisusedfor applicationprograms:the code
canbewrittenfaster,ismorecompact,andiseasiertounderstandanddebug.
In addition, improvements in compiler technology will improve the gener-
ated code for the entire operating system by simple recompilation. Finally,
an operating system is far easier to port to other hardware if it is written in
a higher-level language. This is particularly important for operating systems
that are intended to run on several different hardware systems, such as small
embedded devices, Intel x86 systems, and ARMchips running on phones and
tablets.
Theonlypossibledisadvantagesofimplementinganoperatingsystemina
higher-level language are reduced speed and increased storage requirements.
This, however, is not a major issue in today’s systems. Although an expert
assembly-languageprogrammercanproduceefficientsmallroutines,forlarge
programsamoderncompilercanperformcomplexanalysisandapplysophis-
ticated optimizations that produce e xcellent code. Modern processors have
deep pipelining and multiple function al units that can handle the details of
complexdependenciesmuch moreeasilythan can the human mind.
Asistrueinothersystems,majorperformanceimprovementsinoperating
systemsaremorelikelytobetheresultofbetterdatastructuresandalgorithms
thanofexcellentassembly-languagecode.Inaddition,althoughoperatingsys-
temsarelarge,onlyasmallamountofthecodeiscriticaltohighperformance;
theinterrupthandlers, I/Omanager,memorymanager,and CPUschedulerare
probablythemostcritical routines.Afterthesystemiswrittenand isworking
correctly, bottlenecks can be identified and can be refactored to operate more
efficiently.
2.8 Operating-System Structure
A system as large and complex as a modern operating system must be engi-
neeredcarefullyifitistofunctionpr operlyandbemodifiedeasily.Acommon
approach is to partition the task into small components, or modules, rather
than have one single system. Each of these modules should be a well-defined
portionofthesystem,withcarefullydefinedinterfacesandfunctions.Youmay
useasimilarapproachwhenyoustructureyourprograms:ratherthanplacing
allofyourcodeinthe main()function,youinsteadseparatelogicintoanum-
berof functions, clearlyarticulatepara metersand returnvalues,and thencall
those functions from main()."
3,2.8.1 Monolithic Structure,112,2.8 Operating-System Structure,"82 Chapter 2 Operating-System Structureskernel(the users)
shells and commands
compilers and interpreters
system libraries
system-call interface to the kernel
signals terminal
handling
character I/O system
terminal driversfile system
swapping block I/O
system
disk and tape driversCPU scheduling
page replacement
demand paging
virtual memory
kernel interface to the hardware
terminal controllers
terminalsdevice controllers
disks and tapesmemory controllers
physical memory
Figure 2.12 Traditional UNIX system structure.
We briefly discussed the common components of operating systems in
Chapter1.Inthissection,wediscusshowthesecomponentsareinterconnected
and meldedinto a kernel.
2.8.1 Monolithic Structure
Thesimpleststructurefororganizinganoperatingsystemisnostructureatall.
Thatis,placeallofthefunctionalityofthekernelintoasingle,staticbinaryfile
that runs in a single address space. This approach—known as a monolithic
structure—is acommon techniquefor designingoperatingsystems.
An example of such limited structuring is the original UNIXoperating
system, which consists of two separable parts: the kernel and the system
programs.Thekernelisfurtherseparatedintoaseriesofinterfacesanddevice
drivers, which have been added and expanded over the years as UNIXhas
evolved. We can view the traditional UNIXoperating system as being layered
to some extent, as shown in Figure 2.12. Everything below the system-call
interface and above the physical hardw are is the kernel. The kernel provides
the file system, CPUscheduling, memory management, and other operating-
system functions through system calls. Taken in sum, that is an enormous
amount of functionality tobe combined into one single addressspace.
TheLinuxoperatingsystemisbasedon UNIXandisstructuredsimilarly,as
shown in Figure 2.13. Applications typicallyuse the glibcstandardC library
when communicating with the system call interface to the kernel. The Linux
kernel is monolithic in that it runs entirely in kernel mode in a single address
space, but as we shall see in Section 2.8.4, it does have a modular design that
allows thekerneltobe modifiedduring runtime.
Despite the apparent simplicity of monolithic kernels, they are difficult
to implement and extend. Monolithic kernels do have a distinct performance
advantage, however: there is very little overhead in the system-call interface,
andcommunicationwithinthekernelisfast.Therefore,despitethedrawbacks"
3,2.8.2 Layered Approach,113,2.8.1 Monolithic Structure,"2.8 Operating-System Structure 83
glibc standard c library
system-call interface
hardwareapplications
file 
systemsCPU
scheduler
memory
manager
character
devicesblock
devicesnetworks
(TCP/IP)
device drivers
Figure 2.13 Linux system structure.
of monolithic kernels, their speed and efficiency explains why we still see
evidenceofthisstructureinthe UNIX,Linux,andWindowsoperatingsystems.
2.8.2 Layered Approach
The monolithic approach is often known as a tightly coupled system because
changestoonepartofthesystemcanhavewide-rangingeffectsonotherparts.
Alternatively, we could design a loosely coupled system. Such a system is
dividedintoseparate,smallercomponentsthathavespecificandlimitedfunc-
tionality. All these components togeth er comprise the kernel. The advantage
of this modular approach is that changes in one component affect only that
component, and no others, allowing system implementers more freedom in
creatingand changing the inner workings of the system.
Asystemcanbe mademodularinmany ways.One methodisthe layered
approach , in which the operating system is broken into a number of layers
(levels).Thebottomlayer(layer0)isthehardware;thehighest(layer N)isthe
userinterface.This layeringstructureis depictedinFigure2.14.
Anoperating-systemlayerisanimplementationofanabstractobjectmade
up of data and the operations that can manipulate those data. A typical
operating-system layer—say, layer M—consists of data structures and a set
of functions that can be invoked by higher-level layers. Layer M,in turn, can
invokeoperationsonlower-levellayers.
The main advantage of the layered approach is simplicity of construction
anddebugging.Thelayersareselectedsothateachusesfunctions(operations)"
3,2.8.3 Microkernels,114,2.8.2 Layered Approach,"84 Chapter 2 Operating-System Structures
layer N
user interface
•••
layer 1
layer 0
hardware
Figure 2.14 A layered operating system.
and services of only lower-level layers. This approach simplifies debugging
and system verification. The first layer can be debugged without any concern
fortherestofthesystem,because,bydefinition,itusesonlythebasichardware
(which is assumed correct) to implement its functions. Once the first layer is
debugged, its correct functioning can be assumed while the second layer is
debugged,andsoon.Ifanerrorisfoundduringthedebuggingofaparticular
layer, the error must be on that layer, because the layers below it are already
debugged.Thus,the designand implementationofthe systemaresimplified.
Each layer is implemented only with operations provided by lower-level
layers.Alayerdoesnotneedtoknowhow theseoperationsare implemented;
it needs to know only what these operations do. Hence, each layer hides the
existence of certain data structures, operations, and hardware from higher-
levellayers.
Layeredsystemshavebeensuccessfullyusedincomputernetworks(such
asTCP/IP) and web applications. Nevertheless, relatively few operating sys-
tems use a pure layered approach. One reason involves the challenges of
appropriately defining the functionality of each layer. In addition, the overall
performance of such systems is poor due to the overhead of requiring a user
programtotraversethroughmultiplelayerstoobtainanoperating-systemser-
vice. Somelayering is common in contemporary operating systems, however.
Generally,thesesystemshavefewerlayerswithmorefunctionality,providing
most of the advantages of modularized code while avoiding the problems of
layerdefinitionand interaction.
2.8.3 Microkernels
We have already seen that the original UNIXsystem had a monolithic struc-
ture. As UNIXexpanded, the kernel became large and difficult to manage.
In the mid-1980s, researchers at Carnegie Mellon University developed an
operating system called Machthat modularized the kernel using the micro-
kernelapproach. This method structures the operating system by removing"
3,2.8.4 Modules,116,2.8.3 Microkernels,"86 Chapter 2 Operating-System Structures
address spaces. In addition, the operating system may have to switch from
one process to the next to exchange the messages. The overhead involved
in copying messages and switching bet ween processes has been the largest
impediment to the growth of microkernel-based operating systems. Consider
thehistoryofWindows NT:Thefirstreleasehadalayeredmicrokernelorgani-
zation. This version’s performance was low compared with that of Windows
95. Windows NT4.0 partially corrected the performance problem by moving
layers from user space to kernel space and integrating them more closely.
B yt h et i m eW i n d o w s XPwas designed, Windows architecture had become
more monolithic than microkernel. Section 2.8.5.1 will describe how mac OS
addressesthe performanceissuesof theMach microkernel.
2.8.4 Modules
Perhaps the best current methodology for operating-system design involves
using loadable kernel modules (LKMs). Here, the kernel has a set of core
componentsandcanlinkinadditionalservicesviamodules,eitheratboottime
orduringruntime.Thistypeofdesigniscommoninmodernimplementations
ofUNIX, such as Linux, mac OS, and Solaris,as wellas Windows.
The idea of the design is for the kernel to provide core services, while
otherservicesareimplementeddynamically,asthekernelisrunning.Linking
servicesdynamicallyispreferabletoaddingnewfeaturesdirectlytothekernel,
which would require recompiling the kernel every time a change was made.
Thus,forexample,wemightbuild CPUschedulingandmemorymanagement
algorithms directly into the kernel and then add support for different file
systemsby way of loadablemodules.
The overall result resembles a layered system in that each kernel section
has defined,protectedinterfaces;but it ismore flexiblethan a layeredsystem,
becauseanymodulecancallanyothermodule.Theapproachisalsosimilarto
the microkernel approach in that the p rimary module has only core functions
and knowledge of how to load and communicate with other modules; but it
is more efficient, because modules do not need to invoke message passing in
orderto communicate.
Linux uses loadable kernel modules, primarily for supporting device
drivers and file systems. LKMsc a nb e “inserted ”into the kernel as the sys-
tem is started (or booted) or during run time, such as when a USBdevice is
plugged into a running machine. If the Linux kernel does not have the nec-
essary driver, it can be dynamically loaded. LKMs can be removed from the
kernelduringruntimeaswell.ForLinux, LKMsallowadynamicandmodular
kernel,whilemaintainingtheperforma ncebenefitsofamonolithicsystem.We
cover creating LKMs in Linux in several programming exercises at the end of
this chapter.
2.8.5 Hybrid Systems
In practice, very few operating systems adopt a single, strictly defined struc-
ture. Instead, they combine different structures, resulting in hybrid systems
that address performance, security, an d usability issues. For example, Linux
is monolithic, because having the operating system in a single address space
provides very efficient performance. However, it also modular, so that new
functionality can be dynamically added to the kernel. Windows is largely"
3,2.8.5 Hybrid Systems,116,2.8.4 Modules,"86 Chapter 2 Operating-System Structures
address spaces. In addition, the operating system may have to switch from
one process to the next to exchange the messages. The overhead involved
in copying messages and switching bet ween processes has been the largest
impediment to the growth of microkernel-based operating systems. Consider
thehistoryofWindows NT:Thefirstreleasehadalayeredmicrokernelorgani-
zation. This version’s performance was low compared with that of Windows
95. Windows NT4.0 partially corrected the performance problem by moving
layers from user space to kernel space and integrating them more closely.
B yt h et i m eW i n d o w s XPwas designed, Windows architecture had become
more monolithic than microkernel. Section 2.8.5.1 will describe how mac OS
addressesthe performanceissuesof theMach microkernel.
2.8.4 Modules
Perhaps the best current methodology for operating-system design involves
using loadable kernel modules (LKMs). Here, the kernel has a set of core
componentsandcanlinkinadditionalservicesviamodules,eitheratboottime
orduringruntime.Thistypeofdesigniscommoninmodernimplementations
ofUNIX, such as Linux, mac OS, and Solaris,as wellas Windows.
The idea of the design is for the kernel to provide core services, while
otherservicesareimplementeddynamically,asthekernelisrunning.Linking
servicesdynamicallyispreferabletoaddingnewfeaturesdirectlytothekernel,
which would require recompiling the kernel every time a change was made.
Thus,forexample,wemightbuild CPUschedulingandmemorymanagement
algorithms directly into the kernel and then add support for different file
systemsby way of loadablemodules.
The overall result resembles a layered system in that each kernel section
has defined,protectedinterfaces;but it ismore flexiblethan a layeredsystem,
becauseanymodulecancallanyothermodule.Theapproachisalsosimilarto
the microkernel approach in that the p rimary module has only core functions
and knowledge of how to load and communicate with other modules; but it
is more efficient, because modules do not need to invoke message passing in
orderto communicate.
Linux uses loadable kernel modules, primarily for supporting device
drivers and file systems. LKMsc a nb e “inserted ”into the kernel as the sys-
tem is started (or booted) or during run time, such as when a USBdevice is
plugged into a running machine. If the Linux kernel does not have the nec-
essary driver, it can be dynamically loaded. LKMs can be removed from the
kernelduringruntimeaswell.ForLinux, LKMsallowadynamicandmodular
kernel,whilemaintainingtheperforma ncebenefitsofamonolithicsystem.We
cover creating LKMs in Linux in several programming exercises at the end of
this chapter.
2.8.5 Hybrid Systems
In practice, very few operating systems adopt a single, strictly defined struc-
ture. Instead, they combine different structures, resulting in hybrid systems
that address performance, security, an d usability issues. For example, Linux
is monolithic, because having the operating system in a single address space
provides very efficient performance. However, it also modular, so that new
functionality can be dynamically added to the kernel. Windows is largely"
2,2.9 Building and Booting an Operating System,122,2.8 Operating-System Structure,"92 Chapter 2 Operating-System Structures
2.9 Building and Booting an Operating System
It is possible to design, code, and implement an operating system specifically
for one specific machine configuration. More commonly, however, operating
systems are designed to run on any of a class of machines with a variety of
peripheralconfigurations.
2.9.1 Operating-System Generation
Mostcommonly,acomputersystem,whenpurchased,hasanoperatingsystem
alreadyinstalled.Forexample,youmaypurchaseanewlaptopwithWindows
or macOSpreinstalled.But suppose you wish to replace the preinstalledoper-
atingsystemoraddadditionaloperatingsystems.Orsupposeyoupurchasea
computer without an operating system. In these latter situations, you have a
fewoptionsforplacingtheappropriateoperatingsystemonthecomputerand
configuring itfor use.
If you are generating (or building) an operating system from scratch, you
mustfollow thesesteps:
1.Write the operating system source code (or obtain previously written
source code).
2.Configure the operatingsystemfor the systemon which itwill run.
3.Compilethe operatingsystem.
4.Installthe operatingsystem.
5.Boot thecomputerand itsnew operatingsystem.
Configuring the system involves specifying which features will be
included,andthisvariesbyoperatingsyst em.Typically,parametersdescribing
how the system is configured is stored in a configuration file of some type,
and once this fileiscreated,itcan beusedinseveralways.
At one extreme, a system administrator can use it to modify a copy of
the operating-system source code. Then the operating system is completely
compiled (known as a system build ). Data declarations, initializations, and
constants, along with compilation, produce an output-object version of the
operating system that is tailored to the system described in the configuration
file.
Ataslightlylesstailoredlevel,thesystemdescriptioncanleadtotheselec-
tionofprecompiledobjectmodulesfromanexistinglibrary.Thesemodulesare
linked together to form the generated o perating system. This process allows
thelibrarytocontainthedevicedriversforallsupported I/Odevices,butonly
those needed are selected and linked into the operating system. Because the
systemisnotrecompiled,systemgenerationisfaster,buttheresultingsystem
maybeoverlygeneralandmaynotsupportdifferenthardwareconfigurations.
Attheotherextreme,itispossibletoconstructasystemthatiscompletely
modular.Here,selectionoccursatexecutiontimeratherthanatcompileorlink
time. System generation involves simply setting the parameters that describe
the systemconfiguration."
3,2.9.1 Operating-System Generation,122,2.9 Building and Booting an Operating System,"92 Chapter 2 Operating-System Structures
2.9 Building and Booting an Operating System
It is possible to design, code, and implement an operating system specifically
for one specific machine configuration. More commonly, however, operating
systems are designed to run on any of a class of machines with a variety of
peripheralconfigurations.
2.9.1 Operating-System Generation
Mostcommonly,acomputersystem,whenpurchased,hasanoperatingsystem
alreadyinstalled.Forexample,youmaypurchaseanewlaptopwithWindows
or macOSpreinstalled.But suppose you wish to replace the preinstalledoper-
atingsystemoraddadditionaloperatingsystems.Orsupposeyoupurchasea
computer without an operating system. In these latter situations, you have a
fewoptionsforplacingtheappropriateoperatingsystemonthecomputerand
configuring itfor use.
If you are generating (or building) an operating system from scratch, you
mustfollow thesesteps:
1.Write the operating system source code (or obtain previously written
source code).
2.Configure the operatingsystemfor the systemon which itwill run.
3.Compilethe operatingsystem.
4.Installthe operatingsystem.
5.Boot thecomputerand itsnew operatingsystem.
Configuring the system involves specifying which features will be
included,andthisvariesbyoperatingsyst em.Typically,parametersdescribing
how the system is configured is stored in a configuration file of some type,
and once this fileiscreated,itcan beusedinseveralways.
At one extreme, a system administrator can use it to modify a copy of
the operating-system source code. Then the operating system is completely
compiled (known as a system build ). Data declarations, initializations, and
constants, along with compilation, produce an output-object version of the
operating system that is tailored to the system described in the configuration
file.
Ataslightlylesstailoredlevel,thesystemdescriptioncanleadtotheselec-
tionofprecompiledobjectmodulesfromanexistinglibrary.Thesemodulesare
linked together to form the generated o perating system. This process allows
thelibrarytocontainthedevicedriversforallsupported I/Odevices,butonly
those needed are selected and linked into the operating system. Because the
systemisnotrecompiled,systemgenerationisfaster,buttheresultingsystem
maybeoverlygeneralandmaynotsupportdifferenthardwareconfigurations.
Attheotherextreme,itispossibletoconstructasystemthatiscompletely
modular.Here,selectionoccursatexecutiontimeratherthanatcompileorlink
time. System generation involves simply setting the parameters that describe
the systemconfiguration."
3,2.9.2 System Boot,124,2.9.1 Operating-System Generation,"94 Chapter 2 Operating-System Structures
2.9.2 System Boot
After an operating system is generated, it must be made available for use by
thehardware.Buthowdoesthehardwareknowwherethekernelisorhowto
load that kernel? The process of start ing a computer by loading the kernel is
known as booting the system. On most systems, the boot process proceeds as
follows:
1.As m a l lp i e c eo fc o d ek n o w na st h e bootstrap program orboot loader
locates thekernel.
2.The kernelis loadedinto memoryand started.
3.The kernelinitializeshardware.
4.The rootfile systemismounted.
In thissection, webrieflydescribetheboot processin moredetail.
Somecomputersystemsuseamultistagebootprocess:Whenthecomputer
isfirstpoweredon,asmallbootloaderlocatedinnonvolatilefirmwareknown
asBIOSis run. This initial boot loader usually does nothing more than load
a second boot loader, which is located at a fixed disk location called the boot
block. The program stored in the boot block may be sophisticated enough to
load the entire operating system into memory and begin its execution. More
typically,itissimplecode(asitmustfitinasinglediskblock)andknowsonly
theaddressondiskandthelengthoftheremainderofthebootstrapprogram.
Manyrecentcomputersystemshavereplacedthe BIOS-basedbootprocess
with UEFI(UnifiedExtensibleFirmwareInterface). UEFIhasseveraladvantages
overBIOS,includingbettersupportfor64-bitsystemsandlargerdisks.Perhaps
the greatest advantage is that UEFIis a single, complete boot manager and
thereforeisfasterthan themultistage BIOSboot process.
Whether booting from BIOSorUEFI, the bootstrap program can perform a
variety of tasks. In addition to loading t he file containing the kernel program
into memory, it also runs diagnostics to determine the state of the machine
—for example, inspecting memory and the CPUand discovering devices. If
the diagnostics pass, the program can continue with the booting steps. The
bootstrap can also initialize all aspects of the system, from CPUregisters to
device controllers and the contents of main memory. Sooner or later, it starts
the operatingsystemand mounts the rootfile system.Itisonly atthispointis
thesystemsaidto be running.
GRUBis an open-source bootstrap program for Linux and UNIXsystems.
Boot parameters for the system are set in a GRUBconfiguration file, which is
loadedatstartup. GRUBisflexibleandallowschangestobemadeatboottime,
including modifying kernel parameters and even selecting among different
kernelsthatcanbebooted.Asanexample,thefollowingarekernelparameters
from thespecialLinuxfile /proc/cmdline ,which is usedat boot time:
BOOT
 IMAGE=/boot/vmlinuz-4.4.0-59-generic
root=UUID=5f2e2232-4e47-4fe8-ae94-45ea749a5c92
BOOT
 IMAGEis the name of the kernel image to be loaded into memory, and
rootspecifiesa uniqueidentifierof the rootfilesystem."
2,2.10 Operating-System Debugging,125,2.9 Building and Booting an Operating System,"2.10 Operating-System Debugging 95
To save space as well as decrease boot time, the Linux kernel image is a
compressedfilethatisextractedafteritisloadedintomemory.Duringtheboot
process,thebootloadertypicallycreatesatemporary RAMfilesystem,known
asinitramfs .Thisfilesystemcontainsnecessarydriversandkernelmodules
thatmustbeinstalledtosupportthe realrootfilesystem(whichisnotinmain
memory). Once the kernel has started and the necessary drivers are installed,
the kernel switches the root file system from the temporary RAMlocation to
the appropriate root file system location. Finally, Linux creates the systemd
process, the initial process in the system, and then starts other services (for
example, a web server and/or database). Ultimately, the system will present
the user with a login prompt. In Section 11.5.2, we describe the boot process
forWindows.
It is worthwhile to note that the booting mechanism is not independent
from the boot loader. Therefore, there are specific versions of the GRUBboot
loader for BIOSandUEFI, and the firmware must know as well which specific
bootloaderisto beused.
The boot process for mobile systems is slightly different from that for
traditional PCs.Forexample,althoughitskernelisLinux-based,Androiddoes
not use GRUBand instead leaves it up to vendors to provide boot loaders.
The most common Android boot loader is LK(for “little kernel ”). Android
systems use the same compressed kernel image as Linux, as well as an initial
RAMfile system. However, whereas Linux discards the initramfs once all
necessarydrivershavebeenloaded,Androidmaintains initramfs astheroot
file system for the device. Once the kernel has been loaded and the root file
system mounted, Android starts the initprocess and creates a number of
servicesbeforedisplayingthe homescreen.
Finally, boot loaders for most operating systems—including Windows,
Linux, and mac OS,a sw e l la sb o t hi OSand Android—provide booting into
recovery mode orsingle-user mode for diagnosing hardware issues, fixing
corruptfilesystems,andevenreinstallingtheoperatingsystem.Inadditionto
hardwarefailures,computersystemscansufferfromsoftwareerrorsandpoor
operating-systemperformance,which weconsider inthe following section.
2.10 Operating-System Debugging
Wehavementioneddebuggingfromtimetotimeinthischapter.Here,wetake
a closer look. Broadly, debugging is the activity of finding and fixing errors
in a system, both in hardware and in software. Performance problems are
considered bugs, so debugging can also include performance tuning ,w h i c h
seeks to improve performance by removing processing bottlenecks .I nt h i s
section, we explore debugging process and kernel errors and performance
problems.Hardwaredebuggingisoutsidethescope ofthis text.
2.10.1 Failure Analysis
If a process fails, most operating systems write the error information to a log
filto alert system administrators or users that the problem occurred. The
operating system can also take a core dump —a capture of the memory of the
process—andstoreitinafileforlateranalysis.(Memorywasreferredtoasthe"
3,2.10.1 Failure Analysis,125,2.10 Operating-System Debugging,"2.10 Operating-System Debugging 95
To save space as well as decrease boot time, the Linux kernel image is a
compressedfilethatisextractedafteritisloadedintomemory.Duringtheboot
process,thebootloadertypicallycreatesatemporary RAMfilesystem,known
asinitramfs .Thisfilesystemcontainsnecessarydriversandkernelmodules
thatmustbeinstalledtosupportthe realrootfilesystem(whichisnotinmain
memory). Once the kernel has started and the necessary drivers are installed,
the kernel switches the root file system from the temporary RAMlocation to
the appropriate root file system location. Finally, Linux creates the systemd
process, the initial process in the system, and then starts other services (for
example, a web server and/or database). Ultimately, the system will present
the user with a login prompt. In Section 11.5.2, we describe the boot process
forWindows.
It is worthwhile to note that the booting mechanism is not independent
from the boot loader. Therefore, there are specific versions of the GRUBboot
loader for BIOSandUEFI, and the firmware must know as well which specific
bootloaderisto beused.
The boot process for mobile systems is slightly different from that for
traditional PCs.Forexample,althoughitskernelisLinux-based,Androiddoes
not use GRUBand instead leaves it up to vendors to provide boot loaders.
The most common Android boot loader is LK(for “little kernel ”). Android
systems use the same compressed kernel image as Linux, as well as an initial
RAMfile system. However, whereas Linux discards the initramfs once all
necessarydrivershavebeenloaded,Androidmaintains initramfs astheroot
file system for the device. Once the kernel has been loaded and the root file
system mounted, Android starts the initprocess and creates a number of
servicesbeforedisplayingthe homescreen.
Finally, boot loaders for most operating systems—including Windows,
Linux, and mac OS,a sw e l la sb o t hi OSand Android—provide booting into
recovery mode orsingle-user mode for diagnosing hardware issues, fixing
corruptfilesystems,andevenreinstallingtheoperatingsystem.Inadditionto
hardwarefailures,computersystemscansufferfromsoftwareerrorsandpoor
operating-systemperformance,which weconsider inthe following section.
2.10 Operating-System Debugging
Wehavementioneddebuggingfromtimetotimeinthischapter.Here,wetake
a closer look. Broadly, debugging is the activity of finding and fixing errors
in a system, both in hardware and in software. Performance problems are
considered bugs, so debugging can also include performance tuning ,w h i c h
seeks to improve performance by removing processing bottlenecks .I nt h i s
section, we explore debugging process and kernel errors and performance
problems.Hardwaredebuggingisoutsidethescope ofthis text.
2.10.1 Failure Analysis
If a process fails, most operating systems write the error information to a log
filto alert system administrators or users that the problem occurred. The
operating system can also take a core dump —a capture of the memory of the
process—andstoreitinafileforlateranalysis.(Memorywasreferredtoasthe"
3,2.10.2 Performance Monitoring and Tuning,126,2.10.1 Failure Analysis,"96 Chapter 2 Operating-System Structures
“core ”intheearlydaysofcomputing.)Runningprogramsandcoredumpscan
beprobedbyadebugger,whichallowsaprogrammertoexplorethecodeand
memoryof a processatthe timeof failure.
Debugginguser-levelprocesscodeisachallenge.Operating-systemkernel
debugging is even more complex because of the size and complexity of the
kernel,its control of the hardware, and the lack of user-leveldebugging tools.
Afailureinthekerneliscalleda crash.Whenacrashoccurs,errorinformation
issavedtoa logfile,and thememorystateis savedtoa crash dump .
Operating-system debugging and process debugging frequently use dif-
ferenttoolsandtechniquesduetotheverydifferentnature ofthesetwotasks.
Consider that a kernel failure in the file-system code would make it risky for
the kernelto try to save itsstate to a file on the file systembefore rebooting. A
common technique is to save the kernel’s memory state to a section of disk
set aside for this purpose that contains no file system. If the kernel detects
an unrecoverable error, it writes the entire contents of memory, or at least the
kernel-owned parts of the system memory, to the disk area. When the system
reboots, a process runs to gather the data from that area and write it to a crash
dump file within a file system for analysis. Obviously, such strategies would
be unnecessaryfor debuggingordinary user-levelprocesses.
2.10.2 Performance Monitoring and Tuning
We mentioned earlier that performance tuning seeks to improve performance
by removing processing bottlenecks. To identify bottlenecks, we must be able
to monitor system performance. Thus, the operating system must have some
means of computing and displaying measures of system behavior. Tools may
becharacterizedasprovidingeither per-process orsystem-wide observations.
To make these observations, tools may use one of two approaches— counters
ortracing.We explore each ofthese in the following sections.
2.10.2.1 Counters
Operating systems keep track of system activity through a series of counters,
such as the number of system calls made or the number of operations
performed to a network device or disk. The following are examples of Linux
tools thatuse counters:
Per-Process
•ps—reportsinformation fora singleprocessor selectionofprocesses
•top—reportsreal-timestatisticsfor currentprocesses
System-Wide
•vmstat—reportsmemory-usagestatistics
•netstat —reportsstatisticsfornetwork interfaces
•iostat—reports I/Ousagefor disks"
3,2.10.3 Tracing,127,2.10.2 Performance Monitoring and Tuning,"2.10 Operating-System Debugging 97
Figure 2.19 The Windows 10 task manager.
Most of the counter-based tools on Linux systems read statistics from the
/procfile system. /procis a “pseudo ”file system that exists only in kernel
memory and is used primarily for querying various per-process as well as
kernel statistics. The /procfile system is organized as a directory hierarchy,
with the process (a unique integer value assigned to each process) appearing
as a subdirectory below /proc. For example, the directory entry /proc/2155
would contain per-process statistics for the process with an IDof 2155. There
are/procentries for various kernel statistics as well. In both this chapter and
Chapter3,weprovideprogrammingprojectswhereyouwillcreateandaccess
the/procfilesystem.
Windows systems provide the Windows Task Manager , a tool that
includes information for current applications as well as processes, CPUand
memory usage, and networking statistics. A screen shot of the task manager
inWindows 10 appearsinFigure2.19.
2.10.3 Tracing
Whereas counter-based tools simply inquire on the current value of certain
statistics that are maintained by the ke rnel, tracing tools collect data for a
specificevent—such as thestepsinvolvedina system-callinvocation.
The following areexamplesof Linuxtools that traceevents:
Per-Process
•strace—traces systemcallsinvokedby a process
•gdb—a source-leveldebugger
System-Wide
•perf—a collection of Linuxperformancetools
•tcpdump —collects network packets"
3,2.10.4 BCC,128,2.10.3 Tracing,"98 Chapter 2 Operating-System Structures
Kernighan’s Law
“Debugging is twice as hard as writing the code in the first place. Therefore,
ifyouwritethecodeascleverlyaspossible,youare,bydefinition,notsmart
enoughtodebug it. ”
Making operating systems easier to understand, debug, and tune as they
run is an active area of research and practice. A new generation of kernel-
enabledperformanceanalysistoolshas madesignificantimprovementsinhow
this goal can be achieved. Next, we discuss BCC, a toolkit for dynamic kernel
tracing in Linux.
2.10.4 BCC
Debugging the interactions between user-level and kernel code is nearly
impossiblewithoutatoolsetthatunderstandsbothsetsofcodeandcaninstru-
ment their interactions. For that toolset to be truly useful, it must be able to
debuganyareaofasystem,includingareasthatwerenotwrittenwithdebug-
ging in mind, and do so without affecting system reliability.This toolset must
also have a minimal performance impact—ideally it should have no impact
when not in use and a proportional impact during use. The BCCtoolkit meets
these requirements and provides a dynamic, secure, low-impact debugging
environment.
BCC(BPFCompiler Collection) is a rich toolkit that provides tracing fea-
tures for Linux systems. BCCis a front-end interface to the e BPF(extended
Berkeley Packet Filter) tool. The BPFtechnology was developed in the early
1990sforfilteringtrafficacrossacomputernetwork.The “extended ”BPF(eBPF)
added various features to BPF.eBPFprograms are written in a subset of C and
are compiled into e BPFinstructions, which can be dynamically inserted into a
running Linux system. The e BPFinstructions can be used to capture specific
events(such as a certainsystem call being invoked)or to monitor system per-
formance (such as the time required to perform disk I/O). To ensure that e BPF
instructions are well behaved, they are passed through a verifiebefore being
inserted into the running Linux kernel. The verifier checks to make sure that
theinstructions donot affectsystemperformanceor security.
Although e BPFprovides a rich set of features for tracing within the Linux
kernel, it traditionally has been very difficult to develop programs using its
Ci n t e r f a c e . BCCwas developed to make it easier to write tools using e BPFby
providingafront-endinterfaceinPython.A BCCtooliswritteninPythonand
it embeds C code that interfaces with the e BPFinstrumentation, which in turn
interfaceswiththekernel.The BCCtoolalsocompilestheCprogramintoe BPF
instructions and inserts it into the kernel using either probes or tracepoints,
two techniquesthat allowtracing eventsinthe Linuxkernel.
The specifics of writing custom BCCtools are beyond the scope of this
text, but the BCCpackage (which is installed on the Linux virtual machine
we provide) provides a number of existing tools that monitor several areas"
2,2.11 Summary,130,2.10 Operating-System Debugging,"100 Chapter 2 Operating-System Structures
What makes BCCespecially powerful is that its tools can be used on
liveproduction systemsthat are running critical applications without causing
harm to the system. This is particularly useful for system administrators who
must monitor system performance to identify possible bottlenecks or security
exploits. Figure 2.20 illustrates the wide range of tools currently provided by
BCCandeBPFandtheirabilitytotraceessentiallyanyareaoftheLinuxoperat-
ingsystem. BCCisarapidlychangingtechnologywithnewfeaturesconstantly
being added.
2.11 Summary
•An operating system provides an environment for the execution of pro-
gramsby providingservicesto usersand programs.
•The three primary approaches for interacting with an operating system
are (1) command interpreters,(2) grap hical user interfaces, and (3) touch-
screeninterfaces.
•Systemcallsprovideaninterfacetotheservicesmadeavailablebyanoper-
ating system. Programmers use a system call’s application programming
interface( API) foraccessing system-callservices.
•System calls can be divided into six major categories: (1) process control,
(2)filemanagement,(3)devicemanagement,(4)informationmaintenance,
(5) communications, and (6) protection.
•The standard C library provides the system-call interface for UNIXand
Linuxsystems.
•Operating systems also include a collection of system programs that pro-
videutilitiesto users.
•Alinker combines several relocatable object modules into a single binary
executable file. A loader loads the executable file into memory, where it
becomeseligibleto runonanavailable CPU.
•There are several reasons why applications are operating-system specific.
These include different binary formats for program executables, different
instruction sets for different CPUs, and system calls that vary from one
operatingsystemtoanother.
•An operating system is designed with specific goals in mind. These goals
ultimatelydeterminetheoperatingsystem’spolicies.Anoperatingsystem
implementsthesepoliciesthrough specificmechanisms.
•A monolithic operating system has no structure; all functionality is pro-
vided in a single, static binary file that runs in a single address space.
Although such systems are difficult to modify, their primary benefit is
efficiency.
•A layered operating system is divided into a number of discrete layers,
where the bottom layer is the hardware interface and the highest layer is
theuserinterface.Althoughlayeredsoftwaresystemshavehadsomesuc-"
2,Practice Exercises,131,2.11 Summary,"Further Reading 101
cess, this approach is generally not ideal for designing operating systems
dueto performanceproblems.
•Themicrokernelapproachfordesigningoperatingsystemsusesaminimal
kernel;mostservicesrunasuser-levelapplications.Communicationtakes
place viamessagepassing.
•Amodularapproachfordesigningoperatingsystemsprovidesoperating-
systemservicesthroughmodulesthatcanbeloadedandremovedduring
runtime.Manycontemporaryoperatingsystemsareconstructedashybrid
systemsusing a combination of amonolithic kerneland modules.
•Abootloaderloadsanoperatingsystemintomemory,performsinitializa-
tion, and beginssystemexecution.
•The performance of an operating system can be monitored using either
counters or tracing. Counters are a collection of system-wide or per-
processstatistics,whiletracingfollo wstheexecutionofaprogramthrough
the operatingsystem.
Practice Exercises
2.1What isthepurposeof systemcalls?
2.2What is the purpose of the command interpreter? Why is it usually
separatefromthe kernel?
2.3Whatsystemcallshavetobeexecutedbyacommandinterpreterorshell
inordertostarta newprocessona UNIXsystem?
2.4What isthepurposeof systemprograms?
2.5What is the main advantage of the layered approach to system design?
What are the disadvantagesof the layeredapproach?
2.6Listfiveservicesprovidedbyanoperatingsystem,andexplainhoweach
createsconvenienceforusers.Inwhichcaseswoulditbeimpossiblefor
user-levelprogramsto providetheseservices?Explainyouranswer.
2.7Why do some systems store the operating system in firmware, while
others storeit ondisk?
2.8Howcouldasystembedesignedtoallowachoiceofoperatingsystems
from which to boot? What would the bootstrapprogram needto do?
Further Reading
[Bryant and O’Hallaron (2015)] provide an overview of computer systems,
includingtheroleofthelinkerandloader.[Atlidakisetal.(2016)]discuss POSIX
system calls and how they relate to modern operating systems. [Levin (2013)]
coverstheinternalsofbothmac OSandiOS,and[Levin(2015)]describesdetails
oftheAndroidsystem.Windows10internalsarecoveredin[Russinovichetal.
(2017)]. BSD UNIX is described in [McKusick et al. (2015)]. [Love (2010)] and"
2,Further Reading,131,Practice Exercises,"Further Reading 101
cess, this approach is generally not ideal for designing operating systems
dueto performanceproblems.
•Themicrokernelapproachfordesigningoperatingsystemsusesaminimal
kernel;mostservicesrunasuser-levelapplications.Communicationtakes
place viamessagepassing.
•Amodularapproachfordesigningoperatingsystemsprovidesoperating-
systemservicesthroughmodulesthatcanbeloadedandremovedduring
runtime.Manycontemporaryoperatingsystemsareconstructedashybrid
systemsusing a combination of amonolithic kerneland modules.
•Abootloaderloadsanoperatingsystemintomemory,performsinitializa-
tion, and beginssystemexecution.
•The performance of an operating system can be monitored using either
counters or tracing. Counters are a collection of system-wide or per-
processstatistics,whiletracingfollo wstheexecutionofaprogramthrough
the operatingsystem.
Practice Exercises
2.1What isthepurposeof systemcalls?
2.2What is the purpose of the command interpreter? Why is it usually
separatefromthe kernel?
2.3Whatsystemcallshavetobeexecutedbyacommandinterpreterorshell
inordertostarta newprocessona UNIXsystem?
2.4What isthepurposeof systemprograms?
2.5What is the main advantage of the layered approach to system design?
What are the disadvantagesof the layeredapproach?
2.6Listfiveservicesprovidedbyanoperatingsystem,andexplainhoweach
createsconvenienceforusers.Inwhichcaseswoulditbeimpossiblefor
user-levelprogramsto providetheseservices?Explainyouranswer.
2.7Why do some systems store the operating system in firmware, while
others storeit ondisk?
2.8Howcouldasystembedesignedtoallowachoiceofoperatingsystems
from which to boot? What would the bootstrapprogram needto do?
Further Reading
[Bryant and O’Hallaron (2015)] provide an overview of computer systems,
includingtheroleofthelinkerandloader.[Atlidakisetal.(2016)]discuss POSIX
system calls and how they relate to modern operating systems. [Levin (2013)]
coverstheinternalsofbothmac OSandiOS,and[Levin(2015)]describesdetails
oftheAndroidsystem.Windows10internalsarecoveredin[Russinovichetal.
(2017)]. BSD UNIX is described in [McKusick et al. (2015)]. [Love (2010)] and"
2,Bibliography,132,Further Reading,"102 Chapter 2 Operating-System Structures
[Mauerer(2008)]thoroughlydiscusstheLinuxkernel.Solarisisfullydescribed
in [McDougall and Mauro (2007)].
Linux source code is available at http://www.kernel.org .T h eU b u n t u ISO
imageisavailablefrom https://www.ubuntu.com/ .
Comprehensive coverage of Linux kernel modules can be found at
http://www.tldp.org/LD P/lkmpg/2.6/lkmpg.pdf .[Ward(2015)]and http://www
.ibm.com/developerworks/li nux/library/l-linuxboot/ describe the Linux boot
process using GRUB. Performance tuning—with a focus on Linux and Solaris
systems—iscoveredin[Gregg(2014)].Detailsforthe BCCtoolkitcanbefound
athttps://github.com/iovisor/bcc/#tools .
Bibliography
[Atlidakis et al. (2016)] V. Atlidakis, J. Andrus, R. Geambasu, D. Mitropoulos,
and J. Nieh, “POSIX Abstractions in Modern Operating Systems: The Old, the
New,and theMissing ”(2016), pages19:1–19:17.
[Bryant and O’Hallaron (2015)] R.BryantandD.O’Hallaron, Computer Systems:
A Programmer’s Perspective, ThirdEdition (2015).
[Gregg (2014)] B. Gregg, Systems Performance–Enterprise and the Cloud ,P e a r s o n
(2014).
[Levin (2013)] J. Levin, Mac OS X and i OSInternals to the Apple’s Core , Wiley
(2013).
[Levin (2015)] J. Levin, Android Internals–A Confectioner’s Cookbook. Volume I
(2015).
[Love (2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library (2010).
[Mauerer (2008)] W. Mauerer, Professional Linux Kernel Architecture , John Wiley
and Sons(2008).
[McDougall and Mauro (2007)] R. McDougall and J. Mauro, Solaris Internals,
SecondEdition, PrenticeHall (2007).
[McKusick et al. (2015)] M. K. McKusick, G. V. Neville-Neil, and R. N. M. Wat-
son,The Design and Implementation of the FreeBSD UNIX Operating System–Second
Edition, Pearson(2015).
[Russinovich et al. (2017)] M.Russinovich,D.A.Solomon,andA.Ionescu, Win-
dows Internals–Part 1, SeventhEdition, MicrosoftPress (2017).
[Ward (2015)] B. Ward, How LINUX Works–What Every Superuser Should Know,
SecondEdition, NoStarchPress (2015)."
2,Chapter 2 Exercises,133,Bibliography,"Chapter 2 Exercises
2.9The services and functions provided by an operating system can be
divided into two main categories. Briefly describe the two categories,
and discusshow they differ.
2.10Describethreegeneralmethodsfor passingparameterstotheoperating
system.
2.11Describehowyoucouldobtainastatisticalprofileoftheamountoftime
a program spends executing different sections of its code. Discuss the
importance of obtaining such a statisticalprofile.
2.12What are the advantages and disadvantages of using the same system-
callinterface formanipulating both filesanddevices?
2.13Woulditbepossiblefortheusertodevelopanewcommandinterpreter
using thesystem-callinterfaceprovidedby theoperatingsystem?
2.14DescribewhyAndroidusesahead-of-time( AOT)ratherthanjust-in-time
(JIT)compilation.
2.15What are the two models of interprocess communication? What are the
strengthsand weaknessesofthe two approaches?
2.16Contrast and compare an application programming interface ( API)a n d
an application binary interface ( ABI).
2.17Why isthe separationof mechanism and policydesirable?
2.18Itissometimesdifficulttoachievealayeredapproachiftwocomponents
oftheoperatingsystemaredependent oneachother.Identifyascenario
in which it is unclear how to layer tw o system components that require
tightcoupling of theirfunctionalities.
2.19What is the main advantage of the microkernel approach to system
design?Howdouserprogramsandsystemservicesinteractinamicro-
kernel architecture? What are the disadvantages of using the microker-
nelapproach?
2.20What arethe advantagesof using loadablekernelmodules?
2.21How are i OSand Androidsimilar?Howaretheydifferent?
2.22ExplainwhyJavaprogramsrunningonAndroidsystemsdonotusethe
standardJava APIand virtualmachine.
2.23The experimental Synthesis operat ing system has an assembler incor-
porated in the kernel. To optimize system-call performance, the kernel
assemblesroutineswithinkernelspacetominimizethepaththatthesys-
temcallmusttakethroughthekernel.Thisapproachistheantithesisof
the layeredapproach, in which the path through the kernel is extended
tomakebuildingtheoperatingsystemeasier.Discusstheprosandcons
of the Synthesis approach to kern el design and system-performance
optimization.EX-3"
2,Programming Problems,134,Chapter 2 Exercises,"Chapter 2 Operating-System Structures
Programming Problems
2.24InSection2.3,wedescribedaprogramthatcopiesthecontentsofonefile
toadestinationfile.Thisprogramworksbyfirstpromptingtheuserfor
the name of the source and destination files. Write this program using
either the POSIXor Windows API. Be sure to include all necessary error
checking, including ensuringthat the source file exists.
Onceyouhavecorrectlydesignedandtestedtheprogram,ifyouused
asystemthatsupportsit,runtheprogramusingautilitythattracessys-
temcalls.Linuxsystemsprovidethe straceutility,andmac OSsystems
use the dtrusscommand. (The dtrusscommand, which actually is a
front end to dtrace,r e q u i r e s adminprivileges, so it must be run using
sudo.) These tools can be used as follows (assume that the name of the
executablefileis FileCopy :
Linux:
strace ./FileCopy
mac OS:
sudo dtruss ./FileCopy
Since Windows systems do not provide such a tool, you will have to
trace throughtheWindows versionof thisprogramusing a debugger.
Programming Projects
Introduction to Linux Kernel Modules
Inthisproject,youwilllearnhowtocreateakernelmoduleandloaditintothe
Linuxkernel.Youwillthenmodifythekernelmodulesothatitcreatesanentry
inthe /procfilesystem.Theprojectcan becompletedusing theLinuxvirtual
machinethat isavailablewiththistext.Althoughyoumayuseanytexteditor
to write these C programs, you will have to use the terminal application to
compiletheprograms,andyouwillhavetoentercommandsonthecommand
linetomanage themodulesinthekernel.
As you’ll discover, the advantage of developing kernel modules is that it
is a relatively easy method of interacting with the kernel, thus allowing you
towriteprogramsthatdirectlyinvokekernelfunctions.Itisimportantforyou
to keep in mind that you are indeedwriting kernel code that directlyinteracts
with the kernel. That normally means that any errors in the code could crash
the system! However, since you will be using a virtual machine, any failures
willatworst only requirerebootingthe system.P-1"
2,Programming Projects,134,Programming Problems,"Chapter 2 Operating-System Structures
Programming Problems
2.24InSection2.3,wedescribedaprogramthatcopiesthecontentsofonefile
toadestinationfile.Thisprogramworksbyfirstpromptingtheuserfor
the name of the source and destination files. Write this program using
either the POSIXor Windows API. Be sure to include all necessary error
checking, including ensuringthat the source file exists.
Onceyouhavecorrectlydesignedandtestedtheprogram,ifyouused
asystemthatsupportsit,runtheprogramusingautilitythattracessys-
temcalls.Linuxsystemsprovidethe straceutility,andmac OSsystems
use the dtrusscommand. (The dtrusscommand, which actually is a
front end to dtrace,r e q u i r e s adminprivileges, so it must be run using
sudo.) These tools can be used as follows (assume that the name of the
executablefileis FileCopy :
Linux:
strace ./FileCopy
mac OS:
sudo dtruss ./FileCopy
Since Windows systems do not provide such a tool, you will have to
trace throughtheWindows versionof thisprogramusing a debugger.
Programming Projects
Introduction to Linux Kernel Modules
Inthisproject,youwilllearnhowtocreateakernelmoduleandloaditintothe
Linuxkernel.Youwillthenmodifythekernelmodulesothatitcreatesanentry
inthe /procfilesystem.Theprojectcan becompletedusing theLinuxvirtual
machinethat isavailablewiththistext.Althoughyoumayuseanytexteditor
to write these C programs, you will have to use the terminal application to
compiletheprograms,andyouwillhavetoentercommandsonthecommand
linetomanage themodulesinthekernel.
As you’ll discover, the advantage of developing kernel modules is that it
is a relatively easy method of interacting with the kernel, thus allowing you
towriteprogramsthatdirectlyinvokekernelfunctions.Itisimportantforyou
to keep in mind that you are indeedwriting kernel code that directlyinteracts
with the kernel. That normally means that any errors in the code could crash
the system! However, since you will be using a virtual machine, any failures
willatworst only requirerebootingthe system.P-1"
0,PART TWO PROCESS MANAGEMENT,141,PART ONE OVERVIEW,"Part Two
Process
Management
Aprocess is a program in execution. A process will need certain
resources—such as CPU time, memory, ﬁles, and I/Odevices—to
accomplish its task. These resources are typically allocated to the
process while it is executing.
A process is the unit of work in most systems. Systems consist of
a collection of processes: operati ng-system processes execute system
code, and user processes execute user code. All these processes may
execute concurrently.
Modern operating systems support processes having multiple
threads of control. On systems with multiple hardware processing cores,
these threads can run in parallel.
One of the most important aspects of an operating system is how it
schedules threads onto available processing cores. Several choices for
designing CPU schedulers are available to programmers."
1,Chapter 3 Processes,143,PART TWO PROCESS MANAGEMENT,"3CHAPTER
Processes
Earlycomputersallowedonlyoneprogramtobeexecutedatatime.Thispro-
gram had complete control of the system and had access to all the system’s
resources. In contrast, contemporary computer systems allow multiple pro-
grams to be loaded into memory and executed concurrently. This evolution
required firmer control and more compartmentalization of the various pro-
grams;andtheseneedsresultedinthenotionofa process,whichisaprogram
inexecution.Aprocessisthe unitof work ina moderncomputing system.
Themorecomplextheoperatingsystemis,themoreitisexpectedtodoon
behalfofitsusers.Althoughitsmainconcernistheexecutionofuserprograms,
italsoneedstotakecareofvarioussystemtasksthatarebestdoneinuserspace,
rather than within the kernel. A system therefore consists of a collection of
processes,some executinguser code,ot hers executingoperating systemcode.
Potentially,alltheseprocessescanexecuteconcurrently,withthe CPU(orCPUs)
multiplexed among them. In this chapter, you will read about what processes
are,how theyarerepresentedinanoperatingsystem,and how theywork.
CHAPTER OBJECTIVES
•Identify the separate components of a process and illustrate how they are
represented and scheduled in an operating system.
Describe how processes are created and terminated in an operating sys-
tem, including developing programs using the appropriate system calls
that perform these operations.
Describe and contrast interprocess communication using shared memory
and message passing.
Design programs that use pipes and POSIX shared memory to perform
interprocess communication.
Describe client–server communication using sockets and remote proce-
dure calls.
Design kernel modules that interact with the Linux operating system.
105"
2,3.1 Process Concept,144,Chapter 3 Processes,"106 Chapter 3 Processes
3.1 Process Concept
A question that arises in discussing operating systems involves what to call
all theCPUactivities.Early computers were batch systems that executed jobs,
followedby theemergenceof time-sharedsystemsthat ran user programs ,o r
tasks.Evenonasingle-usersystem,ausermaybeabletorunseveralprograms
atonetime:awordprocessor,awebbrowser,andane-mailpackage.Andeven
ifacomputercanexecuteonlyoneprogramatatime,suchasonanembedded
device that does not support multitasking, the operating system may need to
supportitsowninternalprogrammedact ivities,suchasmemorymanagement.
Inmanyrespects,alltheseactivitiesaresimilar,sowecallallofthem processes .
Although we personally prefer the more contemporary term process,t h e
term jobhas historical significance, as much of operating system theory and
terminologywasdevelopedduringatimewhenthemajoractivityofoperating
systems was job processing. Therefore, in some appropriate instances we use
jobwhendescribingtheroleoftheoperatingsystem.Asanexample,itwould
be misleading to avoid the use of commonly accepted terms that include the
word job(suchas job scheduling )simplybecause processhassuperseded job.
3.1.1 The Process
Informally,asmentionedearlier,aproce ssisaprograminexecution.Thestatus
of the current activity of a process is represented by the value of the program
counterand the contents of the processor’s registers. The memory layout of a
process is typicallydividedinto multiplesections, and is shown inFigure 3.1.
Thesesections include:
•Text section —the executablecode
•Data section —global variables
text
0max
dataheapstack
Figure 3.1 Layout of a process in memory."
3,3.1.1 The Process,144,3.1 Process Concept,"106 Chapter 3 Processes
3.1 Process Concept
A question that arises in discussing operating systems involves what to call
all theCPUactivities.Early computers were batch systems that executed jobs,
followedby theemergenceof time-sharedsystemsthat ran user programs ,o r
tasks.Evenonasingle-usersystem,ausermaybeabletorunseveralprograms
atonetime:awordprocessor,awebbrowser,andane-mailpackage.Andeven
ifacomputercanexecuteonlyoneprogramatatime,suchasonanembedded
device that does not support multitasking, the operating system may need to
supportitsowninternalprogrammedact ivities,suchasmemorymanagement.
Inmanyrespects,alltheseactivitiesaresimilar,sowecallallofthem processes .
Although we personally prefer the more contemporary term process,t h e
term jobhas historical significance, as much of operating system theory and
terminologywasdevelopedduringatimewhenthemajoractivityofoperating
systems was job processing. Therefore, in some appropriate instances we use
jobwhendescribingtheroleoftheoperatingsystem.Asanexample,itwould
be misleading to avoid the use of commonly accepted terms that include the
word job(suchas job scheduling )simplybecause processhassuperseded job.
3.1.1 The Process
Informally,asmentionedearlier,aproce ssisaprograminexecution.Thestatus
of the current activity of a process is represented by the value of the program
counterand the contents of the processor’s registers. The memory layout of a
process is typicallydividedinto multiplesections, and is shown inFigure 3.1.
Thesesections include:
•Text section —the executablecode
•Data section —global variables
text
0max
dataheapstack
Figure 3.1 Layout of a process in memory."
3,3.1.2 Process State,145,3.1.1 The Process,"3.1 Process Concept 107
•Heap section —memorythatisdynamicallyallocatedduringprogramrun
time
•Stack section —temporarydatastoragewheninvokingfunctions(suchas
function parameters,returnaddresses,and local variables)
Noticethatthesizesofthetextanddatasectionsarefixed,astheirsizesdo
notchangeduringprogramruntime.However,thestackandheapsectionscan
shrinkandgrowdynamicallyduringprogramexecution.Eachtimeafunction
iscalled,an activation record containing function parameters,local variables,
andthereturnaddressispushedontothestack;whencontrolisreturnedfrom
thefunction,theactivationrecordispoppedfromthestack.Similarly,theheap
willgrowasmemoryisdynamicallyallocated,andwillshrinkwhenmemory
is returned to the system. Although the stack and heap sections grow toward
oneanother,theoperatingsystemmustensuretheydonot overlaponeanother.
We emphasize that a program by itself is not a process. A program is a
passiveentity, such as a file containing a list of instructions stored on disk
(often called an executable fil ) .I nc o n t r a s t ,ap r o c e s si sa n activeentity,
with a program counter specifying the next instruction to execute and a set
ofassociatedresources.Aprogrambecomesaprocesswhenanexecutablefile
is loaded into memory. Two common techniques for loading executable files
are double-clicking an icon representing the executable file and entering the
name of the executablefile on the command line (asin prog.exe ora.out).
Although two processes may be associated with the same program, they
are nevertheless considered two separate execution sequences. For instance,
severalusersmayberunningdifferentcopiesofthemailprogram,orthesame
user may invoke many copies of the web browser program. Each of these is a
separateprocess;andalthoughthetextse ctionsareequivalent,thedata,heap,
andstacksectionsvary.Itisalsocommontohaveaprocessthatspawnsmany
processesas itruns.Wediscuss suchmattersinSection3.4.
Note that a process can itself be an execution environment for other code.
The Java programming environment provides a good example. In most cir-
cumstances, an executable Java program is executed within the Java virtual
machine ( JVM). TheJVMexecutes as a process that interprets the loaded Java
codeandtakesactions(vianativemachineinstructions)onbehalfofthatcode.
For example, to run the compiled Java program Program.class ,w ew o u l d
enter
java Program
The command javaruns the JVMas an ordinary process, which in turns
executes the Java program Program in the virtual machine. The concept is the
sameassimulation,exceptthatthecode,insteadofbeingwrittenforadifferent
instructionset,iswritteninthe Javalanguage.
3.1.2 Process State
Asaprocessexecutes,itchanges state.Thestateofaprocessisdefinedinpart
bythecurrentactivityofthatprocess.Aprocessmaybeinoneofthefollowing
states:"
3,3.1.3 Process Control Block,147,3.1.2 Process State,"3.1 Process Concept 109
new terminated
running readyadmitted interrupt
scheduler dispatchI/O or event completion I/O or event waitexit
waiting
Figure 3.2 Diagram of process state.
•Terminated .Theprocesshas finishedexecution.
These names are arbitrary, and they vary across operating systems. The states
that they represent are found on all syst ems, however. Certain operating sys-
tems also more finely delineate process s tates. It is important to realize that
only one process can be runningon any processor core at any instant. Many
processesmaybe readyandwaiting,however.Thestatediagramcorresponding
tothesestatesispresentedinFigure3.2.
3.1.3 Process Control Block
Each process is represented in the operating system by a process control
block(PCB)—also called a task control block .APCBis shown in Figure 3.3.
It contains many pieces of information associated with a specific process,
includingthese:
•Process state . The state may be new, ready, ru nning, waiting, halted, and
so on.
•Program counter .Thecounterindicatestheaddressofthenextinstruction
to be executedfor this process.
process state
process number
program counter
memory limits
list of open filesregisters



Figure 3.3 Process control block (PCB)."
3,3.1.4 Threads,148,3.1.3 Process Control Block,"110 Chapter 3 Processes
•CPU registers . The registers vary in number and type, depending on the
computer architecture. They include accumulators, index registers, stack
pointers,andgeneral-purposeregisters,plusanycondition-codeinforma-
tion.Alongwiththeprogramcounter,thisstateinformationmustbesaved
when an interrupt occurs, to allow the process to be continued correctly
afterwardwhenitis rescheduledto run.
•CPU-scheduling information . This information includes a process prior-
ity, pointers to scheduling queues, an d any other scheduling parameters.
(Chapter5 describesprocessscheduling.)
•Memory-management information . This information may include such
itemsasthevalueofthebaseandlimitregistersandthepagetables,orthe
segment tables, depending on the memory system used by the operating
system(Chapter9).
•Accounting information . This information includes the amount of CPU
andrealtimeused,timelimits,account numbers,joborprocessnumbers,
and soon.
•I/Ostatus information . This information includes the list of I/Odevices
allocatedtothe process,a listof openfiles,and so on.
Inbrief,the PCBsimplyservesastherepositoryforallthedataneededtostart,
or restart,a process,along with some accounting data.
3.1.4 Threads
Theprocessmodeldiscussedsofarhasimpliedthataprocessisaprogramthat
performsasingle threadofexecution.Forexample,whenaprocessisrunning
a word-processor program, a single thread of instructions is being executed.
This single thread of control allows the process to perform only one task at a
time.Thus,theusercannotsimultaneouslytypeincharactersandrunthespell
checker. Most modern operating systems have extended the process concept
to allow a process to have multiple threads of execution and thus to perform
more than one task at a time. This feature is especially beneficial on multicore
systems, where multiple threads can run in parallel. A multithreaded word
processor could, for example, assign one thread to manage user input while
anotherthreadrunsthespellchecker.Onsystemsthatsupportthreads,the PCB
isexpandedtoincludeinformationforeachthread.Otherchangesthroughout
the system are also needed to support threads. Chapter 4 explores threads in
detail.
3.2 Process Scheduling
Theobjectiveofmultiprogrammingistohavesomeprocessrunningatalltimes
so as to maximize CPUutilization. The objective of time sharing is to switch
aCPUcore among processes so frequently that users can interact with each
program while it is running. To meet these objectives, the process scheduler
selectsanavailableprocess(possiblyfromasetofseveralavailableprocesses)
for program executionon a core. Each CPUcore can run one process at a time."
2,3.2 Process Scheduling,148,3.1 Process Concept,"110 Chapter 3 Processes
•CPU registers . The registers vary in number and type, depending on the
computer architecture. They include accumulators, index registers, stack
pointers,andgeneral-purposeregisters,plusanycondition-codeinforma-
tion.Alongwiththeprogramcounter,thisstateinformationmustbesaved
when an interrupt occurs, to allow the process to be continued correctly
afterwardwhenitis rescheduledto run.
•CPU-scheduling information . This information includes a process prior-
ity, pointers to scheduling queues, an d any other scheduling parameters.
(Chapter5 describesprocessscheduling.)
•Memory-management information . This information may include such
itemsasthevalueofthebaseandlimitregistersandthepagetables,orthe
segment tables, depending on the memory system used by the operating
system(Chapter9).
•Accounting information . This information includes the amount of CPU
andrealtimeused,timelimits,account numbers,joborprocessnumbers,
and soon.
•I/Ostatus information . This information includes the list of I/Odevices
allocatedtothe process,a listof openfiles,and so on.
Inbrief,the PCBsimplyservesastherepositoryforallthedataneededtostart,
or restart,a process,along with some accounting data.
3.1.4 Threads
Theprocessmodeldiscussedsofarhasimpliedthataprocessisaprogramthat
performsasingle threadofexecution.Forexample,whenaprocessisrunning
a word-processor program, a single thread of instructions is being executed.
This single thread of control allows the process to perform only one task at a
time.Thus,theusercannotsimultaneouslytypeincharactersandrunthespell
checker. Most modern operating systems have extended the process concept
to allow a process to have multiple threads of execution and thus to perform
more than one task at a time. This feature is especially beneficial on multicore
systems, where multiple threads can run in parallel. A multithreaded word
processor could, for example, assign one thread to manage user input while
anotherthreadrunsthespellchecker.Onsystemsthatsupportthreads,the PCB
isexpandedtoincludeinformationforeachthread.Otherchangesthroughout
the system are also needed to support threads. Chapter 4 explores threads in
detail.
3.2 Process Scheduling
Theobjectiveofmultiprogrammingistohavesomeprocessrunningatalltimes
so as to maximize CPUutilization. The objective of time sharing is to switch
aCPUcore among processes so frequently that users can interact with each
program while it is running. To meet these objectives, the process scheduler
selectsanavailableprocess(possiblyfromasetofseveralavailableprocesses)
for program executionon a core. Each CPUcore can run one process at a time."
3,3.2.1 Scheduling Queues,150,3.2 Process Scheduling,"112 Chapter 3 Processes
queue header PCB7
PCB3 PCB14 PCB6PCB2
head
headready
queue
wait
queuetail registers registers
tail•
•
••
•
•
Figure 3.4 The ready queue and wait queues.
to wait until a core is free and can be rescheduled. The number of processes
currentlyinmemoryisknown as the degree of multiprogramming .
Balancing the objectives of multiprogramming and time sharing also
requirestakingthegeneralbehaviorofaprocessintoaccount.Ingeneral,most
processes can be described as either I/Obound or CPUbound. An I/O-bound
process is one that spends more of its time doing I/Othan it spends doing
computations. A CPU-bound process , in contrast, generates I/Orequests
infrequently,usingmoreof itstimedoingcomputations.
3.2.1 Scheduling Queues
Asprocessesenterthesystem,theyareputintoa ready queue ,wheretheyare
readyandwaitingtoexecuteona CPU’scoreThisqueueisgenerallystoredas
alinkedlist;aready-queueheadercontains pointerstothefirst PCBinthelist,
and each PCBincludes a pointer field that points to the next PCBin the ready
queue.
The system also includes other queues. When a process is allocated a CPU
core,itexecutesforawhileandeventuallyterminates,isinterrupted,orwaits
for the occurrence of a particular event, such as the completion of an I/O
request. Suppose the process makes an I/Orequest to a device such as a disk.
Since devices run significantly slower than processors, the process will have
towaitforthe I/Otobecomeavailable.Processesthatarewaitingforacertain
event to occur — such as completion of I/O—a r ep l a c e di na wait queue
(Figure3.4).
A common representation of process scheduling is a queueing diagram ,
suchasthatinFigure3.5.Twotypesofqueuesarepresent:thereadyqueueand
a set of wait queues. The circles representthe resources that serve the queues,
and the arrows indicate the flow of processesin the system.
Anew process is initially put in the ready queue. It waits there until it is
selectedforexecution,or dispatched .Once the processisallocateda CPUcore
and isexecuting,one ofseveraleventscould occur:"
3,3.2.2 CPU Scheduling,151,3.2.1 Scheduling Queues,"3.2 Process Scheduling 113
ready queue CPU
I/O I/O wait queue I/O request
time slice
expired
create child
processchild 
termination
wait queue
wait for an
interruptinterrupt 
wait queueinterrupt
occurschild
terminates
Figure 3.5 Queueing-diagram representation of process scheduling.
•The process could issue an I/Orequest and then be placed in an I/Owait
queue.
•The processcould createanewchild processand thenbe placedina wait
queuewhileitawaits the child’s termination.
•The process could be removed forcibly from the core, as a result of an
interruptorhavingitstimesliceexp ire,andbeputbackinthereadyqueue.
Inthefirsttwocases,theprocesseventuallyswitchesfromthewaitingstate
tothereadystateandisthenputbackinthereadyqueue.Aprocesscontinues
this cycle until it terminates, at which time it is removed from all queues and
has itsPCBand resourcesdeallocated.
3.2.2 CPU Scheduling
Aprocessmigratesamongthereadyqueueandvariouswaitqueuesthrough-
out its lifetime. The role of the CPU scheduler is to select from among the
processesthatareinthereadyqueueandallocatea CPUcoretooneofthem.The
CPUschedulermustselectanewprocessforthe CPUfrequently.An I/O-bound
process may execute for only a few milliseconds before waiting for an I/O
request.Althougha CPU-boundprocesswillrequirea CPUcoreforlongerdura-
tions, the scheduler is unlikely to grant the core to a process for an extended
period.Instead,itislikelydesignedtoforciblyremovethe CPUfromaprocess
andscheduleanotherprocesstorun.Therefore,the CPUschedulerexecutesat
leastonce every100 milliseconds,althoughtypicallymuch morefrequently.
Someoperatingsystemshaveanintermediateform of scheduling,known
asswapping , whose key idea is that sometimes it can be advantageous to
remove a process from memory (and from active contention for the CPU)
and thus reduce the degree of multiprogramming. Later, the process can be
reintroducedintomemory,anditsexecutioncanbecontinuedwhereitleftoff.
This scheme is known as swapping because a process can be “swapped out ”"
3,3.2.3 Context Switch,152,3.2.2 CPU Scheduling,"114 Chapter 3 Processes
frommemorytodisk,whereitscurrentstatusissaved,andlater “swappedin ”
from disk back to memory, where its status is restored. Swapping is typically
only necessary whenmemoryhas beenovercommittedand mustbe freedup.
Swappingis discussedinChapter9.
3.2.3 Context Switch
AsmentionedinSection1.2.1,interruptscausetheoperatingsystemtochange
aCPUcore from its current task and to run a kernel routine. Such operations
happenfrequentlyongeneral-purposesystems.Whenaninterruptoccurs,the
system needs to save the current contextof the process running on the CPU
core so that it can restore that context when its processing is done, essentially
suspending the process and then resuming it. The context is represented in
thePCBof the process. It includes the value of the CPUregisters, the process
state (see Figure 3.2), and memory-management information. Generically, we
performa state save ofthe currentstateof the CPUcore,be itin kerneloruser
mode,and thena state restore to resumeoperations.
Switching the CPUcore to another process requires performing a state
save of the current process and a state restore of a different process. This
task is known as a context switch and is illustrated in Figure 3.6. When a
context switch occurs, the kernel saves the context of the old process in its
PCBandloadsthesavedcontextofthenewprocessscheduledtorun.Context-
switch time is pure overhead, because the system does no useful work while
switching.Switchingspeedvariesfrommachinetomachine,dependingonthe
process P0 process P1
save state into PCB0
save state into PCB1reload state from PCB1
reload state from PCB0operating system
idle
idleexecuting idleexecuting
executinginterrupt or system call
interrupt or system call





Figure 3.6 Diagram showing context switch from process to process."
2,3.3 Operations on Processes,154,3.2 Process Scheduling,"116 Chapter 3 Processes
3.3 Operations on Processes
Theprocessesinmost systemscan executeconcurrently,and theymay becre-
atedanddeleteddynamically.Thus,thesesystemsmustprovideamechanism
for process creation and termination. In this section, we explore the mecha-
nisms involved in creating processes and illustrate process creation on UNIX
and Windows systems.
3.3.1 Process Creation
Duringthecourseofexecution,aprocessmaycreateseveralnewprocesses.As
mentioned earlier,the creating process is called a parentprocess, and the new
processes are called the children of that process. Each of these new processes
may inturncreateother processes,forminga treeof processes.
Most operating systems (including UNIX, Linux, and Windows) identify
processes according to a unique process identifie (orpid), which is typically
an integer number. The pid provides a unique value for each process in the
system,anditcanbeusedasanindextoaccessvariousattributesofaprocess
withinthe kernel.
Figure3.7illustratesa typicalprocesstreeforthe Linux operatingsystem,
showingthenameofeachprocessanditspid.(Weusetheterm processrather
loosely in this situation, as Linux prefers the term taskinstead.) The systemd
process (which always has a pid of 1) serves as the root parent process for all
user processes, and is the first user process created when the system boots.
Once the system has booted, the systemd process creates processes which
provide additional services such as a web or print server, an sshserver, and
the like. In Figure 3.7, we see two children of systemd —logindandsshd.
Thelogindprocess is responsible for managing clients that directly log onto
thesystem.Inthisexample,aclienthasloggedonandisusingthe bashshell,
which has been assigned pid 8416. Using the bashcommand-line interface,
thisuserhascreatedtheprocess psaswellasthe vimeditor.The sshdprocess
is responsible for managing clients that connect to the system by using ssh
(which isshort for secure shell ).
python
pid = 2808logind
pid = 8415systemd
pid = 1
bash
pid = 8416
ps
pid = 9298vim
pid = 9204sshd
pid = 3028
sshd
pid = 3610
tcsh
pid = 4005
Figure 3.7 A tree of processes on a typical Linux system."
3,3.3.1 Process Creation,154,3.3 Operations on Processes,"116 Chapter 3 Processes
3.3 Operations on Processes
Theprocessesinmost systemscan executeconcurrently,and theymay becre-
atedanddeleteddynamically.Thus,thesesystemsmustprovideamechanism
for process creation and termination. In this section, we explore the mecha-
nisms involved in creating processes and illustrate process creation on UNIX
and Windows systems.
3.3.1 Process Creation
Duringthecourseofexecution,aprocessmaycreateseveralnewprocesses.As
mentioned earlier,the creating process is called a parentprocess, and the new
processes are called the children of that process. Each of these new processes
may inturncreateother processes,forminga treeof processes.
Most operating systems (including UNIX, Linux, and Windows) identify
processes according to a unique process identifie (orpid), which is typically
an integer number. The pid provides a unique value for each process in the
system,anditcanbeusedasanindextoaccessvariousattributesofaprocess
withinthe kernel.
Figure3.7illustratesa typicalprocesstreeforthe Linux operatingsystem,
showingthenameofeachprocessanditspid.(Weusetheterm processrather
loosely in this situation, as Linux prefers the term taskinstead.) The systemd
process (which always has a pid of 1) serves as the root parent process for all
user processes, and is the first user process created when the system boots.
Once the system has booted, the systemd process creates processes which
provide additional services such as a web or print server, an sshserver, and
the like. In Figure 3.7, we see two children of systemd —logindandsshd.
Thelogindprocess is responsible for managing clients that directly log onto
thesystem.Inthisexample,aclienthasloggedonandisusingthe bashshell,
which has been assigned pid 8416. Using the bashcommand-line interface,
thisuserhascreatedtheprocess psaswellasthe vimeditor.The sshdprocess
is responsible for managing clients that connect to the system by using ssh
(which isshort for secure shell ).
python
pid = 2808logind
pid = 8415systemd
pid = 1
bash
pid = 8416
ps
pid = 9298vim
pid = 9204sshd
pid = 3028
sshd
pid = 3610
tcsh
pid = 4005
Figure 3.7 A tree of processes on a typical Linux system."
3,3.3.2 Process Termination,159,3.3.1 Process Creation,"3.3 Operations on Processes 121
In this instance, we are loading the Microsoft Windows mspaint.exe appli-
cation.Beyondthesetwoinitialparameters,weusethedefaultparametersfor
inheritingprocessandthreadhandlesaswellasspecifyingthattherewillbeno
creationflags.Wealsousetheparent’sexistingenvironmentblockandstarting
directory.Last,we providetwo pointers to the STARTUPINFO andPROCESS
 -
INFORMATION structures created at the beginning of the program. In Figure
3.8,the parent process waits for the child to complete by invoking the wait()
system call. The equivalent of this in Windows is WaitForSingleObject() ,
which is passed a handle of the child process— pi.hProcess —andwaitsfor
thisprocesstocomplete.Oncethechild processexits,controlreturnsfromthe
WaitForSingleObject() function in the parentprocess.
3.3.2 Process Termination
A process terminates when it finishes executing its final statement and asks
the operating system to delete it by using the exit()system call. At that
point,theprocessmayreturnastatusvalue(typicallyaninteger)toitswaiting
parent process (via the wait()system call). All the resources of the process
—including physical and virtual memory, open files, and I/Obuffers—are
deallocatedandreclaimedby theoperating system.
Termination can occur in othercircumstances aswell. Aprocesscan cause
theterminationofanotherprocessviaanappropriatesystemcall(forexample,
TerminateProcess() inWindows).Usually,suchasystemcallcanbeinvoked
only by the parent of the process that is to be terminated.Otherwise, a user—
or a misbehavingapplication—could arbitrarily killanother user’s processes.
Notethataparentneedstoknowtheidentitiesofitschildrenifitistoterminate
them.Thus,whenoneprocesscreatesanewprocess,theidentityofthenewly
createdprocessispassedtothe parent.
Aparentmayterminatetheexecutionofoneofitschildrenforavarietyof
reasons,such as these:
•The child has exceeded its usage of some of the resources that it has been
allocated. (To determine whether this has occurred, the parent must have
a mechanism to inspectthe stateof itschildren.)
•The taskassignedto thechild isno longerrequired.
•The parent is exiting, and the operating system does not allow a child to
continue ifitsparentterminates.
Some systems do not allow a child to exist if its parent has terminated.
In such systems, if a process terminates (either normally or abnormally), then
all its children must also be terminated. This phenomenon, referred to as
cascading termination ,is normallyinitiatedby the operatingsystem.
Toillustrateprocessexecutionandtermination,considerthat,inLinuxand
UNIXsystems, we can terminate a process by using the exit()system call,
providinganexitstatusas aparameter:
/* exit with status 1 */
exit(1);"
2,3.4 Interprocess Communication,161,3.3 Operations on Processes,"3.4 Interprocess Communication 123
•Service process —A process that is similar to a background process but
is performing an activity that is apparent to the user (such as streaming
music)
•Background process —Aprocess that may be performing an activity but
is not apparenttothe user.
•Empty process —A process that holds no active components associated
with any application
Ifsystemresourcesmustbereclaimed,Androidwillfirstterminateempty
processes, followed by background processes, and so forth. Processes are
assigned an importance ranking, and Android attempts to assign a process as
higharankingaspossible.Forexample,ifaprocessisprovidingaserviceand
isalsovisible,itwill beassignedthem ore-importantvisibleclassification.
Furthermore,Androiddevelopmentpracticessuggestfollowingtheguide-
lines of the process life cycle. When these guidelines are followed, the state of
a process will be saved prior to termination and resumed at its saved state if
theusernavigatesback to theapplication.
3.4 Interprocess Communication
Processes executing concurrently in the operating system may be either inde-
pendentprocessesorcooperatingprocesses.Aprocessis independent ifitdoes
not share data with any other processes executing in the system. A process
iscooperating if it can affect or be affected by the other processes executing
in the system. Clearly, any process that shares data with other processes is a
cooperatingprocess.
Thereareseveralreasonsforprovidinganenvironmentthatallowsprocess
cooperation:
•Information sharing . Since several applications may be interested in the
same piece of information (for instance, copying and pasting), we must
providean environmentto allow concurrent access to such information.
•Computation speedup .Ifwewantaparticulartasktorunfaster,wemust
break itinto subtasks, each of which willbe executingin parallelwith the
others. Notice that such a speedup can be achieved only if the computer
has multipleprocessingcores.
•Modularity . We may want to construct the system in a modular fashion,
dividing the system functions into separate processes or threads, as we
discussedinChapter2.
Cooperating processes require an interprocess communication (IPC)
mechanism that will allow them to exchange data— that is, send data to
and receive data from each other. There are two fundamental models of
interprocess communication: shared memory and message passing .I nt h e
shared-memory model, a region of memory that is shared by the cooperating
processes is established. Processes can then exchange information by reading
and writing data to the shared region. In the message-passing model,"
2,3.5 IPC in Shared-Memory Systems,163,3.4 Interprocess Communication,"3.5 IPC in Shared-Memory Systems 125
process A
message queue
(a) (b)process B
m0m1m2 ... m3 mn
kernelshared memory
kernelprocess process 
BA
Figure 3.11 Communications models. (a) Shared memory. (b) Message passing.
Both of the models just mentioned are common in operating systems,
and many systemsimplementboth. Messagepassing isusefulforexchanging
smalleramountsofdata,because noco nflicts needbeavoided.Messagepass-
ing is also easier to implement in a distributed system than shared memory.
(Although there are systems that provide distributed shared memory, we do
notconsidertheminthistext.)Sharedmemorycanbefasterthanmessagepass-
ing, since message-passing systems are typically implemented using system
calls and thus require the more time-consuming task of kernel intervention.
Inshared-memorysystems,systemcallsarerequiredonlytoestablishshared-
memory regions. Once shared memory is established, all accesses are treated
asroutinememoryaccesses,and no assistance from thekernelisrequired.
In Section 3.5 and Section 3.6 we explore shared-memory and message-
passingsystemsinmoredetail.
3.5 IPC in Shared-Memory Systems
Interprocess communication using shared memory requires communicating
processesto establisha regionof shared memory.Typically,a shared-memory
region residesin the address space of the process creating the shared-memory
segment.Otherprocessesthatwishtocommunicateusingthisshared-memory
segment must attach it to their address space. Recall that, normally, the oper-
ating system tries to prevent one proces s from accessing another process’s
memory.Sharedmemoryrequiresthattwoormoreprocessesagreetoremove
this restriction. They can then exchange information by reading and writing
datain thesharedareas.Theformofthedataandthelocationaredetermined
by these processes and are not under the operating system’s control. The pro-
cesses are also responsible for ensuring that they are not writing to the same
location simultaneously."
2,3.6 IPC in Message-Passing Systems,165,3.5 IPC in Shared-Memory Systems,"3.6 IPC in Message-Passing Systems 127
item next
 produced;
while (true) {
/* produce an item in next
 produced */
while (((in + 1) % BUFFER
 SIZE) == out)
; /* do nothing */
buffer[in] = next
 produced;
in = (in + 1) % BUFFER
 SIZE;
}
Figure 3.12 The producer process using shared memory.
Oneissuethisillustrationdoesnotaddressconcernsthesituationinwhich
both the producer process and the consumer process attempt to access the
shared buffer concurrently. In Chapter 6 and Chapter 7, we discuss how syn-
chronization among cooperating processes can be implemented effectively in
ashared-memoryenvironment.
3.6 IPC in Message-Passing Systems
In Section 3.5, we showed how cooperating processes can communicate in a
shared-memoryenvironment.Theschemerequiresthattheseprocessessharea
regionofmemoryandthatthecodeforaccessingandmanipulatingtheshared
memorybewrittenexplicitlyby theapplicationprogrammer.Anotherway to
achieve the same effect is for the operating system to provide the means for
cooperating processesto communicate with each other via a message-passing
facility.
item next
 consumed;
while (true) {
while (in == out)
; /* do nothing */
next
 consumed = buffer[out];
out = (out + 1) % BUFFER
 SIZE;
/* consume the item in next
 consumed */
}
Figure 3.13 The consumer process using shared memory."
3,3.6.1 Naming,166,3.6 IPC in Message-Passing Systems,"128 Chapter 3 Processes
Messagepassingprovidesamechanismtoallowprocessestocommunicate
and to synchronize their actions without sharing the same address space. It
is particularly useful in a distributedenvironment, where the communicating
processes may reside on different computers connected by a network. For
example,anInternet chatprogramcouldbedesignedsothatchatparticipants
communicate with one another by exchanging messages.
Amessage-passingfacilityprovidesatleasttwo operations:
send(message)
and
receive(message)
Messages sent by a process can be either fixed or variable in size. If only
fixed-sizedmessagescan besent,thesystem-levelimplementationisstraight-
forward.Thisrestriction,however,makesthetaskofprogrammingmorediffi-
cult.Conversely,variable-sizedmessagesrequireamorecomplexsystem-level
implementation,buttheprogrammingtaskbecomessimpler.Thisisacommon
kindof tradeoffseenthroughout operating-systemdesign.
Ifprocesses PandQwanttocommunicate,theymustsendmessagestoand
receive messages from each other: a communication link must exist between
them.Thislinkcanbeimplementedinavarietyofways.Weareconcernedhere
notwiththelink’sphysicalimplementation(suchassharedmemory,hardware
bus, or network, which are covered in Chapter 19) but rather with its logical
implementation. Here are several methods for logically implementing a link
and the send()/receive() operations:
•Directorindirectcommunication
•Synchronous or asynchronous communication
•Automaticor explicitbuffering
Welook at issuesrelatedto eachof thesefeaturesnext.
3.6.1 Naming
Processes that want to communicate must have a way to refer to each other.
Theycan use eitherdirector indirectcommunication.
Under direct communication , each process that wants to communicate
must explicitly name the recipient or sender of the communication. In this
scheme, the send()andreceive() primitivesaredefinedas:
•send(P, message) —Senda message toprocess P.
•receive(Q, message) —Receivea message fromprocess Q.
Acommunication linkin this schemehas the following properties:
•A link is established automatically between every pair of processes that
want to communicate. The processes need to know only each other’s
identityto communicate."
3,3.6.2 Synchronization,168,3.6.1 Naming,"130 Chapter 3 Processes
•Allowat mostone processat atimeto executea receive() operation.
•Allow the system to select arbitrarily which process will receive the mes-
sage (that is, either P2orP3, but not both, will receive the message). The
system may define an algorithm for selecting which process will receive
themessage(forexample, round robin, whereprocessestaketurnsreceiv-
ing messages).Thesystemmayidentifythereceivertothe sender.
Amailbox may be owned either by a process or by the operating system.
Ifthemailboxisownedbyaprocess(th atis,themailboxispartoftheaddress
space of the process), then we distinguish between the owner (which can
only receive messages through this mailbox) and the user (which can only
send messages to the mailbox). Since each mailbox has a unique owner, there
can be no confusion about which process should receive a message sent to
this mailbox. When a process that owns a mailbox terminates, the mailbox
disappears. Any process that subsequently sends a message to this mailbox
mustbe notified that the mailboxno longerexists.
In contrast, a mailbox that is owned by the operating system has an exis-
tenceofitsown.Itisindependentandisnotattachedtoanyparticularprocess.
Theoperatingsystemthenmustprovideamechanismthatallowsaprocessto
dothe following:
•Createa newmailbox.
•Sendand receivemessagesthrough themailbox.
•Deletea mailbox.
The process that creates a new mailbox is that mailbox’s owner by default.
Initially, the owner is the only process that can receive messages through this
mailbox. However, the ownership and receiving privilege may be passed to
other processes through appropriate system calls. Of course, this provision
could resultinmultiplereceiversfor eachmailbox.
3.6.2 Synchronization
Communication between processes takes place through calls to send()and
receive() primitives. There are different design options for implementing
each primitive. Message passing may be either blocking ornonblocking —
alsoknownas synchronous andasynchronous .(Throughoutthistext,youwill
encountertheconceptsofsynchronousandasynchronousbehaviorinrelation
to variousoperating-systemalgorithms.)
•Blocking send . The sending process is blocked until the message is
receivedby thereceivingprocessor by themailbox.
•Nonblocking send . The sending process sends the message and resumes
operation.
•Blocking receive . The receiverblocks until amessageisavailable.
•Nonblocking receive . The receiver retrieves either a valid message or a
null."
3,3.6.3 Buffering,169,3.6.2 Synchronization,"3.6 IPC in Message-Passing Systems 131
message next
 produced;
while (true) {
/* produce an item in next
 produced */
send(next
 produced);
}
Figure 3.14 The producer process using message passing.
Differentcombinationsof send()andreceive() arepossible.Whenboth
send() and receive() are blocking, we have a rendezvous between the
sender and the receiver. The solution to the producer–consumer problem
becomestrivialwhenweuseblocking send()andreceive() statements.The
producermerelyinvokestheblocking send()callandwaitsuntilthemessage
isdeliveredtoeitherthereceiverorthemailbox.Likewise,whentheconsumer
invokes receive() ,itblocksuntilamessageisavailable.Thisisillustratedin
Figures3.14 and 3.15.
3.6.3 Buffering
Whethercommunicationisdirectorindirect,messagesexchangedbycommu-
nicating processes reside in a temporar y queue. Basically, such queues can be
implementedinthreeways:
•Zero capacity . The queue has a maximum length of zero; thus, the link
cannothaveanymessageswaitinginit.Inthiscase,thesendermustblock
until therecipientreceivesthemessage.
•Bounded capacity .Thequeuehasfinitelength n;thus,atmost nmessages
can reside in it. If the queue is not full when a new message is sent, the
message is placed in the queue (either the message is copied or a pointer
to the message is kept), and the sender can continue execution without
message next
 consumed;
while (true) {
receive(next
 consumed);
/* consume the item in next
 consumed */
}
Figure 3.15 The consumer process using message passing."
2,3.7 Examples of IPC Systems,170,3.6 IPC in Message-Passing Systems,"132 Chapter 3 Processes
waiting.Thelink’scapacityisfinite,however.Ifthelinkisfull,thesender
mustblock untilspaceis availableinthe queue.
•Unbounded capacity . The queue’s length is potentially infinite; thus, any
number of messagescan waitinit.Thesenderneverblocks.
The zero-capacity case is sometimes referred to as a message system with no
buffering.Theothercasesarereferredtoassystemswithautomaticbuffering.
3.7 Examples of IPC Systems
In this section, we explore four different IPCsystems. We first cover the POSIX
APIfor shared memory and then discuss message passing in the Mach oper-
ating system. Next, we present Windows IPC, which interestingly uses shared
memory as a mechanism for providing certain types of message passing. We
conclude withpipes,one of theearliest IPCmechanisms on UNIXsystems.
3.7.1 POSIX Shared Memory
Several IPCmechanisms are available for POSIXsystems, including shared
memory and message passing. Here, we explore the POSIX API for shared
memory.
POSIXshared memory is organized using memory-mapped files, which
associate the region of shared memory with a file. Aprocess must first create
a shared-memoryobject using the shm
open()systemcall, asfollows:
fd = shm
 open(name, O
 CREAT | O
 RDWR, 0666);
Thefirstparameterspecifiesthenameoftheshared-memoryobject.Processes
that wish to access this shared memory must refer to the object by this name.
Thesubsequentparametersspecifythattheshared-memoryobjectistobecre-
atedifitdoesnotyetexist( O
CREAT)andthattheobjectisopenforreadingand
writing ( O
RDWR). The last parameter establishes the file-access permissions of
the shared-memory object. Asuccessful call to shm
open()returns an integer
filedescriptorforthe shared-memoryobject.
Once the object is established, the ftruncate() function is used to
configure the size of the object in bytes.The call
ftruncate(fd, 4096);
setsthesizeof theobject to 4,096 bytes.
Finally,the mmap()functionestablishesamemory-mappedfilecontaining
theshared-memoryobject.Italsoreturnsapointertothememory-mappedfile
that isused for accessing the shared-memoryobject.
The programs shown in Figure 3.16 and Figure 3.17 use the producer–
consumermodelinimplementingsharedmemory.Theproducerestablishesa
shared-memory object and writes to shared memory, and the consumer reads
from sharedmemory."
3,3.7.1 POSIX Shared Memory,170,3.7 Examples of IPC Systems,"132 Chapter 3 Processes
waiting.Thelink’scapacityisfinite,however.Ifthelinkisfull,thesender
mustblock untilspaceis availableinthe queue.
•Unbounded capacity . The queue’s length is potentially infinite; thus, any
number of messagescan waitinit.Thesenderneverblocks.
The zero-capacity case is sometimes referred to as a message system with no
buffering.Theothercasesarereferredtoassystemswithautomaticbuffering.
3.7 Examples of IPC Systems
In this section, we explore four different IPCsystems. We first cover the POSIX
APIfor shared memory and then discuss message passing in the Mach oper-
ating system. Next, we present Windows IPC, which interestingly uses shared
memory as a mechanism for providing certain types of message passing. We
conclude withpipes,one of theearliest IPCmechanisms on UNIXsystems.
3.7.1 POSIX Shared Memory
Several IPCmechanisms are available for POSIXsystems, including shared
memory and message passing. Here, we explore the POSIX API for shared
memory.
POSIXshared memory is organized using memory-mapped files, which
associate the region of shared memory with a file. Aprocess must first create
a shared-memoryobject using the shm
open()systemcall, asfollows:
fd = shm
 open(name, O
 CREAT | O
 RDWR, 0666);
Thefirstparameterspecifiesthenameoftheshared-memoryobject.Processes
that wish to access this shared memory must refer to the object by this name.
Thesubsequentparametersspecifythattheshared-memoryobjectistobecre-
atedifitdoesnotyetexist( O
CREAT)andthattheobjectisopenforreadingand
writing ( O
RDWR). The last parameter establishes the file-access permissions of
the shared-memory object. Asuccessful call to shm
open()returns an integer
filedescriptorforthe shared-memoryobject.
Once the object is established, the ftruncate() function is used to
configure the size of the object in bytes.The call
ftruncate(fd, 4096);
setsthesizeof theobject to 4,096 bytes.
Finally,the mmap()functionestablishesamemory-mappedfilecontaining
theshared-memoryobject.Italsoreturnsapointertothememory-mappedfile
that isused for accessing the shared-memoryobject.
The programs shown in Figure 3.16 and Figure 3.17 use the producer–
consumermodelinimplementingsharedmemory.Theproducerestablishesa
shared-memory object and writes to shared memory, and the consumer reads
from sharedmemory."
3,3.7.2 Mach Message Passing,173,3.7.1 POSIX Shared Memory,"3.7 Examples of IPC Systems 135
The consumer process, shown in Figure 3.17, reads and outputs the con-
tents of the shared memory. The consumer also invokes the shm
unlink()
function, which removes the shared-me mory segment after the consumer has
accessedit.Weprovidefurtherexercisesusingthe POSIXshared-memory APIin
theprogrammingexercisesattheendofthischapter.Additionally,weprovide
moredetailedcoverageof memorymapping inSection13.5.
3.7.2 Mach Message Passing
As an example of message passing, we next consider the Mach operating
system.Machwasespeciallydesignedfordistributedsystems,butwasshown
to be suitable for desktop and mobile systems as well, as evidenced by its
inclusion in the mac OSand iOSoperatingsystems,as discussedinChapter2.
The Mach kernel supports the creation and destruction of multiple tasks,
which are similar to processes but have multiple threads of control and
fewerassociatedresources.MostcommunicationinMach—includingallinter-
task communication—is carried out by messages . Messages are sent to, and
receivedfrom,mailboxes,whicharecalled portsinMach.Portsarefiniteinsize
andunidirectional;fortwo-waycommunication,amessageissenttooneport,
and a response is sent to a separate replyport. Each port may have multiple
senders, but only one receiver. Mach uses ports to represent resources such
as tasks, threads, memory, and processors, while message passing provides
an object-oriented approach for interacting with these system resources and
services.Messagepassingmayoccurbetweenanytwoportsonthesamehost
oronseparatehosts ona distributedsystem.
Associated with each port is a collection of port rights that identify
the capabilities necessary for a task to interact with the port. For example,
for a task to receive a message from a port, it must have the capability
MACH
 PORT
 RIGHT
 RECEIVE for that port. The task that creates a port is that
port’sowner,andtheowneristheonlytaskthatisallowedtoreceivemessages
fromthatport.Aport’sownermayalsomanipulatethecapabilitiesforaport.
Thisismostcommonlydoneinestablishingareplyport.Forexample,assume
that task T1o w n sp o r t P1, and it sends a message to port P2, which is owned
by task T2. If T1 expects to receive a reply from T2, it must grant T2t h e
right MACH
 PORT
 RIGHT
 SENDfor port P1. Ownership of port rights is at the
task level, which means that all threads belonging to the same task share the
same port rights. Thus, two threads belonging to the same task can easily
communicatebyexchangingmessagesthroughtheper-threadportassociated
with each thread.
When a task is created, two special ports—the Task Self port and the
Notifyport—are also created. The kernel has receive rights to the Task Self
port, which allows a task to send messages to the kernel. The kernel can send
notification of event occurrences to a task’s Notify port (to which, of course,
thetaskhas receiverights).
Themach
 port
 allocate() function callcreatesanewportandallocates
space for its queue of messages. It also id entifies the rights for the port. Each
port right represents a namefor that port, and a port can only be accessed via"
3,3.7.3 Windows,176,3.7.2 Mach Message Passing,"138 Chapter 3 Processes
port’s queue is full, the sender has several options (specified via parameters
tomach
 msg():
1.Wait indefinitelyuntil thereisroominthe queue.
2.Wait at most nmilliseconds.
3.D on o tw a i ta ta l lb u tr a t h e rr e t u r ni m m e d i a t e l y .
4.Temporarily cache a message. Here, a message is given to the operating
system to keep, even though the queue to which that message is being
sent is full. When the message can be put in the queue, a notification
messageissentback tothesender.Onlyonemessagetoa fullqueuecan
be pendingatany timefor a givensending thread.
The final option is meant for server tasks. After finishing a request, a server
task may need to send a one-time reply to the task that requested the service,
butitmustalsocontinuewithotherservicerequests,evenifthereplyportfor
a clientisfull.
Themajorproblemwithmessagesystemshasgenerallybeenpoorperfor-
mance causedbycopyingofmessagesfromthesender’sporttothe receiver’s
port. The Mach message system attempts to avoid copy operations by using
virtual-memory-managementtechniques(Chapter10).Essentially,Machmaps
the address space containing the sender’s message into the receiver’saddress
space.Therefore,themessageitselfisneveractuallycopied,asboththesender
and receiver access the same memory. This message-management technique
providesalargeperformanceboost butworks only for intrasystemmessages.
3.7.3 Windows
TheWindowsoperatingsystemisanexampleofmoderndesignthatemploys
modularity to increase functionalit y and decrease the time needed to imple-
ment new features. Windows provides support for multiple operating envi-
ronments,or subsystems. Applicationprogramscommunicatewiththesesub-
systemsviaamessage-passingmechanism.Thus,applicationprogramscanbe
consideredclientsof a subsystemserver.
Themessage-passingfacilityinWindowsiscalledthe advanced local pro-
cedure call (ALPC)facility.Itisusedforcommunicationbetweentwoprocesses
on the same machine. It is similar to the standard remote procedure call ( RPC)
mechanismthatiswidelyused,butitisoptimizedforandspecifictoWindows.
(Remoteprocedurecallsarecoveredinde tailinSection3.8.2.)LikeMach,Win-
dows uses a port object to establish and maintain a connection between two
processes.Windows usestwo typesofports: connection ports and communi-
cation ports .
Serverprocessespublishconnection-portobjectsthatarevisibletoallpro-
cesses.Whenaclientwantsservicesfromasubsystem,itopensahandletothe
server’s connection-port object and sends a connection request to that port.
The serverthen createsachannel and returnsahandle tothe client.The chan-
nel consists of a pair of private communication ports: one for client–server
messages, the other for server–client messages. Additionally, communication
channels support a callback mechani sm that allows the client and server to
accept requestswhen theywould normally be expectinga reply."
3,3.7.4 Pipes,177,3.7.3 Windows,"3.7 Examples of IPC Systems 139
Connection
PortConnection
request Handle
Handle
HandleClient
Communication Port
Server
Communication Port
Shared
Section Object
(> 256 bytes)Server Client
Figure 3.19 Advanced local procedure calls in Windows.
Whenan ALPCchanneliscreated,oneofthreemessage-passingtechniques
ischosen:
1.For small messages (up to 256 bytes), the port’s message queue is used
asintermediatestorage,andthemessagesarecopiedfromoneprocessto
theother.
2.Larger messages must be passed through a section object ,w h i c hi sa
regionof sharedmemoryassociatedwith thechannel.
3.W h ent h ea m o u n to fda t ai st o ol a r g et ofi ti n t oas ec t i o no b j ec t ,a n APIis
available that allows server processes to read and write directly into the
addressspaceof a client.
The client has to decide when it sets up the channel whether it will need
to send a large message. If the client determines that it does want to send
largemessages,itasksforasectionobjecttobecreated.Similarly,iftheserver
decides that replies will be large, it creates a section object. So that the section
object can be used, a small message is sent that contains a pointer and size
informationaboutthesectionobject.Thismethodismorecomplicatedthanthe
firstmethodlistedabove,butitavoidsdatacopying.Thestructureofadvanced
localprocedurecallsin Windows is shown in Figure3.19.
It is important to note that the ALPCfacility in Windows is not part of the
Windows APIand hence is not visible to the app lication programmer. Rather,
applications using the Windows APIinvoke standard remote procedure calls.
When the RPCis being invoked on a process on the same system, the RPCis
handledindirectlythroughan ALPCprocedurecall.Additionally,manykernel
servicesuse ALPCto communicate with clientprocesses.
3.7.4 Pipes
Apipeacts as a conduit allowing two processes to communicate. Pipes were
one of the first IPCmechanisms in early UNIXsystems. They typically pro-
vide one of the simpler ways for processes to communicate with one another,
althoughtheyalsohavesomelimitations.Inimplementinga pipe,fourissues
mustbe considered:"
2,3.8 Communication in Client–Server Systems,183,3.7 Examples of IPC Systems,"3.8 Communication in Client–Server Systems 145
#include <stdio.h >
#include <windows.h >
#define BUFFER
 SIZE 25
int main(VOID)
{
HANDLE Readhandle;
CHAR buffer[BUFFER
 SIZE];
DWORD read;
/* get the read handle of the pipe */
ReadHandle = GetStdHandle(STD
 INPUT
 HANDLE);
/* the child reads from the pipe */
if (ReadFile(ReadHandle, buffer, BUFFER
 SIZE, &read, NULL))
printf(""child read %s"",buffer);
else
fprintf(stderr, ""Error reading from pipe"");
return 0;
}
Figure 3.25 Windows anonymous pipes—child process.
fromthefile system.Although FIFOs allow bidirectionalcommunication, only
half-duplex transmission is permitted. If data must travel in both directions,
twoFIFOsaretypicallyused.Additionally,thecommunicatingprocessesmust
resideonthesamemachine.Ifintermachinecommunicationisrequired,sock-
ets(Section3.8.1)must beused.
NamedpipesonWindowssystemsprovidearichercommunicationmech-
anism than their UNIXcounterparts. Full-duplex communication is allowed,
and the communicating processes may reside on either the same or different
machines. Additionally, only byte-oriented data may be transmitted across a
UNIX FIFO , whereas Windows systems allow either byte- or message-oriented
data. Named pipes are created with the CreateNamedPipe() function, and a
client can connect to a named pipe using ConnectNamedPipe() . Communi-
cation over the named pipe can be accomplished using the ReadFile() and
WriteFile() functions.
3.8 Communication in Client–Server Systems
In Section 3.4, we described how processes can communicate using shared
memory and message passing. These techniques can be used for communica-
tioninclient–serversystems(Section1.10.3)aswell.Inthissection,weexplore
two other strategies for communication in client–server systems: sockets and"
3,3.8.1 Sockets,184,3.8 Communication in Client–Server Systems,"146 Chapter 3 Processes
PIPES IN PRACTICE
Pipes are used quite often in the UNIXcommand-line environment for situ-
ations in which the output of one command serves as input to another. For
example, the UNIX lscommand produces a directory listing. For especially
long directory listings, the output may scroll through several screens. The
command lessmanages output by displaying only one screen of output at
at i m ew h e r et h eu s e rm a yu s ec e r t a i n keys to move forward or backward
in the file. Setting up a pipe between the lsandlesscommands (which
are running as individual processes) allows the output of lsto be delivered
as the input to less, enabling the user to display a large directory listing a
screenat a time. Apipecan beconstructedon thecommandline using the |
character.Thecompletecommandis
ls | less
In this scenario, the lscommand serves as the producer, and its output is
consumedby the lesscommand.
Windows systems provide a morecommand for the DOSshell with func-
tionality similar to that of its UNIXcounterpart less.(UNIXsystems also
providea morecommand,butinthetongue-in-cheekstylecommonin UNIX,
thelesscommand in fact provides morefunctionality than more!) TheDOS
shell also uses the |character for establishing a pipe. The only difference is
that to get a directory listing, DOSuses the dircommand rather than ls,a s
shown below:
dir | more
remote procedure calls ( RPCs). As we shall see in our coverage of RPCs, not
onlyaretheyusefulforclient–servercomputing,butAndroidalsousesremote
proceduresas a formof IPCbetweenprocessesrunning on the samesystem.
3.8.1 Sockets
Asocketisdefinedasanendpointforcommunication.Apairofprocessescom-
municating over a network employs a pair of sockets—one for each process.
As o c k e ti si d e n t i fi e db ya n IPaddress concatenated with a port number. In
general,socketsuseaclient–serverarchitecture.Theserverwaitsforincoming
client requests by listening to a specified port. Once a request is received, the
server accepts a connection from the client socket to complete the connection.
Servers implementing specific services (such as SSH,FTP,a n dHTTP) listen to
well-known ports (an SSHserver listens to port 22; an FTPserver listens to
port 21; and a web, or HTTP, server listens to port 80). All ports below 1024
areconsidered well known and areusedtoimplementstandardservices.
When a client process initiates a request for a connection, it is assigned a
port by its host computer. This port has some arbitrary number greater than
1024. For example, if a client on host XwithIPaddress 146.86.5.20 wishes to
establish a connection with a web server (which is listening on port 80) at"
3,3.8.2 Remote Procedure Calls,187,3.8.1 Sockets,"3.8 Communication in Client–Server Systems 149
import java.net.*;
import java.io.*;
public class DateClient
{
public static void main(String[] args) {
try {
/* make connection to server socket */
Socket sock = new Socket (""127.0.0.1"",6013);
InputStream in = sock.getInputStream();
BufferedReader bin = new
BufferedReader(new InputStreamReader(in));
/* read the date from the socket */
String line;
while ( (line = bin.readLine()) != null)
System.out.println(line);
/* close the socket connection*/
sock.close();
}
catch (IOException ioe) {
System.err.println(ioe);
}
}
}
Figure 3.28 Date client.
Communication using sockets—although common and efficient—is con-
sidered a low-level form of communication between distributed processes.
One reason is that sockets allow only an unstructured stream of bytes to be
exchanged between the communicating threads. It is the responsibility of the
client or server application to impose a structure on the data. In the next sub-
section, we look a higher-level method of communication: remote procedure
calls(RPCs).
3.8.2 Remote Procedure Calls
One of the most common forms of remote service is the RPCparadigm, which
was designed as a way to abstract the procedure-call mechanism for use
betweensystemswithnetworkconnections.Itissimilarinmanyrespectstothe
IPCmechanismdescribedinSection3.4,anditisusuallybuiltontopofsucha
system.Here,however,becauseweared ealingwithanenvironmentinwhich
theprocessesareexecutingonseparatesystems,wemustuseamessage-based
communication schemeto provideremoteservice."
2,3.9 Summary,191,3.8 Communication in Client–Server Systems,"3.9 Summary 153
service. This interface is written in regular Java syntax and uses the Android
InterfaceDefinition Language— AIDL—to createstubfiles,whichserveasthe
clientinterfaceto remoteservices.
Here, we briefly outline the process required to provide a generic remote
servicenamed remoteMethod() usingAIDLand the binder service.The inter-
facefor theremoteserviceappearsasfollows:
/* RemoteService.aidl */
interface RemoteService
{
boolean remoteMethod(int x, double y);
{
This file is written as RemoteService.aidl . The Android development kit
will use it to generate a .javainterface from the .aidlfile, as well as a stub
thatservesasthe RPCinterfaceforthisservice.Theservermustimplementthe
interfacegeneratedby the .aidlfile,andtheimplementationofthisinterface
willbecalledwhen the clientinvokes remoteMethod() .
When a client calls bindService() ,t h e onBind() method is invoked on
the server, and it returns the stub for the RemoteService object to the client.
The clientcan then invoke the remotemethod asfollows:
RemoteService service;
...
service.remoteMethod(3, 0.14);
Internally, the Androidbinder frame work handles parametermarshaling,
transferring marshaled parameters between processes, and invoking the nec-
essaryimplementationoftheservice,aswellassendinganyreturnvaluesback
tothe clientprocess.
3.9 Summary
•Aprocessisaprograminexecution,andthestatusofthecurrentactivityof
aprocessisrepresentedbytheprogramcounter,aswellasotherregisters.
•Thelayoutofaprocessinmemoryisrepresentedbyfourdifferentsections:
(1) text,(2)data,(3) heap,and (4) stack.
•As a process executes, it changes state. There are four general states of a
process:(1) ready,(2)running, (3) waiting, and(4) terminated.
•Aprocess control block ( PCB) is the kerneldata structurethat representsa
processinanoperating system.
•Theroleoftheprocessscheduleristoselectanavailableprocesstorunon
aCPU.
•An operating system performs a context switch when it switches from
running one processto running another."
2,Practice Exercises,192,3.9 Summary,"154 Chapter 3 Processes
•Thefork()andCreateProcess() system calls are used to create pro-
cesseson UNIXand Windows systems,respectively.
•Whensharedmemoryisusedforcommunicationbetweenprocesses,two
(or more) processes share the same region of memory. POSIXprovides an
APIfor shared memory.
•Two processes may communicate by exchanging messages with one
anotherusingmessagepassing.TheMachoperatingsystemusesmessage
passing as its primary form of interprocess communication. Windows
providesa form of messagepassing aswell.
•A pipe provides a conduit for two processes to communicate. There are
twoformsofpipes,ordinaryandnamed.Ordinarypipesaredesignedfor
communication between processes that have a parent–child relationship.
Named pipes are more general and allow several processes to communi-
cate.
•UNIXsystems provide ordinary pipes through the pipe()system call.
Ordinarypipeshaveareadendandawriteend.Aparentprocesscan,for
example, send data to the pipe using its write end, and the child process
canreaditfrom itsreadend.Namedpipesin UNIXaretermed FIFOs.
•Windows systems also provide two forms of pipes—anonymous and
named pipes.Anonymous pipes are similarto UNIXordinary pipes.They
are unidirectional and employ parent–child relationships between the
communicatingprocesses.Namedpipesofferaricherformofinterprocess
communication than the UNIXcounterpart, FIFOs.
•Two common forms of client–server communication are sockets and
remote procedure calls ( RPCs). Sockets allow two processes on different
machines to communicate over a network. RPCs abstract the concept of
function(procedure)callsinsuchawaythatafunctioncanbeinvokedon
another processthat may resideona separatecomputer.
•The Android operating system uses RPCs as a form of interprocess com-
munication usingitsbinder framework.
Practice Exercises
3.1Using the program shown in Figure 3.30, explain what the output will
be at LINE A.
3.2Includingthe initialparentprocess,howmanyprocessesarecreatedby
the programshown in Figure 3.31?
3.3Original versions of Apple’s mobile i OSoperating system provided no
meansofconcurrentprocessing.Discussthreemajorcomplicationsthat
concurrent processing addsto an operatingsystem.
3.4Some computer systems provide multiple register sets. Describe what
happens when a context switch occurs if the new context is already"
2,Further Reading,194,Practice Exercises,"156 Chapter 3 Processes
#include <stdio.h >
#include <unistd.h >
int main()
{
/* fork a child process */
fork();
/* fork another child process */
fork();
/* and fork another */
fork();
return 0;
}
Figure 3.31 How many processes are created?
Further Reading
Process creation, management, and IPCinUNIXand Windows systems,
respectively, are discussed in [Robbins and Robbins (2003)] and [Russinovich
et al. (2017)]. [Love (2010)] covers support for processes in the Linux
kernel, and [Hart (2005)] covers Windows systems programming in detail.
CoverageofthemultiprocessmodelusedinGoogle’sChromecanbefoundat
http://blog.chromium.org/2008/09/mu lti-process-architecture.html .
Messagepassingformulticoresystemsisdiscussedin[HollandandSeltzer
(2011)].[Levin(2013)]describesmessagepassingintheMachsystem,particu-
larlywithrespectto mac OSand iOS.
[Harold (2005)] providescoverageof socket programming in Java. Details
onAndroid RPCscanbefoundat https://developer.android.com/guide/compo
nents/aidl.html .[Hart(2005)]and[Robbins andRobbins(2003)]coverpipesin
Windows and UNIXsystems,respectively.
GuidelinesforAndroiddevelopmentcanbefoundat https://developer.and
roid.com/guide/ .
Bibliography
[Harold (2005)] E.R.Harold, Java Network Programming, ThirdEdition,O’Reilly
& Associates (2005).
[Hart (2005)] J. M. Hart, Windows System Programming, Third Edition, Addison-
Wesley (2005)."
2,Bibliography,194,Further Reading,"156 Chapter 3 Processes
#include <stdio.h >
#include <unistd.h >
int main()
{
/* fork a child process */
fork();
/* fork another child process */
fork();
/* and fork another */
fork();
return 0;
}
Figure 3.31 How many processes are created?
Further Reading
Process creation, management, and IPCinUNIXand Windows systems,
respectively, are discussed in [Robbins and Robbins (2003)] and [Russinovich
et al. (2017)]. [Love (2010)] covers support for processes in the Linux
kernel, and [Hart (2005)] covers Windows systems programming in detail.
CoverageofthemultiprocessmodelusedinGoogle’sChromecanbefoundat
http://blog.chromium.org/2008/09/mu lti-process-architecture.html .
Messagepassingformulticoresystemsisdiscussedin[HollandandSeltzer
(2011)].[Levin(2013)]describesmessagepassingintheMachsystem,particu-
larlywithrespectto mac OSand iOS.
[Harold (2005)] providescoverageof socket programming in Java. Details
onAndroid RPCscanbefoundat https://developer.android.com/guide/compo
nents/aidl.html .[Hart(2005)]and[Robbins andRobbins(2003)]coverpipesin
Windows and UNIXsystems,respectively.
GuidelinesforAndroiddevelopmentcanbefoundat https://developer.and
roid.com/guide/ .
Bibliography
[Harold (2005)] E.R.Harold, Java Network Programming, ThirdEdition,O’Reilly
& Associates (2005).
[Hart (2005)] J. M. Hart, Windows System Programming, Third Edition, Addison-
Wesley (2005)."
2,Chapter 3 Exercises,196,Bibliography,"Exercises
Chapter 3 Exercises
3.8Describe the actions taken by a kernel to context-switch between pro-
cesses.
3.9Construct a process tree similar to Figure 3.7. To obtain process infor-
mation for the UNIXor Linux system, use the command ps -ael .
Use the command man psto get more information about the pscom-
mand. The task manager on Windows systems does not provide the
parent process ID,b u tt h e process monitor tool, available from tech-
net.microsoft.com ,providesa process-treetool.
3.10Explain the role of the init(orsystemd )p r o c e s so n UNIXand Linux
systemsinregardto processtermination.
3.11Includingtheinitialparentprocess,how manyprocessesarecreatedby
the programshown in Figure3.32?
3.12Explain the circumstances under which the line of code marked
printf(""LINE J"") inFigure3.33willbe reached.
3.13UsingtheprograminFigure3.34,identifythevaluesof pidatlines A,B,
C,a n d D. (Assume that the actual pids of the parent and child are 2600
and 2603, respectively.)
3.14Giveanexampleofasituationinwhichordinarypipesaremoresuitable
than named pipes and an example of a situation in which named pipes
a r emo r esu ita b leth a no r din a rypipes.
3.15Consider the RPCmechanism. Describe the undesirable consequences
that could arise fromnot enforcingeitherthe “atmost once ”or“exactly
once ”semantic.Describepossibleusesforamechanismthathasneither
of theseguarantees.
3.16Using the program shown in Figure 3.35, explain what the output will
be atlines XandY.
#include <stdio.h >
#include <unistd.h >
int main()
{
int i;
f o r( i=0 ;i<4 ; i++)
fork();
return 0;
}
Figure 3.21 How many processes are created?EX-4"
2,Programming Problems,200,Chapter 3 Exercises,"Programming Problems
Programming Problems
3.18Using either a UNIXor a Linux system, write a C program that forks
a child process that ultimately becomes a zombie process. This zombie
processmustremaininthesystemforatleast10seconds.Processstates
can be obtained fromthe command
ps -l
Theprocessstatesareshownbelowthe Scolumn;processeswithastate
ofZarezombies.Theprocessidentifier(pid)ofthechildprocessislisted
inthe PIDcolumn, and thatof the parentislistedin the PPIDcolumn.
Perhapstheeasiestwaytodeterminethatthechildprocessisindeed
azombieistoruntheprogramthatyouhavewritteninthebackground
(using the &) and then run the command ps -lto determine whether
thechildisazombieprocess.Becauseyoudonotwanttoomanyzombie
processes existing in the system, you will need to remove the one that
you have created. The easiest way to do that is to terminate the parent
process using the killcommand. For example, if the pid of the parent
is4884, you wouldenter
kill -9 4884
3.19Write a C program called time.cthat determines the amount of time
necessarytorunacommandfromthecommandline.Thisprogramwill
be run as "" ./time <command> "" and will report the amount of elapsed
timetorunthespecifiedcommand.Thiswillinvolveusing fork()and
exec()functions, as well as the gettimeofday() function to deter-
mine the elapsed time. It will also require the use of two different IPC
mechanisms.
The general strategy is to fork a child process that will execute the
specified command. However, before the child executes the command,
it will record a timestamp of the current time (which we term “starting
time ”). The parent process will wait for the child process to terminate.
Once the child terminates,the parentwill recordthe current timestamp
for the ending time. The difference between the starting and ending
timesrepresentstheelapsedtimetoexecutethecommand.Theexample
outputbelow reportstheamount of timetorun thecommand ls:
./time ls
time.c
time
Elapsed time: 0.25422
As the parent and child are separate processes, they will need to
arrange how the starting time will be shared between them. You will
writetwoversionsofthisprogram,eachrepresentingadifferentmethod
ofIPC.P-8"
2,Programming Projects,204,Programming Problems,"Programming Problems
java.io.InputStream class returns −1 when the client has closed its
end of the socketconnection.
3.26Design a program using ordinary pipes in which one process sends a
string message to a second process, and the second process reverses
the case of each character in the message and sends it back to the first
process. For example, if the first process sends the message Hi There ,
the second process will return hI tHERE . This will require using two
pipes, one for sending the original message from the first to the second
processandtheotherforsendingthemodifiedmessagefromthesecond
to the first process. You can write this program using either UNIXor
Windows pipes.
3.27Design a file-copying program named filecopy.c using ordinary
pipes.Thisprogramwillbepassedtwoparameters:thenameofthefile
tobecopiedandthenameofthedestinationfile.Theprogramwillthen
createanordinarypipeandwritethecontentsofthefiletobecopiedto
the pipe. The child process will read this file from the pipe and write it
tothedestinationfile.Forexample,ifweinvoketheprogramasfollows:
./filecopy input.txt copy.txt
thefile input.txt willbewrittentothepipe.Thechildprocesswillread
thecontentsofthisfileandwriteittothedestinationfile copy.txt .Y ou
maywritethis programusing either UNIXorWindows pipes.
Programming Projects
Project 1—UNIX Shell
This project consists of designing a C program to serve as a shell interface
that accepts user commands and then executes each command in a separate
process. Your implementation will support input and output redirection, as
well as pipes as a form of IPCbetween a pair of commands. Completing this
project will involve using the UNIX fork(),exec(),wait(),dup2(),a n d
pipe()system calls and can be completed on any Linux, UNIX,o rm a c OS
system.
I. Overview
A shell interface gives the user a prompt, after which the next command
is entered. The example below illustrates the prompt osh>and the user’s
next command: cat prog.c . (This command displays the file prog.con the
terminalusing the UNIX catcommand.)
osh>cat prog.cP-12"
1,Chapter 4 Threads & Concurrency,216,Chapter 3 Processes,"4CHAPTER
Threads &
Concurrency
The process model introduced in Chapter 3 assumed that a process was an
executingprogramwithasinglethreadofcontrol.Virtuallyallmodernoperat-
ingsystems,however,providefeatures enabling a processto contain multiple
threadsofcontrol.Identifyingopportunitiesforparallelismthroughtheuseof
threadsisbecomingincreasinglyimportantformodernmulticoresystemsthat
providemultiple CPUs.
In this chapter,we introduce many concepts, as wellas challenges,associ-
atedwithmultithreadedcomputersystems,includingadiscussionofthe APIs
forthePthreads,Windows,andJavathreadlibraries.Additionally,weexplore
several new features that abstract the concept of creating threads, allowing
developers to focus on identifying opportunities for parallelism and letting
language features and APIframeworks manage the details of thread creation
andmanagement.Welookatanumberofissuesrelatedtomultithreadedpro-
gramminganditseffectonthedesignofoperatingsystems.Finally,weexplore
how the Windows and Linux operating systemssupport threads at the kernel
level.
CHAPTER OBJECTIVES
•Identify the basic components of a thread, and contrast threads and
processes.
•Describe the major benefits and significant challenges of designing multi-
threaded processes.
•Illustrate different approaches to implicit threading, including thread pools,
fork-join, and Grand Central Dispatch.
•Describe how the Windows and Linux operating systems represent
threads.
•Design multithreaded applications using the Pthreads, Java, and Windows
threading APIs.
159"
2,4.1 Overview,217,Chapter 4 Threads & Concurrency,"160 Chapter 4 Threads & Concurrency
4.1 Overview
Athread is a basic unit of CPUutilization; it comprises a thread ID,ap r o g r a m
counter ( PC), a registerset,and a stack. It shares with other threads belonging
to the same process its code section, data section, and other operating-system
resources, such as open files and signals. A traditional process has a single
thread of control. If a process has multiple threads of control, it can perform
more than one task at a time. Figure 4.1 illustrates the difference between a
traditional single-threaded processand a multithreaded process.
4.1.1 Motivation
Mostsoftwareapplicationsthatrunonmoderncomputersandmobiledevices
are multithreaded.Anapplicationtypic allyis implementedas a separatepro-
cess with several threads of control. Below we highlight a few examples of
multithreadedapplications:
•An application that creates photo thumbnails from a collection of images
may use a separate thread to generate a thumbnail from each separate
image.
•Awebbrowsermighthaveonethreaddisplayimagesortextwhileanother
threadretrievesdata fromthe network.
•A word processor may have a thread for displaying graphics, another
thread for responding to keystrokes from the user, and a third thread for
performingspellingand grammarchecking in the background.
thread
multithreaded process single-threaded process registers
k kstack
kfiles data code files data code
threadPC registers registers
stack stac stacregisters
PC PC PC
Figure 4.1 Single-threaded and multithreaded processes."
3,4.1.1 Motivation,217,4.1 Overview,"160 Chapter 4 Threads & Concurrency
4.1 Overview
Athread is a basic unit of CPUutilization; it comprises a thread ID,ap r o g r a m
counter ( PC), a registerset,and a stack. It shares with other threads belonging
to the same process its code section, data section, and other operating-system
resources, such as open files and signals. A traditional process has a single
thread of control. If a process has multiple threads of control, it can perform
more than one task at a time. Figure 4.1 illustrates the difference between a
traditional single-threaded processand a multithreaded process.
4.1.1 Motivation
Mostsoftwareapplicationsthatrunonmoderncomputersandmobiledevices
are multithreaded.Anapplicationtypic allyis implementedas a separatepro-
cess with several threads of control. Below we highlight a few examples of
multithreadedapplications:
•An application that creates photo thumbnails from a collection of images
may use a separate thread to generate a thumbnail from each separate
image.
•Awebbrowsermighthaveonethreaddisplayimagesortextwhileanother
threadretrievesdata fromthe network.
•A word processor may have a thread for displaying graphics, another
thread for responding to keystrokes from the user, and a third thread for
performingspellingand grammarchecking in the background.
thread
multithreaded process single-threaded process registers
k kstack
kfiles data code files data code
threadPC registers registers
stack stac stacregisters
PC PC PC
Figure 4.1 Single-threaded and multithreaded processes."
3,4.1.2 Benefits,219,4.1.1 Motivation,"162 Chapter 4 Threads & Concurrency
4.1.2 Beneﬁts
The benefits of multithreaded programming can be broken down into four
major categories:
1.Responsiveness . Multithreading an interactive application may allow a
program to continue running even if part of it is blocked or is perform-
ing a lengthy operation, thereby increasing responsiveness to the user.
Thisqualityisespeciallyusefulindesi gninguserinterfaces.Forinstance,
consider what happens when a user clicks a button that results in the
performance of a time-consuming operation. A single-threaded appli-
cation would be unresponsive to the user until the operation had been
completed. In contrast, if the time-consuming operation is performed in
a separate, asynchronous thread, the application remains responsive to
the user.
2.Resource sharing .Processescanshareresourcesonlythroughtechniques
such as shared memory and message passing. Such techniques must
be explicitly arranged by the programmer. However, threads share the
memoryandtheresourcesoftheprocesstowhichtheybelongbydefault.
The benefit of sharing code and data is that it allows an application to
have severaldifferentthreadsof activitywithinthesameaddressspace.
3.Economy . Allocating memory and resources for process creation is
costly. Because threads share the resources of the process to which they
belong, it is more economical to create and context-switch threads.
Empirically gauging the difference in overhead can be difficult, but in
general thread creation consumes less time and memory than process
creation. Additionally, context sw itching is typically faster between
threadsthan betweenprocesses.
4.Scalability. The benefits of multithreading can be even greater in a mul-
tiprocessor architecture, where threads may be running in parallel on
different processing cores. A single-threaded process can run on only
one processor, regardless how many are available. We explore this issue
further inthe following section.
4.2 Multicore Programming
Earlier in the history of computer design, in response to the need for more
computing performance,single- CPUsystemsevolvedinto multi- CPUsystems.
A later, yet similar, trend in system design is to place multiple computing
cores on a single processing chip where each core appears as a separate CPU
to the operating system (Section 1.3.2). We refer to such systems as multicore ,
and multithreaded programming provides a mechanism for more efficient
use of these multiple computing cores and improved concurrency. Consider
an application with four threads. On a system with a single computing core,
concurrencymerelymeansthattheexecutionofthethreadswillbeinterleaved
overtime(Figure4.3),becausetheprocessingcoreiscapableofexecutingonly
one thread at a time. On a system with multiple cores, however, concurrency"
2,4.2 Multicore Programming,219,4.1 Overview,"162 Chapter 4 Threads & Concurrency
4.1.2 Beneﬁts
The benefits of multithreaded programming can be broken down into four
major categories:
1.Responsiveness . Multithreading an interactive application may allow a
program to continue running even if part of it is blocked or is perform-
ing a lengthy operation, thereby increasing responsiveness to the user.
Thisqualityisespeciallyusefulindesi gninguserinterfaces.Forinstance,
consider what happens when a user clicks a button that results in the
performance of a time-consuming operation. A single-threaded appli-
cation would be unresponsive to the user until the operation had been
completed. In contrast, if the time-consuming operation is performed in
a separate, asynchronous thread, the application remains responsive to
the user.
2.Resource sharing .Processescanshareresourcesonlythroughtechniques
such as shared memory and message passing. Such techniques must
be explicitly arranged by the programmer. However, threads share the
memoryandtheresourcesoftheprocesstowhichtheybelongbydefault.
The benefit of sharing code and data is that it allows an application to
have severaldifferentthreadsof activitywithinthesameaddressspace.
3.Economy . Allocating memory and resources for process creation is
costly. Because threads share the resources of the process to which they
belong, it is more economical to create and context-switch threads.
Empirically gauging the difference in overhead can be difficult, but in
general thread creation consumes less time and memory than process
creation. Additionally, context sw itching is typically faster between
threadsthan betweenprocesses.
4.Scalability. The benefits of multithreading can be even greater in a mul-
tiprocessor architecture, where threads may be running in parallel on
different processing cores. A single-threaded process can run on only
one processor, regardless how many are available. We explore this issue
further inthe following section.
4.2 Multicore Programming
Earlier in the history of computer design, in response to the need for more
computing performance,single- CPUsystemsevolvedinto multi- CPUsystems.
A later, yet similar, trend in system design is to place multiple computing
cores on a single processing chip where each core appears as a separate CPU
to the operating system (Section 1.3.2). We refer to such systems as multicore ,
and multithreaded programming provides a mechanism for more efficient
use of these multiple computing cores and improved concurrency. Consider
an application with four threads. On a system with a single computing core,
concurrencymerelymeansthattheexecutionofthethreadswillbeinterleaved
overtime(Figure4.3),becausetheprocessingcoreiscapableofexecutingonly
one thread at a time. On a system with multiple cores, however, concurrency"
3,4.2.1 Programming Challenges,220,4.2 Multicore Programming,"4.2 Multicore Programming 163
single core
timeT... 1T2T2T3T3T4T4T1T1
Figure 4.3 Concurrent execution on a single-core system.
means that some threads can run in parallel, because the system can assign a
separatethreadtoeach core(Figure4.4).
Noticethedistinctionbetween concurrency andparallelism inthisdiscus-
sion.Aconcurrentsystemsupportsmorethanonetaskbyallowingallthetasks
tomakeprogress.Incontrast,aparallelsystemcanperformmorethanonetask
simultaneously. Thus, it is possible to have concurrency without parallelism.
Before the advent of multiprocessor and multicore architectures, most com-
putersystemshadonly a singleprocessor,and CPUschedulersweredesigned
to providethe illusionof parallelismby rapidlyswitching betweenprocesses,
therebyallowingeachprocesstomakeprogress.Suchprocesseswererunning
concurrently,but not in parallel.
4.2.1 Programming Challenges
The trend toward multicore systems continues to place pressure on system
designers and application programmers to make better use of the multiple
computingcores.Designersofoperatingsystemsmustwriteschedulingalgo-
rithmsthatusemultipleprocessingcorestoallowtheparallelexecutionshown
inFigure4.4.Forapplicationprogrammers,thechallengeistomodifyexisting
programsaswellas designnew programsthat aremultithreaded.
In general, five areas present challenges in programming for multicore
systems:
1.Identifying tasks . This involves examining applications to find areas
that can be divided into separate, c oncurrent tasks. Ideally, tasks are
independent of one another and thus can run in parallel on individual
cores.
2.Balance. While identifying tasks that can run in parallel, programmers
must also ensure that the tasks perform equal work of equal value. In
some instances, a certain task may not contribute as much value to the
overallprocessasothertasks.Usingaseparateexecutioncoretorunthat
taskmay not be worth the cost.
core 2core 1
timeT...
...1T1T1
T2T2T2T3T3
T4T4
Figure 4.4 Parallel execution on a multicore system."
3,4.2.2 Types of Parallelism,222,4.2.1 Programming Challenges,"4.2 Multicore Programming 165
core 0data
datadata 
parallelism
task
parallelismcore 1 core 2 core 3
core 0 core 1 core 2 core 3
Figure 4.5 Data and task parallelism.
5.Testing and debugging .Whenaprogramisrunninginparallelonmulti-
plecores,manydifferentexecutionpathsarepossible.Testinganddebug-
ging such concurrent programs is inherently more difficult than testing
and debuggingsingle-threadedapplications.
Becauseofthesechallenges,manysoftwaredevelopersarguethattheadventof
multicoresystemswillrequireanentirelynewapproachtodesigningsoftware
systemsinthefuture.(Similarly,manycomputerscienceeducatorsbelievethat
software development must be taught with increased emphasis on parallel
programming.)
4.2.2 Types of Parallelism
In general, there are two types of parallelism: data parallelism and task par-
allelism. Data parallelism focuses on distributing subsets of the same data
across multiple computing cores and performing the same operation on each
core. Consider,for example,summing the contents of an array of size N.O na
single-core system, one thread would simply sum the elements [0] ...[N−1].
On a dual-core system, however, thread A, running on core 0, could sum the
elements[0]...[ N∕2−1] while thread B, running on core 1, could sum the
elements [ N∕2]...[ N−1]. The two threads would be running in parallel on
separatecomputing cores.
Task parallelism involves distributing not data but tasks (threads) across
multiplecomputing cores.Each threadisperforming a uniqueoperation.Dif-
ferentthreadsmaybeoperatingonthesamedata,ortheymaybeoperatingon
differentdata.Consideragainourexampleabove.Incontrasttothatsituation,
an example of task parallelism might involve two threads, each performing
a unique statistical operation on the array of elements. The threads again are
operating in parallel on separate computing cores, but each is performing a
unique operation.
Fundamentally, then, data parallelism involves the distribution of data
across multiple cores, and task parallelism involves the distribution of tasks
across multiple cores, as shown in Figure 4.5. However, data and task paral-"
2,4.3 Multithreading Models,223,4.2 Multicore Programming,"166 Chapter 4 Threads & Concurrency
user threads
user 
space
kernel threadskernel 
space
Figure 4.6 User and kernel threads.
lelismare not mutuallyexclusive,and an applicationmay infact use a hybrid
of thesetwo strategies.
4.3 Multithreading Models
Ourdiscussionsofarhastreatedthreadsinagenericsense.However,support
forthreadsmaybeprovidedeitherattheuserlevel,for user threads ,orbythe
kernel, for kernel threads . User threads are supported above the kernel and
are managed without kernel support, whereas kernel threads are supported
and managed directly by the operating system. Virtually all contemporary
operatingsystems—includingWindows,Linux,andmac OS— supportkernel
threads.
Ultimately, a relationship must exist between user threads and kernel
threads, as illustrated in Figure 4.6. In this section, we look at three common
ways of establishing such a relationship: the many-to-one model, the one-to-
one model,and the many-to-many model.
4.3.1 Many-to-One Model
The many-to-one model (Figure 4.7) maps many user-level threads to one
kernelthread.Threadmanagementisdonebythethreadlibraryinuserspace,
soitisefficient(wediscussthreadlibrariesinSection4.4).However,theentire
processwillblockifathreadmakesablockingsystemcall.Also,becauseonly
user threads
user 
space
kernel threadskernel 
space
Figure 4.7 Many-to-one model."
3,4.3.1 Many-to-One Model,223,4.3 Multithreading Models,"166 Chapter 4 Threads & Concurrency
user threads
user 
space
kernel threadskernel 
space
Figure 4.6 User and kernel threads.
lelismare not mutuallyexclusive,and an applicationmay infact use a hybrid
of thesetwo strategies.
4.3 Multithreading Models
Ourdiscussionsofarhastreatedthreadsinagenericsense.However,support
forthreadsmaybeprovidedeitherattheuserlevel,for user threads ,orbythe
kernel, for kernel threads . User threads are supported above the kernel and
are managed without kernel support, whereas kernel threads are supported
and managed directly by the operating system. Virtually all contemporary
operatingsystems—includingWindows,Linux,andmac OS— supportkernel
threads.
Ultimately, a relationship must exist between user threads and kernel
threads, as illustrated in Figure 4.6. In this section, we look at three common
ways of establishing such a relationship: the many-to-one model, the one-to-
one model,and the many-to-many model.
4.3.1 Many-to-One Model
The many-to-one model (Figure 4.7) maps many user-level threads to one
kernelthread.Threadmanagementisdonebythethreadlibraryinuserspace,
soitisefficient(wediscussthreadlibrariesinSection4.4).However,theentire
processwillblockifathreadmakesablockingsystemcall.Also,becauseonly
user threads
user 
space
kernel threadskernel 
space
Figure 4.7 Many-to-one model."
3,4.3.2 One-to-One Model,224,4.3.1 Many-to-One Model,"4.3 Multithreading Models 167
user threads
user 
space
kernel threadskernel 
space
Figure 4.8 One-to-one model.
one thread can access the kernel at a time, multiple threads are unable to run
in parallel on multicore systems. Green threads —a thread library available
for Solaris systems and adoptedin early versionsof Java—used the many-to-
one model. However, very few systems continue to use the model because of
its inability to take advantage of multiple processing cores, which have now
becomestandardon most computersystems.
4.3.2 One-to-One Model
Theone-to-onemodel(Figure4.8)mapseachuserthreadtoakernelthread.It
provides more concurrency than the many-to-one model by allowing another
thread to run when a thread makes a blocking system call. It also allows mul-
tiple threads to run in parallel on multiprocessors. The only drawback to this
modelisthatcreatingauserthreadrequirescreatingthecorrespondingkernel
thread, and a large number of kernel threads may burden the performance of
a system.Linux, along with the family of Windows operating systems,imple-
mentthe one-to-one model.
4.3.3 Many-to-Many Model
Themany-to-many model(Figure4.9)multiplexesmany user-levelthreadsto
a smaller or equal number of kernel threads. The number of kernel threads
may be specific to either a particular application or a particular machine (an
application may be allocated more kernel threads on a system with eight
processingcoresthan asystemwith four cores).
user threads
user 
space
kernel threadskernel 
space
Figure 4.9 Many-to-many model."
3,4.3.3 Many-to-Many Model,224,4.3.2 One-to-One Model,"4.3 Multithreading Models 167
user threads
user 
space
kernel threadskernel 
space
Figure 4.8 One-to-one model.
one thread can access the kernel at a time, multiple threads are unable to run
in parallel on multicore systems. Green threads —a thread library available
for Solaris systems and adoptedin early versionsof Java—used the many-to-
one model. However, very few systems continue to use the model because of
its inability to take advantage of multiple processing cores, which have now
becomestandardon most computersystems.
4.3.2 One-to-One Model
Theone-to-onemodel(Figure4.8)mapseachuserthreadtoakernelthread.It
provides more concurrency than the many-to-one model by allowing another
thread to run when a thread makes a blocking system call. It also allows mul-
tiple threads to run in parallel on multiprocessors. The only drawback to this
modelisthatcreatingauserthreadrequirescreatingthecorrespondingkernel
thread, and a large number of kernel threads may burden the performance of
a system.Linux, along with the family of Windows operating systems,imple-
mentthe one-to-one model.
4.3.3 Many-to-Many Model
Themany-to-many model(Figure4.9)multiplexesmany user-levelthreadsto
a smaller or equal number of kernel threads. The number of kernel threads
may be specific to either a particular application or a particular machine (an
application may be allocated more kernel threads on a system with eight
processingcoresthan asystemwith four cores).
user threads
user 
space
kernel threadskernel 
space
Figure 4.9 Many-to-many model."
2,4.4 Thread Libraries,225,4.3 Multithreading Models,"168 Chapter 4 Threads & Concurrency
user threads
user 
space
kernel threadskernel 
space
Figure 4.10 Two-level model.
Let’sconsidertheeffectofthisdesignonconcurrency. Whereasthemany-
to-one model allows the developer to create as many user threads as she
wishes, it does not result in parallelism, because the kernel can schedule only
onekernelthreadatatime.Theone-to-onemodelallowsgreaterconcurrency,
but the developer has to be careful not to create too many threads within an
application. (In fact, on some systems, she may be limited in the number of
threadsshecancreate.)Themany-to-manymodelsuffersfromneitherofthese
shortcomings: developers can create as many user threads as necessary, and
thecorrespondingkernelthreadscanruninparallelonamultiprocessor.Also,
whenathreadperformsablockingsystemcall,thekernelcanscheduleanother
thread for execution.
One variation on the many-to-many model still multiplexes many user-
level threads to a smaller or equal number of kernel threads but also allows a
user-level thread to be bound to a kernel thread. This variation is sometimes
referredto asthe two-level model (Figure4.10).
Although the many-to-many model appears to be the most flexible of the
models discussed, in practice it is diffi cult to implement. In addition, with an
increasing number of processing cores appearing on most systems, limiting
the number of kernel threads has become less important. As a result, most
operatingsystemsnow usetheone-to-onemodel.However,asweshallseein
Section4.5,somecontemporaryconcurrencylibrarieshavedevelopersidentify
tasksthat are then mapped tothreadsusing the many-to-many model.
4.4 Thread Libraries
Athread library provides the programmer with an APIfor creating and man-
aging threads. There are two primary ways of implementing a thread library.
The first approach is to providea library entirelyin user space with no kernel
support. All code and data structures for the library exist in user space. This
means that invoking a function in the library results in a local function call in
userspaceand not a systemcall.
The second approach is to implement a kernel-level library supported
directly by the operating system. In this case, code and data structures for
the library exist in kernel space. Invoking a function in the APIfor the library
typicallyresultsina systemcallto thekernel."
3,4.4.1 Pthreads,226,4.4 Thread Libraries,"4.4 Thread Libraries 169
Threemainthreadlibrariesareinusetoday: POSIXPthreads,Windows,and
Java. Pthreads, the threads extension of the POSIXstandard, may be provided
as either a user-level or a kernel-level library. The Windows thread library
is a kernel-level library available on Windows systems. The Java thread API
allowsthreadstobecreatedandmanageddirectlyinJavaprograms.However,
becauseinmostinstancesthe JVMisrunningontopofahostoperatingsystem,
the Java thread APIis generally implemented using a thread library available
onthehostsystem.ThismeansthatonWindowssystems,Javathreadsaretyp-
ically implemented using the Windows API;UNIX,L i n u x ,a n dm a c OSsystems
typicallyuse Pthreads.
ForPOSIXand Windows threading, any data declared globally—that is,
declared outside of any function—are shared among all threads belonging to
thesameprocess.BecauseJavahasnoeq uivalentnotionofglobaldata,access
toshareddatamust beexplicitlyarrangedbetweenthreads.
In the remainder of this section, we describe basic thread creation using
these three thread libraries. As an illustrative example, we design a multi-
threadedprogramthatperformsthesummationofanon-negativeintegerina
separatethread using the well-known summation function:
sum=N∑
i=1i
For example, if Nwere 5, this function would represent the summation of
integers from 1 to 5, which is 15. Each of the three programs will be run with
theupperboundsofthesummationenteredonthecommandline.Thus,ifthe
userenters8, thesummationof theintegervaluesfrom 1 to8 willbe output.
Before we proceed with our examples of thread creation, we introduce
two general strategies for creating multiple threads: asynchronous threading
and synchronous threading . With asynchronous threading, once the parent
creates a child thread, the parent resumes its execution, so that the parent
and child execute concurrently and independently of one another. Because
the threads are independent, there is typically little data sharing between
them.Asynchronousthreadingisthestra tegyusedinthemultithreadedserver
illustrated in Figure 4.2 and is also commonly used for designing responsive
userinterfaces.
Synchronousthreadingoccurswhentheparentthreadcreatesoneormore
childrenandthenmustwaitforallofitschildrentoterminatebeforeitresumes.
Here, the threads created by the parent perform work concurrently, but the
parent cannot continue until this work has been completed. Once each thread
hasfinisheditswork,itterminatesandjoinswithitsparent.Onlyafterallofthe
children have joined can the parent resume execution. Typically, synchronous
threading involves significant data sh aring among threads. For example, the
parent thread may combine the results calculated by its various children. All
ofthe following examplesuse synchronous threading.
4.4.1 Pthreads
Pthreads referstothe POSIXstandard( IEEE1003.1c) defining an APIforthread
creationandsynchronization.Thisisa specification forthreadbehavior,notan
implementation .Operating-systemdesignersmayimplementthespecification"
3,4.4.2 Windows Threads,228,4.4.1 Pthreads,"4.4 Thread Libraries 171
#define NUM
 THREADS 10
/* an array of threads to be joined upon */
pthread
 t workers[NUM
 THREADS];
for (int i = 0; i < NUM
 THREADS; i++)
pthread
 join(workers[i], NULL);
Figure 4.12 Pthread code for joining ten threads.
main(). After some initialization, main()creates a second thread that begins
control in the runner() function. Both threadsshare the global data sum.
Let’s look more closely at this program. All Pthreads programs must
includethe pthread.h headerfile.Thestatement pthread
 t tiddeclaresthe
identifier for the thread we will create. Each thread has a set of attributes,
including stack size and scheduling information. The pthread
 attr
 t attr
declaration represents the attributes for the thread. We set the attributes in
the function call pthread
 attr
 init(&attr) . Because we did not explicitly
set any attributes, we use the default attributes provided. (In Chapter 5, we
discuss some of the scheduling attributes provided by the Pthreads API.) A
separate thread is created with the pthread
 create() function call. In addi-
tion to passing the thread identifier and the attributes for the thread, we also
pass the name of the function where the new thread will begin execution—in
thiscase,the runner() function.Last,wepasstheintegerparameterthatwas
providedonthecommand line, argv[1] .
Atthispoint,theprogramhastwothre ads:theinitial(orparent)threadin
main()andthesummation(orchild)threadperformingthesummationoper-
a t i o ni nt h e runner() function. This program follows the thread create/join
strategy, whereby after creating the summation thread, the parent thread will
wait for it to terminate by calling the pthread
 join()function. The summa-
tionthreadwillterminatewhenitcallsthefunction pthread
 exit().Oncethe
summationthreadhasreturned,theparentthreadwilloutputthevalueofthe
shareddata sum.
This example program creates only a single thread. With the growing
dominanceofmulticoresystems,writingprogramscontainingseveralthreads
has become increasingly common. A simple method for waiting on several
threadsusing the pthread
 join()function istoenclose theoperation within
asimple forloop.Forexample,youcanjoinontenthreadsusingthePthread
code shown in Figure4.12.
4.4.2 Windows Threads
ThetechniqueforcreatingthreadsusingtheWindowsthreadlibraryissimilar
to the Pthreads technique in several wa ys. We illustrate the Windows thread
APIin the C program shown in Figure 4.13. Notice that we must include the
windows.h headerfile when usingthe Windows API."
3,4.4.3 Java Threads,230,4.4.2 Windows Threads,"4.4 Thread Libraries 173
Threads are created in the Windows APIusing the CreateThread() func-
tion, and—just as in Pthreads—a set of attributes for the thread is passed
to this function. These attributes includ e security information, the size of the
stack,andaflagthatcanbesettoindicateifthethreadistostartinasuspended
state. In this program, we use the default values for these attributes. (The
default values do not initially set the thread to a suspended state and instead
make it eligible to be run by the CPUscheduler.) Once the summation thread
is created, the parent must wait for it to complete before outputting the value
ofSum, as the value is set by the summation thread. Recall that the Pthread
program (Figure 4.11) had the parent thread wait for the summation thread
usingthe pthread
 join()statement.Weperformtheequivalentofthisinthe
Windows APIusing the WaitForSingleObject() function, which causes the
creatingthread toblock untilthe summation threadhas exited.
In situations that require waiting for multiple threads to complete, the
WaitForMultipleObjects() function is used. This function is passed four
parameters:
1.The number of objects towait for
2.Apointerto thearray of objects
3.Aflag indicating whetherall objectshave beensignaled
4.Atimeoutduration(or INFINITE )
For example, if THandles is an array of thread HANDLEobjects of size N,t h e
parentthreadcanwaitforallitschildthreadstocompletewiththisstatement:
WaitForMultipleObjects(N, THandles, TRUE, INFINITE);
4.4.3 Java Threads
Threads are the fundamental model of program execution in a Java program,
andtheJavalanguageandits APIprovidearichsetoffeaturesforthecreation
and management of threads. All Java programs comprise at least a single
thread of control—even a simple Java program consisting of only a main()
method runs as a single thread in the JVM. Java threads are available on any
system that provides a JVMincluding Windows, Linux, and mac OS.T h eJ a v a
threadAPIisavailablefor Androidapplications aswell.
TherearetwotechniquesforexplicitlycreatingthreadsinaJavaprogram.
One approach is to create a new class that is derived from the Threadclass
andtooverrideits run()method.Analternative—andmorecommonlyused
—technique is to define a class that implements the Runnable interface. This
interface defines a single abstract method with the signature public void
run().T h ec o d ei nt h e run()method of a class that implements Runnable
iswhat executesina separatethread.Anexampleisshown below:
class Task implements Runnable
{
public void run(){
System.out.println(""I am a thread."");
}
}"
2,4.5 Implicit Threading,233,4.4 Thread Libraries,"176 Chapter 4 Threads & Concurrency
import java.util.concurrent.*;
class Summation implements Callable<Integer>
{
private int upper;
public Summation(int upper) {
this.upper = upper;
}
/* The thread will execute in this method */
public Integer call(){
int sum = 0;
for (int i = 1; i <= upper; i++)
sum += i;
return new Integer(sum);
}
}
public class Driver
{
public static void main(String[] args) {
int upper = Integer.parseInt(args[0]);
ExecutorService pool = Executors.newSingleThreadExecutor ();
Future<Integer> result = pool. submit (new Summation(upper));
try {
System.out.println(""sum = "" + result. get());
}catch (InterruptedException | ExecutionException ie) {}
}
}
Figure 4.14 Illustration of Java Executor framework API.
Additionally, this approach separates the creation of threads from the results
they produce: rather than waiting for a thread to terminate before retrieving
results,theparentinsteadonlywaitsfortheresultstobecomeavailable.Finally,
as we shall see in Section 4.5.1, this framework can be combined with other
featurestocreaterobust toolsfor managing a largenumber ofthreads.
4.5 Implicit Threading
With the continued growth of multicore processing, applications contain-
ing hundreds—or even thousands—of threads are looming on the horizon.
Designing such applications is not a trivial undertaking: programmers must"
3,4.5.1 Thread Pools,234,4.5 Implicit Threading,"4.5 Implicit Threading 177
THEJVMANDTHEHOSTOPERATINGSYSTEM
TheJVMis typically implemented on top of a host operating system (see
Figure 18.10). This setup allows the JVMto hide the implementation details
of the underlying operating system and to provide a consistent, abstract
environment that allows Java programs to operate on any platform that
supports a JVM. The specification for the JVMdoes not indicate how Java
threadsaretobemappedtotheunderlyingoperatingsystem,insteadleaving
that decision to the particular implementation of the JVM. For example, the
Windows operating system uses the one-to-one model; therefore, each Java
thread for a JVMrunning on Windows maps to a kernel thread. In addition,
there may be a relationship between the Java thread library and the thread
libraryonthehostoperatingsystem.Forexample,implementationsofa JVM
for the Windows family of operatin g systems might use the Windows API
whencreatingJavathreads;Linuxandmac OSsystemsmightusethePthreads
API.
addressnot only the challenges outlined in Section4.2 but additional difficul-
tiesaswell.Thesedifficulties,whichrelatetoprogramcorrectness,arecovered
inChapter6 and Chapter8.
Onewaytoaddressthesedifficultiesandbettersupportthedesignofcon-
current and parallel applications is to transfer the creation and management
of threading from application developers to compilers and run-time libraries.
This strategy, termed implicit threading , is an increasingly popular trend. In
this section, we explore four alternati ve approaches to designing applications
that can take advantage of multicore p rocessors through implicit threading.
As we shall see, these strategies generally require application developers to
identifytasks—not threads—that can run in parallel. Atask is usually writ-
ten as a function, which the run-time library then maps to a separate thread,
typically using the many-to-many model (Section 4.3.3). The advantage of
this approach is that developers only need to identify parallel tasks, and the
librariesdeterminethespecificdetailsof threadcreationand management.
4.5.1 Thread Pools
In Section 4.1, we described a multithreaded web server. In this situation,
whenever the server receives a request, it creates a separate thread to service
therequest.Whereascreatingaseparatethreadiscertainlysuperiortocreating
aseparateprocess,amultithreadedservernonethelesshaspotentialproblems.
The first issue concerns the amount of time required to create the thread,
together with the fact that the thread will be discarded once it has completed
its work. The second issue is more troublesome. If we allow each concurrent
request to be serviced in a new thread, we have not placed a bound on the
numberofthreadsconcurrentlyactiveinthesystem.Unlimitedthreadscould
exhaust system resources, such as CPUtime or memory. One solution to this
problemis tousea thread pool ."
3,4.5.2 Fork Join,237,4.5.1 Thread Pools,"180 Chapter 4 Threads & Concurrency
import java.util.concurrent.*;
public class ThreadPoolExample
{
public static void main(String[] args) {
int numTasks = Integer.parseInt(args[0].trim());
/* Create the thread pool */
ExecutorService pool = Executors.newCachedThreadPool() ;
/* Run each task using a thread in the pool */
for (int i = 0; i < numTasks; i++)
pool. execute (new Task());
/* Shut down the pool once all threads have completed */
pool. shutdown() ;
}
Figure 4.15 Creating a thread pool in Java.
torinterface, allowing us to invoke the execute() method on this object. In
addition, ExecutorService provides methods for managing termination of
th eth r ea dpo o l.
TheexampleshowninFigure4.15createsacachedthreadpoolandsubmits
taskstobeexecutedbyathreadinthepoolusingthe execute() method.When
theshutdown() methodisinvoked,thethreadpoolrejectsadditionaltasksand
shuts down once all existingtasks havecompletedexecution.
4.5.2 Fork Join
The strategy for thread creation covered in Section 4.4 is often known as the
fork-join model. Recall that with this method, the main parent thread creates
(forks) one or more child threads and then waits for the children to terminate
andjoinwith it, at which point it can retrieve and combine their results. This
synchronous model is often characteri zed as explicit thread creation, but it
is also an excellent candidate for implicit threading. In the latter situation,
threadsarenotconstructeddirectlyduringtheforkstage;rather,paralleltasks
are designated.This model is illustratedin Figure 4.16. Alibrary manages the
numberofthreadsthatarecreatedandisalsoresponsibleforassigningtasksto
threads.Insomeways,thisfork-joinmodelisasynchronousversionofthread
pools in which a library determines the actual number of threads to create—
for example,by usingthe heuristicsdescribedinSection4.5.1.
4.5.2.1 Fork Join in Java
Java introduced a fork-join library in Version 1.7 of the APIthat is designed
to be used with recursive divide-and-conquer algorithms such as Quicksort
andMergesort.Whenimplementingdivid e-and-conqueralgorithmsusingthis"
3,4.5.3 OpenMP,240,4.5.2 Fork Join,"4.5 Implicit Threading 183
import java.util.concurrent.*;
public class SumTask extends RecursiveTask<Integer>
{
static final int THRESHOLD = 1000;
private int begin;
private int end;
private int[] array;
public SumTask(int begin, int end, int[] array) {
this.begin = begin;
this.end = end;
this.array = array;
}
protected Integer compute() {
if (end - begin < THRESHOLD) {
int sum = 0;
for (int i = begin; i <= end; i++)
sum += array[i];
return sum;
}
else {
int mid = (begin + end) / 2;
SumTask leftTask = new SumTask(begin, mid, array);
SumTask rightTask = new SumTask(mid + 1, end, array);
leftTask. fork();
rightTask. fork();
return rightTask. join() + leftTask. join();
}
}
}
Figure 4.18 Fork-join calculation using the Java API.
4.5.3 OpenMP
OpenMPisasetofcompilerdirectivesaswellasan APIforprogramswrittenin
C,C++,or FORTRAN thatprovidessupportforparallelprogramminginshared-
memory environments. Open MPidentifies parallel regions as blocks of code
thatmayruninparallel.Applicationdevelopersinsertcompilerdirectivesinto
their code at parallel regions, and these directives instruct the Open MPrun-"
3,4.5.4 Grand Central Dispatch,242,4.5.3 OpenMP,"4.5 Implicit Threading 185
in array c. We can have this task run in parallel by using the following code
segment,which contains the comp ilerdirectivefor parallelizing forloops:
#pragma omp parallel for
for (i = 0; i < N; i++) {
c[i] = a[i] + b[i];
}
OpenMPdividesthe work contained in the forloop among the threads it has
createdinresponseto thedirective
#pragma omp parallel for
In addition to providing directives for parallelization, Open MPallows
developers to choose among several levels of parallelism. For example, they
can set the number of threads manually. It also allows developers to identify
whether data are shared between threads or are private to a thread. Open MP
isavailableonseveralopen-sourceandcommercialcompilersforLinux,Win-
dows, and mac OSsystems. We encourage readers interested in learning more
about Open MPto consult the bibliography atthe end ofthe chapter.
4.5.4 Grand Central Dispatch
Grand Central Dispatch ( GCD) is a technology developed by Apple for its
macOSand iOSoperating systems. It is a combination of a run-time library,
anAPI, and language extensions that allow developers to identify sections of
code(tasks)toruninparallel.LikeOpenMP, GCDmanagesmostofthedetails
ofthreading.
GCDschedulestasksforrun-timeexecutionbyplacingthemona dispatch
queue.Whenitremovesataskfromaqueue,itassignsthetasktoanavailable
thread from a pool of threads that it manages. GCDidentifies two types of
dispatchqueues: serialandconcurrent .
Tasks placed on a serial queue are removed in FIFOorder. Once a task has
beenremovedfromthequeue,itmustcompleteexecutionbeforeanothertask
isremoved.Each processhasitsown serialqueue(known asits main queue ),
anddeveloperscancreateadditionalserialqueuesthatarelocaltoaparticular
process.(Thisiswhyserialqueuesarealsoknownas privatedispatchqueues .)
Serialqueuesareusefulforensuringthesequentialexecutionofseveraltasks.
Tasks placed on a concurrent queue are also removed in FIFOorder, but
severaltasksmayberemovedatatime,thusallowingmultipletaskstoexecute
in parallel. There are several system-wid e concurrent queues (also known as
globaldispatchqueues ),whicharedividedintofourprimaryquality-of-service
classes:
•QOS
CLASS
 USER
 INTERACTIVE —The user-interactive class represents
tasks that interact with the user, such as the user interface and event
handling, to ensure a responsive user interface. Completing a task
belonging to this classshould requireonly a smallamount ofwork.
•QOS
CLASS
 USER
 INITIATED —The user-initiated class is similar to the
user-interactive class in that tasks are associated with a responsive user
interface; however, user-initiated tasks may require longer processing"
3,4.5.5 Intel Thread Building Blocks,243,4.5.4 Grand Central Dispatch,"186 Chapter 4 Threads & Concurrency
times. Opening a file or a URLis a user-initiated task, for example. Tasks
belonging to this class must be completed for the user to continue inter-
acting with the system, but they do not need to be serviced as quickly as
tasksintheuser-interactivequeue.
•QOS
CLASS
 UTILITY —The utilityclass represents tasks that require a
longer time to complete but do not demand immediate results. This class
includeswork such as importingdata.
•QOS
CLASS
 BACKGROUND —Tasks belonging to the background class are
notvisibletotheuserandarenottimesensitive.Examplesincludeindex-
ing amailbox systemand performingbackups.
Tasks submitted to dispatch queues may be expressed in one of two
differentways:
1.For the C, C++, and Objective-C languages, GCDidentifies a language
extension known as a block, which is simply a self-contained unit of
work. Ablock isspecified by a caretˆ inserted in front of a pairof braces
{}.Codewithinthebracesidentifiestheunitofworktobeperformed.A
simple exampleof ablock isshown below:
^{printf(""I am a block""); }
2.For the Swift programming language, a task is defined using a closure,
which is similar to a block in that it expresses a self-contained unit of
functionality. Syntactically, a Swift closure is written in the same way as
a block, minus the leadingcaret.
The following Swift code segment illustrates obtaining a concurrent
queuefortheuser-initiatedclassandsubmittingatasktothequeueusing
thedispatch
 async() function:
let queue = dispatch
 get
global
 queue
(QOS
 CLASS
 USER
 INITIATED, 0)
dispatch
 async(queue, {print(""I am a closure."") })
Internally, GCD’s thread pool is composed of POSIXthreads. GCDactively
managesthepool,allowingthenumberofthreadstogrowandshrinkaccord-
ing to application demand and system capacity. GCDis implemented by the
libdispatch library, which Apple has released under the Apache Commons
license.Ithas sincebeenportedto the FreeBSDoperatingsystem.
4.5.5 Intel Thread Building Blocks
Intelthreadingbuildingblocks( TBB)isatemplatelibrarythatsupportsdesign-
ing parallel applications in C++. As this is a library, it requires no special
compiler or language support. Developers specify tasks that can run in par-"
2,4.6 Threading Issues,245,4.5 Implicit Threading,"188 Chapter 4 Threads & Concurrency
ages the details involved in dividing the work into separate tasks that run in
parallel. Intel TBBhas both commercial and open-source versions that run on
Windows, Linux, and mac OS. Refer to the bibliography for further details on
how todevelopparallelapplications using TBB.
4.6 Threading Issues
In this section, we discuss some of the issues to consider in designing multi-
threadedprograms.
4.6.1 The fork() and exec() System Calls
In Chapter 3, we described how the fork()system call is used to create a
separate, duplicate process. The semantics of the fork()andexec()system
calls change ina multithreadedprogram.
If one thread in a program calls fork(), does the new process duplicate
all threads, or is the new process single-threaded? Some UNIXsystems have
chosen to have two versions of fork(), one that duplicates all threads and
another that duplicatesonly the thread thatinvoked the fork()systemcall.
Theexec()system call typically works in the same way as described in
Chapter 3. That is, if a thread invokes the exec()system call, the program
specifiedintheparameterto exec()willreplacetheentireprocess—including
allthreads.
Which of the two versions of fork()to use depends on the application.
Ifexec()is called immediately after forking, then duplicating all threads is
unnecessary,astheprogramspecifiedintheparametersto exec()willreplace
the process. In this instance, duplicating only the calling thread is appropri-
ate. If, however, the separate process does not call exec()after forking, the
separateprocessshould duplicateall threads.
4.6.2 Signal Handling
Asignalisusedin UNIXsystemstonotifyaprocessthataparticulareventhas
occurred. A signal may be received either synchronously or asynchronously,
depending on the source of and the reason for the event being signaled. All
signals,whether synchronous or asynchronous, follow the same pattern:
1.Asignalis generatedby theoccurrence of a particularevent.
2.The signalis deliveredto a process.
3.Once delivered,thesignal mustbe handled.
Examples of synchronous signals include illegal memory access and divi-
sionby0.Ifarunningprogramperformseitheroftheseactions,asignalisgen-
erated.Synchronous signals are deliveredto the same process that performed
the operation that caused the signal ( that is the reason they are considered
synchronous).
Whena signalisgeneratedby aneventexternaltoa running process,that
process receives the signal asynchronous ly. Examples of such signals include
terminating a process with specific keystrokes (such as <control ><C>)a n d"
3,4.6.1 The fork() and exec() System Calls,245,4.6 Threading Issues,"188 Chapter 4 Threads & Concurrency
ages the details involved in dividing the work into separate tasks that run in
parallel. Intel TBBhas both commercial and open-source versions that run on
Windows, Linux, and mac OS. Refer to the bibliography for further details on
how todevelopparallelapplications using TBB.
4.6 Threading Issues
In this section, we discuss some of the issues to consider in designing multi-
threadedprograms.
4.6.1 The fork() and exec() System Calls
In Chapter 3, we described how the fork()system call is used to create a
separate, duplicate process. The semantics of the fork()andexec()system
calls change ina multithreadedprogram.
If one thread in a program calls fork(), does the new process duplicate
all threads, or is the new process single-threaded? Some UNIXsystems have
chosen to have two versions of fork(), one that duplicates all threads and
another that duplicatesonly the thread thatinvoked the fork()systemcall.
Theexec()system call typically works in the same way as described in
Chapter 3. That is, if a thread invokes the exec()system call, the program
specifiedintheparameterto exec()willreplacetheentireprocess—including
allthreads.
Which of the two versions of fork()to use depends on the application.
Ifexec()is called immediately after forking, then duplicating all threads is
unnecessary,astheprogramspecifiedintheparametersto exec()willreplace
the process. In this instance, duplicating only the calling thread is appropri-
ate. If, however, the separate process does not call exec()after forking, the
separateprocessshould duplicateall threads.
4.6.2 Signal Handling
Asignalisusedin UNIXsystemstonotifyaprocessthataparticulareventhas
occurred. A signal may be received either synchronously or asynchronously,
depending on the source of and the reason for the event being signaled. All
signals,whether synchronous or asynchronous, follow the same pattern:
1.Asignalis generatedby theoccurrence of a particularevent.
2.The signalis deliveredto a process.
3.Once delivered,thesignal mustbe handled.
Examples of synchronous signals include illegal memory access and divi-
sionby0.Ifarunningprogramperformseitheroftheseactions,asignalisgen-
erated.Synchronous signals are deliveredto the same process that performed
the operation that caused the signal ( that is the reason they are considered
synchronous).
Whena signalisgeneratedby aneventexternaltoa running process,that
process receives the signal asynchronous ly. Examples of such signals include
terminating a process with specific keystrokes (such as <control ><C>)a n d"
3,4.6.2 Signal Handling,245,4.6.1 The fork() and exec() System Calls,"188 Chapter 4 Threads & Concurrency
ages the details involved in dividing the work into separate tasks that run in
parallel. Intel TBBhas both commercial and open-source versions that run on
Windows, Linux, and mac OS. Refer to the bibliography for further details on
how todevelopparallelapplications using TBB.
4.6 Threading Issues
In this section, we discuss some of the issues to consider in designing multi-
threadedprograms.
4.6.1 The fork() and exec() System Calls
In Chapter 3, we described how the fork()system call is used to create a
separate, duplicate process. The semantics of the fork()andexec()system
calls change ina multithreadedprogram.
If one thread in a program calls fork(), does the new process duplicate
all threads, or is the new process single-threaded? Some UNIXsystems have
chosen to have two versions of fork(), one that duplicates all threads and
another that duplicatesonly the thread thatinvoked the fork()systemcall.
Theexec()system call typically works in the same way as described in
Chapter 3. That is, if a thread invokes the exec()system call, the program
specifiedintheparameterto exec()willreplacetheentireprocess—including
allthreads.
Which of the two versions of fork()to use depends on the application.
Ifexec()is called immediately after forking, then duplicating all threads is
unnecessary,astheprogramspecifiedintheparametersto exec()willreplace
the process. In this instance, duplicating only the calling thread is appropri-
ate. If, however, the separate process does not call exec()after forking, the
separateprocessshould duplicateall threads.
4.6.2 Signal Handling
Asignalisusedin UNIXsystemstonotifyaprocessthataparticulareventhas
occurred. A signal may be received either synchronously or asynchronously,
depending on the source of and the reason for the event being signaled. All
signals,whether synchronous or asynchronous, follow the same pattern:
1.Asignalis generatedby theoccurrence of a particularevent.
2.The signalis deliveredto a process.
3.Once delivered,thesignal mustbe handled.
Examples of synchronous signals include illegal memory access and divi-
sionby0.Ifarunningprogramperformseitheroftheseactions,asignalisgen-
erated.Synchronous signals are deliveredto the same process that performed
the operation that caused the signal ( that is the reason they are considered
synchronous).
Whena signalisgeneratedby aneventexternaltoa running process,that
process receives the signal asynchronous ly. Examples of such signals include
terminating a process with specific keystrokes (such as <control ><C>)a n d"
3,4.6.3 Thread Cancellation,247,4.6.2 Signal Handling,"190 Chapter 4 Threads & Concurrency
by its name, an APCis roughly equivalent to an asynchronous signal in UNIX.
However,whereas UNIXmustcontendwithhowtodealwithsignalsinamul-
tithreadedenvironment,the APCfacilityismorestraightforward,sincean APC
isdeliveredto a particularthreadratherthan aprocess.
4.6.3 Thread Cancellation
Thread cancellation involvesterminatingathreadbeforeithascompleted.For
example, if multiple threads are concurrently searching through a database
and one thread returns the result, the remaining threads might be canceled.
Anothersituationmightoccurwhenauserpressesabuttononawebbrowser
that stops a web page from loading any further. Often, a web page loads
using several threads—each image is loaded in a separate thread. When a
user presses the stopbutton on the browser, all threads loading the page are
canceled.
A thread that is to be canceled is often referred to as the target thread .
Cancellationof atargetthreadmayoccur intwo differentscenarios:
1.Asynchronous cancellation .Onethreadimmediatelyterminatesthetar-
getthread.
2.Deferred cancellation . The target thread periodically checks whether it
should terminate, allowing it an opportunity to terminate itself in an
orderlyfashion.
The difficulty with cancellation occurs in situations where resources have
been allocated to a canceled thread or where a thread is canceled while in
the midst of updating data it is sharing with other threads. This becomes
especially troublesome with asynchronous cancellation. Often, the operating
system will reclaim system resources from a canceled thread but will not
reclaim all resources. Therefore, canceling a thread asynchronously may not
freea necessary system-wideresource.
With deferred cancellation, in contrast, one thread indicates that a target
threadistobecanceled,butcancellationoccursonlyafterthetargetthreadhas
checked a flag to determine whether or not it should be canceled. The thread
can performthischeck at a pointat which itcan be canceled safely.
In Pthreads, thread cancellation is initiated using the pthread
 cancel()
function.Theidentifierofthetargetthreadispassedasaparametertothefunc-
tion.The following code illustratescreating—and then canceling—a thread:
pthread
 t tid;
/* create the thread */
pthread
 create(&tid, 0, worker, NULL);
...
/* cancel the thread */
pthread
 cancel (tid);
/* wait for the thread to terminate */
pthread
 join(tid,NULL);"
3,4.6.4 Thread-Local Storage,249,4.6.3 Thread Cancellation,"192 Chapter 4 Threads & Concurrency
Thread worker;
...
/* set the interruption status of the thread */
worker. interrupt ()
A thread can check its interruption status by invoking the isInter-
rupted() method, which returns a boolean value of a thread’s interruption
status:
while (!Thread.currentThread(). isInterrupted ()) {
...
}
4.6.4 Thread-Local Storage
Threads belonging to a process share the data of the process. Indeed, this
data sharing provides one of the benefits of multithreaded programming.
However, in some circumstances, each thread might need its own copy of
certaindata.Wewillcallsuchdata thread-local storage (orTLS).Forexample,
in a transaction-processing system, we might service each transaction in a
separate thread. Furthermore, each t ransaction might be assigned a unique
identifier. To associate each thread with its unique transaction identifier, we
could usethread-localstorage.
It is easy to confuse TLSwith local variables. However, local variables
are visible only during a single function invocation, whereas TLSdata are
visible across function invocations. Additionally, when the developer has no
controloverthethreadcreationprocess—forexample,whenusinganimplicit
technique such as athread pool—then an alternativeapproach isnecessary.
In some ways, TLSis similar to staticdata; the difference is that TLS
data are unique to each thread. (In fact, TLSis usually declared as static.)
Most thread libraries and compilers provide support for TLS. For example,
Java provides a ThreadLocal<T> class with set()and get()methods for
ThreadLocal<T> objects. Pthreads includes the type pthread
 key
t,w h i c h
providesakeythatisspecifictoeachthread.Thiskeycanthenbeusedtoaccess
TLSdata.Microsoft’sC#languagesimplyrequiresaddingthestorageattribute
[ThreadStatic] to declare thread-local data. The gcccompiler provides the
storage class keyword
 threadfor declaring TLSdata. For example, if we
wished to assign a unique identifier for each thread, we would declare it as
follows:
static
 thread int threadID;
4.6.5 Scheduler Activations
Afinalissuetobeconsideredwithmultithreadedprogramsconcernscommu-
nication between the kernel and the thread library, which may be required"
3,4.6.5 Scheduler Activations,249,4.6.4 Thread-Local Storage,"192 Chapter 4 Threads & Concurrency
Thread worker;
...
/* set the interruption status of the thread */
worker. interrupt ()
A thread can check its interruption status by invoking the isInter-
rupted() method, which returns a boolean value of a thread’s interruption
status:
while (!Thread.currentThread(). isInterrupted ()) {
...
}
4.6.4 Thread-Local Storage
Threads belonging to a process share the data of the process. Indeed, this
data sharing provides one of the benefits of multithreaded programming.
However, in some circumstances, each thread might need its own copy of
certaindata.Wewillcallsuchdata thread-local storage (orTLS).Forexample,
in a transaction-processing system, we might service each transaction in a
separate thread. Furthermore, each t ransaction might be assigned a unique
identifier. To associate each thread with its unique transaction identifier, we
could usethread-localstorage.
It is easy to confuse TLSwith local variables. However, local variables
are visible only during a single function invocation, whereas TLSdata are
visible across function invocations. Additionally, when the developer has no
controloverthethreadcreationprocess—forexample,whenusinganimplicit
technique such as athread pool—then an alternativeapproach isnecessary.
In some ways, TLSis similar to staticdata; the difference is that TLS
data are unique to each thread. (In fact, TLSis usually declared as static.)
Most thread libraries and compilers provide support for TLS. For example,
Java provides a ThreadLocal<T> class with set()and get()methods for
ThreadLocal<T> objects. Pthreads includes the type pthread
 key
t,w h i c h
providesakeythatisspecifictoeachthread.Thiskeycanthenbeusedtoaccess
TLSdata.Microsoft’sC#languagesimplyrequiresaddingthestorageattribute
[ThreadStatic] to declare thread-local data. The gcccompiler provides the
storage class keyword
 threadfor declaring TLSdata. For example, if we
wished to assign a unique identifier for each thread, we would declare it as
follows:
static
 thread int threadID;
4.6.5 Scheduler Activations
Afinalissuetobeconsideredwithmultithreadedprogramsconcernscommu-
nication between the kernel and the thread library, which may be required"
2,4.7 Operating-System Examples,251,4.6 Threading Issues,"194 Chapter 4 Threads & Concurrency
stateoftheblockingthreadandrelinquishesthevirtualprocessoronwhichthe
blocking thread is running. The upcall handler then schedules another thread
that is eligible to run on the new virtual processor. When the event that the
blockingthreadwaswaitingforoccurs,thekernelmakesanotherupcalltothe
thread library informing it that the pr eviously blocked thread is now eligible
to run. The upcall handler for this event also requires a virtual processor, and
the kernel may allocate a new virtual processor or preempt one of the user
threads and run the upcall handler on its virtual processor. After marking the
unblockedthreadaseligibletorun,thea pplicationschedulesaneligiblethread
to runon anavailablevirtualprocessor.
4.7 Operating-System Examples
At this point, we have examined a number of concepts and issues related to
threads. We conclude the chapter by exploring how threads are implemented
in Windows and Linux systems.
4.7.1 Windows Threads
A Windows application runs as a separate process, and each process may
contain oneormorethreads.TheWindows APIforcreatingthreadsiscovered
inSection4.4.2.Additionally,Windows usestheone-to-onemappingdescribed
in Section 4.3.2, where each user-level thread maps to an associated kernel
thread.
Thegeneralcomponents of a threadinclude:
•Athread IDuniquelyidentifyingthe thread
•Aregistersetrepresentingthestatus ofthe processor
•Aprogramcounter
•A user stack, employed when the thread is running in user mode, and a
kernelstack, employedwhenthethreadis running inkernelmode
•Aprivatestorageareausedbyvariousrun-timelibrariesanddynamiclink
libraries( DLLs)
The register set, stacks, and private storage area are known as the contextof
thethread.
Theprimarydata structuresof a threadinclude:
•ETHREAD —executivethreadblock
•KTHREAD —kernel thread block
•TEB—thread environmentblock
The key components of the ETHREAD include a pointer to the process
to which the thread belongs and the address of the routine in which the
threadstartscontrol.The ETHREAD alsocontainsapointertothecorresponding
KTHREAD ."
3,4.7.1 Windows Threads,251,4.7 Operating-System Examples,"194 Chapter 4 Threads & Concurrency
stateoftheblockingthreadandrelinquishesthevirtualprocessoronwhichthe
blocking thread is running. The upcall handler then schedules another thread
that is eligible to run on the new virtual processor. When the event that the
blockingthreadwaswaitingforoccurs,thekernelmakesanotherupcalltothe
thread library informing it that the pr eviously blocked thread is now eligible
to run. The upcall handler for this event also requires a virtual processor, and
the kernel may allocate a new virtual processor or preempt one of the user
threads and run the upcall handler on its virtual processor. After marking the
unblockedthreadaseligibletorun,thea pplicationschedulesaneligiblethread
to runon anavailablevirtualprocessor.
4.7 Operating-System Examples
At this point, we have examined a number of concepts and issues related to
threads. We conclude the chapter by exploring how threads are implemented
in Windows and Linux systems.
4.7.1 Windows Threads
A Windows application runs as a separate process, and each process may
contain oneormorethreads.TheWindows APIforcreatingthreadsiscovered
inSection4.4.2.Additionally,Windows usestheone-to-onemappingdescribed
in Section 4.3.2, where each user-level thread maps to an associated kernel
thread.
Thegeneralcomponents of a threadinclude:
•Athread IDuniquelyidentifyingthe thread
•Aregistersetrepresentingthestatus ofthe processor
•Aprogramcounter
•A user stack, employed when the thread is running in user mode, and a
kernelstack, employedwhenthethreadis running inkernelmode
•Aprivatestorageareausedbyvariousrun-timelibrariesanddynamiclink
libraries( DLLs)
The register set, stacks, and private storage area are known as the contextof
thethread.
Theprimarydata structuresof a threadinclude:
•ETHREAD —executivethreadblock
•KTHREAD —kernel thread block
•TEB—thread environmentblock
The key components of the ETHREAD include a pointer to the process
to which the thread belongs and the address of the routine in which the
threadstartscontrol.The ETHREAD alsocontainsapointertothecorresponding
KTHREAD ."
3,4.7.2 Linux Threads,252,4.7.1 Windows Threads,"4.7 Operating-System Examples 195
user space kernel spacepointer to 
parent processthread start
 addressETHREAD
KTHREAD


kernel
stackscheduling
and
synchronization
information


user
stack
thread-local
storagethread identifierTEB



Figure 4.21 Data structures of a Windows thread.
TheKTHREAD includes scheduling and synchronization information for
thethread.Inaddition,the KTHREAD includesthekernelstack(usedwhenthe
threadis running in kernelmode)and a pointertothe TEB.
TheETHREAD and the KTHREAD exist entirely in kernel space; this means
that only the kernel can access them. The TEBis a user-space data structure
thatisaccessedwhenthethreadisrunninginusermode.Amongotherfields,
theTEBcontains the thread identifier, a user-mode stack, and an array for
thread-localstorage.ThestructureofaWindowsthreadisillustratedinFigure
4.21.
4.7.2 Linux Threads
Linux provides the fork()system call with the traditional functionality of
duplicatingaprocess,asdescribedinChapter3.Linuxalsoprovidestheability
to create threads using the clone() system call. However, Linux does not
distinguish between processes and threads. In fact, Linux uses the term task
—ratherthan processorthread— whenreferringtoaflowofcontrolwithina
program.
When clone() is invoked, it is passed a set of flags that determine how
muchsharingistotakeplacebetweentheparentandchildtasks.Someofthese
flags are listed in Figure 4.22. For example, suppose that clone() is passed
the flags CLONE
 FS,CLONE
 VM,CLONE
 SIGHAND ,a n d CLONE
 FILES. The parent
and child tasks will then share the same file-system information (such as the
currentworkingdirectory),thesamememoryspace,thesamesignalhandlers,"
2,4.8 Summary,253,4.7 Operating-System Examples,"196 Chapter 4 Threads & Concurrency
flag meaning
CLONE_FS
CLONE_VM
CLONE_SIGHAND
CLONE_FILESFile-system information is shared.
The same memory space is shared.
Signal handlers are shared.
The set of open files is shared.
Figure 4.22 Some of the flags passed when clone() is invoked.
and the same set of open files. Using clone() in this fashion is equivalent to
creatingathreadasdescribedinthischapter,sincetheparenttasksharesmost
of its resources with its child task. However, if none of these flags is set when
clone() is invoked, no sharing takes place, resulting in functionality similar
to that providedby the fork()systemcall.
The varyinglevelofsharing ispossiblebecause of theway atask isrepre-
sentedintheLinuxkernel.Auniquekerneldatastructure(specifically, struct
task
 struct) exists for each task in the system. This data structure, instead
of storing data for the task, contains pointers to other data structures where
these data are stored—for example, data structures that represent the list of
open files, signal-handling information, and virtual memory. When fork()is
invoked, a new task is created, along with a copyof all the associated data
structures of the parent process. Anew task is also created when the clone()
systemcallismade.However,ratherthancopyingalldatastructures,thenew
taskpointsto the data structures of the parent task, depending on the set of
flags passedto clone() .
Finally, the flexibility of the clone() system call can be extended to the
concept of containers, a virtualizatio n topic which was introduced in Chapter
1. Recall from that chapter that a contai ner is a virtualization technique pro-
vided by the operating system that allows creating multiple Linux systems
(containers) under a single Linux kernel that run in isolation to one another.
Justascertainflagspassedto clone() candistinguishbetweencreatingatask
thatbehavesmorelikeaprocessorathreadbasedupontheamountofsharing
between the parent and child tasks, there are other flags that can be passed to
clone() thatallowaLinuxcontainertobecreated.Containerswillbecovered
morefullyinChapter18.
4.8 Summary
•Athread represents a basic unit of CPUutilization, and threads belonging
to the same process share many of the process resources, including code
and data.
•Therearefourprimarybenefitstomultithreadedapplications:(1)respon-
siveness,(2)resourcesharing, (3) economy,and (4) scalability.
•Concurrency exists when multiple threads are making progress, whereas
parallelism exists when multiple threads are making progress simulta-"
2,Practice Exercises,254,4.8 Summary,"Practice Exercises 197
neously. On a system with a single CPU, only concurrency is possible;
parallelismrequiresa multicoresystemthat providesmultiple CPUs.
•There are several challenges in designing multithreaded applications.
Theyincludedividingandbalancin gthework,dividingthedatabetween
thedifferentthreads,andidentifyinganydatadependencies.Finally,mul-
tithreadedprogramsareespeciallychallenging to testand debug.
•Dataparallelismdistributessubsetsofthesamedataacrossdifferentcom-
puting cores and performs the same operation on each core. Task paral-
lelism distributes not data but tasks across multiple cores. Each task is
running aunique operation.
•User applications create user-level threads, which must ultimately be
mapped to kernel threads to execute on a CPU. The many-to-one model
maps many user-level threads to one kernel thread. Other approaches
include the one-to-one and many-to-many models.
•Athreadlibraryprovidesan APIforcreatingandmanagingthreads.Three
common threadlibrariesincludeWindows,Pthreads,andJavathreading.
Windows is for the Windows system only, while Pthreads is available for
POSIX-compatible systems such as UNIX,L i n u x ,a n dm a c OS.J a v at h r e a d s
will runonany systemthat supportsa Javavirtualmachine.
•Implicitthreadinginvolvesidentify ingtasks—notthreads—andallowing
languages or APIframeworks to create and manage threads. There are
severalapproachestoimplicitthreading,includingthreadpools,fork-join
frameworks,and Grand CentralDispatc h. Implicitthreadingis becoming
anincreasinglycommontechniqueforprogrammerstouseindeveloping
concurrent and parallelapplications.
•Threadsmaybeterminatedusingeitherasynchronousordeferredcancel-
lation. Asynchronous cancellation stops a thread immediately, even if it
is in the middle of performing an update. Deferred cancellation informs
a thread that it should terminate but allows the thread to terminate in an
orderly fashion. In most circumstances, deferred cancellation is preferred
to asynchronous termination.
•Unlikemanyotheroperatingsystems, Linuxdoesnotdistinguishbetween
processes and threads; instead, it refers to each as a task. The Linux
clone() system call can be used to create tasks that behave either more
likeprocessesor morelikethreads.
Practice Exercises
4.1Providethreeprogrammingexamplesinwhichmultithreadingprovides
betterperformancethan a single-threadedsolution.
4.2Using Amdahl’s Law, calculate the speedup gain of an application that
hasa60percentparallelcomponentfor(a)twoprocessingcoresand(b)
four processingcores."
2,Further Reading,255,Practice Exercises,"198 Chapter 4 Threads & Concurrency
4.3DoesthemultithreadedwebserverdescribedinSection4.1exhibittask
ordata parallelism?
4.4What are two differences between user-level threads and kernel-level
threads?Underwhat circumstances isone type betterthan the other?
4.5Describetheactionstakenbyakernel tocontext-switchbetweenkernel-
levelthreads.
4.6What resources are used when a thread is created? How do they differ
fromthose usedwhena processiscreated?
4.7Assume that an operating system maps user-levelthreads to the kernel
using the many-to-many model and that the mapping is done through
LWPs. Furthermore, the system allows developers to create real-time
threads for use in real-time systems. Is it necessary to bind a real-time
thread toan LWP? Explain.
Further Reading
[Vahalia(1996)] coversthreadinginseveralversionsof UNIX.[Mc Do u ga lla n d
Mauro (2007)] describes developmentsin threading the Solaris kernel.[Russi-
novichetal.(2017)]discussthreadingintheWindowsoperatingsystemfamily.
[Mauerer(2008)]and[Love(2010)]explainhowLinuxhandlesthreading,and
[Levin (2013)] covers threads in mac OSand iOS. [Herlihy and Shavit (2012)]
coversparallelismissuesonmulticoresystems.[Aubanel(2017)]coversparal-
lelismof severaldifferentalgorithms.
Bibliography
[Aubanel (2017)] E. Aubanel, Elements of Parallel Computing , CRCPress (2017).
[Herlihy and Shavit (2012)] M. Herlihy and N. Shavit, The Art of Multiprocessor
Programming, Revised First Edition, MorganK aufmannPublishers Inc. (2012).
[Levin (2013)] J. Levin, Mac OS X and i OSInternals to the Apple’s Core , Wiley
(2013).
[Love (2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library (2010).
[Mauerer (2008)] W. Mauerer, Professional Linux Kernel Architecture , John Wiley
and Sons(2008).
[McDougall and Mauro (2007)] R. McDougall and J. Mauro, Solaris Internals,
SecondEdition, PrenticeHall (2007).
[Russinovich et al. (2017)] M.Russinovich,D.A.Solomon,andA.Ionescu, Win-
dows Internals–Part 1, SeventhEdition, MicrosoftPress (2017).
[Vahalia (1996)] U. Vahalia, Unix Internals: The New Frontiers ,P r e n t i c eH a l l
(1996)."
2,Bibliography,255,Further Reading,"198 Chapter 4 Threads & Concurrency
4.3DoesthemultithreadedwebserverdescribedinSection4.1exhibittask
ordata parallelism?
4.4What are two differences between user-level threads and kernel-level
threads?Underwhat circumstances isone type betterthan the other?
4.5Describetheactionstakenbyakernel tocontext-switchbetweenkernel-
levelthreads.
4.6What resources are used when a thread is created? How do they differ
fromthose usedwhena processiscreated?
4.7Assume that an operating system maps user-levelthreads to the kernel
using the many-to-many model and that the mapping is done through
LWPs. Furthermore, the system allows developers to create real-time
threads for use in real-time systems. Is it necessary to bind a real-time
thread toan LWP? Explain.
Further Reading
[Vahalia(1996)] coversthreadinginseveralversionsof UNIX.[Mc Do u ga lla n d
Mauro (2007)] describes developmentsin threading the Solaris kernel.[Russi-
novichetal.(2017)]discussthreadingintheWindowsoperatingsystemfamily.
[Mauerer(2008)]and[Love(2010)]explainhowLinuxhandlesthreading,and
[Levin (2013)] covers threads in mac OSand iOS. [Herlihy and Shavit (2012)]
coversparallelismissuesonmulticoresystems.[Aubanel(2017)]coversparal-
lelismof severaldifferentalgorithms.
Bibliography
[Aubanel (2017)] E. Aubanel, Elements of Parallel Computing , CRCPress (2017).
[Herlihy and Shavit (2012)] M. Herlihy and N. Shavit, The Art of Multiprocessor
Programming, Revised First Edition, MorganK aufmannPublishers Inc. (2012).
[Levin (2013)] J. Levin, Mac OS X and i OSInternals to the Apple’s Core , Wiley
(2013).
[Love (2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library (2010).
[Mauerer (2008)] W. Mauerer, Professional Linux Kernel Architecture , John Wiley
and Sons(2008).
[McDougall and Mauro (2007)] R. McDougall and J. Mauro, Solaris Internals,
SecondEdition, PrenticeHall (2007).
[Russinovich et al. (2017)] M.Russinovich,D.A.Solomon,andA.Ionescu, Win-
dows Internals–Part 1, SeventhEdition, MicrosoftPress (2017).
[Vahalia (1996)] U. Vahalia, Unix Internals: The New Frontiers ,P r e n t i c eH a l l
(1996)."
2,Chapter 4 Exercises,256,Bibliography,"Exercises
Chapter 4 Exercises
4.8Provide two programming examples in which multithreading does not
providebetterperformance thana single-threadedsolution.
4.9Under what circumstances does a multithreaded solution using multi-
ple kernel threads provide better performance than a single-threaded
solutionona single-processorsystem?
4.10Which of the following components of program state are shared across
threadsina multithreadedprocess?
a. Registervalues
b. Heapmemory
c. Global variables
d. Stack memory
4.11Can a multithreaded solution using multiple user-level threads
achieve better performance on a multiprocessor system than on a
single-processorsystem?Explain.
4.12In Chapter 3, we discussed Google’s Chrome browser and its practice
of openingeachnew tabin aseparateprocess.Wouldthesamebenefits
havebeenachievedif,instead,Chromehadbeendesignedtoopeneach
new tab ina separatethread?Explain.
4.13Is itpossibletohaveconcurrency butnot parallelism?Explain.
4.14UsingAmdahl’sLaw,calculatethespeedupgainforthefollowingappli-
cations:
•40 percent parallel with (a) eight processing cores and (b) sixteen
processingcores
•67 percent parallel with (a) two processing cores and (b) four pro-
cessing cores
•90 percent parallel with (a) four processing cores and (b) eight pro-
cessing cores
4.15Determineif thefollowing problemsexhibittask ordata parallelism:
•Usingaseparatethreadtogenerateathumbnailforeachphotoina
collection
•Transposing a matrixinparallel
•Anetworkedapplicationwhereonethreadreadsfromthenetwork
and another writestothe network
•Thefork-joinarraysummationapp licationdescribedinSection4.5.2
•The GrandCentralDispatchsystem
4.16A system with two dual-core processors has four processors available
for scheduling. A CPU-intensive application is running on this system.
All input is performed at program start-up, when a single file must beEX-8"
2,Programming Problems,260,Chapter 4 Exercises,"Programming Problems
Programming Problems
4.22Writeamultithreadedprogramthatcalculatesvariousstatisticalvalues
for a list of numbers. This program will be passed a series of numbers
onthecommandlineandwillthencreatethreeseparateworkerthreads.
One thread will determine the average of the numbers, the second will
determine the maximum value, and the third will determine the mini-
mum value.For example,supposeyour programis passedtheintegers
90 81 78 95 79 72 85
The program will report
The average value is 82
The minimum value is 72
The maximum value is 95
Thevariablesrepresentingtheaverage,minimum,andmaximumvalues
will be stored globally. The worker threads will set these values, and
t h ep a r e n tt h r e a dw i l lo u t p u tt h ev a l u e so n c et h ew o r k e r sh a v ee x i t e d .
(Wecouldobviouslyexpandthisprogrambycreatingadditionalthreads
that determine other statistical values, such as median and standard
deviation.)
4.23Write a multithreaded program that outputs prime numbers. This pro-
gram should work as follows: The user will run the program and will
enter a number on the command line. The program will then create a
separatethreadthatoutputsalltheprimenumberslessthanorequalto
thenumber enteredby theuser.
4.24Aninterestingwayofcalculating πistouseatechniqueknownas Monte
Carlo,which involvesrandomization.Thistechniqueworksasfollows:
Suppose you have a circle inscribed within a square, as shown in
Figure4.25. (Assumethat the radiusofthis circleis1.)
•First,generateaseriesofrandompointsassimple( x,y)coordinates.
These points must fall within the Cartesian coordinates that bound
thesquare.Ofthetotalnumberofrandompointsthataregenerated,
somewilloccur withinthecircle.
•Next,estimate πby performingthe following calculation:
π=4×(numberofpointsincircle) /(totalnumberofpoints)
Write a multithreaded version of this algorithm that creates a separate
thread to generate a number of random points. The thread will count
the number of points that occur within the circle and store that result
in a global variable. When this thre ad has exited,the parent thread will
calculateandoutputtheestimatedvalueof π.Itisworthexperimenting
with the number of random points generated. As a general rule, the
greaterthenumber of points,the closertheapproximation to π.P-23"
2,Programming Projects,262,Programming Problems,"Programming Problems
multithreadedprogramthattestsyoursolutiontoExercise3.20.Youwill
create a number of threads—for example, 100—and each thread will
request a pid, sleep for a random period of time, and then release the
pid.(Sleepingforarandomperiodoftimeapproximatesthetypicalpid
usage in which a pid is assigned to a new process, the process executes
and then terminates, and the pid is released on the process’s termina-
tion.) On UNIXand Linux systems, sleeping is accomplished through
thesleep() function,whichispassedanintegervaluerepresentingthe
numberofsecondstosleep.ThisproblemwillbemodifiedinChapter7.
4.29Exercise 3.25 in Chapter 3 involves designing an echo server using the
Java threading API. This server is single-threaded, meaning that the
servercannot respondto concurrent echo clientsuntilthe currentclient
exits.ModifythesolutiontoExercise3.25sothattheechoserverservices
eachclient inaseparaterequest.
624539187
519728634
837614295
143865729
958247361
762391458
371956842
496182573
285473916
Figure 4.26 Solution to a 9×9Sudoku puzzle.Programming Projects
Project 1—Sudoku Solution Validator
ASudokupuzzle uses a 9 ×9 grid in which each column and row, as well as
e a c ho ft h en i n e3 ×3 subgrids, must contain all of the digits 1 ⋅⋅⋅9. Figure
4.26 presents an example of a valid Sudoku puzzle. This project consists of
designing a multithreaded application t hat determines whether the solution
to aSudokupuzzle isvalid.
There are several different ways of multithreading this application. One
suggestedstrategyis tocreatethreadsthat check thefollowing criteria:
•Athread to check that each column contains the digits1 through 9
•Athread to check that each row contains the digits1through 9P-25"
1,Chapter 5 CPU Scheduling,266,Chapter 4 Threads & Concurrency,"5CHAPTER
CPU
Scheduling
CPUschedulingisthebasisofmultiprogrammedoperatingsystems.Byswitch-
ing the CPUamong processes, the operating system can make the computer
moreproductive.Inthischapter,we introducebasic CPU-scheduling concepts
and present several CPU-scheduling algorithms, including real-time systems.
Wealsoconsidertheproblemofselectinganalgorithmforaparticularsystem.
InChapter4,weintroducedthreadstotheprocessmodel.Onmodernoper-
ating systems it is kernel-levelthreads—not processes—that are in fact being
scheduled by the operating system. However, the terms ""process scheduling""
and""threadscheduling""areoftenusedin terchangeably.Inthischapter,weuse
process scheduling when discussing general scheduling concepts and thread
scheduling to referto thread-specificideas.
Similarly, in Chapter 1 we describe how a coreis the basic computational
unit of a CPU, and that a process executes on a CPU’s core. However, in many
instances in this chapter, when we use the general terminology of scheduling
ap r o c e s st o"" r u no na CPU"", we are implying that the process is running on a
CPU’s core.
CHAPTER OBJECTIVES
•Describe various CPUscheduling algorithms.
•Assess CPUscheduling algorithms based on scheduling criteria.
•Explain the issues related to multiprocessor and multicore scheduling.
•Describe various real-time scheduling algorithms.
•Describe the scheduling algorithms used in the Windows, Linux, and
Solaris operating systems.
•Apply modeling and simulations to evaluate CPUscheduling algorithms.
•Design a program that implements several different CPUscheduling algo-
rithms.
199"
2,5.1 Basic Concepts,267,Chapter 5 CPU Scheduling,"200 Chapter 5 CPU Scheduling
5.1 Basic Concepts
In a system with a single CPUcore, only one process can run at a time. Others
must wait until the CPU’s core is freeand can be rescheduled.The objectiveof
multiprogramming is to have some process running at all times, to maximize
CPUutilization.Theideaisrelativelysimple.Aprocessisexecuteduntilitmust
wait, typically for the completion of some I/Orequest. In a simple computer
system, the CPUthen just sits idle. All this waiting time is wasted; no useful
workisaccomplished.Withmultiprogramming,wetrytousethistimeproduc-
tively.Severalprocessesarekeptinmemoryatonetime.Whenoneprocesshas
to wait, the operating system takes the CPUaway from that process and gives
theCPUtoanotherprocess.Thispatterncontinues.Everytimeoneprocesshas
to wait, another process can take over use of the CPU. On a multicore system,
thisconceptofkeepingthe CPUbusyisextendedtoallprocessingcoresonthe
system.
Scheduling of this kind is a fundamental operating-system function.
Almostallcomputerresourcesarescheduledbeforeuse.The CPUis,ofcourse,
o n eo ft h ep r i m a r yc o m p u t e rr e s o u r c e s .T h u s ,i t ss c h e d u l i n gi sc e n t r a lt o
operating-systemdesign.
CPU burstload store
add store
read  from file
store increment
index
write  to file
load store
add store
read  from filewait for I/O
wait for I/O
wait for I/OI/O burst
I/O burst
I/O burstCPU burst
CPU burst





Figure 5.1 Alternating sequence of CPU and I/O bursts."
3,5.1.1 CPU–I/O Burst Cycle,268,5.1 Basic Concepts,"5.1 Basic Concepts 201
5.1.1 CPU–I/O Burst Cycle
Thesuccessof CPUschedulingdependsonanobservedpropertyofprocesses:
process execution consists of a cycleofCPUexecution and I/Owait. Processes
alternatebetweenthesetwostates.Processexecutionbeginswitha CPU burst.
Thatisfollowedbyan I/Oburst,whichisfollowedbyanother CPUburst,then
another I/Oburst,andsoon.Eventually,thefinal CPUburstendswithasystem
requestto terminateexecution(Figure5.1).
The durations of CPUbursts have been measured extensively. Although
they vary greatly from process to process and from computer to computer,
they tend to have a frequency curve similar to that shown in Figure 5.2. The
curve is generally characterized as exp onential or hyperexponential, with a
large number of short CPUbursts and a small number of long CPUbursts.
AnI/O-bound program typically has many short CPUbursts. A CPU-bound
programmighthaveafewlong CPUbursts.Thisdistributioncanbeimportant
whenimplementinga CPU-scheduling algorithm.
5.1.2 CPU Scheduler
Whenever the CPUbecomes idle, the operating system must select one of the
processesinthereadyqueuetobeexecuted.Theselectionprocessiscarriedout
by the CPU scheduler ,w h i c hs e l e c t sap r o c e s sf r o mt h ep r o c e s s e si nm e m o r y
thatarereadyto executeand allocatesthe CPUtothat process.
Notethatthereadyqueueisnotnecessarilyafirst-in,first-out( FIFO)queue.
As we shall see when we consider the various scheduling algorithms, a ready
queuecan be implementedas a FIFOqueue,a priorityqueue,atree,or simply
anunorderedlinkedlist.Conceptually,however,alltheprocessesintheready
queue are lined up waiting for a chance to run on the CPU. The records in the
queuesaregenerallyprocess control blocks ( PCBs) of theprocesses.
burst durationfrequency
Figure 5.2 Histogram of CPU-burst durations."
3,5.1.2 CPU Scheduler,268,5.1.1 CPU–I/O Burst Cycle,"5.1 Basic Concepts 201
5.1.1 CPU–I/O Burst Cycle
Thesuccessof CPUschedulingdependsonanobservedpropertyofprocesses:
process execution consists of a cycleofCPUexecution and I/Owait. Processes
alternatebetweenthesetwostates.Processexecutionbeginswitha CPU burst.
Thatisfollowedbyan I/Oburst,whichisfollowedbyanother CPUburst,then
another I/Oburst,andsoon.Eventually,thefinal CPUburstendswithasystem
requestto terminateexecution(Figure5.1).
The durations of CPUbursts have been measured extensively. Although
they vary greatly from process to process and from computer to computer,
they tend to have a frequency curve similar to that shown in Figure 5.2. The
curve is generally characterized as exp onential or hyperexponential, with a
large number of short CPUbursts and a small number of long CPUbursts.
AnI/O-bound program typically has many short CPUbursts. A CPU-bound
programmighthaveafewlong CPUbursts.Thisdistributioncanbeimportant
whenimplementinga CPU-scheduling algorithm.
5.1.2 CPU Scheduler
Whenever the CPUbecomes idle, the operating system must select one of the
processesinthereadyqueuetobeexecuted.Theselectionprocessiscarriedout
by the CPU scheduler ,w h i c hs e l e c t sap r o c e s sf r o mt h ep r o c e s s e si nm e m o r y
thatarereadyto executeand allocatesthe CPUtothat process.
Notethatthereadyqueueisnotnecessarilyafirst-in,first-out( FIFO)queue.
As we shall see when we consider the various scheduling algorithms, a ready
queuecan be implementedas a FIFOqueue,a priorityqueue,atree,or simply
anunorderedlinkedlist.Conceptually,however,alltheprocessesintheready
queue are lined up waiting for a chance to run on the CPU. The records in the
queuesaregenerallyprocess control blocks ( PCBs) of theprocesses.
burst durationfrequency
Figure 5.2 Histogram of CPU-burst durations."
3,5.1.3 Preemptive and Nonpreemptive Scheduling,269,5.1.2 CPU Scheduler,"202 Chapter 5 CPU Scheduling
5.1.3 Preemptive and Nonpreemptive Scheduling
CPU-scheduling decisions may take place under the following four circum-
stances:
1.When a process switches from the running state to the waiting state (for
example,astheresultofan I/Orequestoraninvocationof wait()forthe
terminationofa child process)
2.When a process switches from the running state to the ready state (for
example,when aninterruptoccurs)
3.When a process switches from the waiting state to the ready state (for
example,at completionof I/O)
4.When aprocessterminates
Forsituations1and4,thereisnochoiceintermsofscheduling.Anewprocess
(if one exists in the ready queue) must be selected for execution. There is a
choice, however,forsituations 2 and3.
Whenschedulingtakesplaceonlyundercircumstances1and4,wesaythat
the scheduling scheme is nonpreemptive orcooperative .O t h e r w i s e ,i ti s pre-
emptive. Under nonpreemptive scheduling, once the CPUhas been allocated
toaprocess,theprocesskeepsthe CPUuntilitreleasesiteitherbyterminating
or by switching to the waiting state. Virtually all modern operating systems
includingWindows,mac OS,Linux,and UNIXusepreemptiveschedulingalgo-
rithms.
Unfortunately, preemptive schedulin g can result in race conditions when
data are shared among several processes. Consider the case of two processes
that share data. While one process is updating the data, it is preempted so
that the second process can run. The second process then tries to read the
data, which are in an inconsistent state. This issue will be explored in detail
inChapter6.
Preemptionalso affects the designof the operating-systemkernel.During
the processing of a system call, the kernel may be busy with an activity on
behalf of a process. Such activities may involve changing important kernel
data (for instance, I/Oqueues). What happens if the process is preempted
in the middle of these changes and the kernel (or the device driver) needs
to read or modify the same structure? Chaos ensues. As will be discussed in
Section6.2,operating-systemkernelscanbedesignedaseithernonpreemptive
orpreemptive.Anonpreemptivekernelwillwaitforasystemcalltocomplete
orforaprocesstoblockwhile waitingfor I/Otocompletetotakeplacebefore
doingacontextswitch.Thisschemeensuresthatthekernelstructureissimple,
sincethekernelwillnotpreemptaprocesswhilethekerneldatastructuresare
in an inconsistent state. Unfortunatel y, this kernel-execution model is a poor
oneforsupportingreal-timecomputing, wheretasksmustcompleteexecution
within a given time frame. In Section 5.6, we explore scheduling demands of
real-time systems. A preemptive kernel requires mechanisms such as mutex
lockstopreventraceconditionswhenaccessingsharedkerneldatastructures.
Most modern operating systems are now fully preemptive when running in
kernelmode."
3,5.1.4 Dispatcher,270,5.1.3 Preemptive and Nonpreemptive Scheduling,"5.1 Basic Concepts 203
P0 
executing
P1 
executingsave state
into PCB0
restore state
from PCB1dispatch 
latency
Figure 5.3 The role of the dispatcher.
Because interrupts can, by definition, occur at any time, and because they
cannot always be ignored by the kernel, the sections of code affected by inter-
ruptsmustbeguardedfromsimultaneoususe.Theoperatingsystemneedsto
accept interruptsat almost all times.Otherwise, input might be lost or output
overwritten. So that these sections of code are not accessed concurrently by
several processes, they disable interrupts at entry and reenable interrupts at
exit. It is important to note that sections of code that disable interrupts do not
occur veryoftenand typicallycontain fewinstructions.
5.1.4 Dispatcher
Anothercomponentinvolvedinthe CPU-schedulingfunctionisthe dispatcher .
Thedispatcheristhemodulethatgivescontrolofthe CPU’scoretotheprocess
selectedby the CPUscheduler.Thisfunction involvesthefollowing:
•Switching context from one processtoanother
•Switching to usermode
•Jumpingtotheproperlocationintheuserprogramtoresumethatprogram
Thedispatchershouldbeasfastaspossible,sinceitisinvokedduringevery
contextswitch.Thetimeittakesforthedispatchertostoponeprocessandstart
another running is known as the dispatch latency and is illustrated in Figure
5.3.
An interesting question to consider is, how often do context switches
occur?Onasystem-widelevel,thenumberofcontextswitchescanbeobtained
byusingthe vmstatcommandthatisavailableonLinuxsystems.Belowisthe
output(which has been trimmed)fromthe command
vmstat 1 3"
2,5.2 Scheduling Criteria,271,5.1 Basic Concepts,"204 Chapter 5 CPU Scheduling
This command provides3 linesof outputovera 1-second delay:
------cpu-----
24
225
339
The first line gives the average number of context switches over 1 second
since the system booted, and the next two lines give the number of context
switches over two 1-second intervals. Since this machine booted, it has aver-
aged 24 context switches per second. And in the past second, 225 context
switches were made,with 339 context switches inthe second prior tothat.
We can also use the /procfile system to determine the number of
context switches for a given process. For example, the contents of the file
/proc/2166/status will list various statistics for the process with pid =
2166. The command
cat /proc/2166/status
providesthefollowing trimmedoutput:
voluntary
 ctxt
 switches 150
nonvoluntary
 ctxt
 switches 8
This output shows the number of context switches over the lifetime of the
process. Notice the distinction between voluntary andnonvoluntary context
switches. A voluntary context switch occurs when a process has given up
control of the CPUbecause it requires a resource that is currently unavailable
(suchasblockingfor I/O.)Anonvoluntarycontextswitchoccurswhenthe CPU
hasbeentakenawayfromaprocess,suchaswhenitstimeslicehasexpiredor
ithas beenpreemptedby ahigher-priorityprocess.
5.2 Scheduling Criteria
Different CPU-scheduling algorithmshavedifferentproperties,and thechoice
of a particular algorithm may favor one class of processes over another. In
choosing which algorithm to use in a particular situation, we must consider
thepropertiesof thevariousalgorithms.
Many criteria have been suggested for comparing CPU-scheduling algo-
rithms. Which characteristics are used for comparison can make a substantial
difference in which algorithm is judged to be best. The criteria include the
following:
•CPU utilization . We want to keep the CPUas busy as possible. Concep-
tually,CPUutilization can range from 0 to 100 percent. In a real system, it
should range from 40 percent (for a lightly loaded system) to 90 percent
(for a heavily loaded system). ( CPUutilization can be obtained by using
thetopcommand on Linux, mac OS,a n dUNIXsystems.)
•Throughput .I ft h e CPUis busy executing processes, then work is being
done.Onemeasureofworkisthenumberofprocessesthatarecompleted"
2,5.3 Scheduling Algorithms,272,5.2 Scheduling Criteria,"5.3 Scheduling Algorithms 205
per time unit, called throughput . For long processes, this rate may be
one process over several seconds; for short transactions, it may be tens of
processespersecond.
•T urnaround time . From the point of view of a particular process, the
importantcriterionishowlongittakestoexecutethatprocess.Theinterval
f r o mt h et i m eo fs u b m i s s i o no fap r o c e s st ot h et i m eo fc o m p l e t i o ni st h e
turnaroundtime.Turnaroundtimeisthesumoftheperiodsspentwaiting
inthe readyqueue,executingonthe CPU,a n dd o i n g I/O.
•Waiting time .T h eCPU-scheduling algorithm does not affect the amount
of time during which a process executes or does I/O. It affects only the
amountoftimethataprocessspendswaitinginthereadyqueue.Waiting
timeisthe sumof theperiodsspentwaiting inthe readyqueue.
•Response time . In an interactive system, turnaround time may not be
the best criterion. Often, a process can produce some output fairly early
and can continue computing new results while previous results are being
outputtotheuser.Thus,anothermeasureisthetimefromthesubmission
of a request until the first response is produced. This measure, called
responsetime,isthetimeittakestostartresponding,not thetimeittakes
to outputthe response.
Itisdesirabletomaximize CPUutilizationandthroughputandtominimize
turnaroundtime,waitingtime,andresponsetime.Inmostcases,weoptimize
the average measure. However, under some circumstances, we prefer to opti-
mizetheminimumormaximumvaluesratherthan theaverage.Forexample,
to guarantee that all users get good service, we may want to minimize the
maximumresponsetime.
Investigators have suggested that, for interactive systems (such as a PC
desktop or laptop system), it is more important to minimize the variance in
the response time than to minimize the average response time. Asystem with
reasonable and predictable response time may be considered more desirable
thanasystemthatisfasterontheaverageb utishighlyvariable.However,little
work has beendone on CPU-scheduling algorithmsthat minimizevariance.
Aswediscussvarious CPU-schedulingalgorithmsinthefollowingsection,
we illustrate their operation. An accura te illustration should involve many
processes, each a sequence of several hundred CPUbursts and I/Obursts.
For simplicity, though, we consider only one CPUburst (in milliseconds) per
process in our examples. Our measure of comparison is the average waiting
time.Moreelaborateevaluationmechanisms arediscussedinSection5.8.
5.3 Scheduling Algorithms
CPUscheduling deals with the problem of deciding which of the processes in
thereadyqueueistobeallocatedthe CPU’score.Therearemanydifferent CPU-
scheduling algorithms. In this section, we describe several of them. Although
most modern CPUarchitectures have multiple processing cores, we describe
these scheduling algorithms in the context of only one processing core avail-
able. That is, a single CPUthat has a single processing core, thus the system is"
3,"5.3.1 First-Come, First-Served Scheduling",273,5.3 Scheduling Algorithms,"206 Chapter 5 CPU Scheduling
capable of only running one process at a time. In Section 5.5 we discuss CPU
schedulingin the contextof multiprocessorsystems.
5.3.1 First-Come, First-Served Scheduling
By far the simplest CPU-scheduling algorithm is the first-come first-serve
(FCFS) scheduling algorithm. With this scheme, the process that requests the
CPUfirst is allocated the CPUfirst. The implementation of the FCFSpolicy is
easilymanagedwitha FIFOqueue.Whenaprocessentersthereadyqueue,its
PCBis linked onto the tail of the queue. When the CPUis free, it is allocated to
theprocessattheheadofthequeue.Therunningprocessisthenremovedfrom
the queue.The code for FCFSscheduling issimpleto writeandunderstand.
On the negative side, the average waiting time under the FCFSpolicy is
often quite long. Consider the following set of processes that arrive at time 0,
with the lengthof the CPUburst giveninmilliseconds:
Process BurstTime
P1 24
P2 3
P3 3
If theprocessesarriveinthe order P1,P2,P3,and are servedin FCFSorder,
we getthe resultshown in the following Gantt chart , which isa barchart that
illustratesaparticularschedule,inclu dingthe startand finish timesof eachof
theparticipating processes:
P1 P2 P3
30 27 24 0
The waiting time is 0 milliseconds for process P1, 24 milliseconds for process
P2, and 27 milliseconds for process P3. Thus, the average waiting time is (0
+ 24 + 27)/3 = 17 milliseconds. If the processes arrive in the order P2,P3,P1,
however,theresultswillbeas shown inthefollowing Gantt chart:
P1 P2 P3
30 036
Theaveragewaitingtimeisnow(6+0+3)/3=3milliseconds.Thisreduction
issubstantial.Thus,theaveragewaitingtimeunderan FCFSpolicyisgenerally
notminimalandmayvarysubstantiallyiftheprocesses’ CPUbursttimesvary
greatly.
In addition, consider the performance of FCFSscheduling in a dynamic
situation.Assumewehaveone CPU-bound processandmany I/O-bound pro-
cesses. As the processes flow around the system, the following scenario may
result. The CPU-bound processwillgetand holdthe CPU.Duringthistime,all
the other processes will finish their I/Oand will move into the ready queue,
waiting for the CPU. While the processes wait in the ready queue, the I/O"
3,5.3.2 Shortest-Job-First Scheduling,274,"5.3.1 First-Come, First-Served Scheduling","5.3 Scheduling Algorithms 207
devicesare idle.Eventually,the CPU-bound process finishes its CPUburst and
moves to an I/Odevice. All the I/O-bound processes, which have short CPU
bursts, execute quickly and move back to the I/Oqueues. At this point, the
CPUsits idle. The CPU-bound process will then move back to the ready queue
a n db ea l l o c a t e dt h e CPU.A g a i n ,a l lt h e I/Oprocesses end up waiting in the
ready queue until the CPU-bound process is done. There is a convoy effect as
alltheotherprocesseswaitforth eonebigprocesstogetoffthe CPU.Thiseffect
resultsinlower CPUanddeviceutilizationthanmightbepossibleiftheshorter
pr o c essesw er ea llo w edtogofi rst.
Note also that the FCFSscheduling algorithm is nonpreemptive. Once the
CPUhasbeenallocatedtoaprocess,thatprocesskeepsthe CPUuntilitreleases
theCPU,eitherbyterminatingorbyrequesting I/O.TheFCFSalgorithmisthus
particularly troublesome for interactive systems, where it is important that
eachprocessgeta shareofthe CPUatregularintervals.Itwouldbedisastrous
toallowone processtokeepthe CPUfor anextendedperiod.
5.3.2 Shortest-Job-First Scheduling
Adifferent approach to CPUscheduling is the shortest-job-firs (SJF)s c h e d u l -
ing algorithm. This algorithm associates with each process the length of the
process’snext CPUburst.Whenthe CPUisavailable,itisassignedtotheprocess
thathasthesmallestnext CPUburst.Ifthenext CPUburstsoftwoprocessesare
the same, FCFSscheduling is used to break the tie. Note that a more appro-
priateterm for this scheduling method would be the shortest-next- CPU-burst
algorithm, because scheduling dependson the lengthof the next CPUburst of
aprocess,ratherthanitstotallength.Weusetheterm SJFbecausemostpeople
andtextbooks usethistermto referto thistypeof scheduling.
As an example of SJFscheduling, consider the following set of processes,
with the length ofthe CPUburst giveninmilliseconds:
Process BurstTime
P1 6
P2 8
P3 7
P4 3
UsingSJFscheduling, we would schedule these processes according to the
following Gantt chart:
P3 P2 P4 P1
24 16 9 03
The waiting time is 3 milliseconds for process P1, 16 milliseconds for process
P2, 9 milliseconds for process P3, and 0 milliseconds for process P4.T h u s ,t h e
average waiting time is (3 + 16 + 9 + 0)/4 = 7 milliseconds. By comparison, if
we were using the FCFSscheduling scheme, the average waiting time would
be10.25 milliseconds.
TheSJFschedulingalgorithmisprovably optimal,inthatitgivesthemini-
mumaveragewaitingtimeforagivensetofprocesses.Movingashortprocess"
3,5.3.3 Round-Robin Scheduling,276,5.3.2 Shortest-Job-First Scheduling,"5.3 Scheduling Algorithms 209
Tounderstandthebehavioroftheexponentialaverage,wecanexpandthe
formulafor τn+1bysubstituting for τntofind
τn+1=αtn+(1−α)αtn−1+···+(1−α)jαtn−j+···+(1−α)n+1τ0.
Typically, αis less than 1. As a result, (1 −α) is also less than 1, and each
successivetermhas lessweightthan itspredecessor.
TheSJFalgorithm can be either preemptive or nonpreemptive. The choice
arises when a new process arrives at the ready queue while a previous pro-
cess is still executing. The next CPUburst of the newly arrived process may
be shorter than what is left of the currently executing process. A preemptive
SJFalgorithm will preempt the currently executing process, whereas a non-
preemptive SJFalgorithmwillallow the currentlyrunning processtofinish its
CPUburst.Preemptive SJFschedulingissometimescalled shortest-remaining-
time-firs scheduling.
As an example, consider the following four processes, with the length of
theCPUburst giveninmilliseconds:
Process ArrivalTime BurstTime
P1 08
P2 14
P3 29
P4 35
If the processes arrive at the ready queue at the times shown and need the
indicatedbursttimes,thentheresultingpreemptive SJFscheduleisasdepicted
inthe following Gantt chart:
P1P3P1P2P4
26 17 10 01 5
Process P1isstartedattime0,sinceitistheonlyprocessinthequeue.Process
P2arrives at time 1. The remaining time for process P1(7 milliseconds) is
larger than the time required by process P2(4 milliseconds), so process P1is
preempted, and process P2is scheduled. The average waiting time for this
exampleis [(10 −1) + (1−1) + (17−2) + (5−3)]/4 = 26/4 = 6.5 milliseconds.
Nonpreemptive SJFschedulingwouldresultinanaveragewaitingtimeof7.75
milliseconds.
5.3.3 Round-Robin Scheduling
The round-robin (RR) scheduling algorithm is similar to FCFSscheduling, but
preemptionisaddedtoenablethesystemtoswitchbetweenprocesses.Asmall
unit of time, called a time quantum ortime slice , is defined. Atime quantum
isgenerallyfrom10to100millisecondsinlength.Thereadyqueueistreatedas
a circular queue. The CPUscheduler goes around the ready queue, allocating
theCPUto eachprocessfor atimeintervalof up to1 timequantum.
To implement RRscheduling, we again treat the ready queue as a FIFO
queue of processes. New processes are added to the tail of the ready queue."
3,5.3.4 Priority Scheduling,278,5.3.3 Round-Robin Scheduling,"5.3 Scheduling Algorithms 211
process time = 10 quantum context
switches
12 0
61
1901 0
01 0
0123456789 1 06
Figure 5.5 How a smaller time quantum increases context switches.
number of context switches. Assume, for example, that we have only one
process of 10 time units. If the quantum is 12 time units, the process finishes
inlessthan1timequantum,withno overhead.Ifthequantumis6timeunits,
however, the process requires 2 quanta, resulting in a context switch. If the
timequantumis1timeunit,thenninecon textswitcheswilloccur,slowingthe
executionof theprocessaccordingly (Figure5.5).
Thus, we want the time quantum to be large with respect to the context-
switch time. If the context-switch time is approximately 10 percent of the
time quantum, then about 10 percent of the CPUtime will be spent in context
switching. In practice, most modern systems have time quanta ranging from
10 to 100 milliseconds. The time required for a context switch is typically less
than 10 microseconds; thus, the context-switch time is a small fraction of the
timequantum.
Turnaround time also depends on the size of the time quantum. As we
can see from Figure 5.6, the average turnaround time of a set of processes
does not necessarily improve as the time-quantum size increases. In general,
the average turnaround time can be improved if most processes finish their
nextCPUburst in a single time quantum. For example, given three processes
of 10 time units each and a quantum of 1 time unit, the average turnaround
time is 29. If the time quantum is 10, however, the average turnaround time
drops to 20. If context-switch time is added in, the average turnaround time
increases even more for a smaller time quantum, since more context switches
arerequired.
Although the time quantum should be large compared with the context-
switch time, it should not be too large. As we pointed out earlier, if the time
quantum is too large, RRscheduling degenerates to an FCFSpolicy. A rule of
thumb is that 80 percent of the CPUbursts should be shorter than the time
quantum.
5.3.4 Priority Scheduling
TheSJFalgorithmisaspecialcaseofthegeneral priority-scheduling algorithm.
A priority is associated with each process, and the CPUis allocated to the"
3,5.3.5 Multilevel Queue Scheduling,281,5.3.4 Priority Scheduling,"214 Chapter 5 CPU Scheduling
Using priority scheduling with round-robin for processes with equal priority,
we would schedule these processes according to the following Gantt chart
using a timequantum of 2 milliseconds:
P4P2P3P2P3P2P3P1P5P1P5
07 9 11 13 15 16 20 22 24 2627
Inthisexample,process P4hasthehighestpriority,soitwillruntocomple-
tion.Processes P2andP3havethenext-highestpriority,andtheywillexecutein
around-robinfashion.Noticethatwhenprocess P2finishesattime16,process
P3is the highest-priority process, so it will run until it completes execution.
Now, only processes P1and P5remain, and as they have equal priority, they
willexecuteinround-robinorderuntil theycomplete.
5.3.5 Multilevel Queue Scheduling
With both priority and round-robin scheduling, all processes may be placed
in a single queue, and the scheduler then selects the process with the highest
priority to run. Depending on how the queues are managed, an O(n)s e a r c h
may be necessary to determine the highest-priority process. In practice, it is
often easier to have separate queues for each distinct priority, and priority
scheduling simply schedules the process in the highest-priority queue. This
is illustrated in Figure 5.7. This approach—known as multilevel queue —
also works well when priority schedu ling is combined with round-robin: if
therearemultipleprocessesinthehighest-priorityqueue,theyareexecutedin
round-robinorder.Inthemostgeneralizedformof thisapproach,a priorityis
assigned statically to each process, and a process remains in the same queue
for theduration of itsruntime.
T0T1T2T3T4
T5T6T7
T8T9T10T11
TxTyTzpriority = 2
priority = npriority = 1priority = 0
Figure 5.7 Separate queues for each priority."
3,5.3.6 Multilevel Feedback Queue Scheduling,283,5.3.5 Multilevel Queue Scheduling,"216 Chapter 5 CPU Scheduling
among its processes, while the background queue receives 20 percent of the
CPUto giveto itsprocessesonan FCFSbasis.
5.3.6 Multilevel Feedback Queue Scheduling
Normally,when themultilevelqueuescheduling algorithmisused,processes
are permanently assigned to a queue when they enter the system. If there
are separate queues for foreground and background processes, for example,
processes do not move from one queue to the other, since processes do not
change their foreground or background nature. This setup has the advantage
of lowschedulingoverhead,but itisinflexible.
The multilevel feedback queue scheduling algorithm, in contrast, allows
aprocesstomovebetweenqueues.Theideaistoseparateprocessesaccording
to the characteristics of their CPUbursts. If a process uses too much CPUtime,
itwillbemovedtoalower-priorityqueue.Thisschemeleaves I/O-boundand
interactive processes—which are typically characterized by short CPUbursts
—in the higher-priority queues.In addition,a process that waits too long ina
lower-priority queue may be moved to a higher-priority queue. This form of
aging preventsstarvation.
For example, consider a multilevel feedback queue scheduler with three
queues, numbered from 0 to 2 (Figure 5.9). The scheduler first executes all
processes in queue 0. Only when queue 0 is empty will it execute processes
in queue 1. Similarly, processes in queue 2 will be executed only if queues 0
and 1 are empty. Aprocess that arrives for queue 1 will preempt a process in
queue 2. Aprocess in queue 1 will in turn be preemptedby a process arriving
for queue0.
Anenteringprocessisputinqueue0.Aprocessinqueue0isgivenatime
quantum of 8 milliseconds. If it does not finish within this time, it is moved
to the tailof queue1. If queue0 isempty,the process atthe head of queue1 is
givenaquantumof16milliseconds.Ifitdoesnotcomplete,itispreemptedand
is put into queue 2. Processes in queue 2 are run on an FCFSbasis but are run
onlywhenqueues0and1areempty.Topreventstarvation,aprocessthatwaits
toolonginalower-priorityqueuemaygraduallybemovedtoahigher-priority
queue.
quantum = 8
quantum = 16
FCFS
Figure 5.9 Multilevel feedback queues."
2,5.4 Thread Scheduling,284,5.3 Scheduling Algorithms,"5.4 Thread Scheduling 217
Thisschedulingalgorithmgiveshighestprioritytoanyprocesswitha CPU
burst of 8 milliseconds or less. Such a process will quickly get the CPU, finish
itsCPUburst, and go off to its next I/Oburst. Processes that need more than
8 but less than 24 milliseconds are also served quickly, although with lower
priority than shorter processes. Long processes automatically sink to queue
2 and are served in FCFSorder with any CPUcycles left over from queues 0
and 1.
Ingeneral,amultilevelfeedbackqueueschedulerisdefinedbythefollow-
ingparameters:
•The number of queues
•The schedulingalgorithm foreach queue
•The method used to determine when to upgrade a process to a higher-
priorityqueue
•The method used to determine when to demote a process to a lower-
priorityqueue
•Themethodusedtodeterminewhichqueueaprocesswillenterwhenthat
processneedsservice
The definition of a multilevel feedback queue scheduler makes it the most
general CPU-scheduling algorithm. It can be configured to match a specific
system under design. Unfortunately, it is also the most complex algorithm,
sincedefiningthebestschedulerrequiressomemeansbywhichtoselectvalues
forall theparameters.
5.4 Thread Scheduling
In Chapter 4, we introduced threads to the process model, distinguishing
between user-level andkernel-level threads. On most modern operating sys-
tems it is kernel-level threads—not processes—that are being scheduled by
theoperatingsystem.User-levelthreadsaremanagedbya threadlibrary,and
the kernel is unaware of them. To run on a CPU, user-level threads must ulti-
matelybemappedtoanassociatedkernel-levelthread,althoughthismapping
may be indirect and may use a lightweight process ( LWP). In this section, we
explore scheduling issues involving user-level and kernel-level threads and
offerspecific examplesof schedulingfor Pthreads.
5.4.1 Contention Scope
One distinction between user-level and kernel-level threads lies in how they
are scheduled. On systems implementing the many-to-one (Section 4.3.1)
and many-to-many (Section 4.3.3) model s, the thread library schedules user-
level threads to run on an available LWP. This scheme is known as process-
contention scope (PCS), since competition for the CPUtakes place among
threadsbelongingtothesameprocess.(When wesaythethreadlibrary sched-
ulesuser threads onto available LWPs, we do not mean that the threads are
actually running on aCPUas that further requires the operating system to
schedule the LWP’s kernel thread onto a physical CPUcore.) To decide which"
3,5.4.1 Contention Scope,284,5.4 Thread Scheduling,"5.4 Thread Scheduling 217
Thisschedulingalgorithmgiveshighestprioritytoanyprocesswitha CPU
burst of 8 milliseconds or less. Such a process will quickly get the CPU, finish
itsCPUburst, and go off to its next I/Oburst. Processes that need more than
8 but less than 24 milliseconds are also served quickly, although with lower
priority than shorter processes. Long processes automatically sink to queue
2 and are served in FCFSorder with any CPUcycles left over from queues 0
and 1.
Ingeneral,amultilevelfeedbackqueueschedulerisdefinedbythefollow-
ingparameters:
•The number of queues
•The schedulingalgorithm foreach queue
•The method used to determine when to upgrade a process to a higher-
priorityqueue
•The method used to determine when to demote a process to a lower-
priorityqueue
•Themethodusedtodeterminewhichqueueaprocesswillenterwhenthat
processneedsservice
The definition of a multilevel feedback queue scheduler makes it the most
general CPU-scheduling algorithm. It can be configured to match a specific
system under design. Unfortunately, it is also the most complex algorithm,
sincedefiningthebestschedulerrequiressomemeansbywhichtoselectvalues
forall theparameters.
5.4 Thread Scheduling
In Chapter 4, we introduced threads to the process model, distinguishing
between user-level andkernel-level threads. On most modern operating sys-
tems it is kernel-level threads—not processes—that are being scheduled by
theoperatingsystem.User-levelthreadsaremanagedbya threadlibrary,and
the kernel is unaware of them. To run on a CPU, user-level threads must ulti-
matelybemappedtoanassociatedkernel-levelthread,althoughthismapping
may be indirect and may use a lightweight process ( LWP). In this section, we
explore scheduling issues involving user-level and kernel-level threads and
offerspecific examplesof schedulingfor Pthreads.
5.4.1 Contention Scope
One distinction between user-level and kernel-level threads lies in how they
are scheduled. On systems implementing the many-to-one (Section 4.3.1)
and many-to-many (Section 4.3.3) model s, the thread library schedules user-
level threads to run on an available LWP. This scheme is known as process-
contention scope (PCS), since competition for the CPUtakes place among
threadsbelongingtothesameprocess.(When wesaythethreadlibrary sched-
ulesuser threads onto available LWPs, we do not mean that the threads are
actually running on aCPUas that further requires the operating system to
schedule the LWP’s kernel thread onto a physical CPUcore.) To decide which"
3,5.4.2 Pthread Scheduling,285,5.4.1 Contention Scope,"218 Chapter 5 CPU Scheduling
kernel-levelthreadtoscheduleontoa CPU,thekerneluses system-contention
scope(SCS). Competition for the CPUwithSCSscheduling takes place among
all threads in the system. Systems using the one-to-one model (Section 4.3.2),
such asWindows and Linuxschedule threadsusingonly SCS.
Typically, PCSis done according to priority—the scheduler selects the
runnable thread with the highest priority to run. User-level thread priorities
aresetbytheprogrammerandarenotadjustedbythethreadlibrary,although
some thread libraries may allow the programmer to change the priority of
a thread. It is important to note that PCSwill typically preempt the thread
currently running in favor of a higher-priority thread; however, there is no
guaranteeof timeslicing(Section5.3.3)among threadsof equalpriority.
5.4.2 Pthread Scheduling
We provided a sample POSIXPthread program in Section 4.4.1, along with an
introduction to thread creation with Pthreads. Now, we highlight the POSIX
Pthread APIthatallowsspecifying PCSorSCSduringthreadcreation.Pthreads
identifiesthe following contention scope values:
•PTHREAD
 SCOPE
PROCESS schedulesthreadsusing PCSscheduling.
•PTHREAD
 SCOPE
SYSTEMschedulesthreadsusing SCSscheduling.
On systems implementing the many-to-many model, the
PTHREAD
 SCOPE
PROCESS policy schedules user-level threads onto available
LWPs. The number of LWPs is maintained by the thread library, perhaps using
scheduler activations (Section 4.6.5). The PTHREAD
 SCOPE
SYSTEMscheduling
policywillcreateandbindan LWPforeachuser-levelthreadonmany-to-many
systems,effectivelymapping threadsusingthe one-to-one policy.
ThePthread IPC(InterprocessCommunication)providestwofunctionsfor
setting—and getting—the contention scope policy:
•pthread
 attr
 setscope(pthread
 attr
 t *attr, int scope)
•pthread
 attr
 getscope(pthread
 attr
 t *attr, int *scope)
Thefirstparameterforbothfunctionscontainsapointertotheattributesetfor
thethread.Thesecondparameterforthe pthread
 attr
 setscope() function
is passed either the PTHREAD
 SCOPE
SYSTEMor thePTHREAD
 SCOPE
PROCESS
value, indicating how the contention scope is to be set. In the case of
pthread
 attr
 getscope() , this second parameter contains a pointer to an
intvalue that is set to the current value of the contention scope. If an error
occurs, each of these functions returnsa nonzero value.
In Figure 5.10, we illustrate a Pthread scheduling API.T h ep r o -
gram first determines the existing contention scope and sets it to
PTHREAD
 SCOPE
SYSTEM. It then creates five separate threads that will
run using the SCSscheduling policy. Note that on some systems, only certain
contention scope values are allowed. For example, Linux and mac OSsystems
allow only PTHREAD
 SCOPE
SYSTEM."
2,5.5 Multi-Processor Scheduling,287,5.4 Thread Scheduling,"220 Chapter 5 CPU Scheduling
5.5 Multi-Processor Scheduling
Ourdiscussionthusfarhasfocusedontheproblemsofschedulingthe CPUina
systemwithasingleprocessingcore.Ifmultiple CPUsareavailable, load shar-
ing, where multiple threads may run in parallel, becomes possible, however
scheduling issues become correspondingly more complex. Many possibilities
have been tried; and as we saw with CPUscheduling with a single-core CPU,
thereisno one bestsolution.
Traditionally, the term multiprocessor referred to systems that provided
multiple physical processors, where each processor contained one single-core
CPU. However, the definition of multiprocessor has evolved significantly, and
on modern computing systems, multiprocessor now applies to the following
systemarchitectures:
•Multicore CPUs
•Multithreadedcores
•NUMAsystems
•Heterogeneousmultiprocessing
Here,wediscussseveralconcernsinmultiprocessorschedulinginthecon-
text of these different architectures. In the first three examples we concentrate
onsystemsinwhichtheprocessorsareidentical—homogeneous—intermsof
theirfunctionality.Wecanthenuseanyavailable CPUtorunanyprocessinthe
queue. In the last example we explore a system where the processors are not
identicalintheircapabilities.
5.5.1 Approaches to Multiple-Processor Scheduling
Oneapproachto CPUschedulinginamultiprocessorsystemhasallscheduling
decisions, I/Oprocessing, and other system activities handled by a single
processor — the master server. The other processors execute only user code.
This asymmetric multiprocessing issimplebecauseonlyonecoreaccessesthe
system data structures, reducing the need for data sharing. The downfall of
thisapproachisthemasterserverbecomesapotentialbottleneckwhereoverall
systemperformancemay bereduced.
Thestandardapproachforsupportingmultiprocessorsis symmetric mul-
tiprocessing (SMP), where each processor is self-scheduling. Scheduling pro-
ceeds by having the scheduler for each processor examine the ready queue
and select a thread to run. Note that this provides two possible strategies for
organizing the threadseligibleto bescheduled:
1.Allthreadsmaybe inacommon readyqueue.
2.Each processor mayhaveits own privatequeueof threads.
These two strategies are contrasted in Figure 5.11. If we select the first
option, we have a possible race condition on the shared ready queue and
therefore must ensure that two separate processors do not choose to schedule
the same thread and that threads are not lost from the queue. As discussed in"
3,5.5.1 Approaches to Multiple-Processor Scheduling,287,5.5 Multi-Processor Scheduling,"220 Chapter 5 CPU Scheduling
5.5 Multi-Processor Scheduling
Ourdiscussionthusfarhasfocusedontheproblemsofschedulingthe CPUina
systemwithasingleprocessingcore.Ifmultiple CPUsareavailable, load shar-
ing, where multiple threads may run in parallel, becomes possible, however
scheduling issues become correspondingly more complex. Many possibilities
have been tried; and as we saw with CPUscheduling with a single-core CPU,
thereisno one bestsolution.
Traditionally, the term multiprocessor referred to systems that provided
multiple physical processors, where each processor contained one single-core
CPU. However, the definition of multiprocessor has evolved significantly, and
on modern computing systems, multiprocessor now applies to the following
systemarchitectures:
•Multicore CPUs
•Multithreadedcores
•NUMAsystems
•Heterogeneousmultiprocessing
Here,wediscussseveralconcernsinmultiprocessorschedulinginthecon-
text of these different architectures. In the first three examples we concentrate
onsystemsinwhichtheprocessorsareidentical—homogeneous—intermsof
theirfunctionality.Wecanthenuseanyavailable CPUtorunanyprocessinthe
queue. In the last example we explore a system where the processors are not
identicalintheircapabilities.
5.5.1 Approaches to Multiple-Processor Scheduling
Oneapproachto CPUschedulinginamultiprocessorsystemhasallscheduling
decisions, I/Oprocessing, and other system activities handled by a single
processor — the master server. The other processors execute only user code.
This asymmetric multiprocessing issimplebecauseonlyonecoreaccessesthe
system data structures, reducing the need for data sharing. The downfall of
thisapproachisthemasterserverbecomesapotentialbottleneckwhereoverall
systemperformancemay bereduced.
Thestandardapproachforsupportingmultiprocessorsis symmetric mul-
tiprocessing (SMP), where each processor is self-scheduling. Scheduling pro-
ceeds by having the scheduler for each processor examine the ready queue
and select a thread to run. Note that this provides two possible strategies for
organizing the threadseligibleto bescheduled:
1.Allthreadsmaybe inacommon readyqueue.
2.Each processor mayhaveits own privatequeueof threads.
These two strategies are contrasted in Figure 5.11. If we select the first
option, we have a possible race condition on the shared ready queue and
therefore must ensure that two separate processors do not choose to schedule
the same thread and that threads are not lost from the queue. As discussed in"
3,5.5.2 Multicore Processors,288,5.5.1 Approaches to Multiple-Processor Scheduling,"5.5 Multi-Processor Scheduling 221
T1T1
T1 T1T3T0T0T0
core0core1 corenT0 T2 TnT2T2 ...
... core0core1 coren ...
common ready queue
(a)per-core run queues
(b)
Figure 5.11 Organization of ready queues.
Chapter 6, we could use some form of locking to protect the common ready
queuefromthisracecondition.Lockingwouldbehighlycontended,however,
as all accesses to the queue would require lock ownership, and accessing the
shared queue would likely be a performance bottleneck. The second option
permits each processor to schedule threads from its private run queue and
therefore does not suffer from the possible performance problems associated
with a shared run queue. Thus, it is the most common approach on systems
supporting SMP.Additionally,asdescribedinSect ion5.5.4,havingprivate,per-
processor run queues in fact may lead to more efficient use of cache memory.
There are issues with per-processor run queues—most notably, workloads of
varying sizes. However, as we shall see, balancing algorithms can be used to
equalizeworkloadsamong allprocessors.
Virtually all modernoperating systems support SMP, including Windows,
Linux, and mac OSas well as mobile systems including Android and i OS.I n
theremainderofthissection,wediscussissuesconcerning SMPsystemswhen
designing CPUscheduling algorithms.
5.5.2 Multicore Processors
Traditionally, SMPsystemshaveallowedseveralprocessestoruninparallelby
providing multiple physical processors. However, most contemporary com-
puter hardware now places multiple computing cores on the same physical
chip, resulting in a multicore processor . Each core maintains its architectural
state and thus appears to the operating system to be a separate logical CPU.
SMPsystems that use multicore processors are faster and consume less power
than systemsin which each CPUhas itsown physicalchip.
Multicore processors may complicate scheduling issues. Let’s consider
how this can happen. Researchers have discovered that when a processor
accessesmemory,itspendsasignificantamountoftimewaitingforthedatato
become available. This situation, known as a memory stall , occurs primarily
becausemodernprocessorsoperateatmuchfasterspeedsthanmemory.How-
ever, a memory stall can also occur because of a cache miss (accessing data
that are not in cache memory). Figure 5.12 illustrates a memory stall. In this
scenario, the processor can spend up to 50 percent of its time waiting for data
tobecome available frommemory."
3,5.5.3 Load Balancing,291,5.5.2 Multicore Processors,"224 Chapter 5 CPU Scheduling
processing
corelevel 1
level 2software threads
hardware threads
(logical processors)
Figure 5.15 Two levels of scheduling.
triggerathreadswitch.Whenoneoftheseeventsoccurs,thethread-switching
logic compares the urgency of the two threads and selects the thread with the
highest urgencyvalueto executeonthe processorcore.
Note that the two different levels of scheduling shown in Figure 5.15 are
not necessarily mutually exclusive. In fact, if the operating system scheduler
(thefirstlevel)ismadeawareofthesharingofprocessorresources,itcanmake
more effective scheduling decisions. As an example, assume that a CPUhas
twoprocessingcores,andeachcorehastwohardwarethreads.Iftwosoftware
threadsarerunningonthissystem,theycanberunningeitheronthesamecore
or on separate cores. If they are both scheduled to run on the same core, they
have to share processor resources and thus are likely to proceed more slowly
thaniftheywerescheduledonseparatecores.Iftheoperatingsystemisaware
ofthelevelofprocessorresourcesharing,itcanschedulesoftwarethreadsonto
logical processorsthat donot share resources.
5.5.3 Load Balancing
OnSMPsystems, it is important to keep the workload balanced among all
processorstofullyutilizethebenefitsofhavingmorethanoneprocessor.Oth-
erwise, one or more processors may sit idle while other processors have high
workloads,alongwithreadyqueuesofthreadsawaitingthe CPU.Load balanc-
ingattempts to keep the workload evenly distributed across all processors in
anSMPsystem.Itisimportanttonotethatloadbalancingistypicallynecessary
onlyonsystemswhereeachprocessorhasitsownprivatereadyqueueofeligi-
ble threads to execute. On systems with a common run queue, load balancing
isunnecessary,becauseonceaprocessorbecomesidle,itimmediatelyextracts
a runnable threadfromthe commonreadyqueue.
There are two general approaches to load balancing: push migration and
pull migration. With push migration , a specific task periodically checks the
load on each processor and—if it finds an imbalance—evenly distributes the
load by moving (or pushing) threads from overloaded to idle or less-busy
processors. Pull migration occurs when an idleprocessorpulls a waiting task
fromabusyprocessor.Pushandpullmigrationneednotbemutuallyexclusive
and are, in fact, often implemented in pa rallel on load-balancing systems. For"
3,5.5.4 Processor Affinity,292,5.5.3 Load Balancing,"5.5 Multi-Processor Scheduling 225
example, the Linux CFSscheduler (described in Section 5.7.1) and the ULE
scheduleravailablefor FreeBSDsystemsimplementboth techniques.
The concept of a “balanced load ”may have different meanings. One view
ofabalancedloadmayrequiresimplythatallqueueshaveapproximatelythe
same number of threads. Alternatively, balance may require an equal distri-
bution of thread priorities across all queues. In addition, in certain situations,
neitherofthesestrategiesmaybesufficient.Indeed,theymayworkagainstthe
goalsoftheschedulingalgorithm.(Weleavefurtherconsiderationofthisasan
exercise.)
5.5.4 Processor Afﬁnity
Considerwhathappenstocachememorywhenathreadhasbeenrunningona
specificprocessor.The datamost recen tlyaccessed by the thread populatethe
cache for the processor. Asa result,successive memoryaccessesby the thread
areoftensatisfiedincachememory(knownasa “warmcache ”).Nowconsider
what happens if the thread migrates to another processor—say, due to load
balancing.Thecontentsofcachememorymustbeinvalidatedforthefirstpro-
cessor,andthecacheforthesecondprocessormustberepopulated.Becauseof
thehighcostofinvalidatingandrepopulatingcaches,mostoperatingsystems
withSMPsupporttrytoavoidmigratingathreadfromoneprocessortoanother
and instead attempt to keep a thread running on the same processor and take
advantage of a warm cache. This is known as processor affinit —that is, a
processhas an affinity for the processoron which itiscurrentlyrunning.
The two strategies described in Secti on 5.5.1 for organizing the queue of
threadsavailablefor schedulinghaveimplicationsfor processoraffinity.Ifwe
adopt the approach of a common ready queue, a thread may be selected for
executionby any processor.Thus,ifathreadisscheduledon anew processor,
thatprocessor’scachemustberepopula ted.Withprivate,per-processorready
queues,athreadisalwaysscheduledonthesameprocessorandcan therefore
benefit from the contents of a warm cache. Essentially, per-processor ready
queuesprovideprocessoraffinity for free!
Processor affinity takes several forms. When an operating system has a
policy of attempting to keep a process running on the same processor—but
notguaranteeingthatitwilldoso—wehaveasituationknownas soft affinit .
Here,theoperatingsystemwillattempttokeepaprocessonasingleprocessor,
but it is possible for a process to migrate between processors during load
balancing. In contrast, some systems provide system calls that support hard
affinit,therebyallowingaprocesstospecifyasubsetofprocessorsonwhichit
canrun.Manysystemsprovidebothsoftandhardaffinity.Forexample,Linux
implementssoftaffinity,butitalsoprovidesthe sched
 setaffinity() system
call,whichsupportshardaffinitybyallowingathreadtospecifythesetof CPUs
on which itiseligibleto run.
The main-memory architecture of a system can affect processor affinity
issues as well. Figure 5.16 illustrates an architecture featuring non-uniform
memoryaccess( NUMA)wheretherearetwophysicalprocessorchipseachwith
their own CPUand local memory. Although a system interconnect allows all
CPUsi naNUMAsystem to share one physical address space, a CPUhas faster
accesstoitslocalmemorythantomemorylocaltoanother CPU.Iftheoperating
system’s CPUscheduler and memory-placement algorithms are NUMA -aware"
3,5.5.5 Heterogeneous Multiprocessing,293,5.5.4 Processor Affinity,"226 Chapter 5 CPU Scheduling
CPU
fast access
memoryCPU
fast accessslow access
memory
interconnect
Figure 5.16 NUMA and CPU scheduling.
andworktogether,thenathreadthathasbeenscheduledontoaparticular CPU
can be allocated memory closest to where the CPUresides,thus providing the
threadthefastestpossiblememoryaccess.
Interestingly, load balancing often counteracts the benefits of processor
affinity.Thatis,the benefitofkeepingathreadrunningonthesameprocessor
isthatthethreadcantakeadvantageofitsdatabeinginthatprocessor’scache
memory. Balancing loads by moving a th read from one processor to another
removes this benefit. Similarly, migrat ing a thread between processors may
incurapenaltyon NUMAsystems,whereathreadmaybemovedtoaprocessor
that requires longer memory access times. In other words, there is a natural
tension between load balancing and minimizing memory access times. Thus,
schedulingalgorithmsformodernmulticore NUMAsystemshavebecomequite
complex.InSection5.7.1,weexaminetheLinux CFSschedulingalgorithmand
explorehow itbalances thesecompeting goals.
5.5.5 Heterogeneous Multiprocessing
In the examples we have discussed so far, all processors are identical in terms
of their capabilities, thus allowing any thread to run on any processing core.
Theonlydifferencebeingthatmemoryaccesstimesmayvarybaseduponload
balancing and processoraffinity policies,as wellas on NUMAsystems.
Although mobile systems now include multicore architectures, some sys-
tems are now designed using cores that run the same instruction set, yet vary
in terms of their clock speed and power management, including the ability to
adjust the power consumption of a core to the point of idling the core. Such
systemsareknown as heterogeneous multiprocessing (HMP). Notethisisnot
a form of asymmetric multiprocessing as described in Section 5.5.1 as both
systemandusertaskscanrunonanycore.Rather,theintentionbehind HMPis
tobettermanagepowerconsumptionbyassigningtaskstocertaincoresbased
upon the specificdemandsof the task.
ForARMprocessors that support it, this type of architecture is known
asbig. LITTLEwhere higher-peformance bigcores are combined with energy
efficient LITTLEcores. Bigcores consume greater energy and therefore should"
2,5.6 Real-Time CPU Scheduling,294,5.5 Multi-Processor Scheduling,"5.6 Real-Time CPU Scheduling 227
only be used for short periods of time. Likewise, littlecores use less energy
andcan thereforebe usedfor longerperiods.
There are severaladvantages to this approach. By combining a number of
slower cores with faster ones, a CPUscheduler can assign tasks that do not
require high performance, but may need to run for longer periods, (such as
background tasks) to littlecores, thereby helping to preservea batterycharge.
Similarly, interactive applications wh ich require more processing power, but
may run for shorter durations, can be assigned to big cores. Additionally, if
the mobile device is in a power-saving m ode, energy-intensive big cores can
bedisabledandthesystemcanrelysolelyonenergy-efficientlittlecores.Win-
dows10 supports HMPschedulingby allowing a threadto selecta scheduling
policythat bestsupportsitspower managementdemands.
5.6 Real-Time CPU Scheduling
CPUscheduling for real-time operating systems involves special issues. In
general,wecandistinguishbetweensoftreal-timesystemsandhardreal-time
systems. Soft real-time systems provide no guarantee as to when a critical
real-timeprocesswill bescheduled.Theyguarantee only that the process will
be given preference over noncritical processes. Hard real-time systems have
stricterrequirements.Ataskmustbeservicedbyitsdeadline;serviceafterthe
deadlinehasexpiredisthesameasnoserviceatall.Inthissection,weexplore
several issues related to process scheduling in both soft and hard real-time
operatingsystems.
5.6.1 Minimizing Latency
Considertheevent-drivennatureofareal-timesystem.Thesystemistypically
waiting for an event in real time to occur. Events may arise either in software
—as when a timer expires—or in hardware—as when a remote-controlled
vehicle detects that it is approaching an obstruction. When an event occurs,
the system must respond to and service it as quickly as possible. We refer to
event latency astheamountoftimethatelapsesfromwhenaneventoccursto
whenitisserviced(Figure5.17).
t1 t0event latencyevent E first occurs
real-time system responds to E
Time
Figure 5.17 Event latency."
3,5.6.1 Minimizing Latency,294,5.6 Real-Time CPU Scheduling,"5.6 Real-Time CPU Scheduling 227
only be used for short periods of time. Likewise, littlecores use less energy
andcan thereforebe usedfor longerperiods.
There are severaladvantages to this approach. By combining a number of
slower cores with faster ones, a CPUscheduler can assign tasks that do not
require high performance, but may need to run for longer periods, (such as
background tasks) to littlecores, thereby helping to preservea batterycharge.
Similarly, interactive applications wh ich require more processing power, but
may run for shorter durations, can be assigned to big cores. Additionally, if
the mobile device is in a power-saving m ode, energy-intensive big cores can
bedisabledandthesystemcanrelysolelyonenergy-efficientlittlecores.Win-
dows10 supports HMPschedulingby allowing a threadto selecta scheduling
policythat bestsupportsitspower managementdemands.
5.6 Real-Time CPU Scheduling
CPUscheduling for real-time operating systems involves special issues. In
general,wecandistinguishbetweensoftreal-timesystemsandhardreal-time
systems. Soft real-time systems provide no guarantee as to when a critical
real-timeprocesswill bescheduled.Theyguarantee only that the process will
be given preference over noncritical processes. Hard real-time systems have
stricterrequirements.Ataskmustbeservicedbyitsdeadline;serviceafterthe
deadlinehasexpiredisthesameasnoserviceatall.Inthissection,weexplore
several issues related to process scheduling in both soft and hard real-time
operatingsystems.
5.6.1 Minimizing Latency
Considertheevent-drivennatureofareal-timesystem.Thesystemistypically
waiting for an event in real time to occur. Events may arise either in software
—as when a timer expires—or in hardware—as when a remote-controlled
vehicle detects that it is approaching an obstruction. When an event occurs,
the system must respond to and service it as quickly as possible. We refer to
event latency astheamountoftimethatelapsesfromwhenaneventoccursto
whenitisserviced(Figure5.17).
t1 t0event latencyevent E first occurs
real-time system responds to E
Time
Figure 5.17 Event latency."
3,5.6.2 Priority-Based Scheduling,296,5.6.1 Minimizing Latency,"5.6 Real-Time CPU Scheduling 229
response to event
real-time 
process 
executionevent
conflicts
timedispatch response interval
dispatch latencyprocess made 
available interrupt
processing
Figure 5.19 Dispatch latency.
tasks with immediate access to the CPUmandates that real-time operating
systemsminimizethislatencyaswell.Themosteffectivetechniqueforkeeping
dispatch latency low is to provide preemptive kernels. For hard real-time
systems,dispatchlatency istypicallymeasuredinseveralmicroseconds.
In Figure 5.19, we diagram the makeup of dispatch latency. The conflic
phaseof dispatchlatency has two components:
1.Preemptionof any processrunning in the kernel
2.Releaseby low-priorityprocessesofresourcesneededby a high-priority
process
Following the conflict phase, the dispatch phase schedules the high-priority
processonto anavailable CPU.
5.6.2 Priority-Based Scheduling
Themostimportantfeatureofareal-timeoperatingsystemistorespondimme-
diately to a real-time process as soon as that process requires the CPU.A sa
result,the schedulerfor a real-timeoperating systemmust supporta priority-
based algorithm with preemption. Recall that priority-based scheduling algo-
rithmsassigneachprocessaprioritybasedonitsimportance;moreimportant
tasks are assigned higher priorities th an those deemed less important. If the
scheduler also supports preemption, a process currently running on the CPU
willbepreemptedifa higher-priorityprocessbecomesavailableto run.
Preemptive,priority-basedschedulingalgorithmsarediscussedindetailin
Section 5.3.4, and Section 5.7 presents examples of the soft real-time schedul-
ing features of the Linux, Windows, and Solaris operating systems. Each of
these systems assigns real-time processe s the highest scheduling priority. For"
3,5.6.3 Rate-Monotonic Scheduling,297,5.6.2 Priority-Based Scheduling,"230 Chapter 5 CPU Scheduling
period 1 period 2 period 3Timeppp
d d d
tt t
Figure 5.20 Periodic task.
example,Windowshas32differentprioritylevels.Thehighestlevels—priority
values 16 to 31—are reserved for real-time processes. Solaris and Linux have
similarprioritizationschemes.
Note that providing a preemptive, priority-based scheduler only guaran-
teessoftreal-timefunctionality.Hardreal-timesystemsmustfurtherguarantee
thatreal-timetaskswillbeservicedina ccordwiththeirdeadlinerequirements,
and making such guarantees requires a dditional scheduling features. In the
remainderofthissection,wecoverschedulingalgorithmsappropriateforhard
real-timesystems.
Before we proceed with the details of the individual schedulers, however,
wemustdefinecertaincharacteristicsoftheprocessesthataretobescheduled.
First, the processes are considered periodic . That is, they require the CPUat
constant intervals (periods). Once a periodic process has acquired the CPU,i t
has a fixed processingtime t, a deadline dby which itmust be servicedby the
CPU,andaperiod p.Therelationshipoftheprocessingtime,thedeadline,and
the periodcan be expressedas 0 ≤t≤d≤p.Th e rateof a periodictask is 1 ∕p.
Figure5.20illustratestheexecutionofaperiodicprocessovertime.Schedulers
cantakeadvantageofthesecharacteristicsandassignprioritiesaccordingtoa
process’s deadlineor raterequirements.
Whatisunusualaboutthisformofschedulingisthataprocessmayhaveto
announce its deadline requirements to the scheduler. Then, using a technique
known as an admission-control algorithm, the scheduler does one of two
things.Iteitheradmitstheprocess,guar anteeingthattheprocesswillcomplete
ontime,orrejectstherequestasimpossibleifitcannotguaranteethatthetask
willbe servicedby itsdeadline.
5.6.3 Rate-Monotonic Scheduling
The rate-monotonic scheduling algorithm schedules periodic tasks using a
static priority policy with preemption. If a lower-priority process is run-
ning and a higher-priority process becomes available to run, it will preempt
the lower-priority process. Upon entering the system, each periodic task is
assigned a priority inversely based on i ts period. The shorter the period, the
higher the priority; the longer the period, the lower the priority. The rationale
behind this policy is to assign a higher priority to tasks that require the CPU
moreoften.Furthermore,rate-monotonicschedulingassumesthattheprocess-"
3,5.6.4 Earliest-Deadline-First Scheduling,299,5.6.3 Rate-Monotonic Scheduling,"232 Chapter 5 CPU Scheduling
0 1 02 03 04 05 06 07 08 0 1 2 0 1 3 0 1 4 0 1 5 0 1 6 0 90 100 110P1
P1P2
P1 P2deadlines P1
P2P1, P2
Figure 5.23 Missing deadlines with rate-monotonic scheduling.
scheduling would assign process P1a higher priority, as it has the shorter
period. The total CPUutilization of the two processes is (25 ∕50)+(35∕80)=
0.94, and it therefore seems logical that the two processes could be scheduled
and still leave the CPUwith 6 percent available time. Figure 5.23 shows the
scheduling of processes P1and P2. Initially, P1runs until it completes its CPU
b u r s ta tt i m e2 5 .P r o c e s s P2then begins running and runs until time 50, when
itispreemptedby P1.Atthispoint, P2stillhas10millisecondsremaininginits
CPUburst. Process P1runs until time 75; consequently, P2 finishes its burst at
time85,afterthe deadlinefor completion ofitsCPU burstat time80.
Despite being optimal, then, rate-monotonic scheduling has a limitation:
CPUutilization is bounded, and it is not always possible to maximize CPU
resourcesfully.The worst-case CPUutilizationfor scheduling Nprocessesis
N(21∕N−1).
With one process in the system, CPUutilization is 100 percent, but it falls to
approximately69percentasthenumberofprocessesapproachesinfinity.With
two processes, CPUutilization isbounded atabout 83 percent.Combined CPU
utilization for the two processes scheduled in Figure 5.21 and Figure 5.22 is
75 percent; therefore, the rate-monotonic scheduling algorithm is guaranteed
to schedule them so that they can meet their deadlines. For the two processes
scheduled in Figure 5.23, combined CPUutilization is approximately 94 per-
cent; therefore, rate-monotonic scheduling cannot guarantee that they can be
scheduledso that theymeettheirdeadlines.
5.6.4 Earliest-Deadline-First Scheduling
Earliest-deadline-firs (EDF)schedulingassignsprioritiesdynamicallyaccord-
ing to deadline. The earlier the deadline, the higher the priority; the later the
deadline,thelowerthepriority.Underthe EDFpolicy,whenaprocessbecomes
runnable, itmustannounce itsdeadlinerequirementstothe system.Priorities
mayhavetobeadjustedtoreflectthedeadlineofthe newlyrunnable process.
Note how this differs from rate-monotonic scheduling, where priorities are
fixed.
To illustrate EDFscheduling, we again schedule the processes shown in
Figure5.23,whichfailedtomeetdeadlinerequirementsunderrate-monotonic
scheduling. Recall that P1has values of p1=50 and t1=25 and that P2has
values of p2=80 and t2=35. The EDFscheduling of these processes is shown
inFigure5.24.Process P1hastheearliestdeadline,soitsinitialpriorityishigher
than that of process P2.P r o c e s s P2begins running at the end of the CPUburst
forP1. However, whereas rate-monotonic scheduling allows P1to preempt P2"
3,5.6.5 Proportional Share Scheduling,300,5.6.4 Earliest-Deadline-First Scheduling,"5.6 Real-Time CPU Scheduling 233
0 1 02 03 04 05 06 07 08 0 1 2 0 1 3 0 1 4 0 1 5 0 1 6 0 90 100 110P1
P1 P1P2
P1 P2deadlines P2 P1 P1
P2 P2
Figure 5.24 Earliest-deadline-first scheduling.
at the beginning of its next period at time 50, EDFscheduling allows process
P2to continue running. P2now has a higher priority than P1because its next
deadline (at time 80) is earlier than that of P1(at time 100). Thus, both P1and
P2meet their first deadlines. Process P1again begins running at time 60 and
completes its second CPUburst at time 85, also meeting its second deadlineat
time 100. P2begins running at this point, only to be preempted by P1at the
start of its next period at time 100. P2is preempted because P1has an earlier
deadline(time150)than P2(time160). Attime125, P1completesits CPUburst
and P2resumes execution, finishing at time 145 and meeting its deadline as
well.Thesystemisidleuntiltime150,when P1isscheduledtorunonceagain.
Unliketherate-monotonicalgorithm, EDFschedulingdoesnotrequirethat
processes be periodic, nor must a process require a constant amount of CPU
time per burst. The only requirement is that a process announce its deadline
to the scheduler when it becomes runnable. The appeal of EDFscheduling is
that itistheoreticallyoptimal—theoreti cally,it canscheduleprocessesso that
each process can meet its deadline requirements and CPUutilization will be
100 percent. In practice, however, it is impossible to achieve this level of CPU
utilizationduetothecostofcontextswit chingbetweenprocessesandinterrupt
handling.
5.6.5 Proportional Share Scheduling
Proportional share schedulersoperatebyallocating Tsharesamongallappli-
cations. An application can receive Nshares of time, thus ensuring that the
application will have N∕Tof the total processor time. As an example, assume
thatatotalof T=100sharesistobedividedamong threeprocesses, A,B,and
C.Aisassigned50shares, Bisassigned15shares,and Cisassigned20shares.
Thisscheme ensuresthat Awillhave50 percentoftotal processortime, Bwill
have15 percent,and Cwillhave20 percent.
Proportional share schedulers must work in conjunction with an
admission-controlpolicytoguaranteeth atanapplicationreceivesitsallocated
shares of time. An admission-control policy will admit a client requesting
a particular number of shares only if sufficient shares are available. In our
c u r r e n te x a m p l e ,w eh a v ea l l o c a t e d5 0 +15+20=85 shares of the total of
100 shares. If a new process Drequested 30 shares, the admission controller
would deny Dentry intothe system.
5.6.6 POSIX Real-Time Scheduling
ThePOSIXstandard also provides extensions for real-time computing—
POSIX.1b.Here,wecoversomeofthe POSIX API relatedtoschedulingreal-time
threads. POSIXdefinestwo schedulingclassesfor real-timethreads:"
3,5.6.6 POSIX Real-Time Scheduling,300,5.6.5 Proportional Share Scheduling,"5.6 Real-Time CPU Scheduling 233
0 1 02 03 04 05 06 07 08 0 1 2 0 1 3 0 1 4 0 1 5 0 1 6 0 90 100 110P1
P1 P1P2
P1 P2deadlines P2 P1 P1
P2 P2
Figure 5.24 Earliest-deadline-first scheduling.
at the beginning of its next period at time 50, EDFscheduling allows process
P2to continue running. P2now has a higher priority than P1because its next
deadline (at time 80) is earlier than that of P1(at time 100). Thus, both P1and
P2meet their first deadlines. Process P1again begins running at time 60 and
completes its second CPUburst at time 85, also meeting its second deadlineat
time 100. P2begins running at this point, only to be preempted by P1at the
start of its next period at time 100. P2is preempted because P1has an earlier
deadline(time150)than P2(time160). Attime125, P1completesits CPUburst
and P2resumes execution, finishing at time 145 and meeting its deadline as
well.Thesystemisidleuntiltime150,when P1isscheduledtorunonceagain.
Unliketherate-monotonicalgorithm, EDFschedulingdoesnotrequirethat
processes be periodic, nor must a process require a constant amount of CPU
time per burst. The only requirement is that a process announce its deadline
to the scheduler when it becomes runnable. The appeal of EDFscheduling is
that itistheoreticallyoptimal—theoreti cally,it canscheduleprocessesso that
each process can meet its deadline requirements and CPUutilization will be
100 percent. In practice, however, it is impossible to achieve this level of CPU
utilizationduetothecostofcontextswit chingbetweenprocessesandinterrupt
handling.
5.6.5 Proportional Share Scheduling
Proportional share schedulersoperatebyallocating Tsharesamongallappli-
cations. An application can receive Nshares of time, thus ensuring that the
application will have N∕Tof the total processor time. As an example, assume
thatatotalof T=100sharesistobedividedamong threeprocesses, A,B,and
C.Aisassigned50shares, Bisassigned15shares,and Cisassigned20shares.
Thisscheme ensuresthat Awillhave50 percentoftotal processortime, Bwill
have15 percent,and Cwillhave20 percent.
Proportional share schedulers must work in conjunction with an
admission-controlpolicytoguaranteeth atanapplicationreceivesitsallocated
shares of time. An admission-control policy will admit a client requesting
a particular number of shares only if sufficient shares are available. In our
c u r r e n te x a m p l e ,w eh a v ea l l o c a t e d5 0 +15+20=85 shares of the total of
100 shares. If a new process Drequested 30 shares, the admission controller
would deny Dentry intothe system.
5.6.6 POSIX Real-Time Scheduling
ThePOSIXstandard also provides extensions for real-time computing—
POSIX.1b.Here,wecoversomeofthe POSIX API relatedtoschedulingreal-time
threads. POSIXdefinestwo schedulingclassesfor real-timethreads:"
2,5.7 Operating-System Examples,301,5.6 Real-Time CPU Scheduling,"234 Chapter 5 CPU Scheduling
•SCHED
 FIFO
•SCHED
 RR
SCHED
 FIFOschedulesthreadsaccordingtoafirst-come,first-servedpolicy
using a FIFOqueueas outlinedin Section5.3.1. However,thereis no time slic-
ing among threads of equal priority. Therefore, the highest-priority real-time
thread at the front of the FIFOqueue will be granted the CPUuntil it termi-
natesorblocks. SCHED
 RRusesaround-robinpolicy.Itissimilarto SCHED
 FIFO
except that it provides time slicing among threads of equal priority. POSIX
provides an additional scheduling class— SCHED
 OTHER—but its implemen-
tation is undefined and system specific; it may behave differently on different
systems.
ThePOSIX API specifiesthefollowingtwofunctionsforgettingandsetting
thescheduling policy:
•pthread
 attr
 getschedpolicy(pthread
 attr
 t *attr, int
*policy)
•pthread
 attr
 setschedpolicy(pthread
 attr
 t *attr, int
policy)
The first parameter to both functions is a pointer to the set of attributes for
the thread. The second parameter is either (1) a pointer to an integer that is
set to the current scheduling policy (for pthread
 attr
 getsched
 policy() )
or (2) an integer value ( SCHED
 FIFO,SCHED
 RR,o rSCHED
 OTHER)f o rt h e
pthread
 attr
 setsched
 policy() function. Both functions return nonzero
valuesifanerroroccurs.
In Figure 5.25, we illustrate a POSIXPthread program using this API.T h i s
program first determines the current scheduling policy and then sets the
schedulingalgorithm to SCHED
 FIFO.
5.7 Operating-System Examples
We turn next to a description of the scheduling policies of the Linux, Win-
dows, and Solaris operating systems. It is important to note that we use the
term process scheduling in a general sense here. In fact, we are describing the
scheduling of kernel threads with Solaris and Windows systems and of tasks
with the Linuxscheduler.
5.7.1 Example: Linux Scheduling
ProcessschedulinginLinuxhashadaninterestinghistory.PriortoVersion2.5,
the Linux kernel ran a variation of the traditional UNIXscheduling algorithm.
However, as this algorithm was not designed with SMPsystems in mind, it
did not adequately support systems with multiple processors. In addition, it
resultedinpoorperformanceforsystemswithalargenumberofrunnablepro-
cesses.WithVersion2.5ofthekernel,theschedulerwasoverhauledtoinclude
a scheduling algorithm—known as O(1)—that ran in constant time regard-
less of the number of tasks in the system. The O(1) scheduler also provided"
3,5.7.1 Example: Linux Scheduling,301,5.7 Operating-System Examples,"234 Chapter 5 CPU Scheduling
•SCHED
 FIFO
•SCHED
 RR
SCHED
 FIFOschedulesthreadsaccordingtoafirst-come,first-servedpolicy
using a FIFOqueueas outlinedin Section5.3.1. However,thereis no time slic-
ing among threads of equal priority. Therefore, the highest-priority real-time
thread at the front of the FIFOqueue will be granted the CPUuntil it termi-
natesorblocks. SCHED
 RRusesaround-robinpolicy.Itissimilarto SCHED
 FIFO
except that it provides time slicing among threads of equal priority. POSIX
provides an additional scheduling class— SCHED
 OTHER—but its implemen-
tation is undefined and system specific; it may behave differently on different
systems.
ThePOSIX API specifiesthefollowingtwofunctionsforgettingandsetting
thescheduling policy:
•pthread
 attr
 getschedpolicy(pthread
 attr
 t *attr, int
*policy)
•pthread
 attr
 setschedpolicy(pthread
 attr
 t *attr, int
policy)
The first parameter to both functions is a pointer to the set of attributes for
the thread. The second parameter is either (1) a pointer to an integer that is
set to the current scheduling policy (for pthread
 attr
 getsched
 policy() )
or (2) an integer value ( SCHED
 FIFO,SCHED
 RR,o rSCHED
 OTHER)f o rt h e
pthread
 attr
 setsched
 policy() function. Both functions return nonzero
valuesifanerroroccurs.
In Figure 5.25, we illustrate a POSIXPthread program using this API.T h i s
program first determines the current scheduling policy and then sets the
schedulingalgorithm to SCHED
 FIFO.
5.7 Operating-System Examples
We turn next to a description of the scheduling policies of the Linux, Win-
dows, and Solaris operating systems. It is important to note that we use the
term process scheduling in a general sense here. In fact, we are describing the
scheduling of kernel threads with Solaris and Windows systems and of tasks
with the Linuxscheduler.
5.7.1 Example: Linux Scheduling
ProcessschedulinginLinuxhashadaninterestinghistory.PriortoVersion2.5,
the Linux kernel ran a variation of the traditional UNIXscheduling algorithm.
However, as this algorithm was not designed with SMPsystems in mind, it
did not adequately support systems with multiple processors. In addition, it
resultedinpoorperformanceforsystemswithalargenumberofrunnablepro-
cesses.WithVersion2.5ofthekernel,theschedulerwasoverhauledtoinclude
a scheduling algorithm—known as O(1)—that ran in constant time regard-
less of the number of tasks in the system. The O(1) scheduler also provided"
3,5.7.2 Example: Windows Scheduling,306,5.7.1 Example: Linux Scheduling,"5.7 Operating-System Examples 239
a larger system-level domain would combine separate processor-level NUMA
nodes.
Thegeneralstrategybehind CFSistobalanceloadswithindomains,begin-
ning at the lowest level of the hierarchy. Using Figure 5.27 as an example,
initially a thread would only migrate between cores on the same domain
(i.e. within domain0ordomain1.) Load balancing at the next level would occur
between domain0anddomain1.CFSisreluctanttomigratethreadsbetweensep-
arateNUMAnodes if a thread would be moved farther from its local memory,
and such migration would only occur under severe load imbalances. As a
general rule, if the overall system is busy, CFSwill not load-balance beyond
the domain local to each core to avoid the memory latency penaltiesof NUMA
systems.
5.7.2 Example: Windows Scheduling
Windows schedules threads using a priority-based, preemptive scheduling
algorithm. The Windows scheduler ensures that the highest-priority thread
will always run. The portion of the Win dows kernel that handles scheduling
is called the dispatcher . A thread selected to run by the dispatcher will run
until it is preempted by a higher-priority thread, until it terminates, until its
timequantumends,oruntilitcallsablocking systemcall,such as for I/O.Ifa
higher-priority real-time thread becomes ready while a lower-priority thread
isrunning,thelower-prioritythreadwillbepreempted.Thispreemptiongives
a real-time thread preferential access to the CPUwhen the thread needs such
access.
The dispatcher uses a 32-level priority scheme to determine the order of
thread execution. Priorities are divided into two classes. The variable class
containsthreadshavingprioritiesfrom1to15,andthe real-time class contains
threadswithprioritiesrangingfrom16to31.(Thereisalsoathreadrunningat
priority0thatisusedfor memorymanagement.)Thedispatcherusesaqueue
for each scheduling priority and traverses the set of queues from highest to
lowest until it finds a thread that is ready to run. If no ready thread is found,
thedispatcherwillexecutea specialthreadcalledthe idle thread .
There is a relationship between the numeric priorities of the Windows
kernel and the Windows API. The Windows APIidentifies the following six
priorityclassesto which a processcan belong:
•IDLE
PRIORITY
 CLASS
•BELOW
 NORMAL
 PRIORITY
 CLASS
•NORMAL
 PRIORITY
 CLASS
•ABOVE
 NORMAL
 PRIORITY
 CLASS
•HIGH
PRIORITY
 CLASS
•REALTIME
 PRIORITY
 CLASS
Processes are typically members of the NORMAL
 PRIORITY
 CLASS.Ap r o c e s s
belongs to this class unless the parent of the process was a member of the
IDLE
PRIORITY
 CLASSor unless another class was specified when the process
was created. Additionally, the priority class of a process can be altered with"
3,5.7.3 Example: Solaris Scheduling,309,5.7.2 Example: Windows Scheduling,"242 Chapter 5 CPU Scheduling
(Section4.2)onmulticoreprocessors. ConcRTprovidesauser-modescheduler
together with facilities for decompos ing programs into tasks, which can then
be scheduledon the availableprocessingcores.
Windows also supports scheduling on multiprocessor systems as
described in Section 5.5 by attempting to schedule a thread on the most
optimalprocessingcoreforthatthread,whichincludesmaintainingathread’s
preferredaswellasmostrecentprocessor.OnetechniqueusedbyWindowsis
to create sets of logical processors (known as SMT sets). On a hyper-threaded
SMTsystem, hardware threads belonging to the same CPUcore would also
belong to the same SMTset.Logical processorsare numbered,beginning from
0. As an example, a dual-threaded/quad-core system would contain eight
logicalprocessors,consisting of the four SMTsets: {0, 1},{2, 3},{4, 5},a n d {6,
7}. To avoid cache memory access penalites highlighted in Section 5.5.4, the
scheduler attempts to maintain a thread running on logical processors within
the same SMTset.
To distribute loads across different logical processors, each thread is
assigned an ideal processor , which is a number representing a thread’s
preferred processor. Each process has an initial seed value identifying the
idealCPUfor a thread belonging to that process. This seed is incremented for
each new thread created by that process, thereby distributing the load across
different logical processors. On SMTsystems, the increment for the next ideal
processor is in the next SMTset. For example, on a dual-threaded/quad-core
system,theidealprocessorsforthreadsinaspecificprocesswouldbeassigned
0,2,4,6,0,2,....Toavoidthesituationwherbythefirstthreadforeachprocess
is assigned processor 0, processes are a ssigned different seed values, thereby
distributing the load of threads across all physical processing cores in the
system. Continuing our example from above, if the seed for a second process
were 1, the ideal processors would be assigned in the order 1, 3, 5, 7, 1, 3, and
so forth.
5.7.3 Example: Solaris Scheduling
Solaris uses priority-based thread scheduling. Each thread belongs to one of
sixclasses:
1.Time sharing ( TS)
2.Interactive( IA)
3.Real time( RT)
4.System( SYS)
5.Fair share ( FSS)
6.Fixedpriority( FP)
Within each class there are different priorities and different scheduling algo-
rithms.
The default scheduling class for a proc ess is time sharing. The scheduling
policyforthetime-sharingclassdynami callyaltersprioritiesandassignstime
slices of different lengths using a multilevelfeedback queue. By default, there
is an inverse relationship between prio rities and time slices. The higher the"
2,5.8 Algorithm Evaluation,311,5.7 Operating-System Examples,"244 Chapter 5 CPU Scheduling
•Return from sleep .Thepriorityofathreadthatisreturningfromsleeping
(suchasfromwaitingfor I/O).Asthetableillustrates,when I/Oisavailable
forawaitingthread,itspriorityisboostedtobetween50and59,support-
ing the scheduling policy of providing good response time for interactive
processes.
Threads in the real-time class are given the highest priority. A real-time
process will run before a process in any other class. This assignment allows
a real-time process to have a guaranteed response from the system within
a bounded period of time. In general, however, few processes belong to the
real-timeclass.
Solaris uses the system class to run kernel threads, such as the scheduler
andpagingdaemon.Oncethepriorityo fasystemthreadisestablished,itdoes
notchange.Thesystemclassisreservedforkerneluse(userprocessesrunning
inkernelmodearenot inthe systemclass).
The fixed-priority and fair-share classes were introduced with Solaris 9.
Threads in the fixed-priority class have the same priority range as those in
the time-sharing class; however, their priorities are not dynamically adjusted.
The fair-share class uses CPU sharesinstead of priorities to make scheduling
decisions. CPUshares indicate entitlement to available CPUresources and are
allocatedto asetof processes(known asa project).
Each scheduling class includes a set of priorities. However, the scheduler
convertstheclass-specificprioritiesint oglobalprioritiesandselectsthethread
with the highest global priority to run. The selected thread runs on the CPU
untilit(1)blocks,(2)usesitstimeslice,or(3)ispreemptedbyahigher-priority
thread.Iftherearemultiplethreadswiththesamepriority,thescheduleruses
a round-robin queue. Figure 5.30 illustrates how the six scheduling classes
relate to one another and how they map to global priorities. Notice that the
kernel maintains ten threads for servicing interrupts. These threads do not
belong to any scheduling class and execute at the highest priority (160–169).
Asmentioned,Solarishastraditionallyusedthemany-to-manymodel(Section
4.3.3) but switched to the one-to-one model (Section 4.3.2) beginning with
Solaris9.
5.8 Algorithm Evaluation
How do we select a CPU-scheduling algorithm for a particular system? As we
saw in Section 5.3, there are many scheduling algorithms, each with its own
parameters.Asa result,selectingan algorithmcan bedifficult.
The first problem is defining the criteria to be used in selecting an algo-
rithm. As we saw in Section 5.2, criteria are often defined in terms of CPU
utilization, response time, or throughput. To select an algorithm, we must
firstdefinetherelativeimportanceoftheseelements.Ourcriteriamayinclude
severalmeasures,suchas these:
•Maximizing CPUutilization under the constraint that the maximum
responsetimeis300 milliseconds"
3,5.8.1 Deterministic Modeling,312,5.8 Algorithm Evaluation,"5.8 Algorithm Evaluation 245
interrupt threads169highest
lowestfirstscheduling
orderglobal
priority
last160
159
100
60
59
099realtime (RT) threads
system (SYS) threads
fair share (FSS) threads
fixed priority (FX) threads
timeshare (TS) threads
interactive (IA) threads
Figure 5.30 Solaris scheduling.
•Maximizingthroughputsuchthatturnaroundtimeis(onaverage)linearly
proportional tototal executiontime
Oncetheselectioncriteriahavebeendefined,wewanttoevaluatethealgo-
rithmsunderconsideration.We nextdescribethevariousevaluationmethods
we can use.
5.8.1 Deterministic Modeling
Onemajorclassofevaluationmethodsis analytic evaluation .Analyticevalu-
ationusesthegivenalgorithmandthesystemworkloadtoproduceaformula
ornumber to evaluatethe performance of the algorithmfor that workload.
Deterministic modeling is one type of analytic evaluation. This method
takes a particular predetermined workload and defines the performance of
each algorithm for that workload. For example, assume that we have the
workload shown below. All five processes arrive at time 0, in the order given,
with the length ofthe CPUburst giveninmilliseconds:"
3,5.8.2 Queueing Models,314,5.8.1 Deterministic Modeling,"5.8 Algorithm Evaluation 247
measuretheprogram’sprocessingrequirementsexactly,wemaybeabletouse
deterministic modeling to select a scheduling algorithm. Furthermore, over a
set of examples, deterministic modelin g may indicate trends that can then be
analyzed and proved separately. For example, it can be shown that, for the
environment described (all processes and their times available at time 0), the
SJFpolicy willalways resultinthe minimumwaiting time.
5.8.2 Queueing Models
On many systems, the processes that are run vary from day to day, so there is
nostaticsetofprocesses(ortimes)tous efordeterministicmodeling.Whatcan
be determined, however, is the distribution of CPUandI/Obursts. These dis-
tributions can be measured and then approximated or simply estimated. The
resultisamathematicalformuladescribingtheprobabilityofaparticular CPU
burst.Commonly,thisdistributionisexponentialandisdescribedbyitsmean.
Similarly, we can describe the distribution of times when processes arrive in
the system (the arrival-time distribution). From these two distributions, it is
possible to compute the average throughput, utilization, waiting time, and so
on for mostalgorithms.
Thecomputersystemisdescribedasanetworkofservers.Eachserverhas
aqueueofwaitingprocesses.The CPUisaserverwithitsreadyqueue,asisthe
I/Osystemwithitsdevicequeues.Knowingarrivalratesandservicerates,we
can compute utilization, average queue length, average wait time, and so on.
Thisareaof studyiscalled queueing-network analysis .
Asanexample,let nbetheaveragelong-termqueuelength(excludingthe
process being serviced), let Wbe the average waiting time in the queue, and
letλbe the average arrival rate for new processes in the queue (such as three
processes per second). We expect that during the time Wthat a process waits,
λ×Wnewprocesseswillarriveinthequeue.Ifthesystemisinasteadystate,
then the number of processes leaving the queue must be equal to the number
ofprocessesthat arrive.Thus,
n=λ×W.
This equation, known as Little’s formula , is particularly useful because it is
valid for any scheduling algorithm and arrival distribution. For example n
could be the number of customersin a store.
We can use Little’s formula to compute one of the three variables if we
know the other two. For example, if we know that 7 processes arrive every
second (on average) and that there are normally 14 processes in the queue,
thenwe can computetheaveragewaiting timeperprocessas 2seconds.
Queueing analysis can be useful in comparing scheduling algorithms, but
it also has limitations. At the moment, the classes of algorithms and distribu-
tions that can be handled are fairly limited. The mathematics of complicated
algorithms and distributions can be difficult to work with. Thus, arrival and
servicedistributionsareoftendefinedinmathematicallytractable—but unre-
alistic—ways. It is also generally necessary to make a number of indepen-
dentassumptions, which may not be accurate. As a resultof these difficulties,
queueingmodelsareoftenonlyapproximationsofrealsystems,andtheaccu-
racy ofthe computedresultsmay bequestionable."
3,5.8.3 Simulations,315,5.8.2 Queueing Models,"248 Chapter 5 CPU Scheduling
5.8.3 Simulations
To get a moreaccurate evaluationof scheduling algorithms,we can use simu-
lations. Running simulations involvesprogramming a modelof the computer
system. Software data structures represent the major components of the sys-
tem.Thesimulatorhasavariablerepresentingaclock.Asthisvariable’svalue
is increased, the simulator modifies the system state to reflect the activities
of the devices, the processes, and the sc heduler. As the simulation executes,
statisticsthat indicatealgorithmperformance aregatheredand printed.
Thedatatodrivethesimulationcanbegeneratedinseveralways.Themost
common method uses a random-number generator that is programmed to
generateprocesses, CPUbursttimes,arrivals,departures,andsoon,according
to probability distributions. The distributions can be defined mathematically
(uniform,exponential,Poisson)orempi rically.Ifadistributionistobedefined
empirically, measurements of the actual system under study are taken. The
resultsdefinethedistributionofeventsintherealsystem;thisdistributioncan
thenbeusedto drivethe simulation.
Adistribution-driven simulation may be inaccurate, however, because of
relationships between successive even ts in the real system. The frequency
distributionindicatesonlyhowmanyinstancesofeacheventoccur;itdoesnot
indicate anything about the orderof their occurrence. To correct this problem,
we can use tracefiles. We create a trace by monitoring the real system and
recordingthesequenceofactualevents(Figure5.31).Wethenusethissequence
to drive the simulation. Trace files provide an excellent way to compare two
algorithms on exactly the same set of real inputs. This method can produce
accurate resultsforitsinputs.
Simulations can be expensive, often requiring many hours of computer
time. A more detailed simulation provides more accurate results, but it also
actual
process
executionperformance
statistics
for FCFSsimulation
FCFS
performance
statistics
for SJF
performance
statistics
for RR ( q = 14)trace tapesimulation
SJF
simulation
RR (q = 14)  
CPU   10
I/O    213
CPU   12
I/O    112
CPU     2
I/O    147
CPU 173
  
Figure 5.31 Evaluation of CPU schedulers by simulation."
3,5.8.4 Implementation,316,5.8.3 Simulations,"5.8 Algorithm Evaluation 249
takesmorecomputertime.Inaddition,tracefilescanrequirelargeamountsof
storage space.Finally,the design,coding, and debuggingof the simulatorcan
be a majortask.
5.8.4 Implementation
Even a simulation is of limited accuracy. The only completely accurate way
to evaluate a scheduling algorithm is to code it up, put it in the operating
system, and see how it works. This approach puts the actual algorithm in the
realsystemfor evaluationunderrealoperatingconditions.
Thismethodisnotwithoutexpense.Th eexpenseisincurredincodingthe
algorithm and modifying the operating system to support it (along with its
required data structures). There is also cost in testing the changes, usually in
virtual machines rather than on dedicated hardware. Regression testing con-
firmsthatthechangeshaven’tmadeanythingworse,andhaven’tcausednew
bugs or caused old bugs to be recreated (for example because the algorithm
beingreplacedsolvedsomebug and changing it causedthat bug toreoccur).
Another difficulty is that the environ ment in which the algorithm is used
will change. The environment will change not only in the usual way, as new
programs are written and the types of problems change, but also as a result
of the performance of the scheduler. If short processes are given priority, then
users may break larger processes into sets of smaller processes. If interactive
processes are given priority over noninteractive processes, then users may
switch to interactive use. This problem is usually addressed by using tools or
scripts that encapsulate complete sets of actions, repeatedlyusing those tools,
andusingthosetoolswhilemeasuringtheresults(anddetectinganyproblems
theycause inthe new environment).
Ofcoursehumanorprogrambehaviorcanattempttocircumventschedul-
ing algorithms. For example, researchers designed one system that classi-
fied interactive and noninteractive pro cesses automatically by looking at the
amount of terminal I/O. If a process did not input or output to the terminal
in a 1-second interval, the process was classified as noninteractive and was
moved to a lower-priority queue. In response to this policy, one programmer
modifiedhisprogramstowriteanarbitrarycharactertotheterminalatregular
intervals of less than 1 second. The system gave his programs a high priority,
eventhough theterminaloutput was completelymeaningless.
Ingeneral,mostflexibleschedulingalgorithmsarethosethatcanbealtered
by the system managers or by the users so that they can be tuned for a spe-
cific application or set of applications. Aworkstation that performs high-end
graphicalapplications,forinstance,mayhaveschedulingneedsdifferentfrom
thoseofawebserverorfileserver.Someoperatingsystems—particularlysev-
eral versions of UNIX—allow the system manager to fine-tune the scheduling
parameters for a particular system configuration. For example, Solaris pro-
vides the dispadmin command to allow the system administrator to modify
theparametersof thescheduling classesdescribedinSection5.7.3.
Another approach is to use APIs that can modify the priority of a process
or thread. The Java, POSIX, and Windows APIs provide such functions. The
downfall of this approach is that performance-tuning a system or application
mostoftendoesnotresultinimprovedperformanceinmoregeneralsituations."
2,5.9 Summary,317,5.8 Algorithm Evaluation,"250 Chapter 5 CPU Scheduling
5.9 Summary
•CPUscheduling is the task of selecting a waiting process from the ready
queue and allocating the CPUto it. The CPUis allocated to the selected
processby thedispatcher.
•Scheduling algorithms may be either preemptive (where the CPUcan be
taken away from a process) or nonpreemptive (where a process must
voluntarily relinquish control of the CPU). Almost all modern operating
systemsarepreemptive.
•Scheduling algorithms can be evaluated according to the following five
criteria:(1) CPUutilization,(2)throughput,(3)turnaroundtime,(4)waiting
time,and (5) responsetime.
•First-come,first-served( FCFS) scheduling is thesimplestscheduling algo-
rithm,but itcan causeshort processestowait for verylong processes.
•Shortest-job-first( SJF)schedulingisprovablyoptimal,providingtheshort-
est average waiting time. Implementing SJFscheduling is difficult, how-
ever,becausepredictingthe lengthof the next CPUburst isdifficult.
•Round-robin ( RR) scheduling allocates the CPUto each process for a time
quantum. If the process does not relinquish the CPUbefore its time quan-
tum expires, the process is preempted, and another process is scheduled
torun for a timequantum.
•Priorityschedulingassignseachprocessapriority,andthe CPUisallocated
to the process with the highest priority. Processes with the same priority
can be scheduledin FCFSor derorusin g RRscheduling.
•Multilevel queue scheduling partitions processes into several separate
queues arranged by priority, and the scheduler executes the processes in
the highest-priority queue. Different scheduling algorithms may be used
ineachqueue.
•Multilevelfeedbackqueuesaresimilartomultilevelqueues,exceptthata
processmay migratebetweendifferentqueues.
•Multicore processors place one or more CPUs on the same physical chip,
and each CPUmay have more than one hardware thread. From the per-
spective of the operating system, each hardware thread appears to be a
logicalCPU.
•Load balancing on multicore systems equalizes loads between CPUcores,
althoughmigratingthreadsbetweencorestobalanceloadsmayinvalidate
cache contents and therefore mayincrease memoryaccess times.
•Soft real-time scheduling gives priority to real-time tasks over non-real-
timetasks.Hardreal-timeschedulingp rovidestimingguaranteesforreal-
timetasks,
•Rate-monotonic real-time schedu ling schedules periodic tasks using a
staticprioritypolicywithpreemption."
2,Practice Exercises,318,5.9 Summary,"Practice Exercises 251
•Earliest-deadline-first ( EDF) scheduling assigns priorities according to
deadline. The earlier the deadline, the higher the priority; the later the
deadline,thelowerthe priority.
•Proportionalshareschedulingallocates Tsharesamongallapplications.If
anapplicationisallocated Nsharesoftime,itisensuredofhaving N∕Tof
the totalprocessortime.
•Linuxusesthecompletelyfairscheduler( CFS),whichassignsaproportion
ofCPUprocessingtimetoeachtask.Theproportionisbasedonthevirtual
runtime ( vruntime )value associated with each task.
•Windowsschedulingusesapreemptive,32-levelpriorityschemetodeter-
mine the orderof thread scheduling.
•Solarisidentifiessixuniqueschedu lingclassesthataremappedtoaglobal
priority. CPU-intensive threads are generally assigned lower priorities
(and longer time quantums), and I/O-bound threads are usually assigned
higher priorities(withshortertimequantums.)
•Modelingandsimulationscanbeusedtoevaluatea CPUschedulingalgo-
rithm.
Practice Exercises
5.1ACPU-schedulingalgorithmdeterminesanorderfortheexecutionofits
scheduled processes. Given nprocesses to be scheduled on one proces-
sor,howmanydifferentschedulesarepossible?Giveaformulainterms
ofn.
5.2Explainthedifferencebetweenpreemptiveandnonpreemptiveschedul-
ing.
5.3Suppose that the following processes arrive for execution at the times
indicated.Eachprocesswillrunfortheamountoftimelisted.Inanswer-
ingthequestions,usenonpreemptives cheduling,andbasealldecisions
on theinformation you haveat thetimethedecisionmust bemade.
Process ArrivalTime BurstTime
P1 0.0 8
P2 0.4 4
P3 1.0 1
a. What is the average turnaround time for these processes with the
FCFSscheduling algorithm?
b. What is the average turnaround time for these processes with the
SJFscheduling algorithm?
c. The SJFalgorithmissupposedtoimproveperformance,butnotice
thatwechosetorunprocess P1attime0becausewedidnotknow
that two shorter processes would arrive soon. Compute what the"
2,Further Reading,321,Practice Exercises,"254 Chapter 5 CPU Scheduling
Further Reading
Scheduling policies used in the UNIX FreeBSD5.2 are presented by
[McKusick et al. (2015)]; The Linux CFSscheduler is further described in
https://www.ibm.com/developerworks/lib rary/l-completely-fair-scheduler/ .
Solaris scheduling is described by [Mauro and McDougall (2007)]. [Russi-
novich et al. (2017)] discusses schedulin g in Windows internals. [Butenhof
(1997)] and [Lewis and Berg (1998)] describe scheduling in Pthreads systems.
Multicore scheduling is examined in [McNairy and Bhatia (2005)], [Kongetira
etal.(2005)], and [Siddhaetal.(2007)] .
Bibliography
[Butenhof (1997)] D. Butenhof, Programming with POSIX Threads , Addison-
Wesley (1997).
[Kongetira et al. (2005)] P.Kongetira,K.Aingaran,andK.Olukotun, “Niagara:
A32-Way Multithreaded SPARC Processor ”,IEEE Micro Magazine , Volume 25,
Number2 (2005), pages21–29.
[Lewis and Berg (1998)] B. Lewis and D. Berg, Multithreaded Programming with
Pthreads, SunMicrosystems Press (1998).
[Mauro and McDougall (2007)] J. Mauro and R. McDougall, Solaris Internals:
Core Kernel Architecture ,PrenticeHall (2007).
[McKusick et al. (2015)] M. K. McKusick, G. V. Neville-Neil, and R. N. M. Wat-
son, The Design and Implementation of the FreeBSD UNIX Operating System–Second
Edition, Pearson(2015).
[McNairy and Bhatia (2005)] C. McNairy and R. Bhatia, “Montecito: A Dual–
Core, Dual-Threaded Itanium Processor ”,IEEE Micro Magazine , Volume 25,
Number2 (2005), pages10–20.
[Russinovich et al. (2017)] M.Russinovich,D.A.Solomon,andA.Ionescu, Win-
dows Internals–Part 1, SeventhEdition, MicrosoftPress (2017).
[Siddha et al. (2007)] S. Siddha, V. Pallipadi, and A. Mallick, “Process Schedul-
ing Challenges in the Era of Multi-Core Processors ”,Intel Technology Journal ,
Volume11,Number4(2007)."
2,Bibliography,321,Further Reading,"254 Chapter 5 CPU Scheduling
Further Reading
Scheduling policies used in the UNIX FreeBSD5.2 are presented by
[McKusick et al. (2015)]; The Linux CFSscheduler is further described in
https://www.ibm.com/developerworks/lib rary/l-completely-fair-scheduler/ .
Solaris scheduling is described by [Mauro and McDougall (2007)]. [Russi-
novich et al. (2017)] discusses schedulin g in Windows internals. [Butenhof
(1997)] and [Lewis and Berg (1998)] describe scheduling in Pthreads systems.
Multicore scheduling is examined in [McNairy and Bhatia (2005)], [Kongetira
etal.(2005)], and [Siddhaetal.(2007)] .
Bibliography
[Butenhof (1997)] D. Butenhof, Programming with POSIX Threads , Addison-
Wesley (1997).
[Kongetira et al. (2005)] P.Kongetira,K.Aingaran,andK.Olukotun, “Niagara:
A32-Way Multithreaded SPARC Processor ”,IEEE Micro Magazine , Volume 25,
Number2 (2005), pages21–29.
[Lewis and Berg (1998)] B. Lewis and D. Berg, Multithreaded Programming with
Pthreads, SunMicrosystems Press (1998).
[Mauro and McDougall (2007)] J. Mauro and R. McDougall, Solaris Internals:
Core Kernel Architecture ,PrenticeHall (2007).
[McKusick et al. (2015)] M. K. McKusick, G. V. Neville-Neil, and R. N. M. Wat-
son, The Design and Implementation of the FreeBSD UNIX Operating System–Second
Edition, Pearson(2015).
[McNairy and Bhatia (2005)] C. McNairy and R. Bhatia, “Montecito: A Dual–
Core, Dual-Threaded Itanium Processor ”,IEEE Micro Magazine , Volume 25,
Number2 (2005), pages10–20.
[Russinovich et al. (2017)] M.Russinovich,D.A.Solomon,andA.Ionescu, Win-
dows Internals–Part 1, SeventhEdition, MicrosoftPress (2017).
[Siddha et al. (2007)] S. Siddha, V. Pallipadi, and A. Mallick, “Process Schedul-
ing Challenges in the Era of Multi-Core Processors ”,Intel Technology Journal ,
Volume11,Number4(2007)."
2,Chapter 5 Exercises,322,Bibliography,"Exercises
Chapter 5 Exercises
5.11Of thesetwo typesof programs:
a.I/O-bound
b.CPU-bound
which is more likely to have voluntary context switches, and which
is more likely to have nonvoluntary context switches? Explain your
answer.
5.12Discusshowthefollowingpairsofschedulingcriteriaconflictincertain
settings.
a.CPUutilization andresponsetime
b. Averageturnaround time and maximum waiting time
c.I/Odeviceutilizationand CPUutilization
5.13Onetechniqueforimplementing lottery scheduling worksbyassigning
processeslotterytickets,whichareusedforallocating CPUtime.When-
ever a scheduling decision has to be made, a lottery ticket is chosen at
random,andtheprocessholdingthatticketgetsthe CPU.TheBTVoper-
atingsystemimplementslotteryschedulingbyholdingalottery50times
each second, with each lottery winner getting 20 milliseconds of CPU
time(20milliseconds ×50=1second).Describehowthe BTVscheduler
can ensure that higher-priority threads receive more attention from the
CPUthan lower-prioritythreads.
5.14Mostschedulingalgorithmsmaintaina run queue ,whichlistsprocesses
eligible to run on a processor. On multicore systems, there are two
general options: (1) each processing core has its own run queue, or
(2) a single run queue is shared by all processing cores. What are the
advantagesand disadvantagesof eachof theseapproaches?
5.15Consider the exponential average formula used to predict the length of
thenext CPUburst.Whataretheimplicationsofassigningthefollowing
valuesto theparametersusedby thealgorithm?
a.α=0a n dτ0=100 milliseconds
b.α=0.99 andτ0=10 milliseconds
5.16Avariation of the round-robin scheduler is the regressive round-robin
scheduler. This scheduler assigns each process a time quantum and a
priority.Theinitialvalueofatimequantumis50milliseconds.However,
everytimea process has beenallocatedthe CPUand usesits entiretime
quantum (does not block for I/O), 10 milliseconds is added to its time
quantum, and its priority level is boosted. (The time quantum for a
process can be increased to a maximum of 100 milliseconds.) When a
processblocksbeforeusingitsentiretimequantum,itstimequantumis
reducedby5milliseconds,butitspriorityremainsthesame.Whattype
of process ( CPU-bound or I/O-bound) does the regressive round-robin
schedulerfavor? Explain.EX-12"
2,Programming Projects,327,Chapter 5 Exercises,"Chapter 5 CPU Scheduling
Programming Projects
Scheduling Algorithms
This project involvesimplementing severaldifferent process scheduling algo-
rithms. The scheduler will be assigned a predefined set of tasks and will
schedule the tasks based on the selected scheduling algorithm. Each task is
assigned a priority and CPUburst. The following scheduling algorithms will
be implemented:
•First-come,first-served( FCFS),whichschedulestasksintheorderinwhich
theyrequestthe CPU.
•Shortest-job-first ( SJF), which schedules tasks in order of the length of the
tasks’next CPUburst.
•Priorityscheduling,which schedulestasksbasedonpriority.
•Round-robin ( RR) scheduling, where each task is run for a time quantum
(or forthe remainderof its CPUburst).
•Priority with round-robin, which schedules tasks in order of priority and
usesround-robinscheduling fortasks withequalpriority.
Priorities range from 1 to 10, where a higher numeric value indicates a higher
relative priority. For round-robin sch eduling, the length of a time quantum is
10 milliseconds.
I. Implementation
The implementation of this project may be completed in either C or Java, and
program files supporting both of these languages are provided in the source
codedownloadforthetext.Thesesupportingfilesreadinthescheduleoftasks,
insertthetasksinto a list,and invokethescheduler.
Thescheduleoftaskshastheform[ task name ][priority][CPU burst],with
thefollowing exampleformat:
T1, 4, 20
T2, 2, 25
T3, 3, 25
T4, 3, 15
T5, 10, 10
Thus,task T1haspriority4anda CPUburstof20milliseconds,andsoforth.It
isassumedthatalltasksarriveatthesametime,soyourscheduleralgorithms
do not have to support higher-priority processes preempting processes with
lowerpriorities.Inaddition,tasksdonothavetobeplacedintoaqueueorlist
inany particularorder.
There are a few different strategies for organizing the list of tasks, as
first presented in Section 5.1.2. One approach is to place all tasks in a single
unorderedlist,wherethestrategyfortaskselectiondependsontheschedulingP-29"
0,PART THREE PROCESS SYNCHRONIZATION,330,PART TWO PROCESS MANAGEMENT,"Part Three
Process
Synchronization
A system typically consists of severa l (perhaps hundreds or even thou-
sands) of threads running either concurrently or in parallel. Threads often
share user data. Meanwhile, the oper ating system continuously updates
various data structures to su pport multiple threads. A race condition
exists when access to shared data is not controlled, possibly resulting
in corrupt data values.
Process synchronization involves using tools that control access to
shared data to avoid race conditions. These tools must be used carefully,
as their incorrect use can result in poor system performance, including
deadlock."
1,Chapter 6 Synchronization Tools,332,PART THREE PROCESS SYNCHRONIZATION,"6CHAPTER
Synchronization
Tools
Acooperating process is one that can affect or be affected by other processes
executing in the system. Cooperating processes can either directly share a
logical address space (that is, both code and data) or be allowed to share data
onlythroughsharedmemoryormessagepassing.Concurrentaccesstoshared
data may result in data inconsistency, however. In this chapter, we discuss
various mechanisms to ensure the orderly execution of cooperating processes
thatshare a logicaladdressspace,so t hat dataconsistency is maintained.
CHAPTER OBJECTIVES
•Describe the critical-section problem and illustrate a race condition.
•Illustrate hardware solutions to the critical-section problem using memory
barriers, compare-and-swap operations, and atomic variables.
•Demonstratehowmutexlocks,semaphores,monitors,andconditionvari-
ables can be used to solve the critical-section problem.
•Evaluate tools that solve the critical-section problem in low-, moderate-,
and high-contention scenarios.
6.1 Background
We’vealreadyseenthatprocessescanexecuteconcurrently orinparallel.Sec-
tion 3.2.2 introduced the role of proc ess scheduling and described how the
CPUschedulerswitches rapidlybetweenprocessesto provideconcurrent exe-
cution. This means that one process may only partially complete execution
before another process is scheduled. In fact, a process may be interrupted at
anypointinitsinstructionstream,andtheprocessingcoremaybeassignedto
execute instructions of another process. Additionally, Section 4.2 introduced
parallel execution, in which two instruction streams (representing different
processes) execute simultaneously on separate processing cores. In this chap-
ter, we explain how concurrent or parallel execution can contribute to issues
involvingthe integrityof datasharedby severalprocesses.
257"
2,6.1 Background,332,Chapter 6 Synchronization Tools,"6CHAPTER
Synchronization
Tools
Acooperating process is one that can affect or be affected by other processes
executing in the system. Cooperating processes can either directly share a
logical address space (that is, both code and data) or be allowed to share data
onlythroughsharedmemoryormessagepassing.Concurrentaccesstoshared
data may result in data inconsistency, however. In this chapter, we discuss
various mechanisms to ensure the orderly execution of cooperating processes
thatshare a logicaladdressspace,so t hat dataconsistency is maintained.
CHAPTER OBJECTIVES
•Describe the critical-section problem and illustrate a race condition.
•Illustrate hardware solutions to the critical-section problem using memory
barriers, compare-and-swap operations, and atomic variables.
•Demonstratehowmutexlocks,semaphores,monitors,andconditionvari-
ables can be used to solve the critical-section problem.
•Evaluate tools that solve the critical-section problem in low-, moderate-,
and high-contention scenarios.
6.1 Background
We’vealreadyseenthatprocessescanexecuteconcurrently orinparallel.Sec-
tion 3.2.2 introduced the role of proc ess scheduling and described how the
CPUschedulerswitches rapidlybetweenprocessesto provideconcurrent exe-
cution. This means that one process may only partially complete execution
before another process is scheduled. In fact, a process may be interrupted at
anypointinitsinstructionstream,andtheprocessingcoremaybeassignedto
execute instructions of another process. Additionally, Section 4.2 introduced
parallel execution, in which two instruction streams (representing different
processes) execute simultaneously on separate processing cores. In this chap-
ter, we explain how concurrent or parallel execution can contribute to issues
involvingthe integrityof datasharedby severalprocesses.
257"
2,6.2 The Critical-Section Problem,335,6.1 Background,"260 Chapter 6 Synchronization Tools
another. Because of the importance of this issue, we devotea major portion of
thischapterto process synchronization and coordination amongcooperating
processes.
6.2 The Critical-Section Problem
We begin our consideration of process synchronization by discussing the so-
called critical-section problem. Consider a system consisting of nprocesses
{P0,P1,...,Pn−1}. Each process has a segment of code, called a critical section ,
inwhichtheprocessmaybeaccessing — andupdating — datathatisshared
with at least one other process. The important feature of the system is that,
whenoneprocessisexecutinginitscriticalsection,nootherprocessisallowed
toexecuteinitscriticalsection.Thatis,notwoprocessesareexecutingintheir
critical sections at the same time. The critical-section problem is to design
a protocol that the processes can use to synchronize their activity so as to
cooperatively share data. Each process must request permission to enter its
critical section. The section of code implementing this request is the entry
section.Thecriticalsectionmaybefollowedbyan exit section .Theremaining
code is the remainder section . The general structure of a typical process is
showninFigure6.1.Theentrysectionandexitsectionareenclosedinboxesto
highlight these importantsegmentsof code.
Asolution to the critical-section problem must satisfy the following three
requirements:
1.Mutual exclusion .Ifpr ocess Piisexecutinginitscriticalsection,thenno
other processescan beexecutingin theircritical sections.
2.Progress . If no process is executing in its critical section and some pro-
cesses wish to enter their critical sec tions, then only those processes that
are not executing in their remainder s ections can participate in decid-
ing which will enter its critical section next, and this selection cannot be
postponed indefinitely.
while (true) {
entry section
critical section
exit section
remainder section
}
Figure 6.1 General structure of a typical process."
2,6.3 Peterson’s Solution,337,6.2 The Critical-Section Problem,"262 Chapter 6 Synchronization Tools
of instructions would be allowed to execute in order without preemption. No
other instructions would be run, so no unexpected modifications could be
madetothe sharedvariable.
Unfortunately, this solution is not as feasible in a multiprocessor environ-
ment. Disabling interrupts on a multiprocessor can be time consuming, since
themessageispassedtoalltheprocessors.Thismessagepassingdelaysentry
into each critical section, and system efficiency decreases. Also consider the
effecton a system’sclock if theclock is keptupdatedby interrupts.
Two general approaches are used to handle critical sections in operating
systems: preemptive kernels and nonpreemptive kernels .Apreemptiveker-
nel allows a process to be preempted while it is running in kernel mode. A
nonpreemptive kernel does not allow a process running in kernel mode to be
preempted; a kernel-mode process will run until it exits kernel mode, blocks,
or voluntarilyyieldscontrol of the CPU.
Obviously,anonpreemptivekernelisessentiallyfreefromraceconditions
on kernel data structures, as only one process is active in the kernel at a time.
We cannot say the same about preemptive kernels, so they must be carefully
designed to ensure that shared kernel da ta are free from race conditions. Pre-
emptive kernels are especially difficult to design for SMParchitectures, since
in these environments it is possible for two kernel-mode processes to run
simultaneouslyondifferent CPUcores.
Why, then, would anyone favor a preemptive kernel over a nonpreemp-
tiveone?Apreemptivekernelmay bemoreresponsive,since thereislessrisk
that akernel-modeprocesswillrunfor anarbitrarilylong periodbeforerelin-
quishing the processor to waiting processes. (Of course, this risk can also be
minimized by designing kernel code that does not behave in this way.) Fur-
thermore,a preemptivekernelis more suitable for real-timeprogramming, as
it will allow a real-time process to preempt a process currently running in the
kernel.
6.3 Peterson’s Solution
Next,weillustrateaclassicsoftware-basedsolutiontothecritical-sectionprob-
lem known as Peterson’s solution . Because of the way modern computer
architectures perform basic machine-language instructions, such as loadand
store, there are no guarantees that Peterson’s solution will work correctly
on such architectures. However, we present the solution because it providesa
good algorithmic description of solving the critical-section problem and illus-
trates some of the complexities involvedin designing software that addresses
therequirementsof mutualexclusion,progress,and boundedwaiting.
Peterson’s solution is restricted to two processes that alternate execution
betweentheircriticalsectionsandremaindersections.Theprocessesarenum-
bered P0andP1.Forconvenience,whenpresenting Pi,weuse Pjtodenotethe
other process;that is, jequals1 −i.
Peterson’s solutionrequiresthetwo processestoshare two dataitems:
int turn;
boolean flag[2];"
2,6.4 Hardware Support for Synchronization,340,6.3 Peterson’s Solution,"6.4 Hardware Support for Synchronization 265
processprocess
timecs
csflag[0] = true turn = 10
1turn = 0 , flag[1] = true
Figure 6.4 The effects of instruction reordering in Peterson’s solution.
How does this affect Peterson’s solution? Consider what happens if the
assignments of the first two statements that appear in the entry section of
Peterson’s solution in Figure 6.3 are reordered; it is possible that both threads
maybeactiveintheircriticalsectionsatthesametime,asshowninFigure6.4.
Asyouwillseeinthefollowingsections,theonlywaytopreservemutual
exclusion is by using proper synchronization tools. Our discussion of these
tools begins with primitive support in hardware and proceeds through
abstract, high-level, software-based APIs available to both kernel developers
andapplicationprogrammers.
6.4 Hardware Support for Synchronization
Wehavejustdescribedonesoftware-basedsolutiontothecritical-sectionprob-
lem.(Werefertoitasa software-based solutionbecausethealgorithminvolves
nospecialsupportfromtheoperatingsystemorspecifichardwareinstructions
toensuremutualexclusion.)However,asdiscussed,software-basedsolutions
arenotguaranteedtoworkonmoderncomputerarchitectures.Inthissection,
we present three hardware instructions that provide support for solving the
critical-section problem. These primitive operations can be used directly as
synchronization tools, or they can be used to form the foundation of more
abstract synchronization mechanisms.
6.4.1 Memory Barriers
InSection6.3,wesawthatasystemmayreorderinstructions,apolicythatcan
lead to unreliable data states. How a computer architecture determines what
memory guarantees it will provide to an application program is known as its
memory model .Ingeneral,a memorymodelfalls intoone of two categories:
1.Strongly ordered , where a memory modification on one processor is
immediatelyvisibleto allotherprocessors.
2.Weakly ordered , where modifications to memory on one processor may
not beimmediatelyvisibletoother processors.
Memorymodelsvarybyprocessortype,sokerneldeveloperscannotmake
any assumptions regarding the visibility of modifications to memory on a
shared-memory multiprocessor. To address this issue, computer architectures
provideinstructionsthatcan forceanychangesinmemorytobepropagatedto
allotherprocessors,therebyensuringthatmemorymodificationsarevisibleto"
3,6.4.1 Memory Barriers,340,6.4 Hardware Support for Synchronization,"6.4 Hardware Support for Synchronization 265
processprocess
timecs
csflag[0] = true turn = 10
1turn = 0 , flag[1] = true
Figure 6.4 The effects of instruction reordering in Peterson’s solution.
How does this affect Peterson’s solution? Consider what happens if the
assignments of the first two statements that appear in the entry section of
Peterson’s solution in Figure 6.3 are reordered; it is possible that both threads
maybeactiveintheircriticalsectionsatthesametime,asshowninFigure6.4.
Asyouwillseeinthefollowingsections,theonlywaytopreservemutual
exclusion is by using proper synchronization tools. Our discussion of these
tools begins with primitive support in hardware and proceeds through
abstract, high-level, software-based APIs available to both kernel developers
andapplicationprogrammers.
6.4 Hardware Support for Synchronization
Wehavejustdescribedonesoftware-basedsolutiontothecritical-sectionprob-
lem.(Werefertoitasa software-based solutionbecausethealgorithminvolves
nospecialsupportfromtheoperatingsystemorspecifichardwareinstructions
toensuremutualexclusion.)However,asdiscussed,software-basedsolutions
arenotguaranteedtoworkonmoderncomputerarchitectures.Inthissection,
we present three hardware instructions that provide support for solving the
critical-section problem. These primitive operations can be used directly as
synchronization tools, or they can be used to form the foundation of more
abstract synchronization mechanisms.
6.4.1 Memory Barriers
InSection6.3,wesawthatasystemmayreorderinstructions,apolicythatcan
lead to unreliable data states. How a computer architecture determines what
memory guarantees it will provide to an application program is known as its
memory model .Ingeneral,a memorymodelfalls intoone of two categories:
1.Strongly ordered , where a memory modification on one processor is
immediatelyvisibleto allotherprocessors.
2.Weakly ordered , where modifications to memory on one processor may
not beimmediatelyvisibletoother processors.
Memorymodelsvarybyprocessortype,sokerneldeveloperscannotmake
any assumptions regarding the visibility of modifications to memory on a
shared-memory multiprocessor. To address this issue, computer architectures
provideinstructionsthatcan forceanychangesinmemorytobepropagatedto
allotherprocessors,therebyensuringthatmemorymodificationsarevisibleto"
3,6.4.2 Hardware Instructions,341,6.4.1 Memory Barriers,"266 Chapter 6 Synchronization Tools
threadsrunning on other processors.Such instructions are known as memory
barriers ormemory fences . Whenamemorybarrierinstructionisperformed,
the system ensures that all loads and stores are completed before any subse-
quent load or store operations are performed. Therefore, even if instructions
werereordered,thememorybarrierensuresthatthestoreoperationsarecom-
pleted in memory and visible to other processors before future load or store
operationsareperformed.
Let’sreturntoourmostrecentexample,inwhichreorderingofinstructions
could have resultedin the wrong output, and use a memory barrier to ensure
that weobtain theexpectedoutput.
Ifwe addamemorybarrieroperationtoThread1
while (!flag)
memory
 barrier();
print x;
we guarantee that the value of flagisloadedbeforethe valueof x.
Similarly, if we place a memory barrier between the assignments per-
formed by Thread 2
x = 100;
memory
 barrier();
flag = true;
we ensurethat the assignmentto xoccurs before the assignment to flag.
With respect to Peterson’s solution, we could place a memory barrier
between the first two assignment statem ents in the entry section to avoid the
reordering of operations shown in Figure 6.4. Note that memory barriers are
considered very low-level operations and are typically only used by kernel
developerswhenwriting specializedcodethat ensuresmutual exclusion.
6.4.2 Hardware Instructions
Many modern computer systems provide special hardware instructions that
allowuseithertotestandmodifythecontentofawordortoswapthecontents
of two words atomically —that is, as one uninterruptible unit. We can use
these special instructions to solve the critical-section problem in a relatively
simplemanner.Ratherthandiscussingonespecificinstructionforonespecific
machine, we abstract the main concepts behind these types of instructions by
describingthe test
 and
set()andcompare
 and
swap()instructions.
boolean test
 and
set(boolean *target) {
boolean rv = *target;
*target = true;
return rv;
}
Figure 6.5 The definition of the atomic test
 and
set()instruction."
3,6.4.3 Atomic Variables,344,6.4.2 Hardware Instructions,"6.4 Hardware Support for Synchronization 269
MAKING COMPARE-AND-SWAP ATOMIC
On Intel x86 architectures, the assembly language statement cmpxchg is
usedtoimplementthe compare
 and
swap()instruction.Toenforceatomic
execution, the lockprefix is used to lock the bus while the destination
operandisbeingupdated. Thegeneralformofthisinstructionappearsas:
lock cmpxchg <destination operand>, <source operand>
anotheralgorithmusing the compare
 and
swap()instructionthat satisfiesall
thecritical-sectionrequirements.The common datastructuresare
boolean waiting[n];
int lock;
Theelementsinthe waiting arrayareinitializedto false,and lockisinitial-
izedto 0.Toprovethatthe mutual-exclusionrequirementis met,wenote that
process Pican enter its critical section only if either waiting[i] ==falseor
key==0.T h ev a l u eo f keycan become 0only if the compare
 and
swap()is
executed. The first process to execute the compare
 and
swap()will find key
==0;allothersmustwait.Thevariable waiting[i] canbecome falseonlyif
anotherprocessleavesitscriticalsection;onlyone waiting[i] issetto false,
maintaining themutual-exclusion requirement.
Toprovethattheprogressrequirementismet,wenotethatthearguments
presented for mutual exclusion also apply here, since a process exiting the
criticalsectioneithersets lockto0orsets waiting[j] tofalse.Bothallowa
processthat iswaiting toenteritscritical sectionto proceed.
Toprovethatthebounded-waitingrequirementismet,wenotethat,when
a process leaves its critical section, it scans the array waiting in the cyclic
ordering ( i+1 , i+ 2, ..., n−1, 0, ..., i−1). It designates the first process in
thisorderingthatisintheentrysection( waiting[j] ==true)asthenextone
toenterthecriticalsection.Anyprocesswaitingtoenteritscriticalsectionwill
thus doso within n−1t u r n s .
Details describing the implementationof the atomic test
 and
set()and
compare
 and
swap()instructions are discussed more fully in books on com-
puterarchitecture.
6.4.3 Atomic Variables
Typically,the compare
 and
swap()instruction is not used directlyto provide
mutual exclusion. Rather, it is used as a basic building block for constructing
other tools that solve the critical-section problem. One such tool is an atomic
variable,whichprovidesatomicoperationsonbasicdatatypessuchasintegers
andbooleans.WeknowfromSection6.1thatincrementingordecrementingan
integer value may produce a race condition. Atomic variables can be used in
to ensure mutual exclusion in situations where there may be a data race on a
singlevariablewhile itisbeing updated,as whena counter isincremented.
Most systems that support atomic variables provide special atomic data
types as well as functions for accessing and manipulating atomic variables."
2,6.5 Mutex Locks,345,6.4 Hardware Support for Synchronization,"270 Chapter 6 Synchronization Tools
These functions are often implemented using compare
 and
swap() opera-
tions.As anexample,thefollowing incrementsthe atomicinteger sequence :
increment(&sequence);
where the increment() function isimplementedusing the CASinstruction:
void increment(atomic
 int *v)
{
int temp;
do{
temp = *v;
}
while (temp != compare
 and
swap(v, temp, temp+1));
}
It is important to note that although atomic variables provide atomic
updates, they do not entirely solve race conditions in all circumstances. For
example,inthebounded-bufferproblemdescribedinSection6.1,wecoulduse
anatomicintegerfor count.Thiswouldensurethattheupdatesto countwere
atomic.However,theproducerandconsumerprocessesalsohave whileloops
whoseconditiondependsonthevalueof count.Considerasituationinwhich
thebufferiscurrentlyemptyandtwoconsumersareloopingwhilewaitingfor
count >0. If a producer enteredone itemin the buffer, both consumers could
exittheir whileloops(as countwouldnolongerbeequalto0)andproceedto
consume, eventhough thevalueof countwas only setto1.
Atomic variablesare commonly usedinoperating systemsas wellas con-
current applications, although their use is often limited to single updates of
shared data such as counters and sequence generators. In the following sec-
tions, we explore more robust tools that address race conditions in more gen-
eralizedsituations.
6.5 Mutex Locks
Thehardware-basedsolutionstothecritical-sectionproblempresentedinSec-
tion 6.4 are complicated as well as generally inaccessible to application pro-
grammers. Instead, operating-system designers build higher-level software
tools to solve the critical-section problem. The simplest of these tools is the
mutex lock .(Infa c t,th eterm mutexis short for mutualexclusion.) We use the
mutex lock to protect critical sections and thus prevent race conditions. That
is, a process must acquire the lock before entering a critical section; it releases
the lock when it exitsthe critical section. The acquire() function acquires the
lock,andthe release() functionreleasesthelock,asillustratedinFigure6.10.
Amutex lock has a boolean variable available whose value indicates if
thelockisavailableornot.Ifthelockisavailable,acallto acquire() succeeds,
andthelockisthenconsideredunavaila ble.Aprocessthatattemptstoacquire
an unavailable lockis blockeduntil thelock isreleased."
2,6.6 Semaphores,347,6.5 Mutex Locks,"272 Chapter 6 Synchronization Tools
WHAT IS MEANT BY “SHORT DURATION ”?
Spinlocks are often identified as the locking mechanism of choice on multi-
processor systems when the lock is to be held for a short duration. But what
exactly constitutes a short duration ? Given that waiting on a lock requires
two context switches—a context switch to move the thread to the waiting
state and a secondcontextswitch to restore the waiting threadoncethe lock
becomes available—the general rule is to use a spinlock if the lock will be
held foraduration ofless thantwo contextswitches.
Themaindisadvantageoftheimplementationgivenhereisthatitrequires
busy waiting . While a process is in its critical section, any other process that
triestoenteritscriticalsectionmustloopcontinuouslyinthecallto acquire() .
Thiscontinualloopingisclearlyaprobleminarealmultiprogrammingsystem,
where a single CPUcore is shared among many processes. Busy waiting also
wastes CPUcycles that some other process might be able to use productively.
(InSection6.6,weexamineastrategythatavoidsbusywaitingbytemporarily
putting the waiting process to sleep and then awakening it once the lock
becomes available.)
The type of mutex lock we have been describing is also called a spin-
lockbecause the process “spins ”while waiting for the lock to become avail-
able. (We see the same issue with the code examples illustrating the com-
pare
 and
swap()instruction.) Spinlocks do have an advantage, however, in
that no context switch is required when a process must wait on a lock, and a
context switch may take considerable time.In certain circumstances on multi-
core systems,spinlocks are in fact the preferablechoice for locking. Ifa lock is
to be held for a short duration, one thread can “spin ”on one processing core
while another thread performs its critical section on another core. On modern
multicore computing systems, spinlocks are widely used in many operating
systems.
In Chapter 7 we examine how mutex locks can be used to solve classical
synchronizationproblems.Wealsodiscusshowmutexlocksandspinlocksare
usedinseveraloperatingsystems,aswellas inPthreads.
6.6 Semaphores
Mutexlocks,aswementionedearlier,aregenerallyconsideredthesimplestof
synchronization tools. In this section, we examine a more robust tool that can
behavesimilarlytoamutexlockbutcanalsoprovidemoresophisticatedways
for processesto synchronize theiractivities.
Asemaphore Sis an integer variable that, apart from initialization, is
accessedonlythroughtwostandardatomicoperations: wait()andsignal() .
Semaphores were introduced by the Dutch computer scientist Edsger Dijk-
stra, and such, the wait()operationwas originally termed P(from the Dutch"
3,6.6.1 Semaphore Usage,348,6.6 Semaphores,"6.6 Semaphores 273
proberen, “totest ”);signal() wasoriginallycalled V(from verhogen, “toincre-
ment ”).The definition of wait()isas follows:
wait(S) {
while (S <=0)
; // busy wait
S--;
}
The definition of signal() isas follows:
signal(S) {
S++;
}
Allmodificationsto theintegervalueofthesemaphorein the wait()and
signal() operations must be executed atomically. That is, when one process
modifies the semaphore value, no other process can simultaneously modify
that same semaphore value. In addition, in the case of wait(S) ,t h et e s t i n go f
the integer value of S(S≤0), as well as its possible modification ( S--), must
be executed without interruption. We shall see how these operations can be
implementedinSection6.6.2.First,let’sseehowsemaphorescan beused.
6.6.1 Semaphore Usage
Operating systems often distinguish between counting and binary
semaphores. The value of a counting semaphore can range over an
unrestricted domain. The value of a binary semaphore can range only
between0and1.Thus,binarysemaphoresbehavesimilarlytomutexlocks.In
fact, on systems that do not provide mutex locks, binary semaphores can be
usedinsteadfor providingmutualexclusion.
Counting semaphores can be used to control access to a given resource
consisting of a finite number of instances. The semaphore is initialized to the
number of resources available. Each process that wishes to use a resource
performs a wait()operation on the semaphore (thereby decrementing the
count). When a process releases a resource, it performs a signal() operation
(incrementing the count). When the count for the semaphore goes to 0, all
resourcesarebeing used.Afterthat, processesthat wish to usea resource will
block untilthe count becomes greaterthan 0.
We can also use semaphores to solve various synchronization problems.
Forexample,considertwoconcurrentlyrunningprocesses: P1withastatement
S1andP2withastatement S2.Supposewerequirethat S2beexecutedonlyafter
S1has completed. We can implement this scheme readily by letting P1and P2
shareacommonsemaphore synch,initializedto0.Inprocess P1,weinsertthe
statements
S1;
signal(synch);"
3,6.6.2 Semaphore Implementation,349,6.6.1 Semaphore Usage,"274 Chapter 6 Synchronization Tools
Inprocess P2,weinsertthe statements
wait(synch);
S2;
Because synchis initialized to 0, P2will execute S2only after P1has invoked
signal(synch) ,which isafterstatement S1has beenexecuted.
6.6.2 Semaphore Implementation
Recall that the implementation of mutex locks discussed in Section 6.5 suffers
from busy waiting. The definitions of the wait()andsignal() semaphore
operations just described present the same problem. To overcome this prob-
lem, we can modify the definition of the wait()and signal() operations
as follows: When a process executes the wait()operation and finds that the
semaphore value is not positive, it must wait. However, rather than engaging
in busy waiting, the process can suspend itself. The suspend operation places
aprocessintoawaitingqueueassociatedwiththesemaphore,andthestateof
the process is switched to the waiting st ate. Then control is transferred to the
CPUscheduler,which selectsanother processto execute.
Aprocessthatissuspended,waitingonasemaphore S,shouldberestarted
when some other process executes a signal() operation. The process is
restartedbya wakeup() operation,whichchangestheprocessfromthewaiting
state to the ready state. The process is then placed in the ready queue. (The
CPUmayormaynotbeswitchedfromtherunningprocesstothenewlyready
process,dependingonthe CPU-scheduling algorithm.)
Toimplementsemaphoresunderthisdefinition,wedefineasemaphoreas
follows:
typedef struct {
int value;
struct process *list;
}semaphore ;
Each semaphore has an integer valueand a list of processes list.W h e n
a process must wait on a semaphore, it is added to the list of processes. A
signal() operation removes one process from the list of waiting processes
and awakens that process.
Now, the wait()sema ph o r eo pera tio nc a nb edefi n eda s
wait(semaphore *S) {
S->value--;
if (S->value < 0) {
addthis processto S->list ;
sleep();
}
}"
2,6.7 Monitors,351,6.6 Semaphores,"276 Chapter 6 Synchronization Tools
rarely, and then for only a short time. An entirely different situation exists
with application programs whose critical sections may be long (minutes or
even hours) or may almost always be occupied. In such cases, busy waiting
isextremelyinefficient.
6.7 Monitors
Although semaphoresprovidea conven ient and effectivemechanism for pro-
cess synchronization, using them incorrectly can result in timing errors that
are difficult to detect, since these errors happen only if particular execution
sequencestakeplace,andthesesequencesdonot always occur.
Wehaveseenanexampleofsucherrorsintheuseofacountinoursolution
to the producer–consumer problem (Sect ion 6.1). In that example, the timing
problem happened only rarely, and even then the countvalue appeared to
be reasonable—off by only 1. Nevertheless, the solution is obviously not an
acceptable one. It is for this reason that mutex locks and semaphores were
introducedinthefirst place.
Unfortunately, such timing errors can still occur when either mutex locks
or semaphores are used. To illustrate how, we review the semaphore solution
tothecritical-sectionproblem.Allprocessesshareabinarysemaphorevariable
mutex,whichisinitializedto1.Eachprocessmustexecute wait(mutex) before
entering the critical section and signal(mutex) afterward. If this sequence is
not observed, two processes may be in their critical sections simultaneously.
Next,welistseveraldifficultiesthatmayresult.Notethatthesedifficultieswill
ariseevenifa singleprocessisnotwellbehaved.Thissituationmaybecaused
by an honest programming erroror an uncooperative programmer.
•Suppose that a program interchanges the order in which the wait()and
signal() operations on the semaphore mutexare executed, resulting in
the following execution:
signal(mutex);
...
criticalsection
...
wait(mutex);
In this situation, several processes may be executing in their critical sec-
tions simultaneously, violating the mutual-exclusion requirement. This
errormaybediscoveredonlyifseveralprocessesaresimultaneouslyactive
in theircritical sections. Note that th is situation may not always be repro-
ducible.
•Supposethataprogramreplaces signal(mutex) with wait(mutex) .That
is,itexecutes
wait(mutex);
...
critical section
...
wait(mutex);"
3,6.7.1 Monitor Usage,352,6.7 Monitors,"6.7 Monitors 277
In this case, the process will perman ently block on the second call to
wait(),as the semaphore isnow unavailable.
•Supposethataprocessomitsthe wait(mutex) ,orthe signal(mutex) ,or
both. In this case, either mutual exclusion is violated or the process will
permanentlyblock.
These examples illustrate that various t ypes of errors can be generated easily
when programmers use semaphores or mutex locks incorrectly to solve the
critical-section problem. One strategy for dealing with such errors is to incor-
porate simple synchronization tools as high-level language constructs. In this
section, we describe one fundamental high-level synchronization construct—
themonitor type.
6.7.1 Monitor Usage
Anabstract data type —or ADT—encapsulates data with a set of functions to
operate on that data that are independent of any specific implementation of
theADT.Amonitor type is anADTthat includes a set of programmer-defined
operations that are provided with mutual exclusion within the monitor. The
monitor type also declares the variables whose values define the state of an
monitor monitor name
{
/* shared variable declarations */
function P1 (...) {
...
}
function P2 (...) {
...
}
.
.
.
function Pn (...) {
...
}
initialization
 code ( ...) {
...
}
}
Figure 6.11 Pseudocode syntax of a monitor."
3,6.7.2 Implementing a Monitor Using Semaphores,355,6.7.1 Monitor Usage,"280 Chapter 6 Synchronization Tools
Many programming languages have incorporated the idea of the monitor
asdescribedinthissection,includingJavaandC#.Otherlanguages—such as
Erlang—provide concurrency supportusing asimilarmechanism.
6.7.2 Implementing a Monitor Using Semaphores
We now consider a possible implementation of the monitor mechanism using
semaphores. For each monitor, a binary semaphore mutex(initialized to 1) is
provided to ensure mutual exclusion. A process must execute wait(mutex)
before entering the monitor and must execute signal(mutex) after leaving
the monitor.
We will use the signal-and-wait scheme in our implementation. Since a
signaling process must wait until the resumed process either leaves or waits,
an additional binary semaphore, next, is introduced, initialized to 0. The
signaling processes can use nextto suspend themselves. An integer variable
next
 countis also provided to count the number of processes suspended on
next.Thus,each externalfunction Fisreplacedby
wait(mutex);
...
bodyof F
...
if (next
 count > 0)
signal(next);
else
signal(mutex);
Mutual exclusionwithin a monitor isensured.
We can now describe how condition variables are implemented as well.
For each condition x, we introduce a binary semaphore x
semand an integer
variable x
count, both initialized to 0. The operation x.wait() can now be
implementedas
x
count++;
if (next
 count > 0)
signal(next);
else
signal(mutex);
wait(x
 sem);
x
count--;
Theoperation x.signal() can beimplementedas
if (x
 count > 0) {
next
 count++;
signal(x
 sem);
wait(next);
next
 count--;
}
This implementation is applicable to the definitions of monitors given by
both Hoare and Brinch-Hansen (see the bibliographical notes at the end of
the chapter). In some cases, however, the generality of the implementation is"
3,6.7.3 Resuming Processes within a Monitor,356,6.7.2 Implementing a Monitor Using Semaphores,"6.7 Monitors 281
monitor ResourceAllocator
{
boolean busy;
condition x;
void acquire(int time) {
if (busy)
x.wait(time);
busy = true;
}
void release() {
busy = false;
x.signal();
}
initialization
 code() {
busy = false;
}
}
Figure 6.14 A monitor to allocate a single resource.
unnecessary, and a significant improvementin efficiency is possible. We leave
thisproblemto you inExercise6.27.
6.7.3 Resuming Processes within a Monitor
We turn now to the subject of process-resumption order within a monitor. If
several processes are suspended on condition x,a n da n x.signal() opera-
tion is executed by some process, then how do we determine which of the
suspendedprocessesshouldberesumednext?Onesimplesolutionistousea
first-come, first-served( FCFS) ordering,so that the process that has been wait-
ingthelongestisresumedfirst.Inmanycircumstances,however,suchasimple
scheduling scheme is not adequate. In these circumstances, the conditional-
waitconstruct can be used.This construct has the form
x.wait(c);
where cis an integer expression that is evaluatedwhen the wait()operation
is executed. The value of c, which is called a priority number ,i st h e ns t o r e d
withthenameoftheprocessthatissuspended.When x.signal() isexecuted,
theprocesswiththesmallestprioritynumber is resumednext.
Toillustratethisnewmechanism,considerthe ResourceAllocator mon-
itor shown in Figure 6.14, which controls the allocation of a single resource
among competing processes. Each process, when requesting an allocation of
thisresource,specifiesthemaximumtimeitplanstousetheresource.Themon-
itor allocates the resource to the process that has the shortest time-allocation"
2,6.8 Liveness,358,6.7 Monitors,"6.8 Liveness 283
6.8 Liveness
Oneconsequenceofusingsynchronizationtoolstocoordinateaccesstocritical
sections is the possibility that a process attempting to enter its critical section
will wait indefinitely. Recall that in Secti on 6.2, we outlined three criteria that
solutionstothecritical-sectionproblemm ustsatisfy.Indefinitewaitingviolates
two ofthese—the progressand bounded-waiting criteria.
Liveness refers to a set of properties that a system must satisfy to ensure
thatprocessesmakeprogressduringtheirexecutionlifecycle.Aprocesswait-
ing indefinitely under the circumstances just described is an example of a
“livenessfailure. ”
There are many different forms of liveness failure; however, all are gen-
erally characterized by poor performance and responsiveness. Avery simple
example of a liveness failure is an infinite loop. Abusy wait loop presents the
possibility of a liveness failure, especially if a process may loop an arbitrarily
long period of time. Efforts at providing mutual exclusion using tools such as
mutexlocksandsemaphorescanoftenleadtosuchfailuresinconcurrentpro-
gramming. In this section, we explore two situations that can lead to liveness
failures.
6.8.1 Deadlock
The implementation of a semaphore with a waiting queue may result in a
situation where two or more processes are waiting indefinitely for an event
thatcanbecausedonlybyoneofthewaitingprocesses.Theeventinquestion
is the execution of a signal() operation. When such a state is reached, these
processesaresaidto be deadlocked .
Toillustratethis,considerasystemconsistingoftwoprocesses, P0andP1,
each accessing two semaphores, SandQ,setto thevalue1:
P0 P1
wait(S); wait(Q);
wait(Q); wait(S);
..
..
..
signal(S); signal(Q);
signal(Q); signal(S);
Supposethat P0executes wait(S) andthen P1executes wait(Q) .When P0
executes wait(Q) ,i tm u s tw a i tu n t i l P1executes signal(Q) . Similarly, when
P1executes wait(S) ,i tm u s tw a i tu n t i l P0executes signal(S) .S i n c et h e s e
signal() operations cannot be executed, P0and P1aredeadlocked.
We say that a set of processes is in a deadlocked state when every process
in the set is waiting for an event that can be caused only by another process in the
set.The “events ”withwhichwearemainlyconcerned herearetheacquisition
and release of resources such as mutex locks and semaphores. Other types of
events may result in deadlocks, as we show in more detail in Chapter 8. In"
3,6.8.1 Deadlock,358,6.8 Liveness,"6.8 Liveness 283
6.8 Liveness
Oneconsequenceofusingsynchronizationtoolstocoordinateaccesstocritical
sections is the possibility that a process attempting to enter its critical section
will wait indefinitely. Recall that in Secti on 6.2, we outlined three criteria that
solutionstothecritical-sectionproblemm ustsatisfy.Indefinitewaitingviolates
two ofthese—the progressand bounded-waiting criteria.
Liveness refers to a set of properties that a system must satisfy to ensure
thatprocessesmakeprogressduringtheirexecutionlifecycle.Aprocesswait-
ing indefinitely under the circumstances just described is an example of a
“livenessfailure. ”
There are many different forms of liveness failure; however, all are gen-
erally characterized by poor performance and responsiveness. Avery simple
example of a liveness failure is an infinite loop. Abusy wait loop presents the
possibility of a liveness failure, especially if a process may loop an arbitrarily
long period of time. Efforts at providing mutual exclusion using tools such as
mutexlocksandsemaphorescanoftenleadtosuchfailuresinconcurrentpro-
gramming. In this section, we explore two situations that can lead to liveness
failures.
6.8.1 Deadlock
The implementation of a semaphore with a waiting queue may result in a
situation where two or more processes are waiting indefinitely for an event
thatcanbecausedonlybyoneofthewaitingprocesses.Theeventinquestion
is the execution of a signal() operation. When such a state is reached, these
processesaresaidto be deadlocked .
Toillustratethis,considerasystemconsistingoftwoprocesses, P0andP1,
each accessing two semaphores, SandQ,setto thevalue1:
P0 P1
wait(S); wait(Q);
wait(Q); wait(S);
..
..
..
signal(S); signal(Q);
signal(Q); signal(S);
Supposethat P0executes wait(S) andthen P1executes wait(Q) .When P0
executes wait(Q) ,i tm u s tw a i tu n t i l P1executes signal(Q) . Similarly, when
P1executes wait(S) ,i tm u s tw a i tu n t i l P0executes signal(S) .S i n c et h e s e
signal() operations cannot be executed, P0and P1aredeadlocked.
We say that a set of processes is in a deadlocked state when every process
in the set is waiting for an event that can be caused only by another process in the
set.The “events ”withwhichwearemainlyconcerned herearetheacquisition
and release of resources such as mutex locks and semaphores. Other types of
events may result in deadlocks, as we show in more detail in Chapter 8. In"
3,6.8.2 Priority Inversion,359,6.8.1 Deadlock,"284 Chapter 6 Synchronization Tools
that chapter, we describe various mec hanisms for dealing with the deadlock
problem,aswellas otherforms of livenessfailures.
6.8.2 Priority Inversion
A scheduling challenge arises when a higher-priority process needs to read
or modify kernel data that are currently being accessed by a lower-priority
process—or a chain of lower-priority processes. Since kernel data are typi-
cally protected with a lock, the higher-priority process will have to wait for
a lower-priority one to finish with the resource. The situation becomes more
complicated if the lower-priority process is preempted in favor of another
processwitha higherpriority.
As an example, assume we have three processes— L,M,a n d H—whose
priorities follow the order L<M<H. Assume that process Hrequires
as e m a p h o r e S, which is currently being accessed by process L. Ordinarily,
process Hwould wait for Lto finish using resource S.However,nowsuppose
that process Mbecomes runnable, thereby preempting process L.I n d i r e c t l y ,a
process with a lower priority—process M—has affected how long process H
mustwait for Lto relinquishresource S.
This liveness problem is known as priority inversion , and it can occur
only in systems with more than two priorities. Typically, priority inversion is
avoided by implementing a priority-inheritance protocol . According to this
protocol,allprocessesthatareaccessingresourcesneededbyahigher-priority
processinheritthe higherpriorityuntiltheyarefinished with theresourcesin
question.Whentheyarefinished,theirprioritiesreverttotheiroriginalvalues.
In the example above, a priority-inheritance protocol would allow process L
to temporarilyinherit thepriorityof process H,thereby preventingprocess M
frompreemptingitsexecution.Whenprocess Lhadfinishedusingresource S,it
wouldrelinquishitsinheritedpriorityfrom Handassumeitsoriginalpriority.
Because resource Swould now be available, process H—not M—wouldrun
next.
6.9 Evaluation
We have described several different synchronization tools that can be used to
solve the critical-section problem. Given correct implementation and usage,
thesetoolscanbeusedeffectivelytoensuremutualexclusionaswellasaddress
liveness issues. With the growth of concurrent programs that leverage the
power of modern multicore computer systems, increasing attention is being
paid to the performance of synchronization tools. Trying to identify when
to use which tool, however, can be a daunting challenge. In this section, we
present some simple strategies for dete rmining when to use specific synchro-
nization tools.
The hardware solutions outlined in Section 6.4 are considered very low
levelandaretypicallyusedasthefoundationsforconstructingothersynchro-
nization tools, such as mutex locks. However, there has been a recent focus
on using the CASinstruction to construct lock-free algorithms that provide
protection from race conditions without requiring the overhead of locking.
Althoughtheselock-freesolutionsare gainingpopularityduetolowoverhead"
2,6.9 Evaluation,359,6.8 Liveness,"284 Chapter 6 Synchronization Tools
that chapter, we describe various mec hanisms for dealing with the deadlock
problem,aswellas otherforms of livenessfailures.
6.8.2 Priority Inversion
A scheduling challenge arises when a higher-priority process needs to read
or modify kernel data that are currently being accessed by a lower-priority
process—or a chain of lower-priority processes. Since kernel data are typi-
cally protected with a lock, the higher-priority process will have to wait for
a lower-priority one to finish with the resource. The situation becomes more
complicated if the lower-priority process is preempted in favor of another
processwitha higherpriority.
As an example, assume we have three processes— L,M,a n d H—whose
priorities follow the order L<M<H. Assume that process Hrequires
as e m a p h o r e S, which is currently being accessed by process L. Ordinarily,
process Hwould wait for Lto finish using resource S.However,nowsuppose
that process Mbecomes runnable, thereby preempting process L.I n d i r e c t l y ,a
process with a lower priority—process M—has affected how long process H
mustwait for Lto relinquishresource S.
This liveness problem is known as priority inversion , and it can occur
only in systems with more than two priorities. Typically, priority inversion is
avoided by implementing a priority-inheritance protocol . According to this
protocol,allprocessesthatareaccessingresourcesneededbyahigher-priority
processinheritthe higherpriorityuntiltheyarefinished with theresourcesin
question.Whentheyarefinished,theirprioritiesreverttotheiroriginalvalues.
In the example above, a priority-inheritance protocol would allow process L
to temporarilyinherit thepriorityof process H,thereby preventingprocess M
frompreemptingitsexecution.Whenprocess Lhadfinishedusingresource S,it
wouldrelinquishitsinheritedpriorityfrom Handassumeitsoriginalpriority.
Because resource Swould now be available, process H—not M—wouldrun
next.
6.9 Evaluation
We have described several different synchronization tools that can be used to
solve the critical-section problem. Given correct implementation and usage,
thesetoolscanbeusedeffectivelytoensuremutualexclusionaswellasaddress
liveness issues. With the growth of concurrent programs that leverage the
power of modern multicore computer systems, increasing attention is being
paid to the performance of synchronization tools. Trying to identify when
to use which tool, however, can be a daunting challenge. In this section, we
present some simple strategies for dete rmining when to use specific synchro-
nization tools.
The hardware solutions outlined in Section 6.4 are considered very low
levelandaretypicallyusedasthefoundationsforconstructingothersynchro-
nization tools, such as mutex locks. However, there has been a recent focus
on using the CASinstruction to construct lock-free algorithms that provide
protection from race conditions without requiring the overhead of locking.
Althoughtheselock-freesolutionsare gainingpopularityduetolowoverhead"
2,6.10 Summary,361,6.9 Evaluation,"286 Chapter 6 Synchronization Tools
•High contention .Underveryhighlycontendedloads,traditionalsynchro-
nizationwillultimatelybefasterthan CAS-based synchronization.
Moderatecontentionisparticularlyinterestingtoexamine.Inthisscenario,
theCASoperation succeeds most of the time, and when it fails, it will iterate
through the loop shown in Figure 6.8 only a few times before ultimately suc-
ceeding.Bycomparison,withmutual-exclusionlocking, anyattempttoacquire
acontendedlockwillresultinamorecomplicated—andtime-intensive—code
path that suspends a threadand places it on a wait queue,requiringa context
switch to another thread.
T h ec h o i c eo fam e c h a n i s mt h a ta d d r e s s e srace conditions can also greatly
affect system performance. For example, atomic integers are much lighter
weight than traditional locks, and are generallymore appropriatethan mutex
locks or semaphores for single updates to shared variables such as counters.
We also see this in the design of operating systems where spinlocks are used
onmultiprocessorsystemswhenlocksareheldforshortdurations.Ingeneral,
mutex locks are simpler and require less overhead than semaphores and are
preferable to binary semaphores for protecting access to a critical section.
However, for some uses—such as controlling access to a finite number of
resources—acountingsemaphoreisgenerallymoreappropriatethanamutex
lock. Similarly,in some instances, a reader–writer lock may be preferredover
a mutex lock, as it allows a higher degree of concurrency (that is, multiple
readers).
The appeal of higher-level tools such as monitors and condition variables
is based on their simplicity and ease of use. However, such tools may have
significant overhead and, depending o n their implementation, may be less
likelyto scaleinhighly contendedsituations.
Fortunately, there is much ongoing research toward developing scalable,
efficient tools that address the demands of concurrent programming. Some
examplesinclude:
•Designingcompilersthat generatemoreefficient code.
•Developinglanguagesthatprovidesupportforconcurrentprogramming.
•Improvingthe performanceof existinglibrariesand APIs.
In the next chapter, we examine how various operating systems and APIs
availableto developersimplementthesynchronization toolspresentedinthis
chapter.
6.10 Summary
•Arace condition occurs when processes have concurrent access to shared
data and the final result depends on the particular order in which con-
current accesses occur. Race conditions can result in corrupted values of
shareddata.
•Acritical section is a section of code where shared data may be manipu-
latedandapossibleraceconditionmayoccur.Thecritical-sectionproblem"
2,Practice Exercises,362,6.10 Summary,"Practice Exercises 287
istodesignaprotocolwherebyprocessescansynchronizetheiractivityto
cooperativelyshare data.
•Asolution to the critical-section problem must satisfy the following three
requirements:(1)mutualexclusion,(2)progress,and(3)boundedwaiting.
Mutualexclusionensuresthatonlyoneprocessatatimeisactiveinitscrit-
ical section. Progress ensures that programs will cooperatively determine
what process will next enter its critical section. Bounded waiting limits
how much timea programwillwait beforeitcan enteritscriticalsection.
•Softwaresolutionstothecritical-sectionproblem,suchasPeterson’ssolu-
tion, donot work wellon moderncomputer architectures.
•Hardwaresupportforthecritical-sectionproblemincludesmemorybarri-
ers;hardwareinstructions,suchasthecompare-and-swapinstruction;and
atomicvariables.
•A mutex lock provides mutual exclusion by requiring that a process
acquire a lock before entering a critical section and release the lock on
exitingthe criticalsection.
•Semaphores, like mutex locks, can be used to provide mutual exclusion.
However,whereasamutexlockhasabinaryvaluethatindicatesifthelock
is available or not, a semaphore has an integer value and can thereforebe
usedto solvea varietyof synchronization problems.
•A monitor is an abstract data type that provides a high-level form of
process synchronization. A monitor uses condition variables that allow
processes to wait for certain conditions to become true and to signal one
another when conditions havebeensettotrue.
•Solutions to the critical-section problem may suffer from liveness prob-
lems,includingdeadlock.
•The various tools that can be used to solve the critical-section problem as
well as to synchronize the activity of processes can be evaluated under
varying levels of contention. Some tools work better under certain con-
tention loadsthan others.
Practice Exercises
6.1In Section 6.4, we mentioned that disabling interrupts frequently can
affect the system’s clock. Explain why this can occur and how such
effectscan beminimized.
6.2What is the meaning of the term busy waiting ? What other kinds of
waiting arethereinan operatingsystem?Can busy waiting be avoided
altogether?Explainyour answer.
6.3Explainwhyspinlocksarenotappropriateforsingle-processorsystems
yetareoftenusedinmultiprocessorsystems.
6.4Show that, if the wait()andsignal() semaphore operations are not
executedatomically,thenmutualexclusionmay beviolated."
2,Further Reading,363,Practice Exercises,"288 Chapter 6 Synchronization Tools
6.5Illustrate how a binary semaphore can be used to implement mutual
exclusionamong nprocesses.
6.6Race conditions are possible in many computer systems. Consider a
banking system that maintains an account balance with two functions:
deposit(amount) and withdraw(amount) . These two functions are
passed the amountthat is to be deposited or withdrawn from the bank
accountbalance.Assumethatahusbandandwifeshareabankaccount.
Concurrently, the husband calls the withdraw() function, and the wife
calls deposit() . Describe how a race condition is possible and what
mightbe doneto preventtherace conditionfromoccurring.
Further Reading
The mutual-exclusion problem was first discussed in a classic paper by [Dijk-
stra (1965)]. The semaphore concept was suggested by [Dijkstra (1965)]. The
monitor concept was developed by [Brinch-Hansen (1973)]. [Hoare (1974)]
gavea completedescriptionofthe monitor.
FormoreontheMarsPathfinderproblemsee http://research.microsoft.co
m/en-us/um/people/mbj/mars
 pathﬁnder/authoritative
 account.html
Athoroughdiscussionofmemorybarriersandcachememoryispresented
in [Mckenney (2010)]. [Herlihy and Shavit (2012)] presents details on several
issuesrelatedtomultiprocessorprogramming,includingmemorymodelsand
compare-and-swap instructions. [Bahra (2013)] examines nonblocking algo-
rithmson modernmulticoresystems.
Bibliography
[Bahra (2013)] S. A. Bahra, “Nonblocking Algorithms and Scalable Multicore
Programming ”,ACM queue,Volume11,Number5 (2013).
[Brinch-Hansen (1973)] P. Brinch-Hansen, Operating System Principles ,P r e n t i c e
Hall (1973).
[Dijkstra (1965)] E. W. Dijkstra, “Cooperating Sequential Processes ”, Technical
report,TechnologicalUniversity,E indhoven,theNetherlands(1965).
[Herlihy and Shavit (2012)] M. Herlihy and N. Shavit, The Art of Multiprocessor
Programming, Revised First Edition, MorganK aufmannPublishers Inc. (2012).
[Hoare (1974)] C. A. R. Hoare, “Monitors: An Operating System Structuring
Concept ”,Communications of the ACM , Volume 17, Number 10 (1974), pages
549–557.
[Mckenney (2010)] P. E. Mckenney, “Memory Barriers: a Hardware View for
Software Hackers ”(2010)."
2,Bibliography,363,Further Reading,"288 Chapter 6 Synchronization Tools
6.5Illustrate how a binary semaphore can be used to implement mutual
exclusionamong nprocesses.
6.6Race conditions are possible in many computer systems. Consider a
banking system that maintains an account balance with two functions:
deposit(amount) and withdraw(amount) . These two functions are
passed the amountthat is to be deposited or withdrawn from the bank
accountbalance.Assumethatahusbandandwifeshareabankaccount.
Concurrently, the husband calls the withdraw() function, and the wife
calls deposit() . Describe how a race condition is possible and what
mightbe doneto preventtherace conditionfromoccurring.
Further Reading
The mutual-exclusion problem was first discussed in a classic paper by [Dijk-
stra (1965)]. The semaphore concept was suggested by [Dijkstra (1965)]. The
monitor concept was developed by [Brinch-Hansen (1973)]. [Hoare (1974)]
gavea completedescriptionofthe monitor.
FormoreontheMarsPathfinderproblemsee http://research.microsoft.co
m/en-us/um/people/mbj/mars
 pathﬁnder/authoritative
 account.html
Athoroughdiscussionofmemorybarriersandcachememoryispresented
in [Mckenney (2010)]. [Herlihy and Shavit (2012)] presents details on several
issuesrelatedtomultiprocessorprogramming,includingmemorymodelsand
compare-and-swap instructions. [Bahra (2013)] examines nonblocking algo-
rithmson modernmulticoresystems.
Bibliography
[Bahra (2013)] S. A. Bahra, “Nonblocking Algorithms and Scalable Multicore
Programming ”,ACM queue,Volume11,Number5 (2013).
[Brinch-Hansen (1973)] P. Brinch-Hansen, Operating System Principles ,P r e n t i c e
Hall (1973).
[Dijkstra (1965)] E. W. Dijkstra, “Cooperating Sequential Processes ”, Technical
report,TechnologicalUniversity,E indhoven,theNetherlands(1965).
[Herlihy and Shavit (2012)] M. Herlihy and N. Shavit, The Art of Multiprocessor
Programming, Revised First Edition, MorganK aufmannPublishers Inc. (2012).
[Hoare (1974)] C. A. R. Hoare, “Monitors: An Operating System Structuring
Concept ”,Communications of the ACM , Volume 17, Number 10 (1974), pages
549–557.
[Mckenney (2010)] P. E. Mckenney, “Memory Barriers: a Hardware View for
Software Hackers ”(2010)."
2,Chapter 6 Exercises,364,Bibliography,"Chapter 6 Exercises
6.7The pseudocode of Figure 6.15 illustrates the basic push()andpop()
operations of an array-based stack. Assuming that this algorithm could
be used in a concurrent environment, answer the following questions:
a. What datahave arace condition?
b. How could the race condition be fixed?
6.8Race conditions are possible in many computer systems. Consider an
online auction system where the current highest bid for each item
must be maintained. A person who wishes to bid on an item calls the
bid(amount) function, which compares the amount being bid to the
current highest bid. If the amount exceeds the current highest bid, the
highestbid issettothe new amount. Thisisillustratedbelow:
void bid(double amount) {
if (amount > highestBid)
highestBid = amount;
}
push(item) {
if (top < SIZE) {
stack[top] = item;
top++;
}
else
ERROR
}
pop() {
if (!is
 empty()) {
top--;
return stack[top];
}
else
ERROR
}
is
empty() {
if (top == 0)
return true;
else
return false;
}
Figure 6.16 Array-based stack for Exercise 6.12.EX-17"
2,Programming Problems,373,Chapter 6 Exercises,"Chapter 6 Synchronization Tools
Programming Problems
6.33Assumethatafinitenumberofresourcesofasingleresourcetypemust
bemanaged.Processesmayaskforanumberoftheseresourcesandwill
return them once finished. As an example, many commercial software
packages provide a given number of licenses, indicating the number of
applicationsthatmayrunconcurrently.Whentheapplicationisstarted,
the license count is decremented. W hen the application is terminated,
the license count is incremented. I f all licenses are in use, requests to
start the application are denied. Such a request will be granted only
whenanexistinglicenseholderterm inatestheapplicationandalicense
isreturned.
Thefollowingprogramsegmentisusedtomanageafinitenumberof
instances of an available resource. The maximum number of resources
and thenumber of availableresourcesaredeclaredasfollows:
#define MAX
 RESOURCES 5
int available
 resources = MAX
 RESOURCES;
When a process wishes to obtain a number of resources, it invokes the
decrease
 count() function:
/* decrease available
 resources by count resources */
/* return 0 if sufficient resources available, */
/* otherwise return -1 */
int decrease
 count(int count) {
if (available
 resources <count)
return -1;
else {
available
 resources -= count;
return 0;
}
}
When a process wants to return a number of resources, it calls the
increase
 count() function:
/* increase available
 resources by count */
int increase
 count(int count) {
available
 resources += count;
return 0;
}
The preceding program segment produces a race condition. Do the fol-
lowing:
a. Identifythedatainvolvedintherace condition.P-32"
1,Chapter 7 Synchronization Examples,375,Chapter 6 Synchronization Tools,"7CHAPTER
Synchronization
Examples
In Chapter 6, we presented the critical-section problem and focused on how
race conditions can occur when multiple concurrent processes share data. We
went on to examine several tools that address the critical-section problem by
preventingrace conditions from occurring. Thesetools rangedfrom low-level
hardwaresolutions(suchasmemorybarriersandthecompare-and-swapoper-
ation) to increasingly higher-level tools (from mutex locks to semaphores to
monitors).Wealsodiscussedvariousch allengesindesigningapplicationsthat
are free from race conditions, includ ing liveness hazards such as deadlocks.
In this chapter, we apply the tools presented in Chapter 6 to several classic
synchronization problems. We also explore the synchronization mechanisms
used by the Linux, UNIX, and Windows operating systems, and we describe
APIdetailsfor bothJava and POSIXsystems.
CHAPTER OBJECTIVES
•Explain the bounded-buffer, readers–writers, and dining–philosophers
synchronization problems.
•Describe specific tools used by Linux and Windows to solve process
synchronization problems.
•Illustrate how POSIXand Java can be used to solve process synchroniza-
tion problems.
•Design and develop solutions to process synchronization problems using
POSIXand Java APIs.
7.1 Classic Problems of Synchronization
Inthissection,wepresentanumberofsynchronizationproblemsasexamples
of a large class of concurrency-control problems. These problems are used for
testingnearlyeverynewlyproposedsynchronizationscheme.Inoursolutions
to the problems, we use semaphores for synchronization, since that is the
289"
2,7.1 Classic Problems of Synchronization,375,Chapter 7 Synchronization Examples,"7CHAPTER
Synchronization
Examples
In Chapter 6, we presented the critical-section problem and focused on how
race conditions can occur when multiple concurrent processes share data. We
went on to examine several tools that address the critical-section problem by
preventingrace conditions from occurring. Thesetools rangedfrom low-level
hardwaresolutions(suchasmemorybarriersandthecompare-and-swapoper-
ation) to increasingly higher-level tools (from mutex locks to semaphores to
monitors).Wealsodiscussedvariousch allengesindesigningapplicationsthat
are free from race conditions, includ ing liveness hazards such as deadlocks.
In this chapter, we apply the tools presented in Chapter 6 to several classic
synchronization problems. We also explore the synchronization mechanisms
used by the Linux, UNIX, and Windows operating systems, and we describe
APIdetailsfor bothJava and POSIXsystems.
CHAPTER OBJECTIVES
•Explain the bounded-buffer, readers–writers, and dining–philosophers
synchronization problems.
•Describe specific tools used by Linux and Windows to solve process
synchronization problems.
•Illustrate how POSIXand Java can be used to solve process synchroniza-
tion problems.
•Design and develop solutions to process synchronization problems using
POSIXand Java APIs.
7.1 Classic Problems of Synchronization
Inthissection,wepresentanumberofsynchronizationproblemsasexamples
of a large class of concurrency-control problems. These problems are used for
testingnearlyeverynewlyproposedsynchronizationscheme.Inoursolutions
to the problems, we use semaphores for synchronization, since that is the
289"
3,7.1.1 The Bounded-Buffer Problem,376,7.1 Classic Problems of Synchronization,"290 Chapter 7 Synchronization Examples
while (true) {
...
/* produce an item in next
 produced */
...
wait(empty);
wait(mutex);
...
/* add next
 produced to the buffer */
...
signal(mutex);
signal(full);
}
Figure 7.1 The structure of the producer process.
traditional way to present such solutions. However, actual implementations
of thesesolutionscould usemutexlocks in placeof binary semaphores.
7.1.1 The Bounded-Buffer Problem
Thebounded-bufferproblem wasintroducedinSection6.1;itiscommonlyused
to illustrate the power of synchronization primitives. Here, we present a gen-
eral structure of this scheme without committing ourselves to any particular
implementation.Weprovidearelatedprogrammingprojectintheexercisesat
the end ofthe chapter.
Inourproblem,theproducerandconsumerprocessessharethefollowing
datastructures:
int n;
semaphore mutex = 1;
semaphore empty = n;
semaphore full = 0
Weassumethatthepoolconsistsof nbuffers,eachcapableofholdingoneitem.
Themutexbinary semaphore provides mutual exclusion for accesses to the
buffer pool and is initialized to the value 1. The emptyandfullsemaphores
countthenumberofemptyandfullbuffers.Thesemaphore emptyisinitialized
to thevalue n;th esema ph o r e fullisinitializedto thevalue0.
T h ec o d ef o rt h ep r o d u c e rp r o c e s si ss h o w ni nF i g u r e7 . 1 ,a n dt h ec o d e
for the consumer process is shown in Figure 7.2. Note the symmetry between
the producer and the consumer. We can interpret this code as the producer
producing full buffers for the consumer or as the consumer producing empty
buffersfor the producer.
7.1.2 The Readers–Writers Problem
Suppose that a database is to be shared among several concurrent processes.
Some of these processes may want only to read the database, whereas others
may want to update (that is, read and write) the database. We distinguish"
3,7.1.2 The Readers–Writers Problem,376,7.1.1 The Bounded-Buffer Problem,"290 Chapter 7 Synchronization Examples
while (true) {
...
/* produce an item in next
 produced */
...
wait(empty);
wait(mutex);
...
/* add next
 produced to the buffer */
...
signal(mutex);
signal(full);
}
Figure 7.1 The structure of the producer process.
traditional way to present such solutions. However, actual implementations
of thesesolutionscould usemutexlocks in placeof binary semaphores.
7.1.1 The Bounded-Buffer Problem
Thebounded-bufferproblem wasintroducedinSection6.1;itiscommonlyused
to illustrate the power of synchronization primitives. Here, we present a gen-
eral structure of this scheme without committing ourselves to any particular
implementation.Weprovidearelatedprogrammingprojectintheexercisesat
the end ofthe chapter.
Inourproblem,theproducerandconsumerprocessessharethefollowing
datastructures:
int n;
semaphore mutex = 1;
semaphore empty = n;
semaphore full = 0
Weassumethatthepoolconsistsof nbuffers,eachcapableofholdingoneitem.
Themutexbinary semaphore provides mutual exclusion for accesses to the
buffer pool and is initialized to the value 1. The emptyandfullsemaphores
countthenumberofemptyandfullbuffers.Thesemaphore emptyisinitialized
to thevalue n;th esema ph o r e fullisinitializedto thevalue0.
T h ec o d ef o rt h ep r o d u c e rp r o c e s si ss h o w ni nF i g u r e7 . 1 ,a n dt h ec o d e
for the consumer process is shown in Figure 7.2. Note the symmetry between
the producer and the consumer. We can interpret this code as the producer
producing full buffers for the consumer or as the consumer producing empty
buffersfor the producer.
7.1.2 The Readers–Writers Problem
Suppose that a database is to be shared among several concurrent processes.
Some of these processes may want only to read the database, whereas others
may want to update (that is, read and write) the database. We distinguish"
3,7.1.3 The Dining-Philosophers Problem,379,7.1.2 The Readers–Writers Problem,"7.1 Classic Problems of Synchronization 293
process wishes only to read shared data, it requests the reader–writer lock
in read mode. Aprocess wishing to modify the shared data must request the
lock in write mode. Multiple processes are permitted to concurrently acquire
a reader–writerlock in readmode,but only one process may acquire the lock
forwriting,as exclusiveaccess isrequiredfor writers.
Reader–writerlocks are most usefulin the following situations:
•In applications where it is easy to identify which processes only read
shareddata andwhich processesonly writeshareddata.
•In applications that have more readers than writers. This is because
reader–writer locks generally require more overhead to establish than
semaphores or mutual-exclusion locks. The increased concurrency of
allowing multiple readers compensates for the overhead involved in
settingup thereader–writerlock.
7.1.3 The Dining-Philosophers Problem
Consider five philosophers who spend t heir lives thinking and eating. The
philosophersshareacirculartablesurroundedbyfivechairs,eachbelongingto
onephilosopher.Inthecenterofthetab leisabowlofrice,andthetableislaid
with five single chopsticks (Figure 7.5). When a philosopher thinks, she does
notinteractwithhercolleagues.Fromtimetotime,aphilosophergetshungry
and tries to pick up the two chopsticks that are closest to her (the chopsticks
thatarebetweenherandherleftandrightneighbors).Aphilosophermaypick
uponlyonechopstickatatime.Obviously,shecannotpickupachopstickthat
isalreadyinthe hand ofa neighbor. When ahungry philosopherhasboth her
chopsticks at the same time, she eats w ithout releasing the chopsticks. When
sheisfinishedeating,sheputsdownbothchopsticksandstartsthinkingagain.
The dining-philosophers problem isconsideredaclassicsynchronization
problem neither because of its practical importance nor because computer
scientists dislike philosophers but because it is an example of a large class
of concurrency-control problems. It is a simple representation of the need
RICE
Figure 7.5 The situation of the dining philosophers."
2,7.2 Synchronization within the Kernel,381,7.1 Classic Problems of Synchronization,"7.2 Synchronization within the Kernel 295
thatoneofthephilosopherswillstarvetodeath.Adeadlock-freesolutiondoes
not necessarilyeliminatethepossibilityofstarvation.
7.1.3.2 Monitor Solution
Next,weillustratemonitorconceptsbypresentingadeadlock-freesolutionto
the dining-philosophers problem. This s olution imposes the restriction that a
philosopher may pick up her chopsticks only if both of them are available. To
codethissolution,weneedtodistinguishamongthreestatesinwhichwemay
findaphilosopher.Forthispurpose,weintroducethefollowingdatastructure:
enum {THINKING, HUNGRY, EATING }state[5];
Philosopher ican set the variable state[i] = EATING only if her two neigh-
bors are not eating: ( state[(i+4) % 5] != EATING )a n d( state[(i+1) %
5] != EATING ).
We alsoneedto declare
condition self[5];
This allows philosopher ito delayherself when she is hungry but isunable to
obtain thechopsticks sheneeds.
We are now in a position to describe our solution to the dining-
philosophers problem. The distribution of the chopsticks is controlled by
the monitor DiningPhilosophers , whose definition is shown in Figure 7.7.
Eachphilosopher,beforestartingtoeat,mustinvoketheoperation pickup() .
This act may result in the suspension of the philosopher process. After the
successful completion of the operation, the philosopher may eat. Following
this, the philosopher invokes the putdown() operation. Thus, philosopher
imust invoke the operations pickup() and putdown() in the following
sequence:
DiningPhilosophers.pickup(i);
...
eat
...
DiningPhilosophers.putdown(i);
It is easy to show that this solution ensures that no two neighbors are
eating simultaneouslyand that no deadlocks will occur. As we alreadynoted,
however, it is possible for a philosopher to starve to death. We do not present
asolutionto thisproblembut ratherleaveitasan exercisefor you.
7.2 Synchronization within the Kernel
We next describe the synchronization mechanisms provided by the Windows
and Linux operating systems. These two operating systems provide good
examplesof differentapproachesto synchronizing the kernel,and as you will"
3,7.2.1 Synchronization in Windows,382,7.2 Synchronization within the Kernel,"296 Chapter 7 Synchronization Examples
monitor DiningPhilosophers
{
enum {THINKING, HUNGRY, EATING }state[5];
condition self[5];
void pickup(int i) {
state[i] = HUNGRY;
test(i);
if (state[i] != EATING)
self[i].wait();
}
void putdown(int i) {
state[i] = THINKING;
test((i + 4) % 5);
test((i + 1) % 5);
}
void test(int i) {
if ((state[(i + 4) % 5] != EATING) &&
(state[i] == HUNGRY) &&
(state[(i + 1) % 5] != EATING)) {
state[i] = EATING;
self[i].signal();
}
}
initialization
 code() {
for (int i = 0; i < 5; i++)
state[i] = THINKING;
}
}
Figure 7.7 A monitor solution to the dining-philosophers problem.
see,thesynchronizationmechanismsavailableinthesesystemsdifferinsubtle
yetsignificant ways.
7.2.1 Synchronization in Windows
The Windows operating system is a multi threaded kernel that provides sup-
port for real-time applications and multiple processors. When the Windows
kernel accesses a global resource on a single-processor system, it temporar-
ily masks interrupts for all interrupt handlers that may also access the global
resource. On a multiprocessor system, Windows protects access to global
resources using spinlocks, although th e kernel uses spinlocks only to protect
shortcodesegments.Furthermore,forreasonsofefficiency,thekernelensures
that a threadwillneverbe preemptedwhile holding aspinlock."
3,7.2.2 Synchronization in Linux,384,7.2.1 Synchronization in Windows,"298 Chapter 7 Synchronization Examples
We provide a programming project at the end of this chapter that uses
mutexlocks and semaphoresin the Windows API.
7.2.2 Synchronization in Linux
PriortoVersion2.6,Linuxwasanonpreemptivekernel,meaningthataprocess
running in kernel mode could not be preempted—even if a higher-priority
process became available to run. Now, however, the Linux kernel is fully
preemptive,so a taskcan bepreemptedwhenitis running inthekernel.
Linux provides several different mechanisms for synchronization in
the kernel. As most computer architectures provide instructions for atomic
versions of simple math operations, th e simplest synchronization technique
within the Linux kernel is an atomic in teger, which is represented using the
opaque data type atomic
 t. As the name implies, all math operations using
atomic integers are performed without interruption. To illustrate, consider a
programthat consists of anatomic integer counter and aninteger value.
atomic
 t counter;
int value;
The following code illustrates the effect of performing various atomic opera-
tions:
AtomicOperation
 Effect
atomic
 set(&counter,5);
 counter = 5
atomic
 add(10,&counter);
 counter = counter + 10
atomic
 sub(4,&counter);
 counter = counter - 4
atomic
 inc(&counter);
 counter = counter + 1
value = atomic
 read(&counter);
 value = 12
Atomic integers are particularly efficient in situations where an integer
variable—suchasacounter—needstobeupdated,sinceatomicoperationsdo
notrequiretheoverheadoflockingmechanisms.However,theiruseislimited
to these sorts of scenarios. In situations where there are several variables
contributingtoapossibleracecondition,moresophisticatedlockingtoolsmust
be used.
MutexlocksareavailableinLinuxforprotectingcriticalsectionswithinthe
kernel. Here, a task must invoke the mutex
 lock()function prior to entering
a critical section and the mutex
 unlock() function after exiting the critical
section.Ifthemutexlockisunavailable,ataskcalling mutex
 lock()isputinto
asleepstateandisawakenedwhenthelock’sownerinvokes mutex
 unlock() .
Linux also provides spinlocks and semaphores (as well as reader–writer
versionsofthesetwolocks)forlockinginthekernel.On SMPmachines,thefun-
damental locking mechanism is a spinl ock, and the kernel is designed so that
the spinlock is held only for short durations. On single-processor machines,
such as embedded systems with only a single processing core, spinlocks are
inappropriate for use and are replaced by enabling and disabling kernel pre-
emption.Thatis,onsystemswithasingleprocessingcore,ratherthanholding
aspinlock,thekerneldisableskernelpreemption;andratherthanreleasingthe
spinlock,it enableskernelpreemption.This issummarizedbelow:"
2,7.3 POSIX Synchronization,385,7.2 Synchronization within the Kernel,"7.3 POSIX Synchronization 299
Single Processor Multiple Processors
Acquire spin lock
Release spin lockDisable kernel preemption
Enable kernel preemption
In the Linux kernel, both spinlocks and mutex locks are nonrecursive ,
which meansthatifathreadhasacquiredone oftheselocks,itcannot acquire
the same lock a second time without first releasing the lock. Otherwise, the
second attemptatacquiring the lock willblock.
Linux uses an interesting approach to disable and enable kernel preemp-
tion. It provides two simple system calls— preempt
 disable() and pre-
empt
 enable() —fordisablingandenablingkernelpreemption.Thekernelis
not preemptible, however, if a task running in the kernel is holding a lock. To
enforcethisrule,eachtaskinthesystemhasa thread-info structurecontain-
ing a counter, preempt
 count, to indicate the number of locks being held by
the task. When a lock is acquired, preempt
 countis incremented. It is decre-
mented when a lock is released. If the value of preempt
 countfor the task
currentlyrunninginthekernelisgreaterthan0,itisnotsafetopreempttheker-
nel,asthistaskcurrentlyholdsalock.Ifthecountis0,thekernelcansafelybe
interrupted(assumingtherearenooutstandingcallsto preempt
 disable() ).
Spinlocks—along with enabling and disabling kernel preemption—are
used in the kernel only when a lock (or disabling kernel preemption) is held
forashortduration.Whenalockmustbeheldforalongerperiod,semaphores
ormutexlocks areappropriatefor use.
7.3 POSIX Synchronization
The synchronization methods discusse d in the preceding section pertain to
synchronization within the kernel and are therefore available only to kernel
developers.Incontrast, the POSIX API isavailableforprogrammersat theuser
level and is not part of any particular operating-system kernel. (Of course, it
must ultimately be implemented using tools provided by the host operating
system.)
Inthissection,wecovermutexlocks,semaphores,andconditionvariables
that are available in the Pthreads and POSIX API s. These APIsa r ew i d e l yu s e d
for thread creation and synchronization by developers on UNIX,L i n u x ,a n d
macOSsystems.
7.3.1 POSIX Mutex Locks
Mutex locks represent the fundamental synchronization technique used with
Pthreads. A mutex lock is used to protect critical sections of code—that is, a
thread acquires the lock before entering a critical section and releases it upon
exiting the critical section. Pthreads uses the pthread
 mutex
 tdata type for
mutex locks. A mutex is created with the pthread
 mutex
 init()function.
The first parameter is a pointer to the mutex. By passing NULLas a second
parameter, we initialize the mutex to its default attributes. This is illustrated
below:"
3,7.3.1 POSIX Mutex Locks,385,7.3 POSIX Synchronization,"7.3 POSIX Synchronization 299
Single Processor Multiple Processors
Acquire spin lock
Release spin lockDisable kernel preemption
Enable kernel preemption
In the Linux kernel, both spinlocks and mutex locks are nonrecursive ,
which meansthatifathreadhasacquiredone oftheselocks,itcannot acquire
the same lock a second time without first releasing the lock. Otherwise, the
second attemptatacquiring the lock willblock.
Linux uses an interesting approach to disable and enable kernel preemp-
tion. It provides two simple system calls— preempt
 disable() and pre-
empt
 enable() —fordisablingandenablingkernelpreemption.Thekernelis
not preemptible, however, if a task running in the kernel is holding a lock. To
enforcethisrule,eachtaskinthesystemhasa thread-info structurecontain-
ing a counter, preempt
 count, to indicate the number of locks being held by
the task. When a lock is acquired, preempt
 countis incremented. It is decre-
mented when a lock is released. If the value of preempt
 countfor the task
currentlyrunninginthekernelisgreaterthan0,itisnotsafetopreempttheker-
nel,asthistaskcurrentlyholdsalock.Ifthecountis0,thekernelcansafelybe
interrupted(assumingtherearenooutstandingcallsto preempt
 disable() ).
Spinlocks—along with enabling and disabling kernel preemption—are
used in the kernel only when a lock (or disabling kernel preemption) is held
forashortduration.Whenalockmustbeheldforalongerperiod,semaphores
ormutexlocks areappropriatefor use.
7.3 POSIX Synchronization
The synchronization methods discusse d in the preceding section pertain to
synchronization within the kernel and are therefore available only to kernel
developers.Incontrast, the POSIX API isavailableforprogrammersat theuser
level and is not part of any particular operating-system kernel. (Of course, it
must ultimately be implemented using tools provided by the host operating
system.)
Inthissection,wecovermutexlocks,semaphores,andconditionvariables
that are available in the Pthreads and POSIX API s. These APIsa r ew i d e l yu s e d
for thread creation and synchronization by developers on UNIX,L i n u x ,a n d
macOSsystems.
7.3.1 POSIX Mutex Locks
Mutex locks represent the fundamental synchronization technique used with
Pthreads. A mutex lock is used to protect critical sections of code—that is, a
thread acquires the lock before entering a critical section and releases it upon
exiting the critical section. Pthreads uses the pthread
 mutex
 tdata type for
mutex locks. A mutex is created with the pthread
 mutex
 init()function.
The first parameter is a pointer to the mutex. By passing NULLas a second
parameter, we initialize the mutex to its default attributes. This is illustrated
below:"
3,7.3.2 POSIX Semaphores,386,7.3.1 POSIX Mutex Locks,"300 Chapter 7 Synchronization Examples
#include <pthread.h >
pthread
 mutex
 t mutex;
/* create and initialize the mutex lock */
pthread
 mutex
 init(&mutex,NULL);
The mutex is acquired and releasedwith the pthread
 mutex
 lock()and
pthread
 mutex
 unlock() functions. If the mutex lock is unavailable when
pthread
 mutex
 lock() is invoked, the calling thread is blocked until the
owner invokes pthread
 mutex
 unlock() .Thefollowingcodeillustratespro-
tectinga critical sectionwithmutexlocks:
/* acquire the mutex lock */
pthread
 mutex
 lock(&mutex);
/* critical section */
/* release the mutex lock */
pthread
 mutex
 unlock (&mutex);
Allmutexfunctionsreturnavalueof0withcorrectoperation;ifanerroroccurs,
these functions return a nonzero error code.
7.3.2 POSIX Semaphores
Many systems that implement Pthreads also provide semaphores, although
semaphores are not part of the POSIXstandard and instead belong to the
POSIX SEM extension. POSIXspecifies two types of semaphores— namedand
unnamed .Fundamentally,thetwoarequitesimilar,buttheydifferintermsof
how they are created and shared between processes. Because both techniques
are common, we discuss both here. Beginning with Version 2.6 of the kernel,
Linuxsystemsprovidesupportforboth namedand unnamed semaphores.
7.3.2.1 POSIX Named Semaphores
Thefunction sem
open()isusedtocreateandopena POSIXnamedsempahore:
#include <semaphore.h >
sem
t *sem;
/* Create the semaphore and initialize it to 1 */
sem = sem
 open (""SEM"", O
 CREAT, 0666, 1);
Inthisinstance,wearenamingthesemaphore SEM.The O
CREATflagindicates
thatthesemaphorewillbecreatedifitdoesnotalreadyexist.Additionally,the
semaphore has read and write access for other processes (via the parameter
0666)and isinitializedto 1.
The advantage of named semaphores is that multiple unrelated processes
can easily use a common semaphore as a synchronization mechanism by"
3,7.3.3 POSIX Condition Variables,388,7.3.2 POSIX Semaphores,"302 Chapter 7 Synchronization Examples
/* acquire the semaphore */
sem
wait(&sem);
/* critical section */
/* release the semaphore */
sem
post(&sem);
Just like mutex locks, all semaphore functions return 0 when successful and
nonzero when an errorcondition occurs.
7.3.3 POSIX Condition Variables
ConditionvariablesinPthreadsbehavesimilarlytothosedescribedinSection
6.7. However, in that section, condition variables are used within the context
of a monitor, which provides a locking mechanism to ensure data integrity.
Since Pthreads is typically used in C programs—and since C does not have a
monitor— we accomplish locking by associating a condition variable with a
mutexlock.
Condition variables in Pthreads use the pthread
 cond
 tdata type and
are initialized using the pthread
 cond
 init()function. The following code
createsandinitializesaconditionvariableaswellasitsassociatedmutexlock:
pthread
 mutex
 t mutex;
pthread
 cond
 t cond
 var;
pthread
 mutex
 init(&mutex,NULL);
pthread
 cond
 init(&cond
 var,NULL);
The pthread
 cond
 wait()function is used for waiting on a condition
variable.Thefollowingcodeillustrateshowathreadcanwaitforthecondition
a= =bto becometrueusinga Pthreadcondition variable:
pthread
 mutex
 lock(&mutex);
while (a != b)
pthread
 cond
 wait(&cond
 var, &mutex);
pthread
 mutex
 unlock(&mutex);
The mutex lock associated with the condition variable must be locked
before the pthread
 cond
 wait()function is called, since it is used to protect
thedataintheconditionalclausefromapossibleracecondition.Oncethislock
is acquired, the thread can check the condition. If the condition is not true,
the thread then invokes pthread
 cond
 wait(), passing the mutex lock and
the condition variable as parameters. Calling pthread
 cond
 wait()releases
themutexlock,therebyallowinganotherthreadtoaccesstheshareddataand
possibly update its value so that the condition clause evaluates to true. (To
protect against program errors, it is im portant to place the conditional clause
within a loop sothat the condition is recheckedafterbeingsignaled.)"
2,7.4 Synchronization in Java,389,7.3 POSIX Synchronization,"7.4 Synchronization in Java 303
Athreadthatmodifiestheshareddatacaninvokethe pthread
 cond
 signal()
function, thereby signaling one thread waiting on the condition variable.This
isillustratedbelow:
pthread
 mutex
 lock(&mutex);
a=b ;
pthread
 cond
 signal (&cond
 var);
pthread
 mutex
 unlock(&mutex);
It is important to note that the call to pthread
 cond
 signal() does not
release the mutex lock. It is the subsequent call to pthread
 mutex
 unlock()
that releases the mutex. Once the mutex lock is released, the signaled thread
becomes the owner of the mutex lock and returns control from the call to
pthread
 cond
 wait().
We provideseveralprogrammingproblemsand projectsattheendof this
chapterthatusePthreadsmutexlocksandconditionvariables,aswellas POSIX
semaphores.
7.4 Synchronization in Java
The Java language and its APIhave provided rich support for thread syn-
chronization since the origins of the language. In this section, we first cover
Javamonitors,Java’soriginalsynchronizationmechanism.Wethencoverthree
additional mechanisms that were intr oduced in Release 1.5: reentrant locks,
semaphores,andconditionvariables.Weincludethesebecausetheyrepresent
the most common locking and synchronization mechanisms. However, the
JavaAPIprovides many features that we do not cover in this text—for exam-
ple,supportfor atomic variablesand the CASinstruction—and we encourage
interestedreaderstoconsult the bibliography for moreinformation.
7.4.1 Java Monitors
Java provides a monitor-like concurr ency mechanism for thread synchroniza-
tion. We illustrate this mechanism with the BoundedBuffer class (Figure 7.9),
whichimplementsasolutiontothebounded-bufferproblemwhereinthepro-
ducer and consumer invoke the insert() and remove() methods, respec-
tively.
EveryobjectinJavahasassociatedwithitasinglelock.Whenamethodis
declaredtobe synchronized ,callingthemethodrequiresowningthelockfor
the object. We declare a synchronized method by placing the synchronized
keyword in the method definition, such as with the insert() andremove()
methodsinthe BoundedBuffer class.
Invoking a synchronized method requires owning the lock on an object
instance of BoundedBuffer . If the lock is already owned by another thread,
thethreadcallingthe synchronized methodblocksandisplacedinthe entry
setfor the object’s lock. The entry set represents the set of threads waiting for
the lock to become available. If the lock is available when a synchronized
methodiscalled,thecallingthreadbec omestheowneroftheobject’slockand
can enter the method. The lock is released when the thread exits the method.
If the entry set for the lock is not empty when the lock is released, the JVM"
3,7.4.1 Java Monitors,389,7.4 Synchronization in Java,"7.4 Synchronization in Java 303
Athreadthatmodifiestheshareddatacaninvokethe pthread
 cond
 signal()
function, thereby signaling one thread waiting on the condition variable.This
isillustratedbelow:
pthread
 mutex
 lock(&mutex);
a=b ;
pthread
 cond
 signal (&cond
 var);
pthread
 mutex
 unlock(&mutex);
It is important to note that the call to pthread
 cond
 signal() does not
release the mutex lock. It is the subsequent call to pthread
 mutex
 unlock()
that releases the mutex. Once the mutex lock is released, the signaled thread
becomes the owner of the mutex lock and returns control from the call to
pthread
 cond
 wait().
We provideseveralprogrammingproblemsand projectsattheendof this
chapterthatusePthreadsmutexlocksandconditionvariables,aswellas POSIX
semaphores.
7.4 Synchronization in Java
The Java language and its APIhave provided rich support for thread syn-
chronization since the origins of the language. In this section, we first cover
Javamonitors,Java’soriginalsynchronizationmechanism.Wethencoverthree
additional mechanisms that were intr oduced in Release 1.5: reentrant locks,
semaphores,andconditionvariables.Weincludethesebecausetheyrepresent
the most common locking and synchronization mechanisms. However, the
JavaAPIprovides many features that we do not cover in this text—for exam-
ple,supportfor atomic variablesand the CASinstruction—and we encourage
interestedreaderstoconsult the bibliography for moreinformation.
7.4.1 Java Monitors
Java provides a monitor-like concurr ency mechanism for thread synchroniza-
tion. We illustrate this mechanism with the BoundedBuffer class (Figure 7.9),
whichimplementsasolutiontothebounded-bufferproblemwhereinthepro-
ducer and consumer invoke the insert() and remove() methods, respec-
tively.
EveryobjectinJavahasassociatedwithitasinglelock.Whenamethodis
declaredtobe synchronized ,callingthemethodrequiresowningthelockfor
the object. We declare a synchronized method by placing the synchronized
keyword in the method definition, such as with the insert() andremove()
methodsinthe BoundedBuffer class.
Invoking a synchronized method requires owning the lock on an object
instance of BoundedBuffer . If the lock is already owned by another thread,
thethreadcallingthe synchronized methodblocksandisplacedinthe entry
setfor the object’s lock. The entry set represents the set of threads waiting for
the lock to become available. If the lock is available when a synchronized
methodiscalled,thecallingthreadbec omestheowneroftheobject’slockand
can enter the method. The lock is released when the thread exits the method.
If the entry set for the lock is not empty when the lock is released, the JVM"
3,7.4.2 Reentrant Locks,393,7.4.1 Java Monitors,"7.4 Synchronization in Java 307
entry set wait setacquire lock wait
object
lock
owner
Figure 7.12 Entry and wait sets.
Next, we describe the wait()and notify() methods in terms of the
methods shown in Figure 7.11. We assume that the buffer is full and the lock
forthe objectis available.
•The producer calls the insert() method, sees that the lock is available,
andentersthemethod.Once inthemethod,theproducerdeterminesthat
the buffer is full and calls wait().T h ec a l lt o wait()releasesthe lock for
theobject,setsthestateoftheproducertoblocked,andputstheproducer
in the waitsetfor theobject.
•The consumer ultimately calls and enters the remove() method, as the
lock for the object is now available. The consumer removes an item from
the buffer and calls notify() . Note that the consumer still owns the lock
for the object.
•The call to notify() removes the producer from the wait set for the
object, moves the producer to the entry set, and sets the producer’s state
to runnable.
•Theconsumerexitsthe remove() method.Exitingthismethodreleasesthe
lock for the object.
•Theproducertriestoreacquirethelockandissuccessful.Itresumesexecu-
tionfromthecallto wait().Theproducerteststhe whileloop,determines
thatroomisavailableinthebuffer,andproceedswiththeremainderofthe
insert() method. If no thread is in the wait set for the object, the call to
notify() is ignored. When the producer exits the method, it releases the
lock for the object.
Thesynchronized ,wait(),and notify() mechanismshavebeenpartof
Javasinceitsorigins.However,laterrevisionsoftheJava APIintroducedmuch
more flexible and robust locking mechanisms, some of which we examine in
the following sections.
7.4.2 Reentrant Locks
Perhapsthesimplestlockingmechanismavailableinthe APIisthe Reentrant-
Lock. In many ways, a ReentrantLock acts like the synchronized statement
describedinSection7.4.1:a ReentrantLock isownedbyasinglethreadandis
used to provide mutually exclusive access to a shared resource. However, the
ReentrantLock providesseveraladditionalfeatures,suchassettinga fairness
parameter,whichfavorsgrantingthelock tothelongest-waitingthread.(Recall"
3,7.4.3 Semaphores,394,7.4.2 Reentrant Locks,"308 Chapter 7 Synchronization Examples
that the specification for the JVMdoes not indicate that threads in the wait set
for an object lock are tobe orderedin any specific fashion.)
Athreadacquiresa ReentrantLock lock by invoking its lock()method.
If the lock is available—or if the thread invoking lock()already owns it,
which is why it is termed reentrant —lock()assigns the invoking thread
lock ownership and returns control. If the lock is unavailable, the invoking
thread blocks until it is ultimately assigned the lock when its owner invokes
unlock() .ReentrantLock implementsthe Lockinterface;itisusedasfollows:
Lock key = new ReentrantLock();
key. lock();
try {
/* critical section */
}
finally {
key. unlock ();
}
Theprogrammingidiomofusing tryandfinally requiresabitofexpla-
nation. If the lock is acquired via the lock()method, it is important that the
lock be similarly released. By enclosing unlock() in a finally clause, we
ensurethatthelockisreleasedoncethecriticalsectioncompletesorifanexcep-
tionoccurswithinthe tryblock.Noticethatwedonotplacethecallto lock()
withinthe tryclause,as lock()doesnotthrowanycheckedexceptions.Con-
siderwhathappensifweplace lock()withinthe tryclauseandanunchecked
exception occurs when lock()is invoked (such as OutofMemoryError ): The
finally clausetriggersthecallto unlock() ,whichthenthrowstheunchecked
IllegalMonitorStateException ,asthelockwasneveracquired.This Ille-
galMonitorStateException replacestheuncheckedexceptionthatoccurred
when lock()was invoked, thereby obscuring the reason why the program
initiallyfailed.
Whereas a ReentrantLock provides mutual exclusion, it may be too con-
servative a strategy if multiple threads only read, but do not write, shared
data. (We described this scenario in Section 7.1.2.) To address this need, the
JavaAPIalsoprovidesa ReentrantReadWriteLock ,whichisalockthatallows
multipleconcurrent readersbutonly one writer.
7.4.3 Semaphores
The Java APIalso provides a counting semaphore, as described in Section 6.6.
The constructor for the semaphore appearsas
Semaphore(int value);
where valuespecifies the initial value of the semaphore (a negative value
is allowed). The acquire() method throws an InterruptedException if
the acquiring thread is interrupted. The following example illustrates using
a semaphore formutual exclusion:"
3,7.4.4 Condition Variables,395,7.4.3 Semaphores,"7.4 Synchronization in Java 309
Semaphore sem = new Semaphore(1);
try {
sem. acquire ();
/* critical section */
}
catch (InterruptedException ie) {}
finally {
sem. release ();
}
Noticethatweplacethecallto release() inthe finally clausetoensurethat
the semaphore is released.
7.4.4 Condition Variables
The last utility we cover in the Java APIis the condition variable. Just as
theReentrantLock is similar to Java’s synchronized statement, condition
variables providefunctionality similar to the wait()andnotify() methods.
Therefore,toprovidemutualexclusion,aconditionvariablemustbeassociated
with areentrantlock.
We create a condition variable by first creating a ReentrantLock and
invokingits newCondition() method,whichreturnsa Condition objectrep-
resenting the condition variable for the associated ReentrantLock .T h i si s
illustratedin thefollowing statements:
Lock key = new ReentrantLock();
Condition condVar = key.newCondition();
Once the condition variable has been obtained, we can invoke its await()
andsignal() methods, which function in the same way as the wait()and
signal() commands describedinSection 6.7.
Recall that with monitors as described in Section 6.7, the wait() and
signal() operations can be appliedto namedcondition variables,allowing a
threadtowaitforaspecificconditionor tobenotifiedwhenaspecificcondition
hasbeenmet.Atthelanguagelevel,Javadoesnotprovidesupportfornamed
condition variables. Each Java monitor is associated with just one unnamed
condition variable, and the wait()and notify() operations described in
Section7.4.1applyonlytothissingleconditionvariable.WhenaJavathreadis
awakenedvia notify() ,itreceivesnoinformationastowhyitwasawakened;
it is up to the reactivated thread to check for itself whether the condition
for which it was waiting has been met. Condition variables remedy this by
allowing aspecific thread to be notified.
We illustrate with the following example: Suppose we have five threads,
numbered 0 through 4, and a shared variable turnindicating which thread’s
turn it is. When a thread wishes to do work, it calls the doWork() method
in Figure 7.13, passing its thread number. Only the thread whose value of
threadNumber matchesthevalueof turncanproceed;otherthreadsmustwait
theirturn."
2,7.5 Alternative Approaches,397,7.4 Synchronization in Java,"7.5 Alternative Approaches 311
invokes await() on the condition variable, it releases the associated Reen-
trantLock , allowing another thread to acquire the mutual exclusion lock.
Similarly, when signal() is invoked, only the condition variable is signaled;
thelock isreleasedby invoking unlock() .
7.5 Alternative Approaches
With the emergence of multicore systems has come increased pressure to
develop concurrent applications that take advantage of multiple processing
cores.However,concurrent applications presentanincreasedriskof racecon-
ditions and liveness hazards such as deadlock. Traditionally, techniques such
as mutex locks, semaphores, and monitors have been used to address these
issues,butasthenumberofprocessingcoresincreases,itbecomesincreasingly
difficulttodesignmultithreadedapplicationsthatarefreefromraceconditions
and deadlock. In this section, we explore various features provided in both
programming languages and hardware that support the design of thread-safe
concurrent applications.
7.5.1 Transactional Memory
Quite often in computer science, ideas from one area of study can be used
to solve problems in other areas. The concept of transactional memory orig-
inated in database theory, for example, yet it provides a strategy for process
synchronization. A memory transaction is a sequence of memory read–write
operationsthatareatomic.Ifalloperationsinatransactionarecompleted,the
memorytransaction is committed.Othe rwise,the operations must be aborted
androlledback.Thebenefitsoftransactionalmemorycanbeobtainedthrough
featuresaddedto aprogramming language.
Consideranexample.Supposewehaveafunction update() thatmodifies
shareddata.Traditionally,thisfunctionwouldbewrittenusingmutexlocks(or
semaphores)such as the following:
void update ()
{
acquire();
/* modify shared data */
release();
}
However, using synchronization mechanisms such as mutex locks and
semaphores involves many potential problems, including deadlock.
Additionally, as the number of threads increases, traditional locking doesn’t
scaleaswell,becausethelevelofcontentionamongthreadsforlockownership
becomesveryhigh.
As an alternative to traditional locking methods, new features that take
advantageoftransactionalmemorycanbeaddedtoaprogramminglanguage.
Inourexample,supposewe addthe construct atomic {S},which ensuresthat"
3,7.5.1 Transactional Memory,397,7.5 Alternative Approaches,"7.5 Alternative Approaches 311
invokes await() on the condition variable, it releases the associated Reen-
trantLock , allowing another thread to acquire the mutual exclusion lock.
Similarly, when signal() is invoked, only the condition variable is signaled;
thelock isreleasedby invoking unlock() .
7.5 Alternative Approaches
With the emergence of multicore systems has come increased pressure to
develop concurrent applications that take advantage of multiple processing
cores.However,concurrent applications presentanincreasedriskof racecon-
ditions and liveness hazards such as deadlock. Traditionally, techniques such
as mutex locks, semaphores, and monitors have been used to address these
issues,butasthenumberofprocessingcoresincreases,itbecomesincreasingly
difficulttodesignmultithreadedapplicationsthatarefreefromraceconditions
and deadlock. In this section, we explore various features provided in both
programming languages and hardware that support the design of thread-safe
concurrent applications.
7.5.1 Transactional Memory
Quite often in computer science, ideas from one area of study can be used
to solve problems in other areas. The concept of transactional memory orig-
inated in database theory, for example, yet it provides a strategy for process
synchronization. A memory transaction is a sequence of memory read–write
operationsthatareatomic.Ifalloperationsinatransactionarecompleted,the
memorytransaction is committed.Othe rwise,the operations must be aborted
androlledback.Thebenefitsoftransactionalmemorycanbeobtainedthrough
featuresaddedto aprogramming language.
Consideranexample.Supposewehaveafunction update() thatmodifies
shareddata.Traditionally,thisfunctionwouldbewrittenusingmutexlocks(or
semaphores)such as the following:
void update ()
{
acquire();
/* modify shared data */
release();
}
However, using synchronization mechanisms such as mutex locks and
semaphores involves many potential problems, including deadlock.
Additionally, as the number of threads increases, traditional locking doesn’t
scaleaswell,becausethelevelofcontentionamongthreadsforlockownership
becomesveryhigh.
As an alternative to traditional locking methods, new features that take
advantageoftransactionalmemorycanbeaddedtoaprogramminglanguage.
Inourexample,supposewe addthe construct atomic {S},which ensuresthat"
3,7.5.2 OpenMP,398,7.5.1 Transactional Memory,"312 Chapter 7 Synchronization Examples
the operations in Sexecute as a transaction. This allows us to rewrite the
update() function asfollows:
void update ()
{
atomic {
/* modify shared data */
}
}
The advantage of using such a mechan ism rather than locks is that the
transactional memory system—not the developer—is responsible for guar-
anteeing atomicity. Additionally, bec ause no locks are involved, deadlock is
not possible. Furthermore, a transactional memory system can identify which
statements in atomic blocks can be executed concurrently, such as concurrent
read access to a shared variable. It is, of course, possible for a programmer
to identify these situations and use reader–writer locks, but the task becomes
increasinglydifficult asthe number of threadswithin an applicationgrows.
Transactionalmemorycanbeimplementedineithersoftwareorhardware.
Software transactional memory (STM), as the name suggests, implements
transactionalmemoryexclusivelyinsoftware—nospecialhardwareisneeded.
STMworks by inserting instrumentation code inside transaction blocks. The
code is inserted by a compiler and manages each transaction by examining
wherestatementsmayrunconcurrentlyandwherespecificlow-levellockingis
required. Hardware transactional memory (HTM)useshardwarecachehierar-
chiesandcachecoherencyprotocolstomanageandresolveconflictsinvolving
shared data residing in separate processors’ caches. HTMrequires no special
code instrumentation and thus has less overhead than STM. However, HTM
does require that existing cache hierarchies and cache coherency protocols be
modified tosupporttransactional memory.
Transactional memory has existed for several years without widespread
implementation. However, the growth of multicore systems and the associ-
ated emphasis on concurrent and parallel programming have prompted a
significant amount of research in this area on the part of both academics and
commercial software and hardware vendors.
7.5.2 OpenMP
InSection4.5.2,weprovidedanoverviewofOpen MPanditssupportofparallel
programminginashared-memoryenvironment.RecallthatOpen MPincludes
asetofcompilerdirectivesandan API.Anycodefollowingthecompilerdirec-
tive#pragma omp parallel isidentifiedasaparallelregionandisperformed
byanumberofthreadsequaltothenumberofprocessingcoresinthesystem.
TheadvantageofOpen MP(and similartools)isthatthreadcreationand man-
agement are handled by the Open MPlibrary and are not the responsibility of
applicationdevelopers.
Along with its #pragma omp parallel compiler directive, Open MPpro-
videsthecompilerdirective #pragma omp critical ,whichspecifiesthecode
regionfollowingthedirectiveasacriticalsectioninwhichonlyonethreadmay
be active at a time. In this way, Open MPprovides support for ensuring that
threadsdonot generate race conditions."
3,7.5.3 Functional Programming Languages,399,7.5.2 OpenMP,"7.5 Alternative Approaches 313
As an example of the use of the critical-section compiler directive, first
assume that the shared variable counter can be modified in the update()
function as follows:
void update(int value)
{
counter += value;
}
If the update() function can be part of—or invoked from—a parallelregion,
arace condition ispossibleon the variable counter .
The critical-section compiler directive can be used to remedy this race
condition andis codedas follows:
void update(int value)
{
#pragma omp critical
{
counter += value;
}
}
The critical-section compiler directive behaves much like a binary semaphore
or mutex lock, ensuring that only one thr ead at a time is active in the critical
section. If a thread attempts to enter a critical section when another thread is
currently active in that section (that is, ownsthe section), the calling thread is
blockeduntiltheownerthreadexits.Ifmultiplecriticalsectionsmustbeused,
each critical section can be assigned a separate name, and a rule can specify
that no more than one thread may be active in a critical section of the same
namesimultaneously.
An advantage of using the critical-section compiler directive in Open MP
is that it is generally considered easier to use than standard mutex locks.
However, a disadvantage is that application developers must still identify
possibleraceconditionsandadequatelyprotectshareddatausingthecompiler
directive.Additionally,becausethecri tical-sectioncompilerdirectivebehaves
much like a mutex lock, deadlock is still possible when two or more critical
sectionsare identified.
7.5.3 Functional Programming Languages
Most well-known programming languages—such as C, C++, Java, and C#—
areknownas imperative (orprocedural )languages.Imperativelanguagesare
usedforimplementingalgorithmsthatarestate-based.Intheselanguages,the
flowofthealgorithmiscrucialtoitscorrectoperation,andstateisrepresented
with variables and other data structure s. Of course, program state is mutable,
asvariablesmay beassigneddifferentvaluesovertime.
With the current emphasis on concurrent and parallel programming for
multicore systems, there has been greater focus on functional programming
languages, which follow a programming paradigm much different from that
offeredby imperativelanguages. The fundamental differencebetweenimper-
ative and functional languages is that functional languages do not maintain
state. That is, once a variable has been defined and assigned a value, its value"
2,7.6 Summary,400,7.5 Alternative Approaches,"314 Chapter 7 Synchronization Examples
isimmutable—itcannotchange.Becausefunctionallanguagesdisallowmuta-
ble state, they need not be concerned with issues such as race conditions and
deadlocks. Essentially, most of the problems addressed in this chapter are
nonexistent infunctional languages.
Several functional languages are presently in use, and we briefly mention
twoofthemhere:ErlangandScala.TheErlanglanguagehasgainedsignificant
attentionbecauseofitssupportforconcurrencyandtheeasewithwhichitcan
be used to develop applications that run on parallel systems. Scala is a func-
tionallanguagethatisalsoobject-ori ented.Infact,muchofthesyntaxofScala
issimilartothepopularobject-orientedlanguagesJavaandC#.Readersinter-
estedin ErlangandScala,and infurtherdetailsabout functional languagesin
general, are encouraged to consult the bibliography at the end of this chapter
for additionalreferences.
7.6 Summary
•Classic problems of process synchronization include the bounded-buffer,
readers–writers, and dining-philoso phers problems. Solutions to these
problemscanbedevelopedusingthetoolspresentedinChapter6,includ-
ing mutexlocks,semaphores,monitors, andcondition variables.
•Windows uses dispatcher objects as well as events to implement process
synchronization tools.
•Linux uses a variety of approaches to protect against race conditions,
including atomicvariables,spinlocks,and mutexlocks.
•ThePOSIX API providesmutexlocks,semaphores,andconditionvariables.
POSIXprovides two forms of semaphores: named and unnamed. Several
unrelatedprocesses can easily access the same named semaphore by sim-
plyreferringtoitsname.Unnamedsemaphorescannotbesharedaseasily,
and requireplacing thesemaphorein a regionof sharedmemory.
•Javahasarichlibraryand APIforsynchronization.Availabletoolsinclude
monitors (which are provided at the language level) as well as reentrant
locks, semaphores, and condition variables (which are supported by the
API).
•Alternative approaches to solving the critical-section problem include
transactionalmemory,Open MP,andfunctionallanguages.Functionallan-
guages are particularly intriguing, as they offer a different programming
paradigmfromprocedurallanguages.Unlikeprocedurallanguages,func-
tionallanguagesdonotmaintainstateandthereforearegenerallyimmune
fromrace conditions and criticalsections.
Practice Exercises
7.1Explain why Windows and Linux implement multiple locking mech-
anisms. Describe the circumstances under which they use spinlocks,
mutexlocks,semaphores,andconditionvariables.Ineachcase,explain
why the mechanism isneeded."
2,Practice Exercises,400,7.6 Summary,"314 Chapter 7 Synchronization Examples
isimmutable—itcannotchange.Becausefunctionallanguagesdisallowmuta-
ble state, they need not be concerned with issues such as race conditions and
deadlocks. Essentially, most of the problems addressed in this chapter are
nonexistent infunctional languages.
Several functional languages are presently in use, and we briefly mention
twoofthemhere:ErlangandScala.TheErlanglanguagehasgainedsignificant
attentionbecauseofitssupportforconcurrencyandtheeasewithwhichitcan
be used to develop applications that run on parallel systems. Scala is a func-
tionallanguagethatisalsoobject-ori ented.Infact,muchofthesyntaxofScala
issimilartothepopularobject-orientedlanguagesJavaandC#.Readersinter-
estedin ErlangandScala,and infurtherdetailsabout functional languagesin
general, are encouraged to consult the bibliography at the end of this chapter
for additionalreferences.
7.6 Summary
•Classic problems of process synchronization include the bounded-buffer,
readers–writers, and dining-philoso phers problems. Solutions to these
problemscanbedevelopedusingthetoolspresentedinChapter6,includ-
ing mutexlocks,semaphores,monitors, andcondition variables.
•Windows uses dispatcher objects as well as events to implement process
synchronization tools.
•Linux uses a variety of approaches to protect against race conditions,
including atomicvariables,spinlocks,and mutexlocks.
•ThePOSIX API providesmutexlocks,semaphores,andconditionvariables.
POSIXprovides two forms of semaphores: named and unnamed. Several
unrelatedprocesses can easily access the same named semaphore by sim-
plyreferringtoitsname.Unnamedsemaphorescannotbesharedaseasily,
and requireplacing thesemaphorein a regionof sharedmemory.
•Javahasarichlibraryand APIforsynchronization.Availabletoolsinclude
monitors (which are provided at the language level) as well as reentrant
locks, semaphores, and condition variables (which are supported by the
API).
•Alternative approaches to solving the critical-section problem include
transactionalmemory,Open MP,andfunctionallanguages.Functionallan-
guages are particularly intriguing, as they offer a different programming
paradigmfromprocedurallanguages.Unlikeprocedurallanguages,func-
tionallanguagesdonotmaintainstateandthereforearegenerallyimmune
fromrace conditions and criticalsections.
Practice Exercises
7.1Explain why Windows and Linux implement multiple locking mech-
anisms. Describe the circumstances under which they use spinlocks,
mutexlocks,semaphores,andconditionvariables.Ineachcase,explain
why the mechanism isneeded."
2,Further Reading,401,Practice Exercises,"Bibliography 315
7.2Windowsprovidesalightweightsynchronizationtoolcalled slim reader
–writer locks. Whereas most implementations of reader–writer locks
favoreitherreadersorwriters,orperhapsorderwaitingthreadsusinga
FIFOpolicy, slim reader–writer locks favor neither readers nor writers,
nor are waiting threadsorderedin a FIFOqueue. Explainthe benefits of
providingsuch a synchronization tool.
7.3Describe what changes would be necessary to the producer and con-
sumer processesin Figure 7.1 and Figure 7.2 so that a mutex lock could
be usedinsteadof a binary semaphore.
7.4Describe how deadlock is possible with the dining-philosophers prob-
lem.
7.5Explain the difference between signaled and non-signaled states with
Windows dispatcherobjects.
7.6Assume valisanatomicintegerinaLinuxsystem.Whatisthevalueof
valafterthe following operationshave beencompleted?
atomic
 set(&val,10);
atomic
 sub(8,&val);
atomic
 inc(&val);
atomic
 inc(&val);
atomic
 add(6,&val);
atomic
 sub(3,&val);
Further Reading
Details of Windows synchronization can be found in [Solomon and Russi-
novich (2000)]. [Love (2010)] describes synchronization in the Linux kernel.
[Hart (2005)] describes thread synchronization using Windows. [Breshears
(2009)] and [Pacheco (2011)] provide detailed coverage of synchronization
issues in relation to parallel programming. Details on using Open MPcan be
found at http://openmp.org . Both [Oaks (2014)] and [Goetz et al. (2006)] con-
trasttraditionalsynchronization and CAS-based strategiesinJava.
Bibliography
[Breshears (2009)] C. Breshears, The Art of Concurrency , O’Reilly & Associates
(2009).
[Goetz et al. (2006)] B. Goetz, T. Peirls, J. Bloch, J. Bowbeer, D. Holmes, and
D.Lea,JavaConcurrencyinPractice ,Addison-Wesley (2006).
[Hart (2005)] J. M. Hart, WindowsSystemProgramming, Third Edition, Addison-
Wesley(2005).
[Love (2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library(2010)."
2,Bibliography,401,Further Reading,"Bibliography 315
7.2Windowsprovidesalightweightsynchronizationtoolcalled slim reader
–writer locks. Whereas most implementations of reader–writer locks
favoreitherreadersorwriters,orperhapsorderwaitingthreadsusinga
FIFOpolicy, slim reader–writer locks favor neither readers nor writers,
nor are waiting threadsorderedin a FIFOqueue. Explainthe benefits of
providingsuch a synchronization tool.
7.3Describe what changes would be necessary to the producer and con-
sumer processesin Figure 7.1 and Figure 7.2 so that a mutex lock could
be usedinsteadof a binary semaphore.
7.4Describe how deadlock is possible with the dining-philosophers prob-
lem.
7.5Explain the difference between signaled and non-signaled states with
Windows dispatcherobjects.
7.6Assume valisanatomicintegerinaLinuxsystem.Whatisthevalueof
valafterthe following operationshave beencompleted?
atomic
 set(&val,10);
atomic
 sub(8,&val);
atomic
 inc(&val);
atomic
 inc(&val);
atomic
 add(6,&val);
atomic
 sub(3,&val);
Further Reading
Details of Windows synchronization can be found in [Solomon and Russi-
novich (2000)]. [Love (2010)] describes synchronization in the Linux kernel.
[Hart (2005)] describes thread synchronization using Windows. [Breshears
(2009)] and [Pacheco (2011)] provide detailed coverage of synchronization
issues in relation to parallel programming. Details on using Open MPcan be
found at http://openmp.org . Both [Oaks (2014)] and [Goetz et al. (2006)] con-
trasttraditionalsynchronization and CAS-based strategiesinJava.
Bibliography
[Breshears (2009)] C. Breshears, The Art of Concurrency , O’Reilly & Associates
(2009).
[Goetz et al. (2006)] B. Goetz, T. Peirls, J. Bloch, J. Bowbeer, D. Holmes, and
D.Lea,JavaConcurrencyinPractice ,Addison-Wesley (2006).
[Hart (2005)] J. M. Hart, WindowsSystemProgramming, Third Edition, Addison-
Wesley(2005).
[Love (2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library(2010)."
2,Chapter 7 Exercises,403,Bibliography,"Exercises
Chapter 7 Exercises
7.7 Describe two kernel data structures in which race conditions are possi-
ble. Be sure to include a description of how a race condition can occur.
7.8 The Linux kernel has a policy that a pr ocess cannot hold a spinlock while
attempting to acquire a semaphore. Explain why this policy is in place.
7.9 Design an algorithm for a bounded-buffer monitor in which the buffers
(portions) are embedded within the monitor itself.
7.10 The strict mutual exclusion within a monitor makes the bounded-buffer
monitor of Exercise 7.14 mainly suitable for small portions.
a. Explain why this is true.
b. Design a new scheme that is suitable for larger portions.
7.11 Discuss the tradeoff between fairness and throughput of operations
in the readers–writers problem. Propose a method for solving the
readers–writers problem without causing starvation.
7.12 Explain why the call to the lock() method in a Java ReentrantLock is
not placed in the try clause for exception handling, yet the call to the
unlock() method is placed in a finally clause.
7.13 Explain the difference between software and hardware transactional
memory.EX-26"
2,Programming Problems,404,Chapter 7 Exercises,"Programming Problems
7.14Exercise 3.20 required you to design a PIDmanager that allocated a
unique process identifier to each process. Exercise 4.28 required you to
modifyyoursolutiontoExercise3.20bywritingaprogramthatcreateda
numberofthreadsthatrequestedandreleasedprocessidentifiers.Using
mutex locks, modify your solution to Exercise4.28 by ensuring that the
data structure used to represent the availability of process identifiers is
safefrom raceconditions.
7.15In Exercise 4.27, you wrote a program to generate the Fibonacci
sequence. The program required the parent thread to wait for the child
thread to finish its execution before printing out the computed values.
IfwelettheparentthreadaccesstheFibonaccinumbersassoonasthey
were computed by the child thread—rather than waiting for the child
thread to terminate—what changes would be necessary to the solution
for thisexercise?Implementyour modifiedsolution.
7.16The C program stack-ptr.c (available in the source-code download)
containsanimplementationofastackusingalinkedlist.Anexampleof
itsuseisas follows:
StackNode *top = NULL;
push(5, &top);
push(10, &top);
push(15, &top);
int value = pop(&top);
value = pop(&top);
value = pop(&top);
This program currently has a race condition and is not appropriate for
a concurrent environment. Using Pthreads mutex locks (described in
Section7.3.1),fix therace condition.
7.17Exercise 4.24 asked you to design a multithreaded program that esti-
matedπusing the Monte Carlo technique. In that exercise, you were
asked to create a single thread that generated random points, storing
theresultinaglobalvariable.Oncethatthreadexited,theparentthread
performedthecalculationthatestimatedthevalueof π.Modifythatpro-
gramsothatyoucreateseveralthreads,eachofwhichgeneratesrandom
pointsanddeterminesifthepointsfa llwithinthecircle.Eachthreadwill
have to update the global count of all points that fall within the circle.
Protectagainst race conditions on updatestothe sharedglobal variable
by using mutexlocks.
7.18Exercise 4.25 asked you to design a program using Open MPthat esti-
matedπusingtheMonteCarlotechnique.Examineyoursolutiontothat
program looking for any possible race conditions. If you identify a race
condition, protectagainst itusing the strategyoutlinedinSection7.5.2.
7.19Abarrierisatoolforsynchronizingtheactivityofanumberofthreads.
When a thread reaches a barrier point , it cannot proceed until all otherChapter 7 Synchronization Examples P-34"
2,Programming Projects,405,Programming Problems,"Programming Projects
threads have reached this point as well. When the last thread reaches
the barrier point, all threads are released and can resume concurrent
execution.
Assume that the barrier is initialized to N—the number of threads
that must waitat thebarrierpoint:
init(N);
Eachthreadthenperformssomework until itreachesthebarrierpoint:
/* do some work for awhile */
barrier
 point();
/* do some work for awhile */
Usingeitherthe POSIXorJavasynchronizationtoolsdescribedinthis
chapter, construct a barrierthat implementsthefollowing API:
•int init(int n) —Initializesthebarrierto thespecifiedsize.
•int barrier
 point(void) —Identifies the barrier point. All
threads are released from the barrier when the last thread reaches
this point.
Thereturnvalueofeachfunctionisusedtoidentifyerrorconditions.
Each function will return 0 under normal operation and will return
−1 if an error occurs. A testing harness is provided in the source-code
download to testyour implementationofthe barrier.
Programming Projects
Project 1—Designing a Thread Pool
Thread pools were introduced in Section 4.5.1. When thread pools are used, a
task is submitted to the pool and executed by a thread from the pool. Work is
submitted to the pool using a queue, and an available thread removes work
from the queue. If there are no available threads, the work remains queued
untilonebecomesavailable.Ifthereisnowork,threadsawaitnotificationuntil
atask becomesavailable.
This project involves creating and managing a thread pool, and it may be
completed using either Pthreds and POSIXsynchronization or Java. Below we
providethe detailsrelevanttoeachspecifictechnology.
I. POSIX
ThePOSIXversion of this project will involve creating a number of threads
using the Pthreads APIas well as using POSIXmutex locks and semaphores
forsynchronization.P-35"
1,Chapter 8 Deadlocks,415,Chapter 7 Synchronization Examples,"8CHAPTER
Deadlocks
Inamultiprogrammingenvironment,severalthreadsmaycompeteforafinite
number of resources. A thread requests resources; if the resources are not
available at that time, the thread enters a waiting state. Sometimes, a waiting
threadcanneveragainchangestate,becausetheresourcesithasrequestedare
heldbyotherwaitingthreads.Thissituationiscalleda deadlock .W ediscussed
this issue briefly in Chapter 6 as a form of liveness failure. There, we defined
deadlockasasituationinwhich every process in a set of processes is waiting for an
event that can be caused only by another process in the set .
Perhapsthebestillustrationofadeadlockcanbedrawnfromalawpassed
by the Kansas legislature early in the 20th century. It said, in part: “When two
trains approach each other at a crossing, both shall come to a full stop and
neithershallstartup again untilthe otherhas gone. ”
In this chapter, we describe methods that application developers as well
as operating-system programmers can use to prevent or deal with dead-
locks. Although some applications can identify programs that may dead-
lock, operating systems typically do not provide deadlock-prevention facil-
ities, and it remains the responsibilit y of programmers to ensure that they
designdeadlock-freeprograms.Deadlockproblems—aswellasotherliveness
failures—are becoming more challenging as demand continues for increased
concurrency andparallelismon multicoresystems.
CHAPTER OBJECTIVES
•Illustrate how deadlock can occur when mutex locks are used.
•Define the four necessary conditions that characterize deadlock.
•Identify a deadlock situation in a resource allocation graph.
•Evaluate the four different approaches for preventing deadlocks.
•Apply the banker’s algorithm for deadlock avoidance.
•Apply the deadlock detection algorithm.
•Evaluate approaches for recovering from deadlock.
317"
2,8.1 System Model,416,Chapter 8 Deadlocks,"318 Chapter 8 Deadlocks
8.1 System Model
A system consists of a finite number of resources to be distributed among a
number of competing threads. The resources may be partitioned into several
types (or classes), each consisting o fs o m en u m b e ro fi d e n t i c a li n s t a n c e s . CPU
cycles, files, and I/Odevices (such as network interfaces and DVDdrives) are
examples of resource types. If a system has four CPUs, then the resource type
CPUhas four instances. Similarly, the resource type networkmay have two
instances. If a thread requests an instance of a resource type, the allocation
ofanyinstance of the type should satisfy the request. If it does not, then the
instancesarenotidentical,andtheresourcetypeclasseshavenotbeendefined
properly.
The various synchronization tools discussed in Chapter 6, such as mutex
locks and semaphores, are also system resources; and on contemporary com-
puter systems, they are the most common sources of deadlock. However,def-
initionisnotaproblemhere.Alockistypicallyassociatedwithaspecificdata
structure—that is, one lock may be used to protect access to a queue, another
to protect access to a linked list,and so forth. For that reason, each instance of
a lock istypicallyassigneditsown resourceclass.
Notethatthroughoutthischapterwediscusskernelresources,butthreads
mayuseresourcesfromotherprocesses(forexample,viainterprocesscommu-
nication), and those resource uses can also result in deadlock. Such deadlocks
are not the concern of the kerneland thus not describedhere.
A thread must request a resource before using it and must release the
resource after using it. Athread may request as many resources as it requires
tocarryoutitsdesignatedtask.Obviously,thenumberofresourcesrequested
maynotexceedthetotalnumberofresourcesavailableinthesystem.Inother
words, a thread cannot request two network interfaces if the system has only
one.
Under the normal mode of operation, a thread may utilize a resource in
only thefollowing sequence:
1.Request. The thread requests the resource. If the request cannot be
granted immediately (for example, if a mutex lock is currently held by
anotherthread),thentherequestingthreadmustwaituntilitcanacquire
the resource.
2.Use.Thethreadcan operateon theresource(forexample,ifthe resource
is amutexlock, the thread can access itscriticalsection).
3.Release. The thread releases the resource.
The request and release of resources may be system calls, as explained in
Chapter 2. Examples are the request() andrelease() of a device, open()
and close() of a file, and allocate() and free()memory system calls.
Similarly, as we saw in Chapter 6, request and release can be accomplished
through the wait()and signal() operations on semaphores and through
acquire() andrelease() ofamutexlock.Foreachuseofakernel-managed
resourcebyathread,theoperatingsystemcheckstomakesurethatthethread
has requested and has been allocated the resource. A system table records
whether each resource is free or allocated. For each resource that is allocated,"
2,8.2 Deadlock in Multithreaded Applications,417,8.1 System Model,"8.2 Deadlock in Multithreaded Applications 319
the table also records the thread to which it is allocated. If a thread requests
a resource that is currently allocated to another thread, it can be added to a
queueof threadswaiting forthis resource.
Asetofthreadsisinadeadlockedstatewheneverythreadinthesetiswait-
ingforaneventthatcanbecausedonlybyanotherthreadintheset.Theevents
withwhichwearemainlyconcernedhereareresourceacquisitionandrelease.
Theresourcesaretypicallylogical(forexample,mutexlocks,semaphores,and
files); however, other types of events may result in deadlocks,including read-
ingfromanetworkinterfaceorthe IPC(interprocesscommunication)facilities
discussedinChapter3.
To illustrate a deadlocked state, we ref er back to the dining-philosophers
problem from Section 7.1.3. In this situation, resources are represented by
chopsticks. If all the philosophers get hungry at the same time, and each
philosopher grabs the chopstick on her left, there are no longer any available
chopsticks.Eachphilosopheristhenbloc kedwaitingforherrightchopstickto
become available.
Developers of multithreaded applications must remain aware of the pos-
sibility of deadlocks. The locking tools presented in Chapter 6 are designed
to avoid race conditions. However, in using these tools, developers must pay
carefulattentionto how locks areacquiredand released.Otherwise,deadlock
can occur, asdescribednext.
8.2 Deadlock in Multithreaded Applications
Prior to examining how deadlock issues can be identified and man-
aged, we first illustrate how deadlock can occur in a multithreaded
Pthread program using POSIXmutex locks. The pthread
 mutex
 init()
function initializes an unlocked mutex. Mutex locks are acquired and
released using pthread
 mutex
 lock() and pthread
 mutex
 unlock() ,
respectively. If a thread attempts to acquire a locked mutex, the call to
pthread
 mutex
 lock()b l o c k st h et h r e a du n t i lt h eo w n e ro ft h em u t e xl o c k
invokes pthread
 mutex
 unlock() .
Twomutexlocksarecreatedandinitializedinthefollowingcodeexample:
pthread
 mutex
 t first
 mutex;
pthread
 mutex
 t second
 mutex;
pthread
 mutex
 init(&first
 mutex,NULL);
pthread
 mutex
 init(&second
 mutex,NULL);
Next, two threads— thread
 oneand thread
 two—are created, and both
these threads have access to both mutex locks. thread
 oneandthread
 two
r u ni nt h ef u n c t i o n s do
work
 one()and do
work
 two(), respectively, as
shown inFigure 8.1.
In this example, thread
 oneattempts to acquire the mutex locks in the
order (1) first
 mutex,( 2 ) second
 mutex. At the same time, thread
 two
attempts to acquire the mutex locks in the order (1) second
 mutex,( 2 )
first
 mutex. Deadlock is possible if thread
 oneacquires first
 mutex
while thread
 twoacquires second
 mutex."
3,8.2.1 Livelock,418,8.2 Deadlock in Multithreaded Applications,"320 Chapter 8 Deadlocks
/* thread
 one runs in this function */
void *do
 work
 one(void *param)
{
pthread
 mutex
 lock(&first
 mutex);
pthread
 mutex
 lock(&second
 mutex);
/**
* Do some work
*/
pthread
 mutex
 unlock(&second
 mutex);
pthread
 mutex
 unlock(&first
 mutex);
pthread
 exit(0);
}
/* thread
 two runs in this function */
void *do
 work
 two(void *param)
{
pthread
 mutex
 lock(&second
 mutex);
pthread
 mutex
 lock(&first
 mutex);
/**
* Do some work
*/
pthread
 mutex
 unlock(&first
 mutex);
pthread
 mutex
 unlock(&second
 mutex);
pthread
 exit(0);
}
Figure 8.1 Deadlock example.
Notethat,eventhoughdeadlockispossible,itwillnotoccurif thread
 one
can acquire and release the mutex locks for first
 mutexandsecond
 mutex
before thread
 twoattempts to acquire the locks. And, of course, the order
in which the threads run depends on how they are scheduled by the CPU
scheduler. This example illustrates a pr oblem with handling deadlocks: it is
difficult to identify and test for deadlocks that may occur only under certain
schedulingcircumstances.
8.2.1 Livelock
Livelock is another form of liveness failure. It is similar to deadlock; both
prevent two or more threads from proceeding, but the threads are unable to
proceed for different reasons. Whereas deadlock occurs when every thread
in a set is blocked waiting for an event that can be caused only by another
threadintheset,livelockoccurswhenathreadcontinuouslyattemptsanaction
that fails. Livelock is similar to what sometimes happens when two people
attempt to pass in a hallway: One moves to his right, the other to her left, still
obstructing each other’s progress. Then he moves to his left, and she moves"
2,8.3 Deadlock Characterization,419,8.2 Deadlock in Multithreaded Applications,"8.3 Deadlock Characterization 321
to her right, and so forth. They aren’t blocked, but they aren’t making any
progress.
Livelock can be illustrated with the Pthreads pthread
 mutex
 trylock()
function, which attempts to acquire a mutex lock without blocking. The code
exampleinFigure8.2rewritestheexamplefromFigure8.1sothatitnowuses
pthread
 mutex
 trylock() . This situation can lead to livelock if thread
 one
acquires first
 mutex, followed by thread
 twoacquiring second
 mutex.
Each thread then invokes pthread
 mutex
 trylock() , which fails, releases
theirrespectivelocks,and repeatsthesameactions indefinitely.
Livelocktypicallyoccurswhenthreadsretryfailingoperationsatthesame
time. It thus can generally be avoided by having each thread retry the failing
operation at random times. This is precisely the approach taken by Ethernet
networks when a network collision occurs. Rather than trying to retransmit a
packet immediately after a collision occurs, a host involved in a collision will
backoffa randomperiodoftimebeforeattemptingtotransmit again.
Livelock is less common than deadlock but nonetheless is a challenging
issueindesigningconcurrentapplications,andlikedeadlock,itmayonlyoccur
underspecific schedulingcircumstances.
8.3 Deadlock Characterization
In the previous section we illustrated how deadlock could occur in multi-
threaded programming using mutex locks. We now look more closely at con-
ditionsthatcharacterize deadlock.
8.3.1 Necessary Conditions
Adeadlocksituationcanariseifthefollowingfourconditionsholdsimultane-
ouslyina system:
1.Mutual exclusion . At least one resource must be held in a nonsharable
mode; that is, only one thread at a time can use the resource. If another
threadrequeststhatresource,therequestingthreadmustbedelayeduntil
theresourcehas beenreleased.
2.Hold and wait . A thread must be holding at least one resource and
waiting to acquire additional resources that are currently being held by
otherthreads.
3.No preemption . Resources cannot be preempted; that is, a resource can
bereleasedonlyvoluntarilybythethreadholdingit,afterthatthreadhas
completeditstask.
4.Circular wait .Aset {T0,T1,...,Tn}ofwaitingthreadsmustexistsuchthat
T0is waiting for a resource held by T1,T1is waiting for a resource held
byT2,...,Tn−1iswaitingforaresourceheldby Tn,and Tniswaitingfora
resource held by T0.
We emphasize that all four conditions must hold for a deadlock to occur.
The circular-wait condition implies the hold-and-wait condition, so the four"
3,8.3.1 Necessary Conditions,419,8.3 Deadlock Characterization,"8.3 Deadlock Characterization 321
to her right, and so forth. They aren’t blocked, but they aren’t making any
progress.
Livelock can be illustrated with the Pthreads pthread
 mutex
 trylock()
function, which attempts to acquire a mutex lock without blocking. The code
exampleinFigure8.2rewritestheexamplefromFigure8.1sothatitnowuses
pthread
 mutex
 trylock() . This situation can lead to livelock if thread
 one
acquires first
 mutex, followed by thread
 twoacquiring second
 mutex.
Each thread then invokes pthread
 mutex
 trylock() , which fails, releases
theirrespectivelocks,and repeatsthesameactions indefinitely.
Livelocktypicallyoccurswhenthreadsretryfailingoperationsatthesame
time. It thus can generally be avoided by having each thread retry the failing
operation at random times. This is precisely the approach taken by Ethernet
networks when a network collision occurs. Rather than trying to retransmit a
packet immediately after a collision occurs, a host involved in a collision will
backoffa randomperiodoftimebeforeattemptingtotransmit again.
Livelock is less common than deadlock but nonetheless is a challenging
issueindesigningconcurrentapplications,andlikedeadlock,itmayonlyoccur
underspecific schedulingcircumstances.
8.3 Deadlock Characterization
In the previous section we illustrated how deadlock could occur in multi-
threaded programming using mutex locks. We now look more closely at con-
ditionsthatcharacterize deadlock.
8.3.1 Necessary Conditions
Adeadlocksituationcanariseifthefollowingfourconditionsholdsimultane-
ouslyina system:
1.Mutual exclusion . At least one resource must be held in a nonsharable
mode; that is, only one thread at a time can use the resource. If another
threadrequeststhatresource,therequestingthreadmustbedelayeduntil
theresourcehas beenreleased.
2.Hold and wait . A thread must be holding at least one resource and
waiting to acquire additional resources that are currently being held by
otherthreads.
3.No preemption . Resources cannot be preempted; that is, a resource can
bereleasedonlyvoluntarilybythethreadholdingit,afterthatthreadhas
completeditstask.
4.Circular wait .Aset {T0,T1,...,Tn}ofwaitingthreadsmustexistsuchthat
T0is waiting for a resource held by T1,T1is waiting for a resource held
byT2,...,Tn−1iswaitingforaresourceheldby Tn,and Tniswaitingfora
resource held by T0.
We emphasize that all four conditions must hold for a deadlock to occur.
The circular-wait condition implies the hold-and-wait condition, so the four"
3,8.3.2 Resource-Allocation Graph,421,8.3.1 Necessary Conditions,"8.3 Deadlock Characterization 323
first_mutex second_mutex
thread_two thread_one..
Figure 8.3 Resource-allocation graph for program in Figure 8.1.
conditions are not completely independ ent. We shall see in Section 8.5, how-
ever,that itis usefultoconsidereach conditionseparately.
8.3.2 Resource-Allocation Graph
Deadlockscanbedescribedmorepreciselyintermsofadirectedgraphcalled
asystem resource-allocation graph . This graph consists of a set of vertices V
andasetofedges E.Thesetofvertices Vispartitionedintotwodifferenttypes
of nodes: T={T1,T2, ...,Tn}, the set consisting of all the active threads in the
system, and R={R1,R2, ...,Rm}, the set consisting of all resource types in the
system.
Adirected edge from thread Tito resource type Rjis denoted by Ti→Rj;
it signifies that thread Tihas requested an instance of resource type Rjand is
currently waiting for that resource. A directed edge from resource type Rjto
thread Tiis denoted by Rj→Ti; it signifies that an instance of resource type
Rjhas been allocated to thread Ti. Adirected edge Ti→Rjis called a request
edge;adirectededge Rj→Tiis calledan assignment edge .
Pictorially, we represent each thread Tias a circle and each resource type
Rjas a rectangle. As a simple example, the resource allocation graph shown
inFigure8.3 illustratesthe deadlocksituationfrom theprogram inFigure8.1.
Since resource type Rjm a yh a v em o r et h a no n ei n s t a n c e ,w er e p r e s e n te a c h
such instance as a dot within the rectangle. Note that a request edge points
only to the rectangle Rj, whereas an assignment edgemust also designateone
ofthe dotsin the rectangle.
When thread Tirequests an instance of resource type Rj,ar e q u e s te d g ei s
inserted in the resource-allocation gr aph. When this request can be fulfilled,
therequestedgeis instantaneously transformedtoanassignmentedge.When
thethreadnolongerneedsaccesstotheresource,itreleasestheresource.Asa
result,theassignment edgeisdeleted.
The resource-allocation graph shown in Figure 8.4 depicts the following
situation.
•The sets T, R,andE:
◦T={T1,T2,T3}
◦R={R1,R2,R3,R4}"
2,8.4 Methods for Handling Deadlocks,424,8.3 Deadlock Characterization,"326 Chapter 8 Deadlocks
However,thereisnodeadlock.Observethatthread T4mayreleaseitsinstance
of resource type R2. That resource can then be allocated to T3,b r e a k i n gt h e
cycle.
In summary, if a resource-allocation graph does not have a cycle, then the
system is notin a deadlocked state. If there is a cycle, then the system mayor
may not beinadeadlockedstate.Thisobservationisimportantwhenwedeal
withthe deadlockproblem.
8.4 Methods for Handling Deadlocks
Generally speaking, we can deal with the deadlock problem in one of three
ways:
•We can ignore the problem altogether and pretend that deadlocks never
occur in the system.
•We can use a protocol to prevent or avoid deadlocks, ensuring that the
systemwill neverentera deadlockedstate.
•Wecanallowthesystemtoenteradeadlockedstate,detectit,andrecover.
The first solution is the one used by most operating systems, including Linux
and Windows. It is then up to kernel and application developers to write
programs that handle deadlocks, typi cally using approaches outlined in the
secondsolution.Somesystems—suchasdatabases—adoptthethirdsolution,
allowing deadlockstooccur and thenmanaging the recovery.
Next, we elaborate briefly on the three methods for handling deadlocks.
Then,inSection8.5throughSection8.8,wepresentdetailedalgorithms.Before
proceeding,weshouldmentionthatsomeresearchershavearguedthatnoneof
the basic approaches alone is appropriate for the entire spectrum of resource-
allocation problems in operating systems. The basic approaches can be com-
bined, however, allowing us to select an optimal approach for each class of
resourcesinasystem.
Toensurethatdeadlocksneveroccur, thesystemcanuseeitheradeadlock-
preventionoradeadlock-avoidancescheme. Deadlock prevention providesa
set of methods to ensure that at least one of the necessary conditions (Section
8.3.1) cannot hold. These methods prevent deadlocks by constraining how
requestsfor resourcescan bemade.WediscussthesemethodsinSection8.5.
Deadlock avoidance requires that the operating system be given addi-
tionalinformationinadvanceconcerningwhichresourcesathreadwillrequest
anduseduringitslifetime.Withthisa dditionalknowledge,theoperatingsys-
tem can decide for each request whether or not the thread should wait. To
decide whether the current request can be satisfied or must be delayed, the
systemmustconsidertheresourcescurrentlyavailable,theresourcescurrently
allocated to each thread, and the future requests and releases of each thread.
Wediscuss theseschemes inSection8.6.
If a system does not employ either a deadlock-prevention or a deadlock-
avoidancealgorithm,thenadeadlocksituationmayarise.Inthisenvironment,
the system can provide an algorithm that examines the state of the system to
determinewhetheradeadlockhas occurredandanalgorithmtorecoverfrom"
2,8.5 Deadlock Prevention,425,8.4 Methods for Handling Deadlocks,"8.5 Deadlock Prevention 327
the deadlock (if a deadlock has indeed occurred). We discuss these issues in
Section8.7and Section8.8.
Intheabsenceofalgorithmstodetectandrecoverfromdeadlocks,wemay
arrive at a situation in which the system is in a deadlocked state yet has no
way of recognizing what has happened. In this case, the undetected deadlock
willcausethesystem’sperformancetodeteriorate,becauseresourcesarebeing
held by threads that cannot run and because more and more threads, as they
make requests for resources, will enter a deadlocked state. Eventually, the
systemwillstop functioning and w illneedto berestartedmanually.
Although this method may not seem to be a viable approach to the dead-
lockproblem,itisneverthelessusedinmostoperatingsystems,asmentioned
earlier. Expense is one important consi deration. Ignoring the possibility of
deadlocksischeaperthantheothera pproaches.Sinceinmanysystems,dead-
locks occur infrequently (say, once per month), the extra expense of the other
methodsmaynot seemworthwhile.
In addition,methods used to recover from other livenessconditions, such
as livelock, may be used to recover from deadlock. In some circumstances, a
system is suffering from a liveness failure but is not in a deadlocked state.
We see this situation, for example, with a real-time thread running at the
highest priority (or any thread running on a nonpreemptive scheduler) and
neverreturningcontroltotheoperatingsystem.Thesystemmusthavemanual
recoverymethodsforsuchconditionsandmaysimplyusethosetechniquesfor
deadlockrecovery.
8.5 Deadlock Prevention
As we noted in Section 8.3.1, for a deadlock to occur, each of the four neces-
sary conditions must hold. By ensuring that at least one of these conditions
cannothold,wecan preventtheoccurrenceofadeadlock.Weelaborateonthis
approach by examiningeach ofthe four necessaryconditions separately.
8.5.1 Mutual Exclusion
The mutual-exclusion condition must hold.That is,at leastone resource must
be nonsharable. Sharable resources do not require mutually exclusive access
andthuscannotbeinvolvedinadeadlock.Read-onlyfilesareagoodexample
of a sharable resource. If several threads attempt to open a read-only file at
t h es a m et i m e ,t h e yc a nb eg r a n t e ds i m u ltaneous access to the file. A thread
never needs to wait for a sharable resource. In general, however, we cannot
prevent deadlocks by denying the mutual-exclusion condition, because some
resources are intrinsically nonsharable. For example, a mutex lock cannot be
simultaneouslysharedby severalthreads.
8.5.2 Hold and Wait
Toensurethatthehold-and-waitconditionneveroccursinthesystem,wemust
guarantee that, whenever a thread requests a resource, it does not hold any
other resources. One protocol that we can use requires each thread to request
and be allocated all its resources before it begins execution. This is, of course,"
3,8.5.1 Mutual Exclusion,425,8.5 Deadlock Prevention,"8.5 Deadlock Prevention 327
the deadlock (if a deadlock has indeed occurred). We discuss these issues in
Section8.7and Section8.8.
Intheabsenceofalgorithmstodetectandrecoverfromdeadlocks,wemay
arrive at a situation in which the system is in a deadlocked state yet has no
way of recognizing what has happened. In this case, the undetected deadlock
willcausethesystem’sperformancetodeteriorate,becauseresourcesarebeing
held by threads that cannot run and because more and more threads, as they
make requests for resources, will enter a deadlocked state. Eventually, the
systemwillstop functioning and w illneedto berestartedmanually.
Although this method may not seem to be a viable approach to the dead-
lockproblem,itisneverthelessusedinmostoperatingsystems,asmentioned
earlier. Expense is one important consi deration. Ignoring the possibility of
deadlocksischeaperthantheothera pproaches.Sinceinmanysystems,dead-
locks occur infrequently (say, once per month), the extra expense of the other
methodsmaynot seemworthwhile.
In addition,methods used to recover from other livenessconditions, such
as livelock, may be used to recover from deadlock. In some circumstances, a
system is suffering from a liveness failure but is not in a deadlocked state.
We see this situation, for example, with a real-time thread running at the
highest priority (or any thread running on a nonpreemptive scheduler) and
neverreturningcontroltotheoperatingsystem.Thesystemmusthavemanual
recoverymethodsforsuchconditionsandmaysimplyusethosetechniquesfor
deadlockrecovery.
8.5 Deadlock Prevention
As we noted in Section 8.3.1, for a deadlock to occur, each of the four neces-
sary conditions must hold. By ensuring that at least one of these conditions
cannothold,wecan preventtheoccurrenceofadeadlock.Weelaborateonthis
approach by examiningeach ofthe four necessaryconditions separately.
8.5.1 Mutual Exclusion
The mutual-exclusion condition must hold.That is,at leastone resource must
be nonsharable. Sharable resources do not require mutually exclusive access
andthuscannotbeinvolvedinadeadlock.Read-onlyfilesareagoodexample
of a sharable resource. If several threads attempt to open a read-only file at
t h es a m et i m e ,t h e yc a nb eg r a n t e ds i m u ltaneous access to the file. A thread
never needs to wait for a sharable resource. In general, however, we cannot
prevent deadlocks by denying the mutual-exclusion condition, because some
resources are intrinsically nonsharable. For example, a mutex lock cannot be
simultaneouslysharedby severalthreads.
8.5.2 Hold and Wait
Toensurethatthehold-and-waitconditionneveroccursinthesystem,wemust
guarantee that, whenever a thread requests a resource, it does not hold any
other resources. One protocol that we can use requires each thread to request
and be allocated all its resources before it begins execution. This is, of course,"
3,8.5.2 Hold and Wait,425,8.5.1 Mutual Exclusion,"8.5 Deadlock Prevention 327
the deadlock (if a deadlock has indeed occurred). We discuss these issues in
Section8.7and Section8.8.
Intheabsenceofalgorithmstodetectandrecoverfromdeadlocks,wemay
arrive at a situation in which the system is in a deadlocked state yet has no
way of recognizing what has happened. In this case, the undetected deadlock
willcausethesystem’sperformancetodeteriorate,becauseresourcesarebeing
held by threads that cannot run and because more and more threads, as they
make requests for resources, will enter a deadlocked state. Eventually, the
systemwillstop functioning and w illneedto berestartedmanually.
Although this method may not seem to be a viable approach to the dead-
lockproblem,itisneverthelessusedinmostoperatingsystems,asmentioned
earlier. Expense is one important consi deration. Ignoring the possibility of
deadlocksischeaperthantheothera pproaches.Sinceinmanysystems,dead-
locks occur infrequently (say, once per month), the extra expense of the other
methodsmaynot seemworthwhile.
In addition,methods used to recover from other livenessconditions, such
as livelock, may be used to recover from deadlock. In some circumstances, a
system is suffering from a liveness failure but is not in a deadlocked state.
We see this situation, for example, with a real-time thread running at the
highest priority (or any thread running on a nonpreemptive scheduler) and
neverreturningcontroltotheoperatingsystem.Thesystemmusthavemanual
recoverymethodsforsuchconditionsandmaysimplyusethosetechniquesfor
deadlockrecovery.
8.5 Deadlock Prevention
As we noted in Section 8.3.1, for a deadlock to occur, each of the four neces-
sary conditions must hold. By ensuring that at least one of these conditions
cannothold,wecan preventtheoccurrenceofadeadlock.Weelaborateonthis
approach by examiningeach ofthe four necessaryconditions separately.
8.5.1 Mutual Exclusion
The mutual-exclusion condition must hold.That is,at leastone resource must
be nonsharable. Sharable resources do not require mutually exclusive access
andthuscannotbeinvolvedinadeadlock.Read-onlyfilesareagoodexample
of a sharable resource. If several threads attempt to open a read-only file at
t h es a m et i m e ,t h e yc a nb eg r a n t e ds i m u ltaneous access to the file. A thread
never needs to wait for a sharable resource. In general, however, we cannot
prevent deadlocks by denying the mutual-exclusion condition, because some
resources are intrinsically nonsharable. For example, a mutex lock cannot be
simultaneouslysharedby severalthreads.
8.5.2 Hold and Wait
Toensurethatthehold-and-waitconditionneveroccursinthesystem,wemust
guarantee that, whenever a thread requests a resource, it does not hold any
other resources. One protocol that we can use requires each thread to request
and be allocated all its resources before it begins execution. This is, of course,"
3,8.5.3 No Preemption,426,8.5.2 Hold and Wait,"328 Chapter 8 Deadlocks
impractical for most applications due to the dynamic nature of requesting
resources.
An alternative protocol allows a thread to request resources only when it
has none. A thread may request some resources and use them. Before it can
request any additional resources, it must release all the resources that it is
currentlyallocated.
Both theseprotocols have two main disadvantages.First,resource utiliza-
tionmaybelow,sinceresourcesmaybeallocatedbutunusedforalongperiod.
For example, a thread may be allocated a mutex lock for its entire execution,
yetonlyrequireitforashortduration.Second,starvationispossible.Athread
that needsseveralpopularresourcesmay haveto waitindefinitely,because at
leastoneoftheresourcesthatitneedsi salwaysallocatedtosomeotherthread.
8.5.3 No Preemption
The third necessary condition for deadlocks is that there be no preemption
of resources that have already been allo cated. To ensure that this condition
does not hold, we can use the following protocol. If a thread is holding some
resources and requestsanother resource that cannot be immediatelyallocated
to it (that is, the thread must wait), then all resources the thread is currently
holdingarepreempted.Inotherwords,theseresourcesareimplicitlyreleased.
Thepreemptedresourcesareaddedtothelistofresourcesforwhichthethread
iswaiting.Thethreadwillberestartedonlywhenitcanregainitsoldresources,
as wellasthe new onesthat it isrequesting.
Alternatively, if a thread requests some resources, we first check whether
they are available. If they are, we allocate them. If they are not, we check
whether they are allocated to some other thread that is waiting for additional
resources.Ifso,wepreemptthedesiredresourcesfromthewaitingthreadand
allocatethemtotherequestingthread.Iftheresourcesareneitheravailablenor
heldbya waitingthread,therequestingthreadmustwait.Whileitiswaiting,
some of its resources may be preempted, but only if another thread requests
them. A thread can be restarted only when it is allocated the new resources
it is requesting and recovers any resources that were preempted while it was
waiting.
This protocolis oftenappliedto resourceswhose statecan beeasilysaved
and restored later, such as CPUregisters and database transactions. It can-
not generally be applied to such resources as mutex locks and semaphores,
preciselythe type of resourceswhere deadlockoccurs mostcommonly.
8.5.4 Circular Wait
The three options presented thus far for deadlock prevention are generally
impractical in most situations. However, the fourth and final condition for
deadlocks — the circular-wait condition — presents an opportunity for a
practical solution by invalidating one of the necessary conditions. One way
to ensure that this condition never holds is to impose a total ordering of
all resource types and to require that each thread requests resources in an
increasing orderof enumeration.
To illustrate, we let R={R1,R2, ...,Rm}be the set of resource types. We
assign to each resource type a unique integer number, which allows us to"
3,8.5.4 Circular Wait,426,8.5.3 No Preemption,"328 Chapter 8 Deadlocks
impractical for most applications due to the dynamic nature of requesting
resources.
An alternative protocol allows a thread to request resources only when it
has none. A thread may request some resources and use them. Before it can
request any additional resources, it must release all the resources that it is
currentlyallocated.
Both theseprotocols have two main disadvantages.First,resource utiliza-
tionmaybelow,sinceresourcesmaybeallocatedbutunusedforalongperiod.
For example, a thread may be allocated a mutex lock for its entire execution,
yetonlyrequireitforashortduration.Second,starvationispossible.Athread
that needsseveralpopularresourcesmay haveto waitindefinitely,because at
leastoneoftheresourcesthatitneedsi salwaysallocatedtosomeotherthread.
8.5.3 No Preemption
The third necessary condition for deadlocks is that there be no preemption
of resources that have already been allo cated. To ensure that this condition
does not hold, we can use the following protocol. If a thread is holding some
resources and requestsanother resource that cannot be immediatelyallocated
to it (that is, the thread must wait), then all resources the thread is currently
holdingarepreempted.Inotherwords,theseresourcesareimplicitlyreleased.
Thepreemptedresourcesareaddedtothelistofresourcesforwhichthethread
iswaiting.Thethreadwillberestartedonlywhenitcanregainitsoldresources,
as wellasthe new onesthat it isrequesting.
Alternatively, if a thread requests some resources, we first check whether
they are available. If they are, we allocate them. If they are not, we check
whether they are allocated to some other thread that is waiting for additional
resources.Ifso,wepreemptthedesiredresourcesfromthewaitingthreadand
allocatethemtotherequestingthread.Iftheresourcesareneitheravailablenor
heldbya waitingthread,therequestingthreadmustwait.Whileitiswaiting,
some of its resources may be preempted, but only if another thread requests
them. A thread can be restarted only when it is allocated the new resources
it is requesting and recovers any resources that were preempted while it was
waiting.
This protocolis oftenappliedto resourceswhose statecan beeasilysaved
and restored later, such as CPUregisters and database transactions. It can-
not generally be applied to such resources as mutex locks and semaphores,
preciselythe type of resourceswhere deadlockoccurs mostcommonly.
8.5.4 Circular Wait
The three options presented thus far for deadlock prevention are generally
impractical in most situations. However, the fourth and final condition for
deadlocks — the circular-wait condition — presents an opportunity for a
practical solution by invalidating one of the necessary conditions. One way
to ensure that this condition never holds is to impose a total ordering of
all resource types and to require that each thread requests resources in an
increasing orderof enumeration.
To illustrate, we let R={R1,R2, ...,Rm}be the set of resource types. We
assign to each resource type a unique integer number, which allows us to"
2,8.6 Deadlock Avoidance,428,8.5 Deadlock Prevention,"330 Chapter 8 Deadlocks
void transaction(Account from, Account to, double amount)
{
mutex lock1, lock2;
lock1 = get
 lock(from);
lock2 = get
 lock(to);
acquire(lock1);
acquire(lock2);
withdraw(from, amount);
deposit(to, amount);
release(lock2);
release(lock1);
}
Figure 8.7 Deadlock example with lock ordering.
8.6 Deadlock Avoidance
Deadlock-prevention algorithms, as discussed in Section 8.5, prevent dead-
locks by limiting how requests can be made. The limits ensure that at least
oneofthenecessaryconditionsfordeadlockcannotoccur.Possiblesideeffects
of preventing deadlocks by this method, however, are low device utilization
and reducedsystemthroughput.
An alternative method for avoiding deadlocks is to require additional
informationabouthowresourcesaretoberequested.Forexample,inasystem
with resources R1a n d R2, the system might need to know that thread P
will request first R1a n dt h e n R2 before releasing both resources, whereas
thread Qwill request R2a n dt h e n R1. With this knowledge of the complete
sequence of requests and releases for each thread, the system can decide for
eachrequestwhetherornotthethreadshouldwaitinordertoavoidapossible
futuredeadlock.Eachrequestrequiresthatinmakingthisdecisionthesystem
considerthe resourcescurrentlyavailable,theresourcescurrentlyallocatedto
eachthread,andthe futurerequestsandreleasesof eachthread.
The various algorithms that use this approach differ in the amount and
typeofinformationrequired.Thesimplestandmostusefulmodelrequiresthat
eachthreaddeclarethe maximum number ofresourcesofeachtypethatitmay
need. Given this a priori information, it is possible to construct an algorithm
that ensures that the system will never en ter a deadlocked state. Adeadlock-
avoidance algorithm dynamically examines the resource-allocation state to
ensure that a circular-wait condition can never exist. The resource-allocation
stateis defined by the number of available and allocated resources and the
maximum demands of the threads. In the following sections, we explore two
deadlock-avoidancealgorithms."
3,8.6.1 Safe State,429,8.6 Deadlock Avoidance,"8.6 Deadlock Avoidance 331
LINUX LOCKDEP TOOL
Although ensuring that resources are acquired in the proper order is the
responsibility of kernel and application developers, certain software can be
used to verify that locks are acquired in the proper order. To detect possible
deadlocks,Linuxprovides lockdep ,atoolwithrichfunctionalitythatcanbe
usedtoverifylockingorderinthekernel. lockdep isdesignedtobeenabled
on a running kernel as it monitors usag e patterns of lock acquisitions and
releasesagainstasetofrulesforacqui ringandreleasinglocks.Twoexamples
follow,butnotethat lockdep providessignificantlymorefunctionalitythan
what isdescribedhere:
•Theorderinwhich locks areacquired is dynamically maintained by the
system.If lockdep detectslocksbeingacquiredoutoforder,itreportsa
possible deadlock condition.
•In Linux, spinlocks can be used in interrupt handlers. Apossible source
of deadlock occurswhen thekernelacquires a spinlock that is also used
in an interrupt handler. If the interrupt occurs while the lock is being
held, the interrupt handler preempts the kernel code currently holding
the lock and then spins while attempting to acquire the lock, resulting
indeadlock.Thegeneralstrategyfor avoidingthissituationistodisable
interrupts on the current processor before acquiring a spinlock that is
also used in an interrupt handler. If lockdep detects that interrupts are
enabledwhilekernelcodeacquiresalockthatisalsousedinaninterrupt
handler,it will reporta possibledeadlock scenario.
lockdep was developed to be used as a tool in developing or modifying
code in the kernel and not to be used on production systems, as it can
significantly slow down a system. Its p urpose is to test whether software
such as a new device driver or kernel module provides a possible source
of deadlock. The designers of lockdep have reported that within a few
years of its development in 2006, th e number of deadlocks from system
reportshad beenreducedby an order of magnitude.âŁž Although lockdep
was originally designed only for use in the kernel, recent revisions of this
tool can now be used for detecting deadlocks in user applications using
Pthreads mutex locks. Further details on the lockdep tool can be found at
https://www.kernel.org/doc/Document ation/locking/lockdep-design.txt .
8.6.1 Safe State
A state is safeif the system can allocate resources to each thread (up to its
maximum) in some order and still avoid a deadlock. More formally, a system
is in a safe state only if there exists a safe sequence .As e q u e n c eo ft h r e a d s
<T1,T2, ...,Tn>i sas a f es e q u e n c ef o rt h ec u r r e n ta l l o c a t i o ns t a t ei f ,f o re a c h
Ti, the resource requests that Tican stillmake can be satisfiedbythe currently
availableresourcesplustheresourcesheldbyall Tj,with j<i.Inthissituation,
if the resources that Tineeds are not immediately available, then Tican wait
until all Tjhave finished. When they have finished, Tic a no b t a i na l lo fi t s"
3,8.6.2 Resource-Allocation-Graph Algorithm,431,8.6.1 Safe State,"8.6 Deadlock Avoidance 333
threads had finished and released its resources, then we could have avoided
thedeadlock.
Given theconcept of a safe state,we can define avoidancealgorithms that
ensurethatthesystemwillneverdeadlock .Theideaissimplytoensurethatthe
systemwillalwaysremaininasafestate.Initially,thesystemisinasafestate.
Whenever a thread requests a resource that is currently available, the system
must decide whether the resource can be allocated immediately or the thread
must wait. The request is granted only if the allocation leaves the system in a
safestate.
Inthis scheme,ifa threadrequestsa resourcethat iscurrentlyavailable,it
may still have to wait. Thus, resource utilization may be lower than it would
otherwisebe.
8.6.2 Resource-Allocation-Graph Algorithm
Ifwehavearesource-allocationsystemwithonlyoneinstanceofeachresource
type, we can use a variant of the resource-allocation graph defined in Section
8.3.2fordeadlockavoidance.Inadditi ontotherequestand assignmentedges
already described, we introduce a new type of edge, called a claim edge .A
claimedge Ti→Rjindicatesthatthread Timayrequestresource Rjatsometime
inthefuture.Thisedgeresemblesarequestedgeindirectionbutisrepresented
in the graph by a dashed line. When thread Tirequests resource Rj,t h ec l a i m
edge Ti→Rjis converted to a request edge. Similarly, when a resource Rjis
releasedby Ti,theassignmentedge Rj→Tiisreconvertedtoaclaimedge Ti→
Rj.
Note that the resources must be claimed a priori in the system. That is,
beforethread Tistartsexecuting,allitsclaimedgesmustalreadyappearinthe
resource-allocationgraph.Wecanrelaxthisconditionbyallowingaclaimedge
Ti→Rjtobeaddedtothegraphonlyifalltheedgesassociatedwiththread Ti
areclaimedges.
Now suppose that thread Tirequests resource Rj.T h er e q u e s tc a nb e
granted only if converting the request edge Ti→Rjto an assignment edge
Rj→Tidoes not result in the formation of a cycle in the resource-allocation
graph.Wecheckforsafetybyusingacycle-detectionalgorithm.Analgorithm
for detecting a cycle in this graph requires an order of n2operations, where n
isthenumber of threadsinthesystem.
If no cycle exists, then the allocation of the resource will leave the system
in a safe state. If a cycle is found, then the allocation will put the system in
an unsafe state. In that case, thread Tiwill have to wait for its requests to be
satisfied.
To illustrate this algorithm, we consider the resource-allocation graph of
Figure 8.9. Suppose that T2requests R2.A l t h o u g h R2is currently free, we
cannotallocateitto T2,sincethisactionwillcreateacycleinthegraph(Figure
8.10). Acycle, as mentioned, indicates that the system is in an unsafe state. If
T1requests R2,a n d T2requests R1,then a deadlockwilloccur.
8.6.3 Banker’s Algorithm
The resource-allocation-graph algorithm is not applicable to a resource-
allocation system with multiple instances of each resource type. The"
3,8.6.3 Banker’s Algorithm,431,8.6.2 Resource-Allocation-Graph Algorithm,"8.6 Deadlock Avoidance 333
threads had finished and released its resources, then we could have avoided
thedeadlock.
Given theconcept of a safe state,we can define avoidancealgorithms that
ensurethatthesystemwillneverdeadlock .Theideaissimplytoensurethatthe
systemwillalwaysremaininasafestate.Initially,thesystemisinasafestate.
Whenever a thread requests a resource that is currently available, the system
must decide whether the resource can be allocated immediately or the thread
must wait. The request is granted only if the allocation leaves the system in a
safestate.
Inthis scheme,ifa threadrequestsa resourcethat iscurrentlyavailable,it
may still have to wait. Thus, resource utilization may be lower than it would
otherwisebe.
8.6.2 Resource-Allocation-Graph Algorithm
Ifwehavearesource-allocationsystemwithonlyoneinstanceofeachresource
type, we can use a variant of the resource-allocation graph defined in Section
8.3.2fordeadlockavoidance.Inadditi ontotherequestand assignmentedges
already described, we introduce a new type of edge, called a claim edge .A
claimedge Ti→Rjindicatesthatthread Timayrequestresource Rjatsometime
inthefuture.Thisedgeresemblesarequestedgeindirectionbutisrepresented
in the graph by a dashed line. When thread Tirequests resource Rj,t h ec l a i m
edge Ti→Rjis converted to a request edge. Similarly, when a resource Rjis
releasedby Ti,theassignmentedge Rj→Tiisreconvertedtoaclaimedge Ti→
Rj.
Note that the resources must be claimed a priori in the system. That is,
beforethread Tistartsexecuting,allitsclaimedgesmustalreadyappearinthe
resource-allocationgraph.Wecanrelaxthisconditionbyallowingaclaimedge
Ti→Rjtobeaddedtothegraphonlyifalltheedgesassociatedwiththread Ti
areclaimedges.
Now suppose that thread Tirequests resource Rj.T h er e q u e s tc a nb e
granted only if converting the request edge Ti→Rjto an assignment edge
Rj→Tidoes not result in the formation of a cycle in the resource-allocation
graph.Wecheckforsafetybyusingacycle-detectionalgorithm.Analgorithm
for detecting a cycle in this graph requires an order of n2operations, where n
isthenumber of threadsinthesystem.
If no cycle exists, then the allocation of the resource will leave the system
in a safe state. If a cycle is found, then the allocation will put the system in
an unsafe state. In that case, thread Tiwill have to wait for its requests to be
satisfied.
To illustrate this algorithm, we consider the resource-allocation graph of
Figure 8.9. Suppose that T2requests R2.A l t h o u g h R2is currently free, we
cannotallocateitto T2,sincethisactionwillcreateacycleinthegraph(Figure
8.10). Acycle, as mentioned, indicates that the system is in an unsafe state. If
T1requests R2,a n d T2requests R1,then a deadlockwilloccur.
8.6.3 Banker’s Algorithm
The resource-allocation-graph algorithm is not applicable to a resource-
allocation system with multiple instances of each resource type. The"
2,8.7 Deadlock Detection,435,8.6 Deadlock Avoidance,"8.7 Deadlock Detection 337
(1,0,2) ≤(3,3,2), which is true. We then pretend that this request has been
fulfilled,andwe arriveat thefollowing new state:
Allocation Need Available
ABC ABC ABC
T0010 743 230
T1302 020
T2302 600
T3211 011
T4002 431
We must determine whether this new system state is safe. To do so, we
execute our safety algorithm and find that the sequence <T1,T3,T4,T0,T2>
satisfies the safety requirement.Hence, we can immediatelygrant the request
ofthread T1.
You shouldbeabletosee,however,thatwhenthesystemisinthisstate,a
requestfor(3,3,0)by T4cannotbegranted,sincetheresourcesarenotavailable.
Furthermore, a request for (0,2,0) by T0cannot be granted, even though the
resourcesareavailable,sincethe resultingstateisunsafe.
We leave it as a programming exercise for students to implement the
banker’s algorithm.
8.7 Deadlock Detection
If a system does not employ either a deadlock-prevention or a deadlock-
avoidancealgorithm,thenadeadlocksituationmayoccur.Inthisenvironment,
thesystemmayprovide:
•An algorithm that examines the state of the system to determine whether
a deadlockhas occurred
•Analgorithm torecoverfrom thedeadlock
Next, we discuss these two requirements as they pertain to systems with
only a single instance of each resource type, as well as to systems with sev-
eral instances of each resource type. At this point, however, we note that a
detection-and-recovery scheme requires overhead that includes not only the
run-time costs of maintaining the necessary information and executing the
detection algorithm but also the potential losses inherent in recovering from
adeadlock.
8.7.1 Single Instance of Each Resource Type
If all resources have only a single instance, then we can define a deadlock-
detectionalgorithmthatusesavariantoftheresource-allocationgraph,called
await-for graph. We obtain this graph from the resource-allocation graph by
removingthe resourcenodes andcollapsing theappropriateedges.
Moreprecisely,anedgefrom TitoTjinawait-forgraphimpliesthatthread
Tiis waiting for thread Tjto release a resource that Tineeds. An edge Ti→Tj"
3,8.7.1 Single Instance of Each Resource Type,435,8.7 Deadlock Detection,"8.7 Deadlock Detection 337
(1,0,2) ≤(3,3,2), which is true. We then pretend that this request has been
fulfilled,andwe arriveat thefollowing new state:
Allocation Need Available
ABC ABC ABC
T0010 743 230
T1302 020
T2302 600
T3211 011
T4002 431
We must determine whether this new system state is safe. To do so, we
execute our safety algorithm and find that the sequence <T1,T3,T4,T0,T2>
satisfies the safety requirement.Hence, we can immediatelygrant the request
ofthread T1.
You shouldbeabletosee,however,thatwhenthesystemisinthisstate,a
requestfor(3,3,0)by T4cannotbegranted,sincetheresourcesarenotavailable.
Furthermore, a request for (0,2,0) by T0cannot be granted, even though the
resourcesareavailable,sincethe resultingstateisunsafe.
We leave it as a programming exercise for students to implement the
banker’s algorithm.
8.7 Deadlock Detection
If a system does not employ either a deadlock-prevention or a deadlock-
avoidancealgorithm,thenadeadlocksituationmayoccur.Inthisenvironment,
thesystemmayprovide:
•An algorithm that examines the state of the system to determine whether
a deadlockhas occurred
•Analgorithm torecoverfrom thedeadlock
Next, we discuss these two requirements as they pertain to systems with
only a single instance of each resource type, as well as to systems with sev-
eral instances of each resource type. At this point, however, we note that a
detection-and-recovery scheme requires overhead that includes not only the
run-time costs of maintaining the necessary information and executing the
detection algorithm but also the potential losses inherent in recovering from
adeadlock.
8.7.1 Single Instance of Each Resource Type
If all resources have only a single instance, then we can define a deadlock-
detectionalgorithmthatusesavariantoftheresource-allocationgraph,called
await-for graph. We obtain this graph from the resource-allocation graph by
removingthe resourcenodes andcollapsing theappropriateedges.
Moreprecisely,anedgefrom TitoTjinawait-forgraphimpliesthatthread
Tiis waiting for thread Tjto release a resource that Tineeds. An edge Ti→Tj"
3,8.7.2 Several Instances of a Resource Type,436,8.7.1 Single Instance of Each Resource Type,"338 Chapter 8 Deadlocks
T3T5
T4T2 T1
R2R1 R3 R4
R5T3T5
T4T2 T1
(b) (a)
Figure 8.11 (a) Resource-allocation graph. (b) Corresponding wait-for graph.
exists in a wait-for graph if and only if the corresponding resource-allocation
graph contains two edges Ti→RqandRq→Tjforsomeresource Rq.InFigu r e
8.11, we present a resource-allocation graph and the corresponding wait-for
graph.
Asbefore,a deadlockexistsinthesystemif andonly if thewait-for graph
contains a cycle. To detect deadlocks, the system needs to maintain the wait-
forgraphandperiodically invoke an algorithm thatsearchesforacycle inthe
graph. An algorithm to detect a cycle in a graph requires O(n2)o p e r a t i o n s ,
where nisthenumber of verticesin thegraph.
TheBCCtoolkit described in Section 2.10.4 provides a tool that can
detect potential deadlocks with Pthreads mutex locks in a user process
running on a Linux system. The BCCtool deadlock
 detector operates
by inserting probes which trace calls to the pthread
 mutex
 lock() and
pthread
 mutex
 unlock() functions. When thespecifiedprocessmakesa call
to either function, deadlock
 detector constructs a wait-for graph of mutex
locksinthatprocess,andreportsthepo ssibilityofdeadlockifitdetectsacycle
in thegraph.
8.7.2 Several Instances of a Resource Type
The wait-for graph scheme is not applicable to a resource-allocation system
with multiple instances of each resource type. We turn now to a deadlock-
detectionalgorithmthatisapplicabletosuchasystem.Thealgorithmemploys
several time-varying data structures that are similar to those used in the
banker’s algorithm (Section8.6.3):
•Available .Avectoroflength mindicatesthenumberofavailableresources
of each type."
3,8.7.3 Detection-Algorithm Usage,438,8.7.2 Several Instances of a Resource Type,"340 Chapter 8 Deadlocks
You may wonder why we reclaim the resources of thread Ti(in step 3) as
soon as we determine that Requesti≤Work(in step 2b). We know that Tiis
currently notinvolved in a deadlock (since Requesti≤Work). Thus, we take
an optimistic attitude and assume that Tiwill require no more resources to
complete its task; it will thus soon return all currently allocated resources to
the system. If our assumption is incorrect, a deadlock may occur later. That
deadlock will be detected the next time t he deadlock-detection algorithm is
invoked.
To illustrate this algorithm, we consider a system with five threads T0
through T4and three resource types A, B,and C.Resource type Ahas seven
instances, resource type Bhas two instances, and resource type Chas six
instances. The following snapshot representsthe current state of the system:
Allocation Request Available
ABC ABC ABC
T0010 000 000
T1200 202
T2303 000
T3211 100
T4002 002
Weclaimthatthesystemisnotinadeadlockedstate.Indeed,ifweexecute
our algorithm, we will find that the sequence <T0,T2,T3,T1,T4>results in
Finish[i]= = trueforall i.
Suppose now that thread T2makes one additional request for an instance
of type C.TheRequest matrixismodifiedas follows:
Request
ABC
T0000
T1202
T2001
T3100
T4002
Weclaimthatthesystemisnowdeadlocked.Althoughwecanreclaimthe
resourcesheldbythread T0,thenumberofavailableresourcesisnotsufficient
to fulfill the requests of the other threads. Thus, a deadlock exists, consisting
of threads T1,T2,T3,a n d T4.
8.7.3 Detection-Algorithm Usage
Whenshouldweinvokethedetectionalgorithm?Theanswerdependsontwo
factors:
1.How oftenis adeadlocklikelyto occur?
2.How manythreadswillbe affectedby deadlockwhen ithappens?"
2,8.8 Recovery from Deadlock,439,8.7 Deadlock Detection,"8.8 Recovery from Deadlock 341
MANAGING DEADLOCK IN DATABASES
Database systems provide a useful illustration of how both open-source
and commercial software manage deadlock. Updates to a database may be
performed as transactions , and to ensure data integrity, locks are typically
used. A transaction may involve sever al locks, so it comes as no surprise
that deadlocks are possible in a databa se with multiple concurrent transac-
tions. To manage deadlock, most transactional database systems include a
deadlock detection and recovery mech anism. The database server will peri-
odically search for cycles in the wait -for graph to detect deadlock among a
set of transactions. When deadlock is detected, a victim is selected and the
transaction is aborted and rolled back, releasing the locks held by the victim
transaction and freeing the remaining transactions from deadlock. Once the
remaining transactions have resumed, t he aborted transaction is reissued.
Choiceof a victimtransactiondepends onthedatabase system; forinstance,
MySQLattempts to select transactions that minimize the number of rows
beinginserted, updated, or deleted.
Ifdeadlocksoccur frequently,thenthed etectionalgorithmshouldbeinvoked
frequently. Resources allocated to deadlocked threads will be idle until the
deadlock can be broken. In addition, the number of threads involved in the
deadlockcycle maygrow.
Deadlocks occur only when some thread makes a request that cannot be
granted immediately. This request may be the final request that completes a
chain of waiting threads. In the extreme, then, we can invoke the deadlock-
detection algorithm every time a request for allocation cannot be granted
immediately.Inthiscase,wecanidentifynotonlythedeadlockedsetofthreads
but also the specific thread that “caused ”the deadlock. (In reality, each of the
deadlocked threads is a link in the cycle in the resource graph, so all of them,
jointly, caused the deadlock.) If there are many different resource types, one
request may create many cycles in the resource graph, each cycle completed
by themostrecentrequestand “caused ”by the one identifiable thread.
Of course, invoking the deadlock-detection algorithm for every resource
request will incur considerable overhead in computation time. A less expen-
sive alternative is simply to invoke the algorithm at defined intervals—for
example, once per hour or whenever CPUutilization drops below 40 percent.
(Adeadlockeventuallycripplessystemthroughputandcauses CPUutilization
to drop.) If the detection algorithm is invoked at arbitrary points in time, the
resourcegraphmaycontainmanycycles.Inthiscase,wegenerallycannottell
which of the many deadlockedthreads “caused ”the deadlock.
8.8 Recovery from Deadlock
When a detection algorithm determines that a deadlock exists, several alter-
nativesareavailable.One possibility isto inform the operatorthat a deadlock
hasoccurredandtolettheoperatordealwiththedeadlockmanually.Another
possibility is to let the system recoverfrom the deadlock automatically. There"
3,8.8.1 Process and Thread Termination,440,8.8 Recovery from Deadlock,"342 Chapter 8 Deadlocks
are two options for breaking a deadlock. One is simply to abort one or more
threadstobreakthecircularwait.Theotheristopreemptsomeresourcesfrom
one ormoreof the deadlockedthreads.
8.8.1 Process and Thread Termination
To eliminate deadlocks by aborting a process or thread, we use one of two
methods. In both methods, the system reclaims all resources allocated to the
terminatedprocesses.
•Abort all deadlocked processes .Thismethodclearlywillbreakthedead-
lockcycle,butatgreatexpense.Thedeadlockedprocessesmayhavecom-
puted for a long time, and the results of these partial computations must
bediscardedand probably willhaveto berecomputedlater.
•Abort one process at a time until the deadlock cycle is eliminated .T h i s
methodincursconsiderableoverhead,s inceaftereachprocessisaborted,a
deadlock-detectionalgorithm mustb einvokedtodeterminewhetherany
processesarestilldeadlocked.
Aborting a process may not be easy. If the process was in the midst of
updatingafile,terminatingitmayleavethatfileinanincorrectstate.Similarly,
iftheprocesswasinthemidstofupdatingshareddatawhileholdingamutex
lock,thesystemmustrestorethestatusofthelockasbeingavailable,although
no guaranteescan be maderegardingthe integrityofthe shared data.
If the partial termination method is used, then we must determine which
deadlockedprocess(orprocesses)shouldbeterminated.Thisdeterminationis
apolicydecision,similarto CPU-schedulingdecisions.Thequestionisbasically
an economic one; we should abort tho se processes whose termination will
incurtheminimumcost.Unfortunately,theterm minimum cost isnotaprecise
one. Many factors mayaffect which processischosen, including:
1.What the priorityofthe processis
2.How long the process has computed and how much longer the process
willcompute beforecompletingitsdesignatedtask
3.How many and what types of resources the process has used (for exam-
ple,whether the resourcesaresimpleto preempt)
4.How many moreresourcesthe processneedsinorderto complete
5.How many processeswillneedto beterminated
8.8.2 Resource Preemption
To eliminate deadlocks using resource preemption, we successively preempt
someresourcesfromprocessesandgivetheseresourcestootherprocessesuntil
thedeadlockcycle isbroken.
Ifpreemptionisrequiredtodealwithdeadlocks,thenthreeissuesneedto
be addressed:"
3,8.8.2 Resource Preemption,440,8.8.1 Process and Thread Termination,"342 Chapter 8 Deadlocks
are two options for breaking a deadlock. One is simply to abort one or more
threadstobreakthecircularwait.Theotheristopreemptsomeresourcesfrom
one ormoreof the deadlockedthreads.
8.8.1 Process and Thread Termination
To eliminate deadlocks by aborting a process or thread, we use one of two
methods. In both methods, the system reclaims all resources allocated to the
terminatedprocesses.
•Abort all deadlocked processes .Thismethodclearlywillbreakthedead-
lockcycle,butatgreatexpense.Thedeadlockedprocessesmayhavecom-
puted for a long time, and the results of these partial computations must
bediscardedand probably willhaveto berecomputedlater.
•Abort one process at a time until the deadlock cycle is eliminated .T h i s
methodincursconsiderableoverhead,s inceaftereachprocessisaborted,a
deadlock-detectionalgorithm mustb einvokedtodeterminewhetherany
processesarestilldeadlocked.
Aborting a process may not be easy. If the process was in the midst of
updatingafile,terminatingitmayleavethatfileinanincorrectstate.Similarly,
iftheprocesswasinthemidstofupdatingshareddatawhileholdingamutex
lock,thesystemmustrestorethestatusofthelockasbeingavailable,although
no guaranteescan be maderegardingthe integrityofthe shared data.
If the partial termination method is used, then we must determine which
deadlockedprocess(orprocesses)shouldbeterminated.Thisdeterminationis
apolicydecision,similarto CPU-schedulingdecisions.Thequestionisbasically
an economic one; we should abort tho se processes whose termination will
incurtheminimumcost.Unfortunately,theterm minimum cost isnotaprecise
one. Many factors mayaffect which processischosen, including:
1.What the priorityofthe processis
2.How long the process has computed and how much longer the process
willcompute beforecompletingitsdesignatedtask
3.How many and what types of resources the process has used (for exam-
ple,whether the resourcesaresimpleto preempt)
4.How many moreresourcesthe processneedsinorderto complete
5.How many processeswillneedto beterminated
8.8.2 Resource Preemption
To eliminate deadlocks using resource preemption, we successively preempt
someresourcesfromprocessesandgivetheseresourcestootherprocessesuntil
thedeadlockcycle isbroken.
Ifpreemptionisrequiredtodealwithdeadlocks,thenthreeissuesneedto
be addressed:"
2,8.9 Summary,441,8.8 Recovery from Deadlock,"8.9 Summary 343
1.Selecting a victim . Which resources and which processes are to be pre-
empted?Asinprocesstermination,wemustdeterminetheorderofpre-
emption to minimize cost. Cost factors may include such parameters as
thenumberofresourcesadeadlockedprocessisholdingandtheamount
of timethe processhas thus far consumed.
2.Rollback .Ifwepreemptaresourcefromaprocess,whatshouldbedone
withthatprocess?Clearly,itcannotcontinuewithitsnormalexecution;it
is missing some needed resource. We must roll back the process to some
safe state and restartitfrom that state.
Since, in general, it is difficult to determine what a safe state is, the
simplest solution is a total rollback: abort the process and then restart
it. Although it is more effective to roll back the process only as far as
necessarytobreakthedeadlock,thismethodrequiresthesystemtokeep
more information about the state ofall running processes.
3.Starvation .Howdoweensurethatstarvationwillnotoccur?Thatis,how
can we guarantee that resources will not always be preempted from the
sameprocess?
In a system where victim selection is based primarily on cost factors,
it may happen that the same process is always picked as a victim. As
a result, this process never completes its designated task, a starvation
situationanypracticalsystemmustaddress.Clearly,wemustensurethat
a processcanbe pickedas a victimonly a (small)finite number of times.
The most common solution is to include the number of rollbacks in the
cost factor.
8.9 Summary
•Deadlock occurs in a set of processes when every process in the set is
waitingforaneventthatcanonlybecausedbyanotherprocessintheset.
•Therearefournecessaryconditionsfordeadlock:(1)mutualexclusion,(2)
hold and wait, (3) no preemption, and (4) circular wait. Deadlock is only
possible when allfour conditions are present.
•Deadlockscanbemodeledwithresource-allocationgraphs,whereacycle
indicatesdeadlock.
•Deadlocks can be prevented by ensuring that one of the four necessary
conditions for deadlock cannot occur. Of the four necessary conditions,
eliminatingthe circularwait isthe only practicalapproach.
•Deadlock can be avoided by using the banker’s algorithm, which does
not grant resourcesif doingsowould leadthe systemintoan unsafe state
where deadlockwould bepossible.
•Adeadlock-detectionalgorithmcanevaluateprocessesandresourcesona
running systemto determineif a setof processesisina deadlockedstate.
•Ifdeadlockdoesoccur,asystemcanattempttorecoverfromthedeadlock
by either aborting one of the processes in the circular wait or preempting
resourcesthat havebeenassignedto a deadlockedprocess."
2,Practice Exercises,442,8.9 Summary,"344 Chapter 8 Deadlocks
Practice Exercises
8.1List three examples of deadlocks that are not related to a computer-
systemenvironment.
8.2Suppose that a system is in an unsafe state. Show that it is possible for
the threads to complete their execution without entering a deadlocked
state.
8.3Considerthe following snapshot of a system:
Allocation Max Available
ABCD ABCD ABCD
T00012 0012 1520
T11000 1750
T21354 2356
T30632 0652
T40014 0656
Answerthe following questionsusingthe banker’s algorithm:
a. What isthe content of the matrix Need?
b. Isthesystemina safestate?
c. If a request from thread T1arrives for (0,4,2,0), can the request be
grantedimmediately?
8.4A possible method for preventing deadlocks is to have a single,
higher-orderresourcethatmustberequestedbeforeanyotherresource.
For example, if multiple threads attempt to access the synchronization
objects A···E, deadlock is possible.(Such synchronization objects may
includemutexes,semaphores,conditionvariables,andthelike.)Wecan
prevent deadlock by adding a sixth object F. Whenever a thread wants
to acquire the synchronization lock for any object A···E,i tm u s tfi r s t
acquire the lock for object F. This solution is known as containment :
the locks for objects A···Eare contained within the lock for object F.
Comparethis scheme with the circular-wait scheme of Section8.5.4.
8.5Prove that the safety algorithm presented in Section 8.6.3 requires an
orderof m×n2operations.
8.6Consider a computer system that runs 5,000 jobs per month and has no
deadlock-prevention or deadlock-avoidance scheme. Deadlocks occur
about twice per month, and the operator must terminate and rerun
abouttenjobsperdeadlock.Eachjobisworthabouttwodollars(in CPU
time),andthejobsterminatedtend tobeabouthalfdonewhentheyare
aborted.
A systems programmer has estimated that a deadlock-avoidance
algorithm (likethe banker’s algorithm) could be installedin the system
with an increase of about 10 percent in the average execution time per"
2,Further Reading,444,Practice Exercises,"346 Chapter 8 Deadlocks
8.10Suppose that you have coded the deadlock-avoidance safety algorithm
that determines if a system is in a safe state or not, and now have been
askedtoimplementthedeadlock-detectionalgorithm.Canyoudosoby
simply using the safety algorithm code and redefining Maxi=Waitingi
+Allocationi,w h e r e Waitingiis a vector specifying the resources for
which thread iis waiting and Allocationiis as defined in Section 8.6?
Explainyouranswer.
8.11Is it possible to have a deadlock invo lving only one single-threaded
process?Explainyour answer.
Further Reading
Most research involving deadlock was conducted many years ago. [Dijkstra
(1965)] was one of the first and most influential contributors in the deadlock
area.
Details of how the My SQLdatabase manages deadlock can be found at
http://dev.mysql.com/ .
Details on the lockdep tool can be found at https://www.kernel.org/doc/
Documentation/locking/lockdep-design.txt .
Bibliography
[Dijkstra (1965)] E. W. Dijkstra, “Cooperating Sequential Processes ”, Technical
report,TechnologicalUniversity,E indhoven,theNetherlands(1965)."
2,Bibliography,444,Further Reading,"346 Chapter 8 Deadlocks
8.10Suppose that you have coded the deadlock-avoidance safety algorithm
that determines if a system is in a safe state or not, and now have been
askedtoimplementthedeadlock-detectionalgorithm.Canyoudosoby
simply using the safety algorithm code and redefining Maxi=Waitingi
+Allocationi,w h e r e Waitingiis a vector specifying the resources for
which thread iis waiting and Allocationiis as defined in Section 8.6?
Explainyouranswer.
8.11Is it possible to have a deadlock invo lving only one single-threaded
process?Explainyour answer.
Further Reading
Most research involving deadlock was conducted many years ago. [Dijkstra
(1965)] was one of the first and most influential contributors in the deadlock
area.
Details of how the My SQLdatabase manages deadlock can be found at
http://dev.mysql.com/ .
Details on the lockdep tool can be found at https://www.kernel.org/doc/
Documentation/locking/lockdep-design.txt .
Bibliography
[Dijkstra (1965)] E. W. Dijkstra, “Cooperating Sequential Processes ”, Technical
report,TechnologicalUniversity,E indhoven,theNetherlands(1965)."
2,Chapter 8 Exercises,445,Bibliography,"Chapter 8 Exercises
8.12Considerthe trafficdeadlockdepictedinFigure8.12.
a. Show that the four necessary conditions for deadlock hold in this
example.
b. Statea simpleruleforavoidingdeadlocksinthis system.
8.13Draw the resource-allocation graph that illustrates deadlock from the
programexampleshown inFigure8.1inSection8.2.
8.14In Section 6.8.1, we described a pot ential deadlock scenario involv-
ing processes P0andP1and semaphores SandQ.D r a wt h er e s o u r c e -
allocation graph that illustrates deadlock under the scenario presented
in thatsection.
8.15Assumethatamultithreadedapplicationusesonlyreader–writerlocks
for synchronization. Applying the four necessary conditions for dead-
lock,isdeadlockstillpossibleif multiplereader–writerlocks areused?
8.16TheprogramexampleshowninFigure8.1doesn’talwaysleadtodead-
lock. Describe what role the CPUscheduler plays and how it can con-
tributetodeadlockinthisprogram.
8.17InSection8.5.4,we describedasituationinwhich we preventdeadlock
by ensuring that all locks are acquired in a certain order. However, we
also point out that deadlock is possible in this situation if two threads
simultaneously invoke the transaction() function. Fix the transac-
tion()function topreventdeadlocks.











Figure 8.11 Traffic deadlock for Exercise 8.12.EX-27"
2,Programming Problems,450,Chapter 8 Exercises,"Chapter 8 Deadlocks
Programming Problems
8.32Implement your solution to Exercise 8.30 using POSIXsynchronization.
Inparticular,representnorthboundandsouthboundfarmersasseparate
threads.Once afarmerisonthebridge,theassociatedthreadwillsleep
for a random period of time, represe nting traveling across the bridge.
Designyourprogramsothatyoucancreateseveralthreadsrepresenting
the northbound and southbound farmers.
8.33In Figure 8.7, we illustrate a transaction() function that dynamically
acquires locks. In the text, we describe how this function presents
difficulties for acquiring locks in a way that avoids deadlock. Using
the Java implementation of transaction() that is provided in
the source-code download for this text, modify it using the Sys-
tem.identityHashCode() method so that the locks are acquired in
order.
Programming Projects
Banker’s Algorithm
For this project, you will write a program that implements the banker’s algo-
rithmdiscussedinSection8.6.3.Customersrequestandreleaseresourcesfrom
the bank. The banker will grant a requ est only if it leaves the system in a
safe state. A request that leaves the system in an unsafe state will be denied.
AlthoughthecodeexamplesthatdescribethisprojectareillustratedinC,you
mayalso developa solutionusing Java.
The Banker
The banker will consider requests from ncustomers for mresources types, as
outlinedinSection8.6.3.Thebankerwillkeeptrack oftheresourcesusingthe
following datastructures:
#define NUMBER
 OF
CUSTOMERS 5
#define NUMBER
 OF
RESOURCES 4
/* the available amount of each resource */
int available[NUMBER
 OF
RESOURCES];
/*the maximum demand of each customer */
int maximum[NUMBER
 OF
CUSTOMERS][NUMBER
 OF
RESOURCES];
/* the amount currently allocated to each customer */
int allocation[NUMBER
 OF
CUSTOMERS][NUMBER
 OF
RESOURCES];
/* the remaining need of each customer */
int need[NUMBER
 OF
CUSTOMERS][NUMBER
 OF
RESOURCES];P-45"
2,Programming Projects,450,Programming Problems,"Chapter 8 Deadlocks
Programming Problems
8.32Implement your solution to Exercise 8.30 using POSIXsynchronization.
Inparticular,representnorthboundandsouthboundfarmersasseparate
threads.Once afarmerisonthebridge,theassociatedthreadwillsleep
for a random period of time, represe nting traveling across the bridge.
Designyourprogramsothatyoucancreateseveralthreadsrepresenting
the northbound and southbound farmers.
8.33In Figure 8.7, we illustrate a transaction() function that dynamically
acquires locks. In the text, we describe how this function presents
difficulties for acquiring locks in a way that avoids deadlock. Using
the Java implementation of transaction() that is provided in
the source-code download for this text, modify it using the Sys-
tem.identityHashCode() method so that the locks are acquired in
order.
Programming Projects
Banker’s Algorithm
For this project, you will write a program that implements the banker’s algo-
rithmdiscussedinSection8.6.3.Customersrequestandreleaseresourcesfrom
the bank. The banker will grant a requ est only if it leaves the system in a
safe state. A request that leaves the system in an unsafe state will be denied.
AlthoughthecodeexamplesthatdescribethisprojectareillustratedinC,you
mayalso developa solutionusing Java.
The Banker
The banker will consider requests from ncustomers for mresources types, as
outlinedinSection8.6.3.Thebankerwillkeeptrack oftheresourcesusingthe
following datastructures:
#define NUMBER
 OF
CUSTOMERS 5
#define NUMBER
 OF
RESOURCES 4
/* the available amount of each resource */
int available[NUMBER
 OF
RESOURCES];
/*the maximum demand of each customer */
int maximum[NUMBER
 OF
CUSTOMERS][NUMBER
 OF
RESOURCES];
/* the amount currently allocated to each customer */
int allocation[NUMBER
 OF
CUSTOMERS][NUMBER
 OF
RESOURCES];
/* the remaining need of each customer */
int need[NUMBER
 OF
CUSTOMERS][NUMBER
 OF
RESOURCES];P-45"
0,PART FOUR MEMORY MANAGEMENT,453,PART THREE PROCESS SYNCHRONIZATION,"Part Four
Memory
Management
The main purpose of a computer syst em is to execute programs. These
programs, together with the data they access, must be at least partially
in main memory during execution.
Modern computer systems maintain several processes in memory
during system execution. Many me mory-management schemes exist,
reﬂecting various approaches, and the effectiveness of each algorithm
varies with the situation. Selection of a memory-management scheme for
a system depends on many factors, especially on the system’s hardware
design. Most algorithms require some form of hardware support."
1,Chapter 9 Main Memory,455,PART FOUR MEMORY MANAGEMENT,"9CHAPTER
Main Memory
In Chapter 5, we showed how the CPUcan be shared by a set of processes. As
aresultof CPUscheduling,wecanimproveboththeutilizationofthe CPUand
the speed of the computer’s response to its users. To realize this increase in
performance,however,wemustkeepmanyprocessesinmemory—thatis,we
mustsharememory.
Inthischapter,wediscussvariouswaystomanagememory.Thememory-
management algorithms vary from a primitive bare-machine approach to a
strategy that uses paging. Each approach has its own advantages and disad-
vantages. Selection of a memory-management method for a specific system
depends on many factors, especially on the hardware design of the system.
As we shall see, most algorithms require hardware support, leading many
systems to have closely integrated hardware and operating-system memory
management.
CHAPTER OBJECTIVES
•Explain the difference between a logical and a physical address and the
role of the memory management unit ( MMU) in translating addresses.
•Apply first-, best-, and worst-fit stra tegies for allocating memory contigu-
ously.
•Explain the distinction between internal and external fragmentation.
•Translate logical to physical addresses in a paging system that includes a
translation look-aside buffer ( TLB).
•Describe hierarchical paging, hashed paging, and inverted page tables.
•Describe address translation for IA-32, x86-64, and ARMv8 architectures.
9.1 Background
As we saw in Chapter 1, memory is central to the operation of a modern
computersystem.Memoryconsistsofalargearrayofbytes,eachwithitsown
address. The CPUfetches instructions from memory according to the value of
349"
2,9.1 Background,455,Chapter 9 Main Memory,"9CHAPTER
Main Memory
In Chapter 5, we showed how the CPUcan be shared by a set of processes. As
aresultof CPUscheduling,wecanimproveboththeutilizationofthe CPUand
the speed of the computer’s response to its users. To realize this increase in
performance,however,wemustkeepmanyprocessesinmemory—thatis,we
mustsharememory.
Inthischapter,wediscussvariouswaystomanagememory.Thememory-
management algorithms vary from a primitive bare-machine approach to a
strategy that uses paging. Each approach has its own advantages and disad-
vantages. Selection of a memory-management method for a specific system
depends on many factors, especially on the hardware design of the system.
As we shall see, most algorithms require hardware support, leading many
systems to have closely integrated hardware and operating-system memory
management.
CHAPTER OBJECTIVES
•Explain the difference between a logical and a physical address and the
role of the memory management unit ( MMU) in translating addresses.
•Apply first-, best-, and worst-fit stra tegies for allocating memory contigu-
ously.
•Explain the distinction between internal and external fragmentation.
•Translate logical to physical addresses in a paging system that includes a
translation look-aside buffer ( TLB).
•Describe hierarchical paging, hashed paging, and inverted page tables.
•Describe address translation for IA-32, x86-64, and ARMv8 architectures.
9.1 Background
As we saw in Chapter 1, memory is central to the operation of a modern
computersystem.Memoryconsistsofalargearrayofbytes,eachwithitsown
address. The CPUfetches instructions from memory according to the value of
349"
3,9.1.1 Basic Hardware,456,9.1 Background,"350 Chapter 9 Main Memory
the program counter. These instructions may cause additional loading from
and storingto specificmemoryaddresses.
Atypical instruction-execution cycle, for example, first fetches an instruc-
tion from memory. The instruction is then decoded and may cause operands
to be fetched from memory. After the instruction has been executed on the
operands,resultsmaybestoredbackinmemory.Thememoryunitseesonlya
streamofmemoryaddresses;itdoesnotknowhowtheyaregenerated(bythe
instructioncounter,indexing,indirection,literaladdresses,andsoon)orwhat
they are for (instructions or data). Accordingly, we can ignore howap r o g r a m
generatesamemoryaddress.Weareinterestedonlyinthesequenceofmemory
addressesgeneratedby the running program.
We begin our discussion by covering several issues that are pertinent to
managingmemory:basichardware,thebindingofsymbolic(orvirtual)mem-
oryaddressestoactualphysicaladdresse s,andthedistinctionbetweenlogical
andphysicaladdresses.Weconcludethesectionwithadiscussionofdynamic
linking and shared libraries.
9.1.1 Basic Hardware
Main memory and the registers built into each processing core are the only
general-purpose storage that the CPUcan access directly. There are machine
instructionsthattakememoryaddressesasarguments,butnonethattakedisk
addresses. Therefore, any instructions in execution, and any data being used
bytheinstructions,mustbeinoneofthesedirect-accessstoragedevices.Ifthe
dataarenot inmemory,theymustbemovedtherebeforethe CPUcan operate
on them.
Registers that are built into each CPUcore are generally accessible within
one cycle of the CPUclock. Some CPUcores can decode instructions and per-
form simple operations on register contents at the rate of one or more opera-
tionsperclocktick.Thesamecannotbesaidofmainmemory,whichisaccessed
via a transaction on the memory bus. Completing a memory access may take
many cycles of the CPUclock. In such cases, the processor normally needs to
stall,sinceitdoesnothavethedatarequiredtocompletetheinstructionthatit
is executing. This situation is intolerable because of the frequency of memory
accesses. Theremedyisto addfast memorybetweenthe CPUand main mem-
ory, typically on the CPUchip for fast access. Such a cachewas described in
Section1.5.5.Tomanageacachebuiltintothe CPU,thehardwareautomatically
speedsupmemoryaccess without any operating-systemcontrol. (Recall from
Section5.5.2thatduringamemorystall,amultithreadedcorecanswitchfrom
the stalledhardware thread toanother hardware thread.)
Not only are we concerned with the relative speed of accessing physi-
cal memory, but we also must ensure correct operation. For proper system
operation, we must protect the operating system from access by user pro-
cesses,aswellasprotectuserprocessesf romoneanother.Thisprotectionmust
be provided by the hardware, because the operating system doesn’t usually
intervene between the CPUand its memory accesses (because of the resulting
performancepenalty).Hardwareimplementsthisproductioninseveraldiffer-
ent ways, as we show throughout the chapter. Here, we outline one possible
implementation."
3,9.1.2 Address Binding,458,9.1.1 Basic Hardware,"352 Chapter 9 Main Memory
<base
trap to operating system
illegal addressing errorbase + limit
memoryCPUaddress yes yes
no no≥
Figure 9.2 Hardware address protection with base and limit registers.
multiprocessingsystemmustexecutecontextswitches,storingthestateofone
processfromtheregistersintomainmemorybeforeloadingthenextprocess’s
context frommain memoryinto the registers.
9.1.2 Address Binding
Usually, a program resides on a disk as a binary executable file. To run, the
program must be brought into memory and placed within the context of a
process (as described in Section 2.5), where it becomes eligible for execution
on an available CPU.A st h ep r o c e s se x e c u t e s ,i ta c c e s s e si n s t r u c t i o n sa n dd a t a
frommemory.Eventually,theprocessterminates,anditsmemoryisreclaimed
for useby otherprocesses.
Most systems allow a user process to reside in any part of the physical
memory.Thus,althoughtheaddressspaceofthecomputermaystartat00000,
the first address of the user process need not be 00000. You will see later how
theoperating systemactually placesa processinphysicalmemory.
Inmostcases,auserprogramgoesthroughseveralsteps—someofwhich
maybeoptional—beforebeingexecuted(Figure9.3).Addressesmayberepre-
sented in different ways during these steps. Addresses in the source program
aregenerallysymbolic(suchasthevariable count).Acompilertypically binds
these symbolic addresses to relocatable addresses (such as “14 bytes from the
beginningofthismodule ”).Thelinkerorloader(seeSection2.5)inturnbinds
the relocatable addresses to absolute addresses (such as 74014). Each binding
isa mappingfrom one addressspaceto another.
Classically, the binding of instructions and data to memory addresses can
be done atany stepalong the way:
•Compile time .Ifyouknowatcompiletimewheretheprocesswillresidein
memory, then absolute code can be generated. For example, if you know
that a user process will reside starting at location R,then the generated
compiler code will start at that location and extend up from there. If, at
some later time, the starting location changes, then it will be necessary to
recompilethis code."
3,9.1.3 Logical Versus Physical Address Space,459,9.1.2 Address Binding,"9.1 Background 353
source
program
object
fileother
object
files
dynamically
linked
librariesexecutable
file
program
in memorycompiler
linker
loadercompile 
time
execution
time
(run time)load
time
Figure 9.3 Multistep processing of a user program.
•Load time .Ifitisnotknownatcompiletimewheretheprocesswillreside
inmemory,thenthecompilermustgenerate relocatable code .Inthiscase,
finalbindingisdelayeduntilloadtime.Ifthestartingaddresschanges,we
needonly reloadthe usercodeto i ncorporate this changed value.
•Execution time .Iftheprocesscanbemovedduringitsexecutionfromone
memorysegmenttoanother,thenbindingmustbedelayeduntilruntime.
Special hardware must be available for this scheme to work, as will be
discussedinSection9.1.3.Most operatingsystemsusethismethod.
Amajorportionofthischapterisdevotedtoshowinghowthesevariousbind-
ings can be implemented effectively in a computer system and to discussing
appropriatehardwaresupport.
9.1.3 Logical Versus Physical Address Space
Anaddressgeneratedbythe CPUiscommonlyreferredtoasa logical address ,
whereas an address seen by the memory unit—that is, the one loaded into"
3,9.1.4 Dynamic Loading,461,9.1.3 Logical Versus Physical Address Space,"9.1 Background 355
≶
MMUCPU memory
1434614000relocation
register
346logical
addressphysical
address
Figure 9.5 Dynamic relocation using a relocation register.
conceptofalogicaladdressspacethatisboundtoaseparatephysicaladdress
spaceiscentral topropermemorymanagement.
9.1.4 Dynamic Loading
In our discussion so far, it has been necessary for the entire program and all
dataofa processtobeinphysicalmemoryfortheprocesstoexecute.Thesize
of a process has thus been limited to the size of physical memory. To obtain
better memory-space utilization, we can use dynamic loading . With dynamic
loading, a routine is not loaded until it is called. All routines are kept on disk
in a relocatable load format. The main program is loaded into memory and
is executed. When a routine needs to cal l another routine, the calling routine
first checks to see whether the other routine has been loaded. If it has not, the
relocatablelinkingloaderiscalledtoloadthedesiredroutineintomemoryand
to update the program’s address tables to reflect this change. Then control is
passedto the newly loadedroutine.
Theadvantageofdynamicloadingisthataroutineisloadedonlywhen it
is needed. This method is particularly useful when large amounts of code are
needed to handle infrequently occurring cases, such as error routines. In such
a situation, although the total program size may be large, the portion that is
used(and hence loaded)may be much smaller.
Dynamic loading does not require special support from the operating
system. It is the responsibility of the users to design their programs to take
advantage of such a method. Operating systems may help the programmer,
however,by providinglibrary routinestoimplementdynamicloading.
9.1.5 Dynamic Linking and Shared Libraries
Dynamically linked libraries (DLLs)aresystemlibrariesthatarelinkedtouser
programswhentheprogramsarerun(referbacktoFigure9.3).Someoperating
systems support only static linking , in which system libraries are treated"
3,9.1.5 Dynamic Linking and Shared Libraries,461,9.1.4 Dynamic Loading,"9.1 Background 355
≶
MMUCPU memory
1434614000relocation
register
346logical
addressphysical
address
Figure 9.5 Dynamic relocation using a relocation register.
conceptofalogicaladdressspacethatisboundtoaseparatephysicaladdress
spaceiscentral topropermemorymanagement.
9.1.4 Dynamic Loading
In our discussion so far, it has been necessary for the entire program and all
dataofa processtobeinphysicalmemoryfortheprocesstoexecute.Thesize
of a process has thus been limited to the size of physical memory. To obtain
better memory-space utilization, we can use dynamic loading . With dynamic
loading, a routine is not loaded until it is called. All routines are kept on disk
in a relocatable load format. The main program is loaded into memory and
is executed. When a routine needs to cal l another routine, the calling routine
first checks to see whether the other routine has been loaded. If it has not, the
relocatablelinkingloaderiscalledtoloadthedesiredroutineintomemoryand
to update the program’s address tables to reflect this change. Then control is
passedto the newly loadedroutine.
Theadvantageofdynamicloadingisthataroutineisloadedonlywhen it
is needed. This method is particularly useful when large amounts of code are
needed to handle infrequently occurring cases, such as error routines. In such
a situation, although the total program size may be large, the portion that is
used(and hence loaded)may be much smaller.
Dynamic loading does not require special support from the operating
system. It is the responsibility of the users to design their programs to take
advantage of such a method. Operating systems may help the programmer,
however,by providinglibrary routinestoimplementdynamicloading.
9.1.5 Dynamic Linking and Shared Libraries
Dynamically linked libraries (DLLs)aresystemlibrariesthatarelinkedtouser
programswhentheprogramsarerun(referbacktoFigure9.3).Someoperating
systems support only static linking , in which system libraries are treated"
2,9.2 Contiguous Memory Allocation,462,9.1 Background,"356 Chapter 9 Main Memory
like any other object module and are combined by the loader into the binary
program image. Dynamic linking, in contrast, is similar to dynamic loading.
Here, though, linking, rather than loading, is postponed until execution time.
This feature is usually used with system libraries, such as the standard C
languagelibrary.Withoutthisfacility,eachprogramonasystemmustincludea
copyofitslanguagelibrary(oratleasttheroutinesreferencedbytheprogram)
in the executable image. This requirement not only increases the size of an
executable image but also may waste main memory. A second advantage of
DLLs is that these libraries can be shared among multiple processes, so that
only one instance of the DLLin main memory. For this reason, DLLsa r ea l s o
known as shared libraries , and are used extensively in Windows and Linux
systems.
Whenaprogramreferencesaroutinethatisinadynamiclibrary,theloader
locates the DLL, loading it into memory if necessary. It then adjusts addresses
thatreferencefunctionsinthedynamic librarytothelocationinmemorywhere
theDLLisstored.
Dynamically linked libraries can be extended to library updates (such as
bug fixes). In addition, a library may be replaced by a new version, and all
programs that reference the library will automatically use the new version.
Withoutdynamiclinking,allsuchprogramswouldneedtoberelinkedtogain
access to the new library. So that programs will not accidentally execute new,
incompatible versions of libraries, ver sion information is included in both the
program and the library. More than one version of a library may be loaded
into memory, and each program uses its version information to decide which
copyofthelibrarytouse.Versionswithminorchangesretainthesameversion
number, whereas versions with major changes increment the number. Thus,
only programs that are compiled with the new library version are affected by
anyincompatiblechangesincorporatedinit.Otherprogramslinkedbeforethe
new librarywas installedwillcontinue using theolderlibrary.
Unlike dynamic loading, dynamic lin king and shared libraries generally
require help from the operating system. If the processes in memory are pro-
tected from one another, then the operating system is the only entity that can
checktoseewhethertheneededroutineisinanotherprocess’smemoryspace
or that can allow multiple processes to access the same memory addresses.
We elaborate on this concept, as well as how DLLs can be shared by multiple
processes,when wediscusspaging inSection9.3.4.
9.2 Contiguous Memory Allocation
The main memory must accommodate both the operating system and the
various user processes. We therefore need to allocate main memory in the
mostefficientwaypossible.Thissectionexplainsoneearlymethod,contiguous
memoryallocation.
The memory is usually divided into two partitions: one for the operating
system and one for the user processes. We can place the operating system
in either low memory addresses or high memory addresses. This decision
dependsonmanyfactors,suchasthelocationoftheinterruptvector.However,
many operating systems (including Lin ux and Windows) place the operating
systemin high memory,and thereforewediscussonly that situation."
3,9.2.1 Memory Protection,463,9.2 Contiguous Memory Allocation,"9.2 Contiguous Memory Allocation 357
We usually want several user processes to reside in memory at the same
time. We therefore need to consider how to allocate available memory to the
processes that are waiting to be brought into memory. In contiguous mem-
ory allocation , each process is contained in a single section of memory that
is contiguous to the section containing the next process. Before discussing
this memory allocation scheme further, though, we must address the issue of
memoryprotection.
9.2.1 Memory Protection
We can prevent a process from accessing memory that it does not own by
combining two ideas previously discussed. If we have a system with a relo-
cation register (Section 9.1.3), together with a limit register (Section 9.1.1), we
accomplish our goal. The relocation registercontains the value of the smallest
physical address;the limit registercontains the range of logical addresses(for
example, relocation = 100040 and limit = 74600). Each logical address must
fall within the range specified by the limit register. The MMUmaps the log-
ical address dynamically by adding the v alue in the relocation register. This
mappedaddressissentto memory(Figure9.6).
When the CPUscheduler selects a process for execution, the dispatcher
loads the relocation and limit registers with the correct values as part of the
context switch. Because every address generated by a CPUis checked against
these registers, we can protect both the operating system and the other users’
programsand data frombeing modifiedby this running process.
Therelocation-registerschemeprovidesaneffectivewaytoallowtheoper-
atingsystem’ssizetochangedynamically.Thisflexibilityisdesirableinmany
situations. For example, the operating system contains code and buffer space
for device drivers. If a device driver is not currently in use, it makes little
sense to keep it in memory; instead, it can be loaded into memory only when
it is needed. Likewise, when the device driver is no longer needed, it can be
removedand itsmemoryallocatedfor otherneeds.
CPU memorylogical
address
trap: addressing errornoyesphysical
addressrelocation
register
+ <limit
register
Figure 9.6 Hardware support for relocation and limit registers."
3,9.2.2 Memory Allocation,464,9.2.1 Memory Protection,"358 Chapter 9 Main Memory
9.2.2 Memory Allocation
Nowwearereadytoturntomemoryallocation.Oneofthesimplestmethodsof
allocating memory is to assign processes to variably sized partitions in mem-
ory, where each partition may contain exactly one process. In this variable-
partition scheme,theoperatingsystemkeepsatableindicatingwhichpartsof
memoryareavailableandwhichareoccupied.Initially,allmemoryisavailable
for user processes and is considered one large block of available memory, a
hole. Eventually, as you will see, memory contains a set of holes of various
sizes.
Figure 9.7 depicts this scheme. Initially, the memory is fully utilized, con-
taining processes 5, 8, and 2. After process 8 leaves, there is one contiguous
hole. Later on, process 9 arrives and is allocated memory. Then process 5
departs,resultingin two noncontiguous holes.
Asprocessesenterthesystem,theoperatingsystemtakesintoaccountthe
memory requirements of each process and the amount of available memory
space in determining which processes are allocated memory. When a process
isallocatedspace,itisloadedintomemory,whereitcanthencompetefor CPU
time. When a process terminates, it releases its memory, which the operating
systemmaythenprovidetoanother process.
What happens when there isn’t sufficient memory to satisfy the demands
of an arriving process? One option is to simply reject the process and provide
an appropriate error message. Alternatively,we can place such processes into
awaitqueue.Whenmemoryislaterreleased,theoperatingsystemchecksthe
wait queue to determine if it will satisfy the memory demands of a waiting
process.
In general, as mentioned, the memory blocks available comprise a setof
holes of various sizes scattered throughout memory. When a process arrives
and needs memory, the system searches th e set for a hole that is large enough
for this process. If the hole is too large, it is split into two parts. One part is
allocatedtothearrivingprocess;theo therisreturnedtothesetofholes.When
aprocessterminates,itreleasesitsblockofmemory,whichisthenplacedback
inthesetofholes.Ifthenewholeisadjacenttootherholes,theseadjacentholes
aremergedtoform one largerhole.
This procedure is a particular instance of the general dynamic storage-
allocation problem , which concerns how to satisfy a request of size nfrom a
listoffreeholes.Therearemanysolutionstothisproblem.The first-fit,best-fi,
and worst-fi strategies are the ones most commonly used to select a free hole
from thesetof availableholes.
OS
process 5
process 8
process 2OS
process 2OS
process 5
process 9 process 9
process 2OS
process 5
process 2low
memoryhigh
memory
Figure 9.7 Variable partition."
3,9.2.3 Fragmentation,465,9.2.2 Memory Allocation,"9.2 Contiguous Memory Allocation 359
•Firstfit.Allocatethefirstholethatisbigenough.Searchingcanstarteither
at the beginning of the set of holes or at the location where the previous
first-fit searchended.We can stopsearchingassoonaswe find afreehole
that is largeenough.
•Best fi. Allocate the smallest hole that is big enough. We must search the
entire list, unless the list is ordered by size. This strategy produces the
smallestleftoverhole.
•Worstfit. Allocate the largest hole. Again, we must search the entire list,
unless itissortedbysize.This strategyproducesthelargestleftoverhole,
which may be more useful than the smaller leftover hole from a best-fit
approach.
Simulationshaveshownthatbothfirstfitandbestfitarebetterthanworst
fit in terms of decreasingtimeand storage utilization.Neitherfirst fit nor best
fit is clearly better than the other in terms of storage utilization, but first fit is
generallyfaster.
9.2.3 Fragmentation
Boththefirst-fitandbest-fitstrategiesformemoryallocationsufferfrom exter-
nal fragmentation . As processes are loaded and removed from memory, the
free memory space is broken into little pieces. External fragmentation exists
whenthereisenoughtotalmemoryspacetosatisfyarequestbuttheavailable
spaces are not contiguous: storage is fragmented into a large number of small
holes. This fragmentation problem can be severe. In the worst case, we could
have a block of free (or wasted) memory between every two processes. If all
these small pieces of memory were in one big free block instead, we might be
ableto runseveralmoreprocesses.
Whetherweareusingthefirst-fitorbest-fitstrategycanaffecttheamount
of fragmentation. (First fit is betterfor some systems,whereas best fit is better
for others.) Another factor is which end of a free block is allocated. (Which is
the leftover piece—the one on the top or the one on the bottom?) No matter
which algorithmisused,however,externalfragmentationwillbe aproblem.
Dependingonthetotalamountofmemorystorageandtheaverageprocess
size, external fragmentation may be a minor or a major problem. Statistical
analysis of first fit, for instance, reveals that, even with some optimization,
given Nallocated blocks, another 0.5 Nblocks will be lost to fragmentation.
That is, one-third of memory may be unusable! This propertyis known as the
50-percent rule .
Memory fragmentation can be intern al as well as external. Consider a
multiple-partitionallocation scheme with a hole of 18,464 bytes.Suppose that
the next process requests 18,462 bytes. If we allocate exactly the requested
block, we are left with a hole of 2 bytes. The overhead to keep track of this
hole will be substantially larger than the hole itself. The general approach
to avoiding this problem is to break the physical memory into fixed-sized
blocks and allocate memory in units bas ed on block size. With this approach,
the memory allocated to a process may be slightly larger than the requested
memory.Thedifferencebetweenthesetwonumbersis internal fragmentation
—unused memorythat isinternalto a partition."
2,9.3 Paging,466,9.2 Contiguous Memory Allocation,"360 Chapter 9 Main Memory
Onesolutiontotheproblemofexternalfragmentation is compaction .Th e
goal is to shuffle the memory contents so as to place all free memory together
in one large block. Compaction is not always possible, however. If relocation
isstaticandisdoneatassemblyorloadtime,compactioncannotbedone.Itis
possibleonlyifrelocationisdynamicandisdoneatexecutiontime.Ifaddresses
are relocated dynamically, relocation requires only moving the program and
dataandthenchangingthebaseregistertoreflectthenewbaseaddress.When
compaction is possible, we must determine its cost. The simplest compaction
algorithmistomoveallprocessestowardoneendofmemory;allholesmovein
theotherdirection,producingonelargeholeofavailablememory.Thisscheme
can beexpensive.
Anotherpossiblesolutiontotheexternal-fragmentationproblemistoper-
mitthelogicaladdressspaceofprocessestobenoncontiguous,thusallowinga
process to be allocated physical memory wherever such memory is available.
This is the strategy used in paging,the most common memory-management
techniquefor computersystems.Wedescribepaging in thefollowing section.
Fragmentationisageneralproblemincomputingthatcanoccurwherever
we must manage blocks of data. We discuss the topic further in the storage
management chapters(Chapter11 through Chapter15).
9.3 Paging
Memory management discussed thus far has required the physical address
space of a process to be contiguous. We now introduce paging, a memory-
managementschemethatpermitsaprocess’sphysicaladdressspacetobenon-
contiguous.Pagingavoidsexternalfragmentationandtheassociatedneedfor
compaction,twoproblemsthatplaguecontiguousmemoryallocation.Because
itoffersnumerousadvantages,paginginitsvariousformsisusedinmostoper-
ating systems, from those for large servers through those for mobile devices.
Pagingisimplementedthroughcooperationbetweentheoperatingsystemand
thecomputer hardware.
9.3.1 Basic Method
The basic method for implementing paging involves breaking physical mem-
ory into fixed-sized blocks called framesand breaking logical memory into
blocksofthesamesizecalled pages.Whenaprocessistobeexecuted,itspages
areloadedintoanyavailablememoryframesfromtheirsource(afilesystemor
thebackingstore).Thebackingstoreisdividedintofixed-sizedblocksthatare
thesamesizeasthememoryframesorclustersofmultipleframes.Thisrather
simple idea has great functionality and wide ramifications. For example, the
logical address space is now totally separate from the physical address space,
soaprocesscanhavealogical64-bitaddressspaceeventhoughthesystemhas
lessthan264bytes ofphysical memory.
Every address generated by the CPUis divided into two parts: a page
number (p)a n da page offset (d):
pdpage number page offset"
3,9.3.1 Basic Method,466,9.3 Paging,"360 Chapter 9 Main Memory
Onesolutiontotheproblemofexternalfragmentation is compaction .Th e
goal is to shuffle the memory contents so as to place all free memory together
in one large block. Compaction is not always possible, however. If relocation
isstaticandisdoneatassemblyorloadtime,compactioncannotbedone.Itis
possibleonlyifrelocationisdynamicandisdoneatexecutiontime.Ifaddresses
are relocated dynamically, relocation requires only moving the program and
dataandthenchangingthebaseregistertoreflectthenewbaseaddress.When
compaction is possible, we must determine its cost. The simplest compaction
algorithmistomoveallprocessestowardoneendofmemory;allholesmovein
theotherdirection,producingonelargeholeofavailablememory.Thisscheme
can beexpensive.
Anotherpossiblesolutiontotheexternal-fragmentationproblemistoper-
mitthelogicaladdressspaceofprocessestobenoncontiguous,thusallowinga
process to be allocated physical memory wherever such memory is available.
This is the strategy used in paging,the most common memory-management
techniquefor computersystems.Wedescribepaging in thefollowing section.
Fragmentationisageneralproblemincomputingthatcanoccurwherever
we must manage blocks of data. We discuss the topic further in the storage
management chapters(Chapter11 through Chapter15).
9.3 Paging
Memory management discussed thus far has required the physical address
space of a process to be contiguous. We now introduce paging, a memory-
managementschemethatpermitsaprocess’sphysicaladdressspacetobenon-
contiguous.Pagingavoidsexternalfragmentationandtheassociatedneedfor
compaction,twoproblemsthatplaguecontiguousmemoryallocation.Because
itoffersnumerousadvantages,paginginitsvariousformsisusedinmostoper-
ating systems, from those for large servers through those for mobile devices.
Pagingisimplementedthroughcooperationbetweentheoperatingsystemand
thecomputer hardware.
9.3.1 Basic Method
The basic method for implementing paging involves breaking physical mem-
ory into fixed-sized blocks called framesand breaking logical memory into
blocksofthesamesizecalled pages.Whenaprocessistobeexecuted,itspages
areloadedintoanyavailablememoryframesfromtheirsource(afilesystemor
thebackingstore).Thebackingstoreisdividedintofixed-sizedblocksthatare
thesamesizeasthememoryframesorclustersofmultipleframes.Thisrather
simple idea has great functionality and wide ramifications. For example, the
logical address space is now totally separate from the physical address space,
soaprocesscanhavealogical64-bitaddressspaceeventhoughthesystemhas
lessthan264bytes ofphysical memory.
Every address generated by the CPUis divided into two parts: a page
number (p)a n da page offset (d):
pdpage number page offset"
3,9.3.2 Hardware Support,471,9.3.1 Basic Method,"9.3 Paging 365
other programs. The difference between the programmer’s view of memory
andtheactualphysicalmemoryisreconc iledbytheaddress-translationhard-
ware. The logical addresses are transl ated into physical addresses. This map-
pingishiddenfromtheprogrammerandiscontrolledbytheoperatingsystem.
Notice that the user process by definition is unable to access memory it does
notown.Ithasnowayofaddressingmemoryoutsideofitspagetable,andthe
table includesonly those pagesthat the processowns.
Sincetheoperatingsystemismanagingphysicalmemory,itmustbeaware
of the allocation details of physical memory—which frames are allocated,
which frames are available, how many total frames there are, and so on. This
information is generally kept in a single, system-wide data structure called
aframe table . The frame table has one entry for each physical page frame,
indicatingwhetherthelatterisfreeorallocatedand,ifitisallocated,towhich
pageofwhich process (orprocesses).
Inaddition,the operatingsystemmustbe aware that userprocessesoper-
ateinuserspace,andalllogicaladdressesmustbemappedtoproducephysical
addresses.If a user makes a system call (to do I/O, for example) and provides
anaddressasaparameter(abuffer,forinstance),thataddressmustbemapped
toproducethecorrectphysicaladdress.Theoperatingsystemmaintainsacopy
ofthepage tableforeach process,justasitmaintainsacopyofthe instruction
counterandregistercontents.Thiscopyisusedtotranslatelogicaladdressesto
physicaladdresseswhenevertheoperatingsystemmustmapalogicaladdress
to a physical addressmanually. It is also used by the CPUdispatcher to define
the hardware page table when a process is to be allocated the CPU.P a g i n g
thereforeincreasesthecontext-switch time.
9.3.2 Hardware Support
As page tables are per-process data structures, a pointer to the page table
is stored with the other register values (like the instruction pointer) in the
processcontrolblockofeachprocess.Whenthe CPUschedulerselectsaprocess
for execution, it must reload the user registers and the appropriate hardware
page-tablevaluesfromthe storeduserpagetable.
The hardware implementation of the page table can be done in several
ways.Inthesimplestcase,thepagetableisimplementedasasetofdedicated
high-speedhardwareregisters,whichmakesthepage-addresstranslationvery
efficient.However,thisapproachincreasescontext-switchtime,aseachoneof
theseregistersmustbe exchangedduring acontext switch.
Theuseofregistersforthepagetableissatisfactoryifthepagetableisrea-
sonably small (for example, 256 entries). Most contemporary CPUs, however,
supportmuchlargerpagetables(forexample,220entries).Forthesemachines,
the use of fast registers to implement the page table is not feasible. Rather,
the page table is kept in main memory, and a page-table base register (PTBR)
pointstothepagetable.Changingpagetablesrequireschangingonlythisone
register,substantially reducingcontext-switch time.
9.3.2.1 Translation Look-Aside Buffer
Although storing the page table in main memory can yield faster context
switches, it may also result in slower memory access times. Suppose we want
to access location i.We must first index into the page table, using the value in"
3,9.3.3 Protection,474,9.3.2 Hardware Support,"368 Chapter 9 Main Memory
Asnotedearlier, CPUstodaymayprovidemultiplelevelsof TLBs.Calculat-
ingmemoryaccesstimesinmodern CPUsisthereforemuchmorecomplicated
than shown in the example above. For instance, the Intel Core i7 CPUhas a
128-entryL1instruction TLBanda64-entryL1data TLB.Inthecaseofamissat
L1, it takes the CPUsix cycles to check for the entry in the L2 512-entry TLB.A
missinL2meansthatthe CPUmusteitherwalkthroughthepage-tableentries
in memory to find the associated frame address, which can take hundreds of
cycles,or interruptto theoperatingsystemtohave itdothe work.
A complete performance analysis of paging overhead in such a system
would require miss-rate information about each TLBtier. We can see from the
generalinformationabove,however,thathardwarefeaturescanhaveasignif-
icanteffectonmemoryperformancean dthatoperating-systemimprovements
(such as paging) can result in and, in turn, be affected by hardware changes
(such as TLBs).Wewillfurther explorethe impactof thehitratio on the TLBin
Chapter10.
TLBsareahardwarefeatureandthereforewouldseemtobeoflittleconcern
tooperatingsystemsandtheirdesigners.Butthedesignerneedstounderstand
the function and featuresof TLBs, which vary by hardwareplatform.For opti-
mal operation, an operating-system design for a given platform must imple-
ment paging according to the platform’s TLBdesign. Likewise, a change in
theTLBdesign(forexample,betweendifferentgenerationsofIntel CPUs) may
necessitate a change in the paging implementation of the operating systems
that use it.
9.3.3 Protection
Memoryprotectioninapagedenvironmentisaccomplishedbyprotectionbits
associatedwitheachframe.Normally,thesebits arekeptinthepagetable.
One bit can define a page to be read–write or read-only. Every reference
to memory goes through the page table to find the correct frame number. At
the same timethat the physical addressisbeingcomputed,the protectionbits
canbecheckedtoverifythatnowritesarebeingmadetoaread-onlypage.An
attempt to write to a read-only page causes a hardware trap to the operating
system(ormemory-protectionviolation).
We can easily expand this approach to provide a finer level of protection.
We can create hardware to provide read-only, read–write, or execute-only
protection;or,byprovidingseparatep rotectionbitsforeachkindofaccess,we
can allow any combination of these acce sses. Illegal attempts will be trapped
to theoperatingsystem.
One additional bit is generally attached to each entry in the page table: a
valid–invalid bit. When this bit is set to valid,the associated page is in the
process’s logical address space and is thus a legal (or valid) page. When the
bitissetto invalid,thepageisnotintheprocess’slogicaladdressspace.Illegal
addresses are trapped by use of the valid–invalid bit. The operating system
setsthisbit for eachpagetoallow or disallowaccess tothe page.
Suppose, for example, that in a system with a 14-bit address space (0 to
16383), we have a program that should use only addresses 0 to 10468. Given
ap a g es i z eo f2 KB, we have the situation shown in Figure 9.13. Addresses in
pages 0, 1, 2, 3, 4, and 5 are mapped normally through the page table. Any
attempt to generate an address in pages 6 or 7, however, will find that the"
3,9.3.4 Shared Pages,475,9.3.3 Protection,"9.3 Paging 369
page 5page 0
page 1
page 2
page 3
page 4
page 5
page n•••000000
1
2
3
4
5
6
7
8
9frame number
0
1
2
3
4
5
6
72
3
4
7
8
9
0
0v
v
v
v
v
v
i
i
page tablevalid–invalid bit
10,46812,287
page 4
page 3
page 2
page 1
page 0
Figure 9.13 Valid (v) or invalid (i) bit in a page table.
valid–invalid bit is set to invalid, and the computer will trap to the operating
system(invalidpagereference).
Notice that this scheme has created a problem. Because the program
extends only to address 10468, any reference beyond that address is illegal.
However, references to page 5 are classified as valid, so accesses to addresses
upto12287arevalid.Onlytheaddressesfrom12288to16383areinvalid.This
problemisaresultofthe2- KBpagesizeandreflectstheinternalfragmentation
ofpaging.
Rarely does a process use all its address range. In fact, many processes
use only a small fraction of the address space available to them. It would be
wasteful in these cases to create a page table with entries for every page in
the address range. Most of this table would be unused but would take up
valuable memory space. Some systems provide hardware, in the form of a
page-table length register (PTLR), to indicate the size of the page table. This
value is checked against every logical address to verify that the address is in
the valid range for the process. Failure of this test causes an error trap to the
operatingsystem.
9.3.4 Shared Pages
Anadvantageofpagingisthepossibilityof sharingcommoncode,aconsidera-
tionthat is particularly important in an environment with multipleprocesses.
Consider the standard C library, which provides a portion of the system call
interface for many versions of UNIXand Linux. On a typical Linux system,
mostuserprocessesrequirethestandardClibrary libc.Oneoptionistohave"
2,9.4 Structure of the Page Table,477,9.3 Paging,"9.4 Structure of the Page Table 371
The sharing of memory among processes on a system is similar to the
sharing of the address space of a task by threads, described in Chapter 4.
Furthermore,recallthatinChapter3wedescribedsharedmemoryasamethod
of interprocess communication. Som e operating systems implement shared
memoryusingsharedpages.
Organizing memory according to pages provides numerous benefits in
addition to allowing several processes to share the same physical pages. We
coverseveralother benefits inChapter10.
9.4 Structure of the Page Table
Inthissection,weexploresomeofthemostcommontechniquesforstructuring
thepagetable,includinghierarchicalpa ging,hashedpagetables,andinverted
pagetables.
9.4.1 Hierarchical Paging
Most modern computer systems support a large logical address space
(232to 264). In such an environment, the page table itself becomes excessively
large.Forexample,considerasystemwitha32-bitlogicaladdressspace.Ifthe
page size in such a system is 4 KB(212), then a page table may consist of over
1 million entries (220=232/212). Assuming that each entry consists of 4 bytes,
eachprocessmayneedupto4 MBofphysicaladdressspaceforthepagetable
alone. Clearly, we would not want to allocate the page table contiguously in
main memory. One simple solution to this problem is to dividethe page table
intosmallerpieces.Wecan accomplishthis divisioninseveralways.
One way is to use a two-level paging algorithm, in which the page table
itself is also paged (Figure 9.15). For example, consider again the system with
a 32-bit logical address space and a page size of 4 KB. A logical address is
divided into a page number consisting of 20 bits and a page offset consisting
of12bits.Becausewepagethepagetable,thepagenumberisfurtherdivided
intoa10-bitpagenumberanda10-bitpageoffset.Thus,alogicaladdressisas
follows:
p1 p2 dpage number page offset
10 10 12
where p1is an index into the outer page table and p2is the displacement
withinthepageoftheinnerpagetable.Theaddress-translationmethodforthis
architecture is shown in Figure 9.16. Because address translation works from
the outer page table inward, this scheme is also known as a forward-mapped
pagetable.
Forasystemwitha64-bitlogicaladdressspace,atwo-levelpagingscheme
is no longer appropriate. To illustrate th is point, let’s suppose that the page
size in such a system is 4 KB(212). In this case, the page table consists of up
to 252entries. If we use a two-level paging scheme, then the inner page tables
canconvenientlybeonepagelong,orcontain2104-byteentries.Theaddresses
looklikethis:"
3,9.4.1 Hierarchical Paging,477,9.4 Structure of the Page Table,"9.4 Structure of the Page Table 371
The sharing of memory among processes on a system is similar to the
sharing of the address space of a task by threads, described in Chapter 4.
Furthermore,recallthatinChapter3wedescribedsharedmemoryasamethod
of interprocess communication. Som e operating systems implement shared
memoryusingsharedpages.
Organizing memory according to pages provides numerous benefits in
addition to allowing several processes to share the same physical pages. We
coverseveralother benefits inChapter10.
9.4 Structure of the Page Table
Inthissection,weexploresomeofthemostcommontechniquesforstructuring
thepagetable,includinghierarchicalpa ging,hashedpagetables,andinverted
pagetables.
9.4.1 Hierarchical Paging
Most modern computer systems support a large logical address space
(232to 264). In such an environment, the page table itself becomes excessively
large.Forexample,considerasystemwitha32-bitlogicaladdressspace.Ifthe
page size in such a system is 4 KB(212), then a page table may consist of over
1 million entries (220=232/212). Assuming that each entry consists of 4 bytes,
eachprocessmayneedupto4 MBofphysicaladdressspaceforthepagetable
alone. Clearly, we would not want to allocate the page table contiguously in
main memory. One simple solution to this problem is to dividethe page table
intosmallerpieces.Wecan accomplishthis divisioninseveralways.
One way is to use a two-level paging algorithm, in which the page table
itself is also paged (Figure 9.15). For example, consider again the system with
a 32-bit logical address space and a page size of 4 KB. A logical address is
divided into a page number consisting of 20 bits and a page offset consisting
of12bits.Becausewepagethepagetable,thepagenumberisfurtherdivided
intoa10-bitpagenumberanda10-bitpageoffset.Thus,alogicaladdressisas
follows:
p1 p2 dpage number page offset
10 10 12
where p1is an index into the outer page table and p2is the displacement
withinthepageoftheinnerpagetable.Theaddress-translationmethodforthis
architecture is shown in Figure 9.16. Because address translation works from
the outer page table inward, this scheme is also known as a forward-mapped
pagetable.
Forasystemwitha64-bitlogicaladdressspace,atwo-levelpagingscheme
is no longer appropriate. To illustrate th is point, let’s suppose that the page
size in such a system is 4 KB(212). In this case, the page table consists of up
to 252entries. If we use a two-level paging scheme, then the inner page tables
canconvenientlybeonepagelong,orcontain2104-byteentries.Theaddresses
looklikethis:"
3,9.4.2 Hashed Page Tables,479,9.4.1 Hierarchical Paging,"9.4 Structure of the Page Table 373
logical address
outer page
tablep1p2
p1
page of
page tablep2
dd
Figure 9.16 Address translation for a two-level 32-bit paging architecture.
totranslateeachlogicaladdress.Youcanseefromthisexamplewhy,for64-bit
architectures,hierarchical pagetablesaregenerallyconsideredinappropriate.
9.4.2 Hashed Page Tables
Oneapproachforhandlingaddressspaceslargerthan32bitsistousea hashed
page table , with the hash value being the virtual page number. Each entry in
the hash table contains a linked list of elementsthat hash to the same location
(tohandlecollisions).Eachelementconsistsofthreefields:(1)thevirtualpage
number, (2) the value of the mapped page frame, and (3) a pointer to the next
elementinthe linkedlist.
The algorithm works as follows: The virtual page number in the virtual
address is hashed into the hash table. The virtual page number is compared
with field 1 in the first element in the linked list. If there is a match, the
correspondingpageframe(field2)isusedtoformthedesiredphysicaladdress.
If there is no match, subsequent entri es in the linked list are searched for a
matching virtualpage number. This scheme is shown inFigure 9.17.
hash tableqslogical addressphysical
address
physical
memorypd rd
prhash
function  
Figure 9.17 Hashed page table."
3,9.4.3 Inverted Page Tables,480,9.4.2 Hashed Page Tables,"374 Chapter 9 Main Memory
A variation of this scheme that is useful for 64-bit address spaces has
been proposed. This variation uses clustered page tables , which are similar
to hashed page tables except that each entry in the hash table refersto several
pages (such as 16) rather than a single page. Therefore, a single page-table
entry can store the mappings for multiple physical-page frames. Clustered
page tables are particularly useful for sparseaddress spaces, where memory
referencesare noncontiguous and scatteredthroughout the addressspace.
9.4.3 Inverted Page Tables
Usually, each process has an associated page table. The page table has one
entry for each page that the process is using (or one slot for each virtual
address,regardlessofthelatter’svalidity).Thistablerepresentationisanatural
one,sinceprocessesreferencepagesthroughthepages’virtualaddresses.The
operating system must then translate t his reference into a physical memory
address.Sincethetableissortedbyvirtualaddress,theoperatingsystemisable
to calculate where in the table the associ ated physical address entry is located
andtousethatvaluedirectly.Oneofthedrawbacksofthismethodisthateach
page table may consist of millions of entries. These tables may consume large
amountsofphysicalmemoryjusttokeeptrackofhowotherphysicalmemory
isbeing used.
T os o l v et h i sp r o b l e m ,w ec a nu s ea n inverted page table . An inverted
page table has one entry for each real page (or frame) of memory. Each entry
consists ofthevirtualaddressof thepagestoredin thatrealmemorylocation,
with information about the process that owns the page. Thus, only one page
table is in the system, and it has only one entry for each page of physical
memory. Figure 9.18 shows the operation of an inverted page table. Compare
it with Figure 9.8, which depicts a standard page table in operation. Inverted
page tables often require that an address-space identifier (Section 9.3.2) be
stored in each entry of the page table, since the table usually contains several
page tableCPUlogical
addressphysical
addressphysical
memory
ipid p
pidsearch
pd id
Figure 9.18 Inverted page table."
3,9.4.4 Oracle SPARC Solaris,481,9.4.3 Inverted Page Tables,"9.4 Structure of the Page Table 375
differentaddressspacesmappingphysicalmemory.Storingtheaddress-space
identifier ensures that a logical page for a particular process is mapped to the
correspondingphysicalpageframe.Examplesofsystemsusinginvertedpage
tablesinclude the 64-bit Ultra SPARCand Power PC.
To illustrate this method, we describe a simplified version of the inverted
pagetableusedinthe IBM RT.IBMwasthefirstmajorcompanytouseinverted
page tables, starting with the IBMSystem 38 and continuing through the
RS/6000andthecurrent IBMPowerCPUs.Forthe IBM RT,eachvirtualaddress
inthe systemconsists of a triple:
<process-id,page-number,offset >.
Eachinvertedpage-tableentryisapair <process-id,page-number >wherethe
process-id assumes the role of the address-space identifier. When a memory
reference occurs, part of the virtual address, consisting of <process-id, page-
number >, is presented to the memory subsystem. The inverted page table
is then searched for a match. If a match is found—say, at entry i—then the
physical address <i,offset>is generated. If no match is found, then an illegal
addressaccess has beenattempted.
Although this scheme decreases the amount of memory needed to store
eachpagetable,itincreasestheamountoftimeneededtosearchthetablewhen
a page reference occurs. Because the inverted page table is sorted by physical
address, but lookups occur on virtual addresses, the whole table might need
to be searched before a match is found. This search would take far too long.
To alleviate this problem, we use a hash table, as described in Section 9.4.2,
to limit the search to one—or at most a few—page-table entries. Of course,
eachaccesstothehashtableaddsamemoryreferencetotheprocedure,soone
virtualmemoryreferencerequiresatleasttworealmemoryreads—oneforthe
hash-tableentryandoneforthepagetable.(Recallthatthe TLBissearchedfirst,
before the hash table isconsulted,offeringsome performance improvement.)
One interesting issue with inverted page tables involves shared memory.
With standard paging, each process has its own page table, which allows
multiple virtual addresses to be mapped to the same physical address. This
method cannot be used with inverted page tables; because there is only one
virtualpageentryforeveryphysicalpage,onephysicalpagecannothavetwo
(or more) shared virtual addresses. Therefore, with inverted page tables, only
one mapping of a virtual addressto the shared physical addressmay occur at
anygiventime.Areferencebyanotherprocesssharingthememorywillresult
ina pagefault andwill replacethemapping witha differentvirtualaddress.
9.4.4 Oracle SPARC Solaris
Considerasafinalexampleamodern64-bit CPUandoperatingsystemthatare
tightly integrated to provide low-overhead virtual memory. Solarisrunning
on the SPARCCPUis a fully 64-bit operating system and as such has to solve
the problem of virtual memory without using up all of its physical memory
by keeping multiple levels of page tables. Its approach is a bit complex but
solves the problem efficiently using hashed page tables. There are two hash
tables—one for the kernel and one for all user processes. Each maps memory
addresses from virtual to physical memory. Each hash-table entry represents
a contiguous area of mapped virtual memory, which is more efficient than"
2,9.5 Swapping,482,9.4 Structure of the Page Table,"376 Chapter 9 Main Memory
havingaseparatehash-tableentryforeachpage.Eachentryhasabaseaddress
and a span indicatingthe numberof pagesthe entryrepresents.
Virtual-to-physicaltranslationwouldtaketoolongifeachaddressrequired
searchingthroughahashtable,sothe CPUimplementsa TLBthatholdstransla-
tiontableentries( TTEs)forfasthardwarelookups.Acacheofthese TTEsresides
in a translation storage buffer ( TSB), which includes an entry per recently
accessedpage.Whenavirtualaddressreferenceoccurs,thehardwaresearches
theTLBfor a translation. If none is found, the hardware walks through the in-
memory TSBlooking for the TTEthat corresponds to the virtual address that
caused the lookup. This TLB walkfunctionality is found on many modern
CPUs. If a match is found in the TSB,t h eCPUcopies the TSBentry into the TLB,
and the memory translation completes. If no match is found in the TSB,t h e
kernel is interrupted to search the hash table. The kernel then creates a TTE
from the appropriate hash table and stores it in the TSBfor automatic loading
into the TLBby theCPUmemory-management unit. Finally, the interrupthan-
dler returns control to the MMU, which completes the address translation and
retrievestherequestedbyteor wordfrom mainmemory.
9.5 Swapping
Process instructions and the data they operate on must be in memory to be
executed. However, a process, or a portion of a process, can be swapped
temporarily out of memory to a backing store and then brought back into
memory for continued execution (Figure 9.19). Swapping makes it possible
for the total physical addressspace of all processesto exceedthe realphysical
memory of the system, thus increasing the degree of multiprogramming in a
system.
operating
system
swap out
swap in
user
space
main memorybacking storeprocess P2process P11
2
Figure 9.19 Standard swapping of two processes using a disk as a backing store."
3,9.5.1 Standard Swapping,483,9.5 Swapping,"9.5 Swapping 377
9.5.1 Standard Swapping
Standard swapping involves moving entire processes between main memory
and a backing store. The backing store is commonly fast secondary storage.
It must be large enough to accommodate whatever parts of processes need to
be stored and retrieved, and it must provide direct access to these memory
images. When a process or part is swapped to the backing store, the data
structures associated with the process must be written to the backing store.
For a multithreaded process, all per-thread data structures must be swapped
as well. The operating system must also maintain metadata for processes that
have beenswapped out, so they can be restoredwhen they are swappedback
into memory.
The advantage of standard swapping is that it allows physical memory to
be oversubscribed, so that the system can accommodate more processes than
there is actual physical memory to store them. Idle or mostly idle processes
are good candidates for swapping; any memory that has been allocated to
theseinactiveprocessescanthenbededicatedtoactiveprocesses.Ifaninactive
pr ocessthathasbeenswappedoutbecomesactiveonceagain,itmustthenbe
swappedback in.This isillustratedinFigure9.19.
9.5.2 Swapping with Paging
Standardswappingwasusedintraditional UNIXsystems,butitisgenerallyno
longer used in contemporary operating systems, because the amount of time
required to move entire processes between memory and the backing store is
prohibitive.(AnexceptiontothisisSola ris,whichstillusesstandardswapping,
however only under dire circumstances when available memory is extremely
low.)
Mostsystems,includingLinuxandWindows,nowuseavariationofswap-
ping in which pages of a process—rather than an entire process—can be
swapped.Thisstrategystillallowsphysicalmemorytobeoversubscribed,but
does not incur the cost of swapping entire processes, as presumably only a
smallnumberofpageswillbeinvolvedinswapping.Infact,theterm swapping
now generally refers to standard swapping, and pagingrefers to swapping
withpaging.A page out operationmovesapagefrommemorytothebacking
store;thereverseprocessisknownasa page in.Swappingwithpagingisillus-
trated in Figure 9.20 where a subset of pages for processes Aand Bare being
paged-outandpaged-inrespectively.AsweshallseeinChapter10,swapping
with pagingworks wellin conjunction with virtualmemory.
9.5.3 Swapping on Mobile Systems
Most operating systems for PCs and servers support swapping pages. In con-
trast, mobile systems typically do not s upport swapping in any form. Mobile
devices generally use flash memory rather than more spacious hard disks for
nonvolatile storage. The resulting space constraint is one reason why mobile
operating-systemdesignersavoidswappi ng.Otherreasonsincludethelimited
number of writes that flash memory can tolerate before it becomes unreliable
and the poor throughput between main memory and flash memory in these
devices."
3,9.5.2 Swapping with Paging,483,9.5.1 Standard Swapping,"9.5 Swapping 377
9.5.1 Standard Swapping
Standard swapping involves moving entire processes between main memory
and a backing store. The backing store is commonly fast secondary storage.
It must be large enough to accommodate whatever parts of processes need to
be stored and retrieved, and it must provide direct access to these memory
images. When a process or part is swapped to the backing store, the data
structures associated with the process must be written to the backing store.
For a multithreaded process, all per-thread data structures must be swapped
as well. The operating system must also maintain metadata for processes that
have beenswapped out, so they can be restoredwhen they are swappedback
into memory.
The advantage of standard swapping is that it allows physical memory to
be oversubscribed, so that the system can accommodate more processes than
there is actual physical memory to store them. Idle or mostly idle processes
are good candidates for swapping; any memory that has been allocated to
theseinactiveprocessescanthenbededicatedtoactiveprocesses.Ifaninactive
pr ocessthathasbeenswappedoutbecomesactiveonceagain,itmustthenbe
swappedback in.This isillustratedinFigure9.19.
9.5.2 Swapping with Paging
Standardswappingwasusedintraditional UNIXsystems,butitisgenerallyno
longer used in contemporary operating systems, because the amount of time
required to move entire processes between memory and the backing store is
prohibitive.(AnexceptiontothisisSola ris,whichstillusesstandardswapping,
however only under dire circumstances when available memory is extremely
low.)
Mostsystems,includingLinuxandWindows,nowuseavariationofswap-
ping in which pages of a process—rather than an entire process—can be
swapped.Thisstrategystillallowsphysicalmemorytobeoversubscribed,but
does not incur the cost of swapping entire processes, as presumably only a
smallnumberofpageswillbeinvolvedinswapping.Infact,theterm swapping
now generally refers to standard swapping, and pagingrefers to swapping
withpaging.A page out operationmovesapagefrommemorytothebacking
store;thereverseprocessisknownasa page in.Swappingwithpagingisillus-
trated in Figure 9.20 where a subset of pages for processes Aand Bare being
paged-outandpaged-inrespectively.AsweshallseeinChapter10,swapping
with pagingworks wellin conjunction with virtualmemory.
9.5.3 Swapping on Mobile Systems
Most operating systems for PCs and servers support swapping pages. In con-
trast, mobile systems typically do not s upport swapping in any form. Mobile
devices generally use flash memory rather than more spacious hard disks for
nonvolatile storage. The resulting space constraint is one reason why mobile
operating-systemdesignersavoidswappi ng.Otherreasonsincludethelimited
number of writes that flash memory can tolerate before it becomes unreliable
and the poor throughput between main memory and flash memory in these
devices."
3,9.5.3 Swapping on Mobile Systems,483,9.5.2 Swapping with Paging,"9.5 Swapping 377
9.5.1 Standard Swapping
Standard swapping involves moving entire processes between main memory
and a backing store. The backing store is commonly fast secondary storage.
It must be large enough to accommodate whatever parts of processes need to
be stored and retrieved, and it must provide direct access to these memory
images. When a process or part is swapped to the backing store, the data
structures associated with the process must be written to the backing store.
For a multithreaded process, all per-thread data structures must be swapped
as well. The operating system must also maintain metadata for processes that
have beenswapped out, so they can be restoredwhen they are swappedback
into memory.
The advantage of standard swapping is that it allows physical memory to
be oversubscribed, so that the system can accommodate more processes than
there is actual physical memory to store them. Idle or mostly idle processes
are good candidates for swapping; any memory that has been allocated to
theseinactiveprocessescanthenbededicatedtoactiveprocesses.Ifaninactive
pr ocessthathasbeenswappedoutbecomesactiveonceagain,itmustthenbe
swappedback in.This isillustratedinFigure9.19.
9.5.2 Swapping with Paging
Standardswappingwasusedintraditional UNIXsystems,butitisgenerallyno
longer used in contemporary operating systems, because the amount of time
required to move entire processes between memory and the backing store is
prohibitive.(AnexceptiontothisisSola ris,whichstillusesstandardswapping,
however only under dire circumstances when available memory is extremely
low.)
Mostsystems,includingLinuxandWindows,nowuseavariationofswap-
ping in which pages of a process—rather than an entire process—can be
swapped.Thisstrategystillallowsphysicalmemorytobeoversubscribed,but
does not incur the cost of swapping entire processes, as presumably only a
smallnumberofpageswillbeinvolvedinswapping.Infact,theterm swapping
now generally refers to standard swapping, and pagingrefers to swapping
withpaging.A page out operationmovesapagefrommemorytothebacking
store;thereverseprocessisknownasa page in.Swappingwithpagingisillus-
trated in Figure 9.20 where a subset of pages for processes Aand Bare being
paged-outandpaged-inrespectively.AsweshallseeinChapter10,swapping
with pagingworks wellin conjunction with virtualmemory.
9.5.3 Swapping on Mobile Systems
Most operating systems for PCs and servers support swapping pages. In con-
trast, mobile systems typically do not s upport swapping in any form. Mobile
devices generally use flash memory rather than more spacious hard disks for
nonvolatile storage. The resulting space constraint is one reason why mobile
operating-systemdesignersavoidswappi ng.Otherreasonsincludethelimited
number of writes that flash memory can tolerate before it becomes unreliable
and the poor throughput between main memory and flash memory in these
devices."
2,9.6 Example: Intel 32- and 64-bit Architectures,485,9.5 Swapping,"9.6 Example: Intel 32- and 64-bit Architectures 379
9.6 Example: Intel 32- and 64-bit Architectures
ThearchitectureofIntelchipshasdominatedthepersonalcomputerlandscape
for decades. The 16-bit Intel 8086 appeared in the late 1970s and was soon
followedbyanother16-bitchip—theIntel8088—whichwasnotableforbeing
the chip used in the original IBM PC. Intel later produced a series of 32-bit
chips—the IA-32—which included the family of 32-bit Pentium processors.
More recently, Intel has produced a series of 64-bit chips based on the x86-64
architecture.Currently,allthemostpopular PCoperatingsystemsrunonIntel
chips,includingWindows,mac OS,andLinux(althoughLinux,ofcourse,runs
on several other architectures as well). Notably, however, Intel’s dominance
hasnotspreadtomobilesystems,wherethe ARMarchitecturecurrentlyenjoys
considerablesuccess(seeSection9.7).
In this section, we examine address translation for both IA-32 and x86-64
architectures.Beforeweproceed,however,itisimportanttonotethatbecause
Intelhasreleasedseveralversions—aswellasvariations—ofitsarchitectures
over the years, we cannot provide a complete description of the memory-
managementstructureofallitschips.Norcanweprovideallofthe CPUdetails,
as that information is best left to books on computer architecture. Rather, we
presentthemajor memory-managementconcepts of theseIntel CPUs.
9.6.1 IA-32 Architecture
Memory management in IA-32 systems is divided into two components—
segmentation and paging—and works as follows: The CPUgenerates logical
addresses, which are given to the segmentation unit. The segmentation unit
produces a linear address for each logical address. The linear address is then
giventothepagingunit,whichinturngeneratesthephysicaladdressinmain
memory. Thus, the segmentation and paging units form the equivalent of the
memory-managementunit( MMU). Thisscheme isshown in Figure9.21.
9.6.1.1 IA-32 Segmentation
TheIA-32 architecture allows a segment to be as large as 4 GB,a n dt h em a x -
imum number of segments per process is 16 K. The logical address space of
a process is divided into two partitions. The first partition consists of up to
8Ksegments that are private to that proc ess. The second partition consists
of up to 8 Ksegments that are shared among all the processes. Information
aboutthefirstpartitioniskeptinthe local descriptor table (LDT);information
about the second partition is kept in the global descriptor table (GDT). Each
entryinthe LDTandGDTconsistsofan8-bytesegmentdescriptorwithdetailed
information about a particular segment, including the base location and limit
ofthat segment.
CPUlogical
address segmentation
unitlinear
address paging
unitphysical
address physical
memory
Figure 9.21 Logical to physical address translation in IA-32."
3,9.6.1 IA-32 Architecture,485,9.6 Example: Intel 32- and 64-bit Architectures,"9.6 Example: Intel 32- and 64-bit Architectures 379
9.6 Example: Intel 32- and 64-bit Architectures
ThearchitectureofIntelchipshasdominatedthepersonalcomputerlandscape
for decades. The 16-bit Intel 8086 appeared in the late 1970s and was soon
followedbyanother16-bitchip—theIntel8088—whichwasnotableforbeing
the chip used in the original IBM PC. Intel later produced a series of 32-bit
chips—the IA-32—which included the family of 32-bit Pentium processors.
More recently, Intel has produced a series of 64-bit chips based on the x86-64
architecture.Currently,allthemostpopular PCoperatingsystemsrunonIntel
chips,includingWindows,mac OS,andLinux(althoughLinux,ofcourse,runs
on several other architectures as well). Notably, however, Intel’s dominance
hasnotspreadtomobilesystems,wherethe ARMarchitecturecurrentlyenjoys
considerablesuccess(seeSection9.7).
In this section, we examine address translation for both IA-32 and x86-64
architectures.Beforeweproceed,however,itisimportanttonotethatbecause
Intelhasreleasedseveralversions—aswellasvariations—ofitsarchitectures
over the years, we cannot provide a complete description of the memory-
managementstructureofallitschips.Norcanweprovideallofthe CPUdetails,
as that information is best left to books on computer architecture. Rather, we
presentthemajor memory-managementconcepts of theseIntel CPUs.
9.6.1 IA-32 Architecture
Memory management in IA-32 systems is divided into two components—
segmentation and paging—and works as follows: The CPUgenerates logical
addresses, which are given to the segmentation unit. The segmentation unit
produces a linear address for each logical address. The linear address is then
giventothepagingunit,whichinturngeneratesthephysicaladdressinmain
memory. Thus, the segmentation and paging units form the equivalent of the
memory-managementunit( MMU). Thisscheme isshown in Figure9.21.
9.6.1.1 IA-32 Segmentation
TheIA-32 architecture allows a segment to be as large as 4 GB,a n dt h em a x -
imum number of segments per process is 16 K. The logical address space of
a process is divided into two partitions. The first partition consists of up to
8Ksegments that are private to that proc ess. The second partition consists
of up to 8 Ksegments that are shared among all the processes. Information
aboutthefirstpartitioniskeptinthe local descriptor table (LDT);information
about the second partition is kept in the global descriptor table (GDT). Each
entryinthe LDTandGDTconsistsofan8-bytesegmentdescriptorwithdetailed
information about a particular segment, including the base location and limit
ofthat segment.
CPUlogical
address segmentation
unitlinear
address paging
unitphysical
address physical
memory
Figure 9.21 Logical to physical address translation in IA-32."
3,9.6.2 x86-64,488,9.6.1 IA-32 Architecture,"382 Chapter 9 Main Memory
31 30 29 21 20 12 11 0page table offset page directory
4-KB
page
page
tablepage directory
pointer tableCR3
register page
directory
Figure 9.24 Page address extensions.
extendfrom20to24bits.Combinedwiththe12-bitoffset,adding PAEsupport
toIA-32 increased the address space to 36 bits, which supports up to 64 GB
of physical memory. It is important to note that operating system support
is required to use PAE. Both Linux and mac OSsupport PAE. However, 32-bit
versionsofWindowsdesktopoperatingsystemsstillprovidesupportforonly
4GBof physicalmemory,evenif PAEisenabled.
9.6.2 x86-64
Intel has had an interesting history of developing 64-bit architectures. Its ini-
tial entry was the IA-64 (later named Itanium) architecture, but that architec-
ture was not widely adopted. Meanwhile, another chip manufacturer— AMD
— began developing a 64-bit architecture known as x86-64 that was based
on extending the existing IA-32 instruction set. The x86-64 supported much
larger logical and physical address spaces, as well as several other architec-
tural advances. Historically, AMDhad often developed chips based on Intel’s
architecture, but now the roles were reversed as Intel adopted AMD’s x86-64
architecture. In discussing this architecture, rather than using the commercial
names AMD 64and Intel 64,we willuse the more generalterm x86-64.
Support for a 64-bit address space yields an astonishing 264bytes of
addressable memory—a number greater than 16 quintillion (or 16 exabytes).
However,eventhough64-bitsystemscanpotentiallyaddressthismuchmem-
ory, in practice far fewer than 64 bits are used for address representation in
current designs. The x86-64 architecture currently provides a 48-bit virtual
address with support for page sizes of 4 KB,2MB,o r1GBusing four levels
ofpaginghierarchy.TherepresentationofthelinearaddressappearsinFigure
9.25.Becausethisaddressingschemecanuse PAE,virtualaddressesare48bits
insizebut support52-bit physical addresses(4,096 terabytes).
unusedpage map
level 4page directory
pointer tablepage
directorypage
table offset
63 63 47 48 39 38 30 29 21 20 12 11 0
Figure 9.25 x86-64 linear address."
2,9.7 Example: ARMv8 Architecture,489,9.6 Example: Intel 32- and 64-bit Architectures,"9.7 Example: ARMv8 Architecture 383
9.7 Example: ARMv8 Architecture
Although Intel chips have dominated the personalcomputer market for more
than 30 years, chips for mobile device s such as smartphones and tablet com-
puters often instead run on ARMprocessors. Interestingly, whereas Intel both
designs and manufactures chips, ARMonly designs them. It then licenses
its architectural designs to chip manufacturers. Apple has licensed the ARM
designforitsiPhoneandiPadmobiledevices,andmostAndroid-basedsmart-
phones use ARMprocessors as well. In addition to mobile devices, ARMalso
providesarchitecture designsfor real -timeembeddedsystems.Because of the
abundance of devices that run on the ARMarchitecture, over 100 billion ARM
processors have been produced, making it the most widely used architecture
whenmeasuredinthequantityofchipsproduced.Inthissection,wedescribe
the 64-bit ARMv8 architecture.
TheARMv8 has three different translation granules :4KB,1 6KB,a n d6 4
KB. Each translation granule provides different page sizes, as well as larger
sections of contiguous memory, known as regions. The page and region sizes
forthe differenttranslationgranulesareshown below:
Translation Granule Size PageSize Region Size
4KB 4KB 2MB,1GB
16KB 16KB 32MB
64KB 64KB 512MB
For 4-KBand 16- KBgranules, up to four levels of paging may be used,
with up to three levels of paging for 64- KBgranules. Figure 9.26 illustrates
theARMv8 address structure for the 4- KBtranslation granule with up to four
levels of paging. (Notice that although ARMv8 is a 64-bit architecture, only 48
bits are currently used.) The four-level hierarchical paging structure for the
4-KBtranslation granule is illustrated in Figure 9.27. (The TTBRregister is the
translation table base register and points to the level 0 table for the current
thread.)
If all four levels are used, the offset (bits 0–11 in Figure 9.26) refers to the
offsetwithina4- KBpage.However,noticethatthetableentriesforlevel1and
64-BIT COMPUTING
Historyhastaughtusthateventhoughmemorycapacities, CPUspeeds,and
similar computer capabilities seem large enough to satisfy demand for the
foreseeable future, the growth of technology ultimately absorbs available
capacities,andwefindourselvesinneedofadditionalmemoryorprocessing
power,oftensoonerthanwethink.What mightthefutureoftechnologybring
thatwould make a64-bit address space seemtoosmall?"
2,9.8 Summary,490,9.7 Example: ARMv8 Architecture,"384 Chapter 9 Main Memory
unused offset
63 63 47 48 39 38 30 29 21 20 12 11 0level 0
indexlevel 1
indexlevel 2
indexlevel 3
index
Figure 9.26 ARM 4-KB translation granule.
level 2 may refer either to another table or to a 1- GBregion (level-1 table) or
2-MBregion (level-2 table). As an example, if the level-1 table refers to a 1- GB
regionratherthanalevel-2table,thelow-order30bits(bits0–29inFigure9.26)
are used as an offset into this 1- GBregion. Similarly, if the level-2 table refers
to a 2-MBregion rather than a level-3 table, the low-order 21 bits (bits 0–20 in
Figure9.26)refertothe offsetwithin this2- MBregion.
TheARMarchitecture also supports two levels of TLBs. At the inner level
are two micro TLBs—aTLBfor data and another for instructions. The micro
TLBsupports ASIDs as well. At the outer level is a single main TLB. Address
translation begins at the micro- TLBlevel.In the case of a miss, the main TLBis
then checked. If both TLBs yield misses, a page table walk must be performed
in hardware.
9.8 Summary
•Memory is central to the operation of a modern computer system and
consists of alargearray of bytes,each withitsownaddress.
•Onewaytoallocateanaddressspacetoeachprocessisthroughtheuseof
baseandlimitregisters.Thebaseregisterholdsthesmallestlegalphysical
memoryaddress,and thelimitspecifiesthesizeof therange.
level 0
index
level 0
table
TTBR
registerlevel 1
tablelevel 2
tablelevel 3
tablelevel 1
indexlevel 2
indexlevel 3
indexoffset
4-KB
page
1-GB
region2-MB
region
Figure 9.27 A R Mf o u r - l e v e lh i e r a r c h i c a lp a g i n g ."
2,Practice Exercises,491,9.8 Summary,"Practice Exercises 385
•Binding symbolic address references to actual physical addresses may
occur during(1) compile,(2)load,or (3) executiontime.
•An address generated by the CPUis known as a logical address, which
the memory management unit ( MMU)t r a n s l a t e st oap h y s i c a la d d r e s si n
memory.
•One approachtoallocatingmemoryistoallocatepartitionsofcontiguous
memoryofvaryingsizes.Thesepartitionsmaybeallocatedbasedonthree
possiblestrategies:(1)first fit, (2) bestfit,and (3) worst fit.
•Modernoperatingsystemsusepagingtomanagememory.Inthisprocess,
physical memory is divided into fixed-sized blocks called frames and
logical memoryinto blocks of thesamesizecalledpages.
•When paging is used, a logical address is divided into two parts: a page
numberandapageoffset.Thepagenumberservesasanindexintoaper-
process page table that contains the frame in physical memory that holds
the page.The offsetisthe specific location inthe frame being referenced.
•Atranslationlook-asidebuffer( TLB)isahardwarecacheofthepagetable.
EachTLBentry contains a page number an d itscorrespondingframe.
•Using a TLBin address translation for paging systems involves obtaining
thepagenumberfromthelogicaladdressandcheckingiftheframeforthe
page is in the TLB. If it is, the frame is obtained from the TLB.I ft h ef r a m e
is not presentin the TLB, itmustbe retrievedfrom thepagetable.
•Hierarchicalpaginginvolvesdividingalogicaladdressintomultipleparts,
each referring to different levels of page tables. As addresses expand
beyond 32 bits, the number of hierarchical levels may become large. Two
strategies that address this problem are hashed page tables and inverted
pagetables.
•Swappingallowsthesystemtomovepagesbelongingtoaprocesstodisk
to increasethedegreeof multiprogramming.
•The Intel 32-bit architecture has two levels of page tables and supports
either 4- KBor 4-MBpage sizes. This architecture also supports page-
address extension, which allows 32-bit processors to access a physical
address space larger than 4 GB. The x86-64 and ARMv9 architectures are
64-bit architecturesthat usehierarchical paging.
Practice Exercises
9.1Nametwo differencesbetweenlogicaland physical addresses.
9.2Why arepagesizesalwayspowers of 2?
9.3Considera systemin which a program can be separatedinto two parts:
codeanddata.The CPUknowswhetheritwantsaninstruction(instruc-
tionfetch)ordata(datafetchorstore).Therefore,twobase–limitregister
pairsareprovided:oneforinstructionsandonefordata.Theinstruction"
2,Further Reading,493,Practice Exercises,"Bibliography 387
Further Reading
The concept of paging can be credited to the designers of the Atlas system,
which has been described by [Kilburn et al. (1961)] and by [Howarth et al.
(1961)].
[Hennessy and Patterson (2012)] explain the hardware aspects of TLBs,
caches,and MMUs.[JacobandMudge(2001)]describetechniquesformanaging
theTLB.[Fang etal. (2001)] evaluatesupportfor largepages.
PAEsupportforWindowssystems.isdiscussedin http://msdn.microsoft.co
m/en-us/library/windows/hardware/gg487512.aspx An overview of the ARM
architectureisprovidedin http://www.arm.com/products/processors/cortex-
a/cortex-a9.php
Bibliography
[Fang et al. (2001)] Z.Fang,L.Zhang,J.B.Carter ,W .C.Hsieh,andS.A.McKee,
“Reevaluating OnlineSuperpagePromotionwith Hardware Support ”,Proceed-
ings of the International Symposium on Hi gh-Performance Computer Architecture ,
Volume50,Number5 (2001).
[Hennessy and Patterson (2012)] J.HennessyandD.Patterson, Computer Archi-
tecture: A Quantitative Approach, Fifth Edition, MorganKaufmann(2012).
[Howarth et al. (1961)] D .J .H o w a r t h ,R .B .P a y n e ,a n dF .H .S u m n e r , “The
Manchester University Atlas Operating System, Part II: User’s Description ”,
Computer Journal , Volume4, Number3 (1961), pages226–229.
[Jacob and Mudge (2001)] B. Jacob and T. Mudge, “UniprocessorVirtual Mem-
oryWithoutTLBs ”,IEEE Transactions on Computers ,Volume50,Number5(2001).
[Kilburn et al. (1961)] T.Kilburn,D.J.Howarth,R.B.Payne,andF.H.Sumner,
“TheManchesterUniversity Atlas OperatingSystem,PartI:InternalOrganiza-
tion ”,Computer Journal , Volume4, Number3(1961), pages 222–225."
2,Bibliography,493,Further Reading,"Bibliography 387
Further Reading
The concept of paging can be credited to the designers of the Atlas system,
which has been described by [Kilburn et al. (1961)] and by [Howarth et al.
(1961)].
[Hennessy and Patterson (2012)] explain the hardware aspects of TLBs,
caches,and MMUs.[JacobandMudge(2001)]describetechniquesformanaging
theTLB.[Fang etal. (2001)] evaluatesupportfor largepages.
PAEsupportforWindowssystems.isdiscussedin http://msdn.microsoft.co
m/en-us/library/windows/hardware/gg487512.aspx An overview of the ARM
architectureisprovidedin http://www.arm.com/products/processors/cortex-
a/cortex-a9.php
Bibliography
[Fang et al. (2001)] Z.Fang,L.Zhang,J.B.Carter ,W .C.Hsieh,andS.A.McKee,
“Reevaluating OnlineSuperpagePromotionwith Hardware Support ”,Proceed-
ings of the International Symposium on Hi gh-Performance Computer Architecture ,
Volume50,Number5 (2001).
[Hennessy and Patterson (2012)] J.HennessyandD.Patterson, Computer Archi-
tecture: A Quantitative Approach, Fifth Edition, MorganKaufmann(2012).
[Howarth et al. (1961)] D .J .H o w a r t h ,R .B .P a y n e ,a n dF .H .S u m n e r , “The
Manchester University Atlas Operating System, Part II: User’s Description ”,
Computer Journal , Volume4, Number3 (1961), pages226–229.
[Jacob and Mudge (2001)] B. Jacob and T. Mudge, “UniprocessorVirtual Mem-
oryWithoutTLBs ”,IEEE Transactions on Computers ,Volume50,Number5(2001).
[Kilburn et al. (1961)] T.Kilburn,D.J.Howarth,R.B.Payne,andF.H.Sumner,
“TheManchesterUniversity Atlas OperatingSystem,PartI:InternalOrganiza-
tion ”,Computer Journal , Volume4, Number3(1961), pages 222–225."
2,Chapter 9 Exercises,494,Bibliography,"Exercises
Chapter 9 Exercises
9.11Explainthe differencebetweeninternaland externalfragmentation.
9.12Consider the following process for generating binaries. A compiler is
used to generate the object code for individual modules, and a linker is
used to combine multiple object modules into a single program binary.
Howdoesthelinkerchangethebindingofinstructionsanddatatomem-
ory addresses?What information needsto be passedfrom the compiler
to thelinkerto facilitatethememo ry-bindingtasks of thelinker?
9.13Given six memory partitions of 100 MB, 170MB,4 0MB, 205MB, 300MB,
and 185 MB(in order), how would the first-fit, best-fit, and worst-fit
algorithms place processes of size 200 MB,1 5MB, 185MB,7 5MB, 175
MB,a n d8 0 MB(in order)? Indicate which—if any—requests cannot be
satisfied. Comment on how efficiently each of the algorithms manages
memory.
9.14Most systems allow a program to allocate more memory to its address
space during execution. Allocation of data in the heap segments of
programs is an example of such allocated memory. What is required to
supportdynamic memoryallocation in the following schemes?
a. Contiguous memoryallocation
b. Paging
9.15Comparethememoryorganizationschemesofcontiguousmemoryallo-
cation andpaging with respectto thefollowing issues:
a. Externalfragmentation
b. Internal fragmentation
c. Abilitytoshare codeacross processes
9.16On a system with paging, a process cannot access memory that it does
not own. Why? How could the operating system allow access to addi-
tional memory?Why should it orshould itnot?
9.17Explainwhy mobile operatingsystemssuch as i OSand Android do not
supportswapping.
9.18Although Android does not support swapping on its boot disk, it is
possibletosetupaswapspaceusingaseparate SDnonvolatilememory
card.WhywouldAndroiddisallowswappingonitsbootdiskyetallow
iton asecondary disk?
9.19Explainwhy address-spaceidentifiers( ASIDs) areusedin TLBs.
9.20Program binaries in many systems are typically structured as follows.
Codeisstoredstartingwithasmall,fixedvirtualaddress,suchas0.The
codesegmentisfollowedbythedatasegment,whichisusedforstoring
the program variables. When the program starts executing, the stack is
allocated at the other end of the virtual address space and is allowed
to grow towardlower virtualaddresses.What is the significance of this
structure for the following schemes?EX-32"
2,Programming Problems,497,Chapter 9 Exercises,"Programming Projects
Programming Problems
9.28Assumethatasystemhasa32-bitvirtualaddresswitha4- KBpagesize.
Write a C program that is passed a virtual address (in decimal) on the
command line and have it output the page number and offset for the
givenaddress.Asanexample,yourprogram wouldrunas follows:
./addresses 19986
Your program wouldoutput:
The address 19986 contains:
page number = 4
offset = 3602
Writing this program will require using the appropriate data type to
store32 bits.We encourageyou to use unsigned datatypesas well.
Programming Projects
Contiguous Memory Allocation
InSection9.2, we presenteddifferentalgorithms for contiguous memoryallo-
cation. This project will involve managing a contiguous region of memory of
size MAXwher eaddr essesmayrangefr om0... MAX −1.Yourprogrammust
respond to four different requests:
1.Requestfor a contiguous block of memory
2.Releaseof a contiguous block ofmemory
3.Compactunused holesof memoryinto onesingleblock
4.Reporttheregions offreeand allocatedmemory
Your program will be passed the initial amount of memory at startup. For
example, the following initializes the program with 1 MB(1,048,576 bytes) of
memory:
./allocator 1048576
Once yourprogramhasstarted,itwillpresenttheuserwiththefollowing
prompt:
allocator>
It will then respond to the following commands: RQ(request), RL(release), C
(compact), STAT(status report),and X(exit).
Arequestfor 40,000 byteswill appearas follows:
allocator>RQ P0 40000 WP-48"
2,Programming Projects,497,Programming Problems,"Programming Projects
Programming Problems
9.28Assumethatasystemhasa32-bitvirtualaddresswitha4- KBpagesize.
Write a C program that is passed a virtual address (in decimal) on the
command line and have it output the page number and offset for the
givenaddress.Asanexample,yourprogram wouldrunas follows:
./addresses 19986
Your program wouldoutput:
The address 19986 contains:
page number = 4
offset = 3602
Writing this program will require using the appropriate data type to
store32 bits.We encourageyou to use unsigned datatypesas well.
Programming Projects
Contiguous Memory Allocation
InSection9.2, we presenteddifferentalgorithms for contiguous memoryallo-
cation. This project will involve managing a contiguous region of memory of
size MAXwher eaddr essesmayrangefr om0... MAX −1.Yourprogrammust
respond to four different requests:
1.Requestfor a contiguous block of memory
2.Releaseof a contiguous block ofmemory
3.Compactunused holesof memoryinto onesingleblock
4.Reporttheregions offreeand allocatedmemory
Your program will be passed the initial amount of memory at startup. For
example, the following initializes the program with 1 MB(1,048,576 bytes) of
memory:
./allocator 1048576
Once yourprogramhasstarted,itwillpresenttheuserwiththefollowing
prompt:
allocator>
It will then respond to the following commands: RQ(request), RL(release), C
(compact), STAT(status report),and X(exit).
Arequestfor 40,000 byteswill appearas follows:
allocator>RQ P0 40000 WP-48"
1,Chapter 10 Virtual Memory,501,Chapter 9 Main Memory,"10CHAPTER
Virtual
Memory
In Chapter 9, we discussed various memory-management strategies used in
computer systems. All these strategies have the same goal: to keep many
processes in memory simultaneously to allow multiprogramming. However,
theytendtorequirethat anentireprocessbeinmemorybeforeitcan execute.
Virtual memory is a technique that allows the execution of processes that
arenotcompletelyinmemory.Onemajoradvantageofthisschemeisthatpro-
grams can be larger than physical memory. Further, virtual memory abstracts
main memory into an extremely large, uniform array of storage, separating
logical memory as viewed by the programmer from physical memory. This
technique frees programmers from the concerns of memory-storage limita-
tions. Virtual memory also allows processes to share files and libraries, and
to implement shared memory. In addition, it provides an efficient mechanism
for process creation. Virtual memory is not easy to implement, however, and
may substantially decrease performance if it is used carelessly. In this chap-
ter, we provide a detailed overview of virtual memory, examine how it is
implemented,and exploreitscomplexityand benefits.
CHAPTER OBJECTIVES
•Define virtual memory and describe its benefits.
•Illustrate how pages are loaded into memory using demand paging.
•Apply the FIFO,o p t i m a l ,a n d LRUpage-replacement algorithms.
•Describe the working set of a process, and explain how it is related to
program locality.
•Describe how Linux, Windows 10, and Solaris manage virtual memory.
•Design a virtual memory manager simulation in the C programming lan-
guage.
10.1 Background
The memory-management algorithms outlined in Chapter 9 are necessary
because of one basic requirement: the instructions being executed must be in
389"
2,10.1 Background,501,Chapter 10 Virtual Memory,"10CHAPTER
Virtual
Memory
In Chapter 9, we discussed various memory-management strategies used in
computer systems. All these strategies have the same goal: to keep many
processes in memory simultaneously to allow multiprogramming. However,
theytendtorequirethat anentireprocessbeinmemorybeforeitcan execute.
Virtual memory is a technique that allows the execution of processes that
arenotcompletelyinmemory.Onemajoradvantageofthisschemeisthatpro-
grams can be larger than physical memory. Further, virtual memory abstracts
main memory into an extremely large, uniform array of storage, separating
logical memory as viewed by the programmer from physical memory. This
technique frees programmers from the concerns of memory-storage limita-
tions. Virtual memory also allows processes to share files and libraries, and
to implement shared memory. In addition, it provides an efficient mechanism
for process creation. Virtual memory is not easy to implement, however, and
may substantially decrease performance if it is used carelessly. In this chap-
ter, we provide a detailed overview of virtual memory, examine how it is
implemented,and exploreitscomplexityand benefits.
CHAPTER OBJECTIVES
•Define virtual memory and describe its benefits.
•Illustrate how pages are loaded into memory using demand paging.
•Apply the FIFO,o p t i m a l ,a n d LRUpage-replacement algorithms.
•Describe the working set of a process, and explain how it is related to
program locality.
•Describe how Linux, Windows 10, and Solaris manage virtual memory.
•Design a virtual memory manager simulation in the C programming lan-
guage.
10.1 Background
The memory-management algorithms outlined in Chapter 9 are necessary
because of one basic requirement: the instructions being executed must be in
389"
2,10.2 Demand Paging,504,10.1 Background,"392 Chapter 10 Virtual Memory
shared librarystack
shared 
pages
textdataheap
textdataheapshared librarystack
Figure 10.3 Shared library using virtual memory.
In addition to separating logical memory from physical memory, virtual
memory allows files and memory to be shared by two or more processes
through page sharing (Section9.3.4). Thisleadstothe following benefits:
•System libraries such as the standard C library can be shared by several
processes through mapping of the shared object into a virtual address
space. Although each process considers the libraries to be part of its vir-
tual address space, the actual pages where the libraries reside in physical
memoryaresharedbyalltheprocesses(Figure10.3).Typically,alibraryis
mappedread-onlyinto thespace of each processthat islinkedwith it.
•Similarly, processes can share memory. Recall from Chapter 3 that two
or more processes can communicate through the use of shared memory.
Virtualmemoryallowsoneprocesstocreatearegionofmemorythatitcan
share with another process. Processes sharing this region consider it part
oftheirvirtualaddressspace,yettheactualphysicalpagesofmemoryare
shared,much as isillustratedinFigure10.3.
•Pages can be shared during process creation with the fork()system call,
thus speedingupprocesscreation.
We further explore these—and other—benefits of virtual memory later in
this chapter. First, though, we discuss implementing virtual memory through
demand paging.
10.2 Demand Paging
Considerhowanexecutableprogrammightbeloadedfromsecondarystorage
into memory. One option is to load the entire program in physical memory
at program execution time. However, a problem with this approach is that"
3,10.2.1 Basic Concepts,505,10.2 Demand Paging,"10.2 Demand Paging 393
we may not initially needthe entire program in memory. Suppose a program
starts with a list of available options from which the user is to select. Loading
t h ee n t i r ep r o g r a mi n t om e m o r yr e s u l t si nl o a d i n gt h ee x e c u t a b l ec o d ef o r all
options, regardless of whether or not an option is ultimately selected by the
user.
Analternativestrategyistoloadpagesonlyastheyareneeded.Thistech-
nique is known as demand paging and is commonly used in virtual memory
systems. With demand-paged virtual memory, pages are loaded only when
they are demanded during program execution. Pages that are never accessed
arethusneverloadedintophysicalmemory.Ademand-pagingsystemissimi-
lartoapagingsystemwithswapping(Section9.5.2)whereprocessesresidein
secondarymemory(usuallyan HDDorNVMdevice).Demandpagingexplains
one of the primary benefits of virtual memory—by loading only the portions
ofprograms thatareneeded,memoryisusedmoreefficiently.
10.2.1 Basic Concepts
Thegeneralconceptbehinddemandpag ing,asmentioned,istoloadapagein
memoryonlywhenitisneeded.Asaresu lt,whileaprocessisexecuting,some
pageswillbeinmemory,andsomewillbeinsecondarystorage.Thus,weneed
some form of hardware support to distinguish between the two. The valid–
invalidbitschemedescribedinSection9 .3.3canbeusedforthispurpose.This
B
D
DEF
H
logical
memoryvalid–invalid
bitframe
page table104
6 2
3
4
59
6
710
2
3
4
5
6
7iv
v
i
i
v
i
i
physical memorybacking storeA
AB C
C
FGHF10
2
3
4
5
6
7
98
10
11
12
13
14
15A
C
E
G
Figure 10.4 Page table when some pages are not in main memory."
3,10.2.2 Free-Frame List,508,10.2.1 Basic Concepts,"396 Chapter 10 Virtual Memory
3.FetchB.
4.AddAand B.
5.Storethesum inC.
If we fault when we try to store in C (because C is in a page not currently
in memory), we will have to get the desired page, bring it in, correct the
page table, and restart the instruction. The restart will require fetching the
instruction again, decoding it again , fetching the two operands again, and
then adding again. However, there is not much repeated work (less than one
complete instruction), and the repetit ion is necessary only when a page fault
occurs.
The major difficulty arises when one instruction may modify several dif-
ferent locations. For example, consider the IBMSystem 360/370 MVC(move
character) instruction, which can move up to 256 bytes from one location to
another (possibly overlapping)location. If eitherblock (source or destination)
straddles a page boundary, a page fault might occur after the move is par-
tiallydone.Inaddition,ifthesourceanddestinationblocksoverlap,thesource
block may have been modified, in which case we cannot simply restart the
instruction.
This problem can be solved in two different ways. In one solution, the
microcodecomputesandattemptstoaccessbothendsofbothblocks.Ifapage
fault is going to occur, it will happen at this step,before anything is modified.
The move can then take place; we know that no page fault can occur, since all
therelevantpagesareinmemory.Theothersolutionusestemporaryregisters
to hold the values of overwritten locations. If there is a page fault, all the old
valuesarewrittenbackintomemorybeforethetrapoccurs.Thisactionrestores
memory to its state before the instruction was started, so that the instruction
can berepeated.
This is by no means the only architectural problem resulting from adding
paging to an existing architecture to allow demand paging, but it illustrates
some of the difficulties involved. Paging is added between the CPUand the
memory in a computer system. It should be entirely transparent to a process.
Thus,peopleoftenassumethatpagingcan beaddedtoanysystem.Although
this assumption is true for a non-demand-paging environment, where a page
fault represents a fatal error, it is not true where a page fault means only that
an additionalpagemustbe brought into memoryand theprocessrestarted.
10.2.2 Free-Frame List
When a page fault occurs, the operating system must bring the desired page
from secondary storage into main memory. To resolve page faults, most oper-
ating systems maintain a free-frame list , a pool of free frames for satisfying
suchrequests(Figure10.6).(Freeframesmustalsobeallocatedwhenthestack
or heap segments from a process expand.) Operating systems typically allo-
head 79 7 126 75 15 ...
Figure 10.6 List of free frames."
3,10.2.3 Performance of Demand Paging,509,10.2.2 Free-Frame List,"10.2 Demand Paging 397
cate free frames using a technique known as zero-fill-on-deman . Zero-fill-
on-demand frames are “zeroed-out ”before being allocated, thus erasing their
previouscontents.(Considerthepotentialsecurityimplicationsof notclearing
outthe contents of a frame before reassigningit.)
Whenasystemstartsup,allavailablememoryisplacedonthefree-frame
list. As free frames are requested (for example, through demand paging), the
size of the free-frame list shrinks. At some point, the list either falls to zero or
fallsbelowacertainthreshold,atwhichpointitmustberepopulated.Wecover
strategiesfor both ofthesesituations inSection10.4.
10.2.3 Performance of Demand Paging
Demandpagingcansignificantlyaffecttheperformanceofacomputersystem.
Toseewhy,let’scomputethe effective access time forademand-pagedmem-
ory.Assumethememory-accesstime,denoted ma,is10nanoseconds. Aslong
as we have no page faults, the effective access time is equal to the memory
access time. If, however, a page fault occurs, we must first read the relevant
pagefromsecondary storageandthen access the desiredword.
Letpbe the probability of a page fault (0 ≤p≤1). We would expect pto
beclosetozero—that is,wewouldexpecttohaveonlya fewpagefaults.The
effectiveaccess timeisthen
effectiveaccess time=(1 −p)×ma+p×pagefaulttime.
To compute the effective access time, we must know how much time is
needed to service a page fault. Apage fault causes the following sequence to
occur:
1.Trapto theoperating system.
2.Savethe registersand processstate.
3.Determinethat the interruptwas a page fault.
4.Checkthatthepagereferencewaslegal,anddeterminethelocationofthe
pageinsecondarystorage.
5.Issueareadfromthe storagetoa freeframe:
a. Waitina queueuntil thereadrequestisserviced.
b. Waitfor thedeviceseekand/orlatency time.
c. Beginthe transferof thepageto a freeframe.
6.While waiting, allocate the CPUcore to some other process.
7.Receivean interruptfrom the storage I/Osubsystem ( I/Ocompleted).
8.Save the registers and process state for the other process (if step 6 is
executed).
9.Determinethat theinterruptwas from thesecondary storagedevice.
10.Correct the page table and other tables to show that the desired page is
now in memory.
11.Wait for the CPUcore to be allocated to thisprocessagain."
2,10.3 Copy-on-Write,511,10.2 Demand Paging,"10.3 Copy-on-Write 399
systemtogainbetterpagingthroughputisbycopyinganentirefileimageinto
the swap space at process startup and then performing demand paging from
the swap space. The obvious disadvantage of this approach is the copying of
the file image at program start-up. A second option—and one practiced by
severaloperatingsystems,includingL inuxandWindows—istodemand-page
from the file system initially but to write the pages to swap space as they are
replaced. This approach will ensure that only needed pages are read from the
filesystembut thatall subsequentpagingis donefromswap space.
Some systems attempt to limit the amount of swap space used through
demand paging of binary executable files. Demand pages for such files are
brought directly from the file system. However, when page replacement is
called for, these frames can simply be overwritten (because they are never
modified), and the pages can be read in from the file system again if needed.
Usingthisapproach,thefilesystemitselfservesasthebackingstore.However,
swap space must still be used for pages not associated with a file (known as
anonymous memory ); these pages include the stack and heap for a process.
Thismethodappearstobeagoodcompromiseandisusedinseveralsystems,
includingLinux and BSD UNIX .
As described in Section 9.5.3, mobile operating systems typically do not
support swapping. Instead, these systems demand-page from the file sys-
tem and reclaim read-only pages (such as code) from applications if memory
becomes constrained. Such data can be demand-paged from the file system if
it is later needed. Under i OS, anonymous memory pages are never reclaimed
from an application unless the application is terminated or explicitly releases
thememory.InSection10.7,wecovercompressedmemory,acommonlyused
alternativetoswapping inmobilesystems.
10.3 Copy-on-Write
In Section 10.2, we illustrated how a process can start quickly by demand-
paging in the page containing the first instruction. However, process creation
usingthe fork()systemcallmayinitiallybypasstheneedfordemandpaging
by using a technique similar to page sharing (covered in Section 9.3.4). This
technique provides rapid process creation and minimizes the number of new
pagesthatmust be allocated to the newly createdprocess.
Recallthatthe fork()systemcallcreatesachildprocessthatisaduplicate
of its parent. Traditionally, fork()worked by creating a copy of the parent’s
address space for the child, duplicating the pages belonging to the parent.
However,consideringthatmanychildprocessesinvokethe exec()systemcall
immediately after creation, the copying of the parent’s address space may be
unnecessary. Instead, we can use a technique known as copy-on-write ,w h i c h
works by allowing the parent and child processes initially to share the same
pages. These shared pages are marked as copy-on-write pages, meaning that
if either process writes to a shared page, a copy of the shared page is created.
Copy-on-writeisillustratedinFigures10.7and10.8,which showthe contents
ofthe physical memorybeforeandafterprocess1 modifiespageC.
For example, assume that the child process attempts to modify a page
containing portions of the stack, with the pages set to be copy-on-write. The
operatingsystemwillobtainaframefromthefree-framelistandcreateacopy"
2,10.4 Page Replacement,513,10.3 Copy-on-Write,"10.4 Page Replacement 401
is an extremely efficient method of process creation and is sometimes used to
implement UNIXcommand-lineshellinterfaces.
10.4 Page Replacement
In our earlier discussion of the page-fault rate, we assumed that each page
faultsatmostonce,whenitisfirstreferenced.Thisrepresentationisnotstrictly
accurate,however.Ifaprocessoftenpagesactuallyusesonlyhalfofthem,then
demand paging saves the I/Onecessary to load the five pages that are never
used. We could also increase our degree of multiprogramming by running
twice as many processes. Thus, if we had forty frames, we could run eight
processes,rather than the four that could runif each requiredten frames (five
ofwhich wereneverused).
If we increase our degree of multiprogramming, we are over-allocating
memory.Ifwerunsixprocesses,eachofwhichistenpagesinsizebutactually
u s e so n l yfi v ep a g e s ,w eh a v eh i g h e r CPUutilization and throughput, with
ten frames to spare. It is possible, however, that each of these processes, for
aparticulardataset,maysuddenlytrytousealltenofitspages,resultingina
needfor sixtyframeswhenonly forty areavailable.
Further,considerthatsystemmemoryisnotusedonlyforholdingprogram
pages.Buffersfor I/Oalsoconsumeaconsiderableamountofmemory.Thisuse
canincreasethestrainonmemory-placementalgorithms.Decidinghowmuch
memory to allocate to I/Oand how much to program pages is a significant
challenge.Somesystemsallocateafixedpercentageofmemoryfor I/Obuffers,
whereasothersallowbothprocessesandthe I/Osubsystemtocompetefor all
systemmemory.Section14.6discussestheintegratedrelationshipbetween I/O
buffersand virtualmemorytechniques.
Over-allocation of memory manifests itself as follows. While a process is
executing, a page fault occurs. The operating system determines where the
desired page is residing on secondary storage but then finds that there are
nofree frames on the free-frame list; all memory is in use. This situation is
illustratedinFigure10.9,wherethefactthattherearenofreeframesisdepicted
by aquestionmark.
The operating system has several options at this point. It could terminate
the process. However, demand paging is the operating system’s attempt to
improve the computer system’s utilization and throughput. Users should not
be aware that their processes are running on a paged system—paging should
belogicallytransparent tothe user.So thisoption isnot the bestchoice.
The operating system could instead use standard swapping and swap
out a process, freeing all its frames and reducing the level of multiprogram-
ming. However, as discussed in Section 9.5, standard swapping is no longer
used by most operating systems due to the overhead of copying entire pro-
cesses between memory and swap space. Most operating systems now com-
bineswappingpageswith page replacement ,atechniquewedescribeindetail
inthe remainderof thissection.
10.4.1 Basic Page Replacement
Pagereplacementtakesthefollowingapproach.Ifnoframeisfree,wefindone
that is not currently being used and free it. We can free a frame by writing its"
3,10.4.1 Basic Page Replacement,513,10.4 Page Replacement,"10.4 Page Replacement 401
is an extremely efficient method of process creation and is sometimes used to
implement UNIXcommand-lineshellinterfaces.
10.4 Page Replacement
In our earlier discussion of the page-fault rate, we assumed that each page
faultsatmostonce,whenitisfirstreferenced.Thisrepresentationisnotstrictly
accurate,however.Ifaprocessoftenpagesactuallyusesonlyhalfofthem,then
demand paging saves the I/Onecessary to load the five pages that are never
used. We could also increase our degree of multiprogramming by running
twice as many processes. Thus, if we had forty frames, we could run eight
processes,rather than the four that could runif each requiredten frames (five
ofwhich wereneverused).
If we increase our degree of multiprogramming, we are over-allocating
memory.Ifwerunsixprocesses,eachofwhichistenpagesinsizebutactually
u s e so n l yfi v ep a g e s ,w eh a v eh i g h e r CPUutilization and throughput, with
ten frames to spare. It is possible, however, that each of these processes, for
aparticulardataset,maysuddenlytrytousealltenofitspages,resultingina
needfor sixtyframeswhenonly forty areavailable.
Further,considerthatsystemmemoryisnotusedonlyforholdingprogram
pages.Buffersfor I/Oalsoconsumeaconsiderableamountofmemory.Thisuse
canincreasethestrainonmemory-placementalgorithms.Decidinghowmuch
memory to allocate to I/Oand how much to program pages is a significant
challenge.Somesystemsallocateafixedpercentageofmemoryfor I/Obuffers,
whereasothersallowbothprocessesandthe I/Osubsystemtocompetefor all
systemmemory.Section14.6discussestheintegratedrelationshipbetween I/O
buffersand virtualmemorytechniques.
Over-allocation of memory manifests itself as follows. While a process is
executing, a page fault occurs. The operating system determines where the
desired page is residing on secondary storage but then finds that there are
nofree frames on the free-frame list; all memory is in use. This situation is
illustratedinFigure10.9,wherethefactthattherearenofreeframesisdepicted
by aquestionmark.
The operating system has several options at this point. It could terminate
the process. However, demand paging is the operating system’s attempt to
improve the computer system’s utilization and throughput. Users should not
be aware that their processes are running on a paged system—paging should
belogicallytransparent tothe user.So thisoption isnot the bestchoice.
The operating system could instead use standard swapping and swap
out a process, freeing all its frames and reducing the level of multiprogram-
ming. However, as discussed in Section 9.5, standard swapping is no longer
used by most operating systems due to the overhead of copying entire pro-
cesses between memory and swap space. Most operating systems now com-
bineswappingpageswith page replacement ,atechniquewedescribeindetail
inthe remainderof thissection.
10.4.1 Basic Page Replacement
Pagereplacementtakesthefollowingapproach.Ifnoframeisfree,wefindone
that is not currently being used and free it. We can free a frame by writing its"
3,10.4.2 FIFO Page Replacement,516,10.4.1 Basic Page Replacement,"404 Chapter 10 Virtual Memory
I/Ois so expensive. Even slight improvements in demand-paging methods
yieldlargegains insystemperformance.
There are many different page-replacement algorithms. Every operating
system probably has its own replacement scheme. How do we select a par-
ticular replacement algorithm? In general, we want the one with the lowest
page-faultrate.
We evaluate an algorithm by running it on a particular string of memory
references and computing the number of page faults. The string of memory
references is called a reference string . We can generate reference strings arti-
ficially (by using a random-number generator, for example), or we can trace
a given system and record the address of each memory reference. The latter
choice produces a large number of data (on the order of 1 million addresses
persecond).To reducethenumber of data,we usetwo facts.
First,foragivenpagesize(andthepagesizeisgenerallyfixedbythehard-
ware or system), we need to consider only the page number, rather than the
entire address. Second, if we have a reference to a page p,then any references
to page pthatimmediately follow will never cause a page fault. Page pwill
beinmemoryafterthefirstreference,sotheimmediatelyfollowingreferences
willnot fault.
Forexample,ifwetraceaparticularprocess,wemightrecordthefollowing
addresssequence:
0100, 0432, 0101, 0612, 0102, 0103, 0104, 0101, 0611, 0102, 0103,
0104, 0101, 0610, 0102, 0103, 0104, 0101, 0609, 0102, 0105
At 100 bytes per page, this sequence is reduced to the following reference
string:
1, 4, 1, 6, 1, 6, 1, 6, 1, 6, 1
Todeterminethenumberofpagefaultsforaparticularreferencestringand
page-replacementalgorithm,wealsoneedtoknowthenumberofpageframes
available.Obviously,as the number of framesavailableincreases,thenumber
of page faults decreases. For the reference string considered previously, for
example, if we had three or more frames, we would have only three faults—
one fault for the first reference to each page. In contrast, with only one frame
available, we would have a replacement with every reference, resulting in
elevenfaults.Ingeneral,weexpectacurvesuchasthatinFigure10.11.Asthe
numberofframesincreases,thenumberofpagefaultsdropstosomeminimal
level.Of course,addingphysical memoryincreasesthenumber of frames.
We next illustrate several page-replacement algorithms. In doing so, we
use the reference string
7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1
for a memorywiththreeframes.
10.4.2 FIFO Page Replacement
The simplest page-replacement algorithm is a first-in, first-out ( FIFO)a l g o -
rithm.A FIFOreplacementalgorithmassociateswitheachpagethetimewhen
thatpagewasbroughtintomemory.Whenapagemustbereplaced,theoldest
pageischosen.Noticethatitisnotstrictlynecessarytorecordthetimewhena"
3,10.4.3 Optimal Page Replacement,518,10.4.2 FIFO Page Replacement,"406 Chapter 10 Virtual Memorynumber of page faults16
14
12
10
8
6
4
2
123
number of frames4567
Figure 10.13 Page-fault curve for FIFO replacement on a reference string.
one, a fault occurs almost immediatelyto retrievethe active page.Some other
pagemustbereplacedtobringtheactivepageback intomemory.Thus,abad
replacement choice increases the page-fault rate and slows process execution.
Itdoesnot, however,cause incorrect execution.
To illustrate the problems that are possible with a FIFOpage-replacement
algorithm,considerthe following referencestring:
1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5
Figure10.13 shows the curve ofpage faultsforthisreferencestringversusthe
number of available frames. Notice that the number of faults for four frames
(ten) is greaterthan the number of faults for three frames (nine)! This most
unexpected result is known as Belady’s anomaly : for some page-replacement
algorithms,thepage-faultratemay increase asthenumberofallocatedframes
increases. We would expect that giving more memory to a process would
improveitsperformance.Insomeearlyresearch,investigatorsnoticedthatthis
assumptionwasnotalwaystrue.Belady’sanomalywasdiscoveredasaresult.
10.4.3 Optimal Page Replacement
OneresultofthediscoveryofBelady’sanomalywasthesearchforan optimal
page-replacement algorithm —the algorithm that has the lowest page-fault
rate of all algorithms and will never suffer from Belady’s anomaly. Such an
algorithm doesexistand has beencalled OPTorMIN.I ti ss i m p l yt h i s :
Replacethe pagethat willnot be usedfor thelongest periodof time.
Use of this page-replacement algorithm guarantees the lowest possible page-
f a u l tr a t ef o rafi x edn u m b ero ff r a m es .
Forexample,onoursamplereferencestring,theoptimalpage-replacement
algorithmwouldyieldninepagefaults,asshowninFigure10.14.Thefirstthree
references cause faults that fill the three empty frames. The reference to page
2 replaces page 7, because page 7 will not be used until reference 18, whereas"
3,10.4.4 LRU Page Replacement,519,10.4.3 Optimal Page Replacement,"10.4 Page Replacement 407
page framesreference string
77
07
0
12
0
12
0
32
4
32
0
37
0
12
0
17012030423 0 7 110 212 03
Figure 10.14 Optimal page-replacement algorithm.
page 0 will be used at 5, and page 1 at 14. The reference to page 3 replaces
page1,aspage1willbethelastofthethreepagesinmemorytobereferenced
again. With only nine page faults, optimal replacement is much better than
aFIFOalgorithm, which results in fifteen faults. (If we ignore the first three,
whichallalgorithmsmustsuffer,thenoptimalreplacementistwiceasgoodas
FIFOreplacement.)Infact,noreplacementalgorithmcanprocessthisreference
stringin threeframeswith fewerthan nine faults.
Unfortunately, the optimal page-replacement algorithm is difficult to
implement, because it requires future knowledge of the reference string.
(We encountered a similar situation with the SJF CPU-scheduling algorithm in
Section5.3.2.)Asaresult,theoptimalalgorithmisusedmainlyforcomparison
studies.Forinstance,itmaybeusefultoknowthat,althoughanewalgorithm
is not optimal, it is within 12.3 percent of optimal at worst and within 4.7
percenton average.
10.4.4 LRU Page Replacement
If the optimal algorithm is not feasible, perhaps an approximation of the opti-
malalgorithm is possible.The keydistinctionbetweenthe FIFOandOPTalgo-
rithms (other than looking backward versus forward in time) is that the FIFO
algorithm uses the time when a page was brought into memory, whereas the
OPTalgorithmusesthetimewhenapageistobe used.Ifweusetherecentpast
as an approximation of the near future, then we can replace the page that has
not been used forthelongestperiodoftime.Thisapproachisthe least recently
used ( LRU) algorithm .
LRUreplacementassociateswitheachpagethetimeofthatpage’slastuse.
W h e nap a g em u s tb er e p l a c e d , LRUchooses the page that has not been used
for the longest period of time. We can think of this strategy as the optimal
page-replacement algorithm looking b ackward in time, rather than forward.
(Strangely,ifwelet SRbethereverseofareferencestring S,thenthepage-fault
rate for the OPTalgorithm on Sis the same as the page-fault rate for the OPT
algorithmon SR.Similarly,thepage-faultrateforthe LRUalgorithmon Sisthe
same asthe page-faultrate forthe LRUalgorithmon SR.)
The result of applying LRUreplacementto our example reference string is
shown in Figure 10.15. The LRUalgorithm produces twelve faults. Notice that
the first five faults are the same as those for optimal replacement. When the
reference to page 4 occurs, however, LRUreplacement sees that, of the three
frames in memory, page 2 was used least recently. Thus, the LRUalgorithm
replacespage2,notknowingthatpage2isabouttobeused.Whenitthenfaults"
3,10.4.5 LRU-Approximation Page Replacement,521,10.4.4 LRU Page Replacement,"10.4 Page Replacement 409
2
1
0
47
stack
before
a7
2
1
40
stack
after
breference string
4707101212 2 7
ab1
Figure 10.16 Use of a stack to record the most recent page references.
+1f r a m e s .F o r LRUreplacement, the set of pages in memory would be the n
most recently referenced pages. If the number of frames is increased, these n
pageswillstillbe themost recentlyreferencedand sowill stillbe inmemory.
Note that neither implementation of LRUwould be conceivable without
hardware assistance beyond the standard TLBregisters. The updating of the
clock fields or stack must be done for everymemory reference. If we were
to use an interrupt for every reference to allow software to update such data
structures, it would slow every memory reference by a factor of at least ten,
henceslowingeveryprocessbyafactoroften.Fewsystemscouldtoleratethat
levelof overheadfor memorymanagement.
10.4.5 LRU-Approximation Page Replacement
Notmanycomputersystemsprovidesufficienthardwaresupportfortrue LRU
page replacement. In fact, some systems provide no hardware support, and
other page-replacement algorithms (such as a FIFOalgorithm) must be used.
Manysystemsprovidesomehelp,however,intheformofa reference bit .The
referencebitforapageissetbythehardwarewheneverthatpageisreferenced
(either a read or a write to any byte in the page). Reference bits are associated
with each entryin thepagetable.
Initially, all bits are cleared (to 0) by the operating system. As a process
executes, the bit associated with each page referenced is set (to 1) by the
hardware.Aftersometime,wecandeterminewhichpageshavebeenusedand
whichhavenotbeenusedbyexaminingthereferencebits,althoughwedonot
knowthe orderofuse.Thisinformationisthebasisformanypage-replacement
algorithmsthat approximate LRUreplacement.
10.4.5.1 Additional-Reference-Bits Algorithm
Wecangainadditionalorderinginformationbyrecordingthereferencebitsat
regularintervals.Wecankeepan8-bitbyteforeachpageinatableinmemory.
At regular intervals (say, every 100 milliseconds), a timer interrupt transfers
control to the operating system. The operating system shifts the reference bit
foreachpageintothehigh-orderbitofits8-bitbyte,shiftingtheotherbitsright"
3,10.4.6 Counting-Based Page Replacement,523,10.4.5 LRU-Approximation Page Replacement,"10.4 Page Replacement 411
circular queue of pages
(a)next
victim0reference
bitspages
0
1
1
0
1
1
……
circular queue of pages
(b)0reference
bitspages
0
0
0
0
1
1
……
Figure 10.17 Second-chance (clock) page-replacement algorithm.
4.(1,1)recentlyusedandmodified—probablywillbeusedagainsoon,and
thepagewillbeneedtobewrittenouttosecondarystoragebeforeitcan
be replaced
Each pageis inone of thesefour classes.When pagereplacementiscalled
for,weusethesameschemeasintheclockalgorithm;butinsteadofexamining
whether the page to which we are pointing has the reference bit set to 1,
we examine the class to which that page belongs. We replace the first page
encounteredinthelowestnonemptyclass.Noticethatwemayhavetoscanthe
circular queue several times before we find a page to be replaced. The major
differencebetweenthisalgorithmandth esimplerclockalgorithmisthathere
we give preference to those pages that have been modified in order to reduce
the number of I/Osrequired.
10.4.6 Counting-Based Page Replacement
There are many other algorithms that can be used for page replacement. For
example, we can keep a counter of the number of references that have been
madeto eachpageand developthe following two schemes.
•The least frequently used (LFU)page-replacementalgorithmrequiresthat
thepagewiththesmallestcountbereplaced.Thereasonforthisselectionis
thatanactivelyusedpageshouldhavealargereferencecount.Aproblem
arises, however, when a page is used heavily during the initial phase of"
3,10.4.7 Page-Buffering Algorithms,524,10.4.6 Counting-Based Page Replacement,"412 Chapter 10 Virtual Memory
a process but then is never used again. Since it was used heavily, it has
a largecount and remains inmemoryeventhough it is no longer needed.
Onesolutionistoshiftthecountsrightby1bitatregularintervals,forming
an exponentiallydecayingaverageusage count.
•The most frequently used (MFU) page-replacement algorithm is based
on the argument that the page with the smallest count was probably just
brought in and has yettobe used.
Asyoumightexpect,neither MFUnorLFUreplacementiscommon.Theimple-
mentation of these algorithms is expensive,and they do not approximate OPT
replacementwell.
10.4.7 Page-Buffering Algorithms
Other procedures are often used in addition to a specific page-replacement
algorithm. For example,systems commonly keep a pool of free frames. When
a page fault occurs, a victim frame is chosen as before. However, the desired
pageisreadintoafreeframefromthepoolbeforethevictimiswrittenout.This
procedureallowstheprocesstorestartassoonaspossible,withoutwaitingfor
thevictimpagetobewrittenout.Whenthevictimislaterwrittenout,itsframe
isaddedto thefree-framepool.
Anexpansionofthisideaistomaintainalistofmodifiedpages.Whenever
thepagingdeviceisidle,amodifiedpageisselectedandiswrittentosecondary
storage. Its modify bit is then reset.Th is scheme increases the probability that
apagewillbecleanwhenitisselectedforreplacementandwillnotneedtobe
writtenout.
Another modification is to keep a pool of free frames but to remember
whichpagewasineachframe.Sincetheframecontentsarenotmodifiedwhen
aframeiswrittentosecondarystorage,theoldpagecanbereuseddirectlyfrom
thefree-framepoolifitisneededbeforethatframeisreused.No I/Oisneeded
inthiscase.Whenapagefaultoccurs,wefirstcheckwhetherthedesiredpage
is in the free-frame pool. If it is not, we must select a free frame and read into
it.
Some versions of the UNIXsystem use this method in conjunction with
the second-chance algorithm. It can b e a useful augmentation to any page-
replacementalgorithm,toreducethepenaltyincurredifthewrongvictimpage
isselected.We describethese—and ot her—modifications inSection10.5.3.
10.4.8 Applications and Page Replacement
Incertaincases,applicationsaccessingdatathroughtheoperatingsystem’svir-
tual memory perform worse than if the operating system provided no buffer-
ing at all. A typical example is a database, which provides its own memory
management and I/Obuffering. Applications likethis understand their mem-
oryuseandstorageusebetterthandoesanoperatingsystemthatisimplement-
ing algorithms for general-purpose use. Furthermore, if the operating system
isbuffering I/Oandtheapplicationisdoingsoaswell,thentwicethememory
isbeing usedfora setof I/O.
Inanotherexample,datawarehousesfrequentlyperformmassivesequen-
tial storage reads, followed by computations and writes. The LRUalgorithm"
3,10.4.8 Applications and Page Replacement,524,10.4.7 Page-Buffering Algorithms,"412 Chapter 10 Virtual Memory
a process but then is never used again. Since it was used heavily, it has
a largecount and remains inmemoryeventhough it is no longer needed.
Onesolutionistoshiftthecountsrightby1bitatregularintervals,forming
an exponentiallydecayingaverageusage count.
•The most frequently used (MFU) page-replacement algorithm is based
on the argument that the page with the smallest count was probably just
brought in and has yettobe used.
Asyoumightexpect,neither MFUnorLFUreplacementiscommon.Theimple-
mentation of these algorithms is expensive,and they do not approximate OPT
replacementwell.
10.4.7 Page-Buffering Algorithms
Other procedures are often used in addition to a specific page-replacement
algorithm. For example,systems commonly keep a pool of free frames. When
a page fault occurs, a victim frame is chosen as before. However, the desired
pageisreadintoafreeframefromthepoolbeforethevictimiswrittenout.This
procedureallowstheprocesstorestartassoonaspossible,withoutwaitingfor
thevictimpagetobewrittenout.Whenthevictimislaterwrittenout,itsframe
isaddedto thefree-framepool.
Anexpansionofthisideaistomaintainalistofmodifiedpages.Whenever
thepagingdeviceisidle,amodifiedpageisselectedandiswrittentosecondary
storage. Its modify bit is then reset.Th is scheme increases the probability that
apagewillbecleanwhenitisselectedforreplacementandwillnotneedtobe
writtenout.
Another modification is to keep a pool of free frames but to remember
whichpagewasineachframe.Sincetheframecontentsarenotmodifiedwhen
aframeiswrittentosecondarystorage,theoldpagecanbereuseddirectlyfrom
thefree-framepoolifitisneededbeforethatframeisreused.No I/Oisneeded
inthiscase.Whenapagefaultoccurs,wefirstcheckwhetherthedesiredpage
is in the free-frame pool. If it is not, we must select a free frame and read into
it.
Some versions of the UNIXsystem use this method in conjunction with
the second-chance algorithm. It can b e a useful augmentation to any page-
replacementalgorithm,toreducethepenaltyincurredifthewrongvictimpage
isselected.We describethese—and ot her—modifications inSection10.5.3.
10.4.8 Applications and Page Replacement
Incertaincases,applicationsaccessingdatathroughtheoperatingsystem’svir-
tual memory perform worse than if the operating system provided no buffer-
ing at all. A typical example is a database, which provides its own memory
management and I/Obuffering. Applications likethis understand their mem-
oryuseandstorageusebetterthandoesanoperatingsystemthatisimplement-
ing algorithms for general-purpose use. Furthermore, if the operating system
isbuffering I/Oandtheapplicationisdoingsoaswell,thentwicethememory
isbeing usedfora setof I/O.
Inanotherexample,datawarehousesfrequentlyperformmassivesequen-
tial storage reads, followed by computations and writes. The LRUalgorithm"
2,10.5 Allocation of Frames,525,10.4 Page Replacement,"10.5 Allocation of Frames 413
would be removing old pages and preserving new ones, while the applica-
tionwould morelikelybereadingolderpagesthan newerones (asit startsits
sequentialreadsagain).Here, MFUwould actuallybe more efficientthan LRU.
Because of such problems, some operating systems give special programs
the ability to use a secondary storage partition as a large sequential array of
logical blocks, without any file-system data structures. This array is some-
times called the raw disk ,a n dI/Oto this array is termed raw I/O.R a wI/O
bypasses all the file-system services, such as file I/Odemand paging, file
locking, prefetching, space allocation , file names, and directories. Note that
althoughcertainapplicationsaremoree fficientwhenimplementingtheirown
special-purposestorageservicesonarawpartition,mostapplicationsperform
betterwhen theyusetheregularfile-systemservices.
10.5 Allocation of Frames
Weturnnexttotheissueofallocation.Howdoweallocatethefixedamountof
freememoryamong the variousprocesses?If wehave 93 freeframes and two
processes,how many frames doeseachprocessget?
Considerasimplecaseofasystemwith128frames.Theoperatingsystem
may take 35, leaving 93 frames for the user process. Under pure demand
paging,all93frameswouldinitiallybeputonthefree-framelist.Whenauser
processstartedexecution,itwouldgenerateasequenceofpagefaults.Thefirst
93 page faults would all get free frames from the free-frame list. When the
free-frame list was exhausted, a page-replacement algorithm would be used
to select one of the 93 in-memory pages to be replaced with the 94th, and so
on. When the process terminated, the 93 frames would once again be placed
onthefree-framelist.
There are many variations on this simple strategy. We can require that the
operatingsystemallocateallitsbufferandtablespacefromthefree-framelist.
Whenthisspaceisnotinusebytheoperatingsystem,itcanbeusedtosupport
userpaging.Wecantrytokeepthreefreeframesreservedonthefree-framelist
at all times. Thus, when a page fault occurs, there is a free frame available to
page into.While the page swap is takingp lace,a replacementcan be selected,
which is then written to the storage device as the user process continues to
execute. Other variants are also possible, but the basic strategy is clear: the
userprocessisallocatedany freeframe.
10.5.1 Minimum Number of Frames
Our strategies for the allocation of frames are constrained in various ways.
We cannot, for example, allocate more than the total number of available
frames(unlessthereispagesharing).Wemustalsoallocateatleastaminimum
number offrames.Here,welook morecloselyat thelatterrequirement.
One reason for allocating at least a minimum number of frames involves
performance. Obviously, as the number of frames allocated to each process
decreases, the page-fault rate increases, slowing process execution. In addi-
tion, remember that, when a page fault occurs before an executing instruction
is complete, the instruction must be restarted. Consequently, we must have
enough frames to hold all the different pages that any single instruction can
reference."
3,10.5.1 Minimum Number of Frames,525,10.5 Allocation of Frames,"10.5 Allocation of Frames 413
would be removing old pages and preserving new ones, while the applica-
tionwould morelikelybereadingolderpagesthan newerones (asit startsits
sequentialreadsagain).Here, MFUwould actuallybe more efficientthan LRU.
Because of such problems, some operating systems give special programs
the ability to use a secondary storage partition as a large sequential array of
logical blocks, without any file-system data structures. This array is some-
times called the raw disk ,a n dI/Oto this array is termed raw I/O.R a wI/O
bypasses all the file-system services, such as file I/Odemand paging, file
locking, prefetching, space allocation , file names, and directories. Note that
althoughcertainapplicationsaremoree fficientwhenimplementingtheirown
special-purposestorageservicesonarawpartition,mostapplicationsperform
betterwhen theyusetheregularfile-systemservices.
10.5 Allocation of Frames
Weturnnexttotheissueofallocation.Howdoweallocatethefixedamountof
freememoryamong the variousprocesses?If wehave 93 freeframes and two
processes,how many frames doeseachprocessget?
Considerasimplecaseofasystemwith128frames.Theoperatingsystem
may take 35, leaving 93 frames for the user process. Under pure demand
paging,all93frameswouldinitiallybeputonthefree-framelist.Whenauser
processstartedexecution,itwouldgenerateasequenceofpagefaults.Thefirst
93 page faults would all get free frames from the free-frame list. When the
free-frame list was exhausted, a page-replacement algorithm would be used
to select one of the 93 in-memory pages to be replaced with the 94th, and so
on. When the process terminated, the 93 frames would once again be placed
onthefree-framelist.
There are many variations on this simple strategy. We can require that the
operatingsystemallocateallitsbufferandtablespacefromthefree-framelist.
Whenthisspaceisnotinusebytheoperatingsystem,itcanbeusedtosupport
userpaging.Wecantrytokeepthreefreeframesreservedonthefree-framelist
at all times. Thus, when a page fault occurs, there is a free frame available to
page into.While the page swap is takingp lace,a replacementcan be selected,
which is then written to the storage device as the user process continues to
execute. Other variants are also possible, but the basic strategy is clear: the
userprocessisallocatedany freeframe.
10.5.1 Minimum Number of Frames
Our strategies for the allocation of frames are constrained in various ways.
We cannot, for example, allocate more than the total number of available
frames(unlessthereispagesharing).Wemustalsoallocateatleastaminimum
number offrames.Here,welook morecloselyat thelatterrequirement.
One reason for allocating at least a minimum number of frames involves
performance. Obviously, as the number of frames allocated to each process
decreases, the page-fault rate increases, slowing process execution. In addi-
tion, remember that, when a page fault occurs before an executing instruction
is complete, the instruction must be restarted. Consequently, we must have
enough frames to hold all the different pages that any single instruction can
reference."
3,10.5.2 Allocation Algorithms,526,10.5.1 Minimum Number of Frames,"414 Chapter 10 Virtual Memory
For example, consider a machine in which all memory-reference instruc-
tionsmayreferenceonlyonememoryaddress.Inthiscase,weneedatleastone
framefortheinstructionandoneframeforthememoryreference.Inaddition,
if one-level indirect addressing is allowed (for example,a loadinstruction on
frame 16 can refer to an address on frame 0, which is an indirect reference to
frame23),thenpagingrequiresatleastthreeframesperprocess.(Thinkabout
what mighthappen ifa processhad only two frames.)
The minimum number of frames is defined by the computer architecture.
For example, if the move instruction for a given architecture includes more
than one wordfor someaddressingmodes,theinstructionitselfmay straddle
twoframes.Inaddition,ifeachofitstwooperandsmaybeindirectreferences,
a total of six frames are required. As another example, the move instruction
for Intel 32- and 64-bit architectures allows data to move only from registerto
register and between registers and memory; it does not allow direct memory-
to-memory movement, thereby limiting the required minimum number of
framesfor a process.
Whereas the minimum number of frames per process is defined by the
architecture, the maximum number is defined by the amount of available
physical memory. In between, we are still left with significant choice in frame
allocation.
10.5.2 Allocation Algorithms
The easiest way to split mframes among nprocesses is to give everyone an
equalshare, m/nframes(ignoring framesneededby theoperating systemfor
themoment).Forinstance,ifthereare93framesand5processes,eachprocess
willget18frames.The3leftoverframescanbeusedasafree-framebufferpool.
This schemeiscalled equal allocation .
An alternative is to recognize that various processes will need differing
amounts of memory. Consider a system with a 1- KBframe size. If a small
student process of 10 KBand an interactive database of 127 KBare the only
twoprocessesrunninginasystemwith62freeframes,itdoesnotmakemuch
sense to giveeach process31 frames.The studentprocess doesnot needmore
than 10 frames,so theother 21 are,strictlyspeaking,wasted.
To solve this problem, we can use proportional allocation , in which we
allocate available memory to each process according to its size. Let the size of
thevirtualmemoryfor process pibesi, and define
S=∑si.
Then, if the total number of available frames is m,we allocate aiframes to
process pi,w h er e aiisapproximately
ai=si/S×m.
Of course, we must adjust each aito be an integer that is greater than the
minimum number of frames required by the instruction set, with a sum not
exceeding m.
With proportional allocation, we would split 62 frames between two pro-
cesses, one of 10 pages and one of 127 pages, by allocating 4 frames and 57
frames,respectively,since"
3,10.5.3 Global versus Local Allocation,527,10.5.2 Allocation Algorithms,"10.5 Allocation of Frames 415
10/137×62≈4a n d
127/137 ×62≈57.
In this way, both processes share the available frames according to their
“needs, ”ratherthanequally.
In both equal and proportional allocation, of course, the allocation may
varyaccordingtothemultiprogramminglevel.Ifthemultiprogramminglevel
isincreased,eachprocesswilllosesomeframestoprovidethememoryneeded
forthenewprocess.Conversely,ifthemultiprogrammingleveldecreases,the
frames that were allocated to the departed process can be spread over the
remainingprocesses.
Notice that, with either equal or proportional allocation, a high-priority
processistreatedthesameasalow-priorityprocess.Byitsdefinition,however,
we may want to give the high-priority process more memory to speed its
execution, to the detriment of low-priority processes. One solution is to use
a proportional allocation scheme wherein the ratio of frames depends not on
the relative sizes of processes but rather on the priorities of processes or on a
combination of size and priority.
10.5.3 Global versus Local Allocation
Another important factor in the way frames are allocated to the various pro-
cessesispager eplacement.W ithmulti pleprocessescompetingforframes,we
can classify page-replacement algorithms into two broad categories: global
replacement and local replacement . Global replacement allows a process to
select a replacement frame from the set of all frames, even if that frame is
currentlyallocatedtosomeotherprocess;thatis,oneprocesscantakeaframe
fromanother.Localreplacementrequiresthateachprocessselectfromonlyits
ownsetof allocatedframes.
For example, consider an allocation scheme wherein we allow high-
priorityprocessestoselectframesfromlow-priorityprocessesforreplacement.
Aprocess can select a replacement from among its own frames or the frames
of any lower-priority process. This approach allows a high-priority process to
increase its frame allocation at the expenseof a low-priority process. Whereas
with a local replacement strategy,the number of frames allocated to a process
does not change, with global replacement, a process may happen to select
onlyframesallocatedtootherprocesse s,thusincreasingthenumberofframes
allocated to it (assuming that other processes do not choose itsframes for
replacement).
One problem with a global replacement algorithm is that the set of pages
inmemoryforaprocessdependsnotonlyonthepagingbehaviorofthatpro-
cess, but also on the paging behavior of other processes. Therefore, the same
processmayperformquitedifferently(forexample,taking0.5secondsforone
execution and 4.3 seconds for the next execution) because of totally external
circumstances.Such is not the case with alocal replacementalgorithm.Under
local replacement, the set of pages in memory for a process is affected by the
paging behavior of only that process. Local replacement might hinder a pro-
cess,however,by not making availabletoit other,lessusedpagesof memory.
Thus, global replacement generally results in greater system throughput. It is
thereforethemorecommonly usedmethod."
3,10.5.4 Non-Uniform Memory Access,530,10.5.3 Global versus Local Allocation,"418 Chapter 10 Virtual Memory
stances, the reaper routine may begin to reclaim pages more aggressively.For
example, perhaps it will suspend the second-chance algorithm and use pure
FIFO. Another, more extreme, example occurs in Linux; when the amount of
free memory falls to verylow levels, a routine known as the out-of-memory
(OOM)killerselects a process to terminate, thereby freeing its memory. How
does Linux determine which process to terminate? Each process has what is
known as an OOMscore, with a higher score increasing the likelihood that the
process could be terminated by the OOMkiller routine. OOMscores are calcu-
lated according to the percentage of memory a process is using—the higher
the percentage, the higher the OOMscore. (OOMscores can be viewed in the
/procfile system, where the score for a process with pid2500 can be viewed
as/proc/2500/oom
 score.)
Ingeneral,notonlycanreaperroutinesvaryhowaggressivelytheyreclaim
memory, but the values of the minimum and maximum thresholds can be
varied as well. These values can be set to default values, but some systems
may allow a system administrator to configure them based on the amount of
physical memoryin thesystem.
10.5.4 Non-Uniform Memory Access
Thus far in our coverage of virtual memory, we have assumed that all main
memory is created equal—or at least that it is accessed equally. On non-
uniform memory access (NUMA) systems with multiple CPUs (Section 1.3.2),
that isnot thecase.Onthesesystems,a given CPUcan access some sectionsof
main memory faster than it can access others. These performance differences
arecausedbyhow CPUsandmemoryareinterconnectedinthesystem.Sucha
system is made up of multiple CPUs, each with its own local memory (Figure
10.19). The CPUs are organized using a shared system interconnect, and as
youmightexpect,a CPUcan accessitslocalmemoryfasterthan memorylocal
to another CPU.NUMAsystems are without exception slower than systems in
whichallaccessestomainmemoryaretreatedequally.However,asdescribed
in Section 1.3.2, NUMAsystems can accommodate more CPUs and therefore
achievegreaterlevelsofthroughput andparallelism.
CPU0memory0
CPU2CPU3CPU1memory1
memory2memory3interconnect
Figure 10.19 NUMA multiprocessing architecture."
2,10.6 Thrashing,531,10.5 Allocation of Frames,"10.6 Thrashing 419
Managing which page frames are stored at which locations can signifi-
cantly affect performance in NUMAsystems. If we treat memory as uniform
in such a system, CPUs may wait significantly longer for memory access than
if we modify memory allocation algorithms to take NUMAinto account. We
described some of these modifications in Section 5.5.4. Their goal is to have
memoryframesallocated “ascloseaspossible ”totheCPUonwhichtheprocess
isrunning.(Thedefinitionof closeis“withminimumlatency, ”whichtypically
means on the same system board as the CPU). Thus, when a process incurs a
page fault, a NUMA-aware virtual memory system will allocate that process a
frame asclose aspossible to the CPUon which the processisrunning.
To take NUMAinto account, the scheduler must track the last CPUon
which each process ran. If the scheduler tries to schedule each process onto
its previous CPU, and the virtual memory system tries to allocate frames for
the process close to the CPUon which it is being scheduled, then improved
cache hits and decreasedmemoryaccess timeswill result.
The picture is more complicated once threads are added. For example, a
processwithmanyrunningthreadsmayendupwiththosethreadsscheduled
onmanydifferentsystemboards.Howshouldthememorybeallocatedinthis
case?
As we discussed in Section 5.7.1, Linux manages this situation by having
thekernelidentifyahierarchyofschedulingdomains.TheLinux CFSscheduler
does not allow threads to migrate across different domains and thus incur
memory access penalties. Linux also has a separate free-frame list for each
NUMAnode,therebyensuringthatathreadwillbeallocatedmemoryfromthe
node on which it is running. Solaris solves the problem similarly by creating
lgroups (for “locality groups ”) in the kernel. Each lgroup gathers together
CPUs and memory, and each CPUin that group can access any memory in
the group within a defined latency inte r v a l .I na d d i t i o n ,t h e r ei sah i e r a r c h y
of lgroups based on the amount of latency between the groups, similar to the
hierarchyofschedulingdomains inLinux.Solaristriestoscheduleallthreads
of a process and allocate all memory of a process within an lgroup. If that is
not possible, it picks nearby lgroups for the rest of the resources needed. This
practiceminimizesoverallmemorylatencyandmaximizes CPUcachehitrates.
10.6 Thrashing
Consider what occurs if a process does not have “enough ”frames—that is, it
doesnothavetheminimumnumberofframesitneedstosupportpagesinthe
workingset.Theprocesswillquicklypag e-fault.Atthispoint,itmustreplace
somepage.However,sinceallitspagesareinactiveuse,itmustreplaceapage
thatwillbeneededagainrightaway.Con sequently,itquicklyfaultsagain,and
again, and again, replacingpagesthat itmustbring back inimmediately.
This high paging activity is called thrashing . A process is thrashing if it
isspendingmoretimepagingthan executing.Asyoumightexpect,thrashing
resultsinsevereperformanceproblems.
10.6.1 Cause of Thrashing
Considerthefollowingscenario,whichisbasedontheactualbehaviorofearly
pagingsystems.Theoperatingsystemmonitors CPUutilization.If CPUutiliza-"
3,10.6.1 Cause of Thrashing,531,10.6 Thrashing,"10.6 Thrashing 419
Managing which page frames are stored at which locations can signifi-
cantly affect performance in NUMAsystems. If we treat memory as uniform
in such a system, CPUs may wait significantly longer for memory access than
if we modify memory allocation algorithms to take NUMAinto account. We
described some of these modifications in Section 5.5.4. Their goal is to have
memoryframesallocated “ascloseaspossible ”totheCPUonwhichtheprocess
isrunning.(Thedefinitionof closeis“withminimumlatency, ”whichtypically
means on the same system board as the CPU). Thus, when a process incurs a
page fault, a NUMA-aware virtual memory system will allocate that process a
frame asclose aspossible to the CPUon which the processisrunning.
To take NUMAinto account, the scheduler must track the last CPUon
which each process ran. If the scheduler tries to schedule each process onto
its previous CPU, and the virtual memory system tries to allocate frames for
the process close to the CPUon which it is being scheduled, then improved
cache hits and decreasedmemoryaccess timeswill result.
The picture is more complicated once threads are added. For example, a
processwithmanyrunningthreadsmayendupwiththosethreadsscheduled
onmanydifferentsystemboards.Howshouldthememorybeallocatedinthis
case?
As we discussed in Section 5.7.1, Linux manages this situation by having
thekernelidentifyahierarchyofschedulingdomains.TheLinux CFSscheduler
does not allow threads to migrate across different domains and thus incur
memory access penalties. Linux also has a separate free-frame list for each
NUMAnode,therebyensuringthatathreadwillbeallocatedmemoryfromthe
node on which it is running. Solaris solves the problem similarly by creating
lgroups (for “locality groups ”) in the kernel. Each lgroup gathers together
CPUs and memory, and each CPUin that group can access any memory in
the group within a defined latency inte r v a l .I na d d i t i o n ,t h e r ei sah i e r a r c h y
of lgroups based on the amount of latency between the groups, similar to the
hierarchyofschedulingdomains inLinux.Solaristriestoscheduleallthreads
of a process and allocate all memory of a process within an lgroup. If that is
not possible, it picks nearby lgroups for the rest of the resources needed. This
practiceminimizesoverallmemorylatencyandmaximizes CPUcachehitrates.
10.6 Thrashing
Consider what occurs if a process does not have “enough ”frames—that is, it
doesnothavetheminimumnumberofframesitneedstosupportpagesinthe
workingset.Theprocesswillquicklypag e-fault.Atthispoint,itmustreplace
somepage.However,sinceallitspagesareinactiveuse,itmustreplaceapage
thatwillbeneededagainrightaway.Con sequently,itquicklyfaultsagain,and
again, and again, replacingpagesthat itmustbring back inimmediately.
This high paging activity is called thrashing . A process is thrashing if it
isspendingmoretimepagingthan executing.Asyoumightexpect,thrashing
resultsinsevereperformanceproblems.
10.6.1 Cause of Thrashing
Considerthefollowingscenario,whichisbasedontheactualbehaviorofearly
pagingsystems.Theoperatingsystemmonitors CPUutilization.If CPUutiliza-"
3,10.6.2 Working-Set Model,534,10.6.1 Cause of Thrashing,"422 Chapter 10 Virtual Memory
page reference table
. . . 2 6 1 5 7 7 7 7 5 1 6 2 3 4 1 2 3 4 4 4 3 4 3 4 4 4 1 3 2 3 4 4 4 3 4 4 4 . . . 
Δ
t1
WS( t1) = {1,2,5,6,7}Δ
t2
WS( t2) = {3,4}
Figure 10.22 Working-set model.
locality,memoryreferencesaremadetotheinstructionsofthefunctioncall,its
localvariables,andasubsetoftheglobalvariables.Whenweexitthefunction,
theprocessleavesthis locality,since the local variablesand instructions of the
function areno longerinactiveuse.Wemay returnto thislocalitylater.
Figure 10.21 illustrates the concept of locality and how a process’s
locality changes over time. At time ( a), the locality is the set of pages
{18,19,20,21,22,23,24,29,30,33}. At time ( b), the locality changes to
{18,19,20,24,25,26,27,28,29,31,32,33}. Notice the overlap, as some pages
(for example,18,19, and 20) are part ofboth localities.
Thus, we see that localities are defined by the program structure and its
data structures. The locality model states that all programs will exhibit this
basic memoryreferencestructure.Notethat thelocality modelisthe unstated
principle behind the caching discussion s so far in this book. If accesses to any
typesofdata wererandomrather thanpatterned,caching would beuseless.
Suppose we allocate enough frames to a process to accommodate its cur-
rent locality. It will fault for the pages in its locality until all these pages are
in memory; then, it will not fault again until it changes localities. If we do
not allocate enough frames to accommodate the size of the current locality,
the process will thrash, since it cannot keep in memory all the pages that it is
activelyusing.
10.6.2 Working-Set Model
The working-set model is based on the assumption of locality. This model
usesaparameter, Δ,todefinethe working-set window .Theideaistoexamine
the most recent Δpage references. The set of pages in the most recent Δpage
referencesisthe working set (Figure10.22).Ifapageisinactiveuse,itwillbein
theworkingset.Ifitisnolongerbeingused,itwilldropfromtheworkingset
Δtimeunits afterits lastreference.Thus,the working setis anapproximation
of the program’s locality.
For example, given the sequence of memory references shown in Figure
10.22, ifΔ= 10 memory references, then the working set at time t1is{1, 2, 5,
6, 7}.B yt i m e t2, the working sethas changed to {3, 4}.
The accuracy of the working set depends on the selection of Δ.I fΔis too
small,itwillnotencompasstheentirelocality;if Δistoolarge,itmayoverlap
several localities. In the extreme, if Δis infinite, the working set is the set of
pagestouched duringtheprocessexecution.
The most important property of the working set, then, is its size. If we
compute the working-set size, WSSi, for each process in the system, we can
thenconsiderthat"
3,10.6.3 Page-Fault Frequency,536,10.6.2 Working-Set Model,"424 Chapter 10 Virtual Memory
working-set window is a moving window. At each memory reference, a new
referenceappearsat one end,and the oldestreferencedropsoffthe other end.
A page is in the working set if it is referenced anywhere in the working-set
window.
We can approximate the working-set model with a fixed-interval timer
interrupt and a reference bit. For example, assume that Δequals 10,000 ref-
erences and that we can cause a timer interrupt every 5,000 references. When
we get a timer interrupt, we copy and clear the reference-bit values for each
page. Thus, if a page fault occurs, we can examine the current reference bit
andtwoin-memorybitstodeterminewhetherapagewasusedwithinthelast
10,000 to 15,000 references. If it was used, at least one of these bits will be on.
Ifithas notbeenused,thesebitswillbe off.Pages withatleastonebitonwill
be consideredtobe in theworking set.
Notethatthisarrangementisnot entirelyaccurate,because wecannot tell
where, within an interval of 5,000, a reference occurred. We can reduce the
uncertaintybyincreasingthenumberofhistorybitsandthefrequencyofinter-
rupts(forexample,10bitsandinterruptsevery1,000references).However,the
cost to servicethesemorefrequentinterruptswillbe correspondinglyhigher.
10.6.3 Page-Fault Frequency
The working-set model is successful, and knowledge of the working set can
be useful for prepaging (Section 10.9.1), but it seems a clumsy way to control
thrashing. A strategy that uses the page-fault frequency (PFF)t a k e sam o r e
directapproach.
The specific problem is how to prevent thrashing. Thrashing has a high
page-fault rate. Thus, we want to control the page-fault rate. When it is too
high, we know that the process needs more frames. Conversely, if the page-
fault rate is too low, then the process may have too many frames. We can
establishupperandlowerboundsonthede siredpage-faultrate(Figure10.23).
If the actual page-fault rate exceeds the upper limit, we allocate the process
number of framesincrease number
of frames
upper bound
lower bound
decrease number
of framespage-fault rate
Figure 10.23 Page-fault frequency."
3,10.6.4 Current Practice,537,10.6.3 Page-Fault Frequency,"10.7 Memory Compression 425
another frame. If the page-fault rate f alls below the lower limit, we remove a
frame from the process. Thus, we can directly measure and control the page-
faultrateto preventthrashing.
Aswiththeworking-setstrategy,wemayhavetoswapoutaprocess.Ifthe
page-faultrateincreasesandnofreeframesareavailable,wemustselectsome
processandswapitouttobackingstore.Thefreedframesarethendistributed
toprocesseswithhighpage-faultrates.
10.6.4 Current Practice
Practicallyspeaking,thrashingandtheresultingswappinghaveadisagreeably
high impact on performance. The current best practice in implementing a
computer system is to include enough physical memory, whenever possible,
to avoid thrashing and swapping. From smartphones through large servers,
providing enough memory to keep all working sets in memory concurrently,
exceptunderextremeconditions, providesthebest userexperience.
10.7 Memory Compression
An alternative to paging is memory compression . Here, rather than paging
out modified frames to swap space, we compress several frames into a single
frame, enabling the system to reduce memory usage without resorting to
swappingpages.
In Figure 10.24, the free-frame list contains six frames. Assume that this
numberoffreeframesfallsbelowacertainthresholdthattriggerspagereplace-
ment.Thereplacementalgorithm(say,an LRUapproximationalgorithm)selects
four frames—15, 3, 35, and 26—to place on the free-frame list. It first places
theseframesonamodified-framelist.Typically,themodified-framelistwould
next be written to swap space, making t he frames available to the free-frame
list. An alternative strategy is to compress a number of frames—say, three—
andstoretheircompressedversionsinasinglepageframe.
In Figure 10.25, frame 7 is removed from the free-frame list. Frames 15,
3, and 35 are compressed and stored in frame 7, which is then stored in the
list of compressed frames. The frames 15, 3, and 35 can now be moved to the
free-framelist.Ifoneofthethreecompressedframesislaterreferenced,apage
fault occurs, and the compressed frame is decompressed, restoring the three
pages15,3,and 35 in memory.
head 7
head 33 5 26 152 92 1 27free-frame list
modified frame list16
Figure 10.24 Free-frame list before compression."
2,10.7 Memory Compression,537,10.6 Thrashing,"10.7 Memory Compression 425
another frame. If the page-fault rate f alls below the lower limit, we remove a
frame from the process. Thus, we can directly measure and control the page-
faultrateto preventthrashing.
Aswiththeworking-setstrategy,wemayhavetoswapoutaprocess.Ifthe
page-faultrateincreasesandnofreeframesareavailable,wemustselectsome
processandswapitouttobackingstore.Thefreedframesarethendistributed
toprocesseswithhighpage-faultrates.
10.6.4 Current Practice
Practicallyspeaking,thrashingandtheresultingswappinghaveadisagreeably
high impact on performance. The current best practice in implementing a
computer system is to include enough physical memory, whenever possible,
to avoid thrashing and swapping. From smartphones through large servers,
providing enough memory to keep all working sets in memory concurrently,
exceptunderextremeconditions, providesthebest userexperience.
10.7 Memory Compression
An alternative to paging is memory compression . Here, rather than paging
out modified frames to swap space, we compress several frames into a single
frame, enabling the system to reduce memory usage without resorting to
swappingpages.
In Figure 10.24, the free-frame list contains six frames. Assume that this
numberoffreeframesfallsbelowacertainthresholdthattriggerspagereplace-
ment.Thereplacementalgorithm(say,an LRUapproximationalgorithm)selects
four frames—15, 3, 35, and 26—to place on the free-frame list. It first places
theseframesonamodified-framelist.Typically,themodified-framelistwould
next be written to swap space, making t he frames available to the free-frame
list. An alternative strategy is to compress a number of frames—say, three—
andstoretheircompressedversionsinasinglepageframe.
In Figure 10.25, frame 7 is removed from the free-frame list. Frames 15,
3, and 35 are compressed and stored in frame 7, which is then stored in the
list of compressed frames. The frames 15, 3, and 35 can now be moved to the
free-framelist.Ifoneofthethreecompressedframesislaterreferenced,apage
fault occurs, and the compressed frame is decompressed, restoring the three
pages15,3,and 35 in memory.
head 7
head 33 5 26 152 92 1 27free-frame list
modified frame list16
Figure 10.24 Free-frame list before compression."
2,10.8 Allocating Kernel Memory,538,10.7 Memory Compression,"426 Chapter 10 Virtual Memory
3
735 head 21 6 15 9 21 27
head 26free-frame list
modified frame list
headcompressed frame list
Figure 10.25 Free-frame list after compression
As we have noted, mobile systems generally do not support either stan-
dard swapping or swapping pages. Thus, memory compression is an integral
partof the memory-managementstrategyfor most mobileoperatingsystems,
includingAndroidandi OS.Inaddition,bothWindows10andmac OSsupport
memory compression. For Windows 10, Microsoft developed the Universal
Windows Platform (UWP) architecture, which provides a common app plat-
form for devices that run Windows 10, including mobile devices. UWPapps
running on mobile devices are candidates for memory compression. mac OS
first supported memory compression with Version 10.9 of the operating sys-
tem,first compressing LRUpages when free memoryis short and then paging
ifthatdoesn’tsolvetheproblem.Performancetestsindicatethatmemorycom-
pression is faster than paging even to SSDsecondary storage on laptop and
desktopmac OSsystems.
Although memory compression does require allocating free frames to
hold the compressed pages, a significant memory saving can be realized,
depending on the reductions achieved by the compression algorithm. (In the
example above, the three frames were reduced to one-third of their original
size.) As with any form of data compression, there is contention between the
speed of the compression algorithm and the amount of reduction that can be
achieved (known as the compression ratio ). In general, higher compression
ratios (greater reductions) can be achieved by slower, more computationally
expensivealgorithms.Mostalgorithmsinusetodaybalancethesetwofactors,
achievingrelativelyhighcompressionratiosusingfastalgorithms.Inaddition,
compressionalgorithmshaveimprovedbytakingadvantageofmultiplecom-
putingcoresandperformingcompressioninparallel.Forexample,Microsoft’s
Xpress and Apple’s WKdm compression algorithms are considered fast, and
theyreportcompressingpagesto 30 to50 percentof theiroriginalsize.
10.8 Allocating Kernel Memory
When a process running in user mode requests additional memory, pages are
allocated from the list of free page frames maintained by the kernel. This list
is typically populated using a page-replacement algorithm such as those dis-
cussedinSection10.4andmostlikelycontainsfreepagesscatteredthroughout
physical memory, as explained earlier. Remember, too, that if a user process
requests a single byte of memory, internal fragmentation will result, as the
processwillbe grantedanentirepageframe."
3,10.8.1 Buddy System,539,10.8 Allocating Kernel Memory,"10.8 Allocating Kernel Memory 427
Kernel memory is often allocated from a free-memory pool different from
the list used to satisfy ordinary user-mode processes. There are two primary
reasonsfor this:
1.Thekernelrequestsmemoryfordatastructuresofvaryingsizes,someof
whicharelessthanapageinsize.Asaresult,thekernelmustusememory
conservativelyandattempttominimizewasteduetofragmentation.This
is especially important because many operating systems do not subject
kernelcode ordata tothe pagingsystem.
2.Pages allocated to user-mode processes do not necessarily have to be in
contiguousphysicalmemory.However,certainhardwaredevicesinteract
directlywithphysicalmemory—withoutthebenefitofavirtualmemory
interface—andconsequentlymayre quirememoryresidinginphysically
contiguous pages.
Inthefollowingsections,weexaminetwostrategiesformanagingfreememory
thatis assignedtokernelprocesses:the “buddy system ”and slaballocation.
10.8.1 Buddy System
The buddy system allocates memory from a fixed-size segment consisting of
physically contiguous pages. Memory is allocated from this segment using a
power-of-2 allocator , which satisfies requests in units sized as a power of 2
(4KB,8KB,1 6KB, and so forth). Arequest in units not appropriately sized is
rounded up to the next highest power of 2. For example,a requestfor 11 KBis
satisfiedwitha 16- KBsegment.
Let’s consider a simple example. Assume the size of a memory segment
is initially 256 KBand the kernel requests 21 KBof memory. The segment is
initially divided into two buddies —which we will call ALandAR—each 128
KBinsize.Oneofthesebuddiesisfurtherdividedintotwo64- KBbuddies— BL
andBR.However,thenext-highestpowerof2from21 KBis32KBsoeither BL
orBRisagaindividedintotwo32- KBbuddies, CLandCR.Oneofthesebuddies
is used to satisfy the 21- KBrequest. This scheme is illustrated in Figure 10.26,
where CListhe segmentallocated to the 21- KBrequest.
Anadvantageofthebuddysystemishowquicklyadjacentbuddiescanbe
combined to form larger segments using a technique known as coalescing .I n
Figure10.26,forexample,whenthekernelreleasesthe CLunititwasallocated,
thesystemcancoalesce CLandCRintoa64- KBsegment.Thissegment, BL,can
in turn be coalesced with its buddy BRto form a 128- KBsegment. Ultimately,
we can end upwith the original256- KBsegment.
Theobviousdrawbacktothebuddysystemisthatroundinguptothenext
highest power of 2 is very likely to cause fragmentation within allocated seg-
ments.Forexample,a33- KBrequestcanonlybesatisfiedwitha64- KBsegment.
Infact,wecannot guaranteethatlessthan 50percentoftheallocatedunitwill
be wasted due to internal fragmentation. In the following section, we explore
amemoryallocation schemewhereno space islostdueto fragmentation.
10.8.2 Slab Allocation
Asecondstrategyforallocatingkernelmemoryisknownas slab allocation .A
slabis made up of one or more physically contiguous pages.A cacheconsists"
3,10.8.2 Slab Allocation,539,10.8.1 Buddy System,"10.8 Allocating Kernel Memory 427
Kernel memory is often allocated from a free-memory pool different from
the list used to satisfy ordinary user-mode processes. There are two primary
reasonsfor this:
1.Thekernelrequestsmemoryfordatastructuresofvaryingsizes,someof
whicharelessthanapageinsize.Asaresult,thekernelmustusememory
conservativelyandattempttominimizewasteduetofragmentation.This
is especially important because many operating systems do not subject
kernelcode ordata tothe pagingsystem.
2.Pages allocated to user-mode processes do not necessarily have to be in
contiguousphysicalmemory.However,certainhardwaredevicesinteract
directlywithphysicalmemory—withoutthebenefitofavirtualmemory
interface—andconsequentlymayre quirememoryresidinginphysically
contiguous pages.
Inthefollowingsections,weexaminetwostrategiesformanagingfreememory
thatis assignedtokernelprocesses:the “buddy system ”and slaballocation.
10.8.1 Buddy System
The buddy system allocates memory from a fixed-size segment consisting of
physically contiguous pages. Memory is allocated from this segment using a
power-of-2 allocator , which satisfies requests in units sized as a power of 2
(4KB,8KB,1 6KB, and so forth). Arequest in units not appropriately sized is
rounded up to the next highest power of 2. For example,a requestfor 11 KBis
satisfiedwitha 16- KBsegment.
Let’s consider a simple example. Assume the size of a memory segment
is initially 256 KBand the kernel requests 21 KBof memory. The segment is
initially divided into two buddies —which we will call ALandAR—each 128
KBinsize.Oneofthesebuddiesisfurtherdividedintotwo64- KBbuddies— BL
andBR.However,thenext-highestpowerof2from21 KBis32KBsoeither BL
orBRisagaindividedintotwo32- KBbuddies, CLandCR.Oneofthesebuddies
is used to satisfy the 21- KBrequest. This scheme is illustrated in Figure 10.26,
where CListhe segmentallocated to the 21- KBrequest.
Anadvantageofthebuddysystemishowquicklyadjacentbuddiescanbe
combined to form larger segments using a technique known as coalescing .I n
Figure10.26,forexample,whenthekernelreleasesthe CLunititwasallocated,
thesystemcancoalesce CLandCRintoa64- KBsegment.Thissegment, BL,can
in turn be coalesced with its buddy BRto form a 128- KBsegment. Ultimately,
we can end upwith the original256- KBsegment.
Theobviousdrawbacktothebuddysystemisthatroundinguptothenext
highest power of 2 is very likely to cause fragmentation within allocated seg-
ments.Forexample,a33- KBrequestcanonlybesatisfiedwitha64- KBsegment.
Infact,wecannot guaranteethatlessthan 50percentoftheallocatedunitwill
be wasted due to internal fragmentation. In the following section, we explore
amemoryallocation schemewhereno space islostdueto fragmentation.
10.8.2 Slab Allocation
Asecondstrategyforallocatingkernelmemoryisknownas slab allocation .A
slabis made up of one or more physically contiguous pages.A cacheconsists"
2,10.9 Other Considerations,542,10.8 Allocating Kernel Memory,"430 Chapter 10 Virtual Memory
referstoitsslabimplementationas SLAB.RecentdistributionsofLinuxinclude
two other kernelmemoryallocators—the SLOBandSLUBallocators.
TheSLOBallocatorisdesignedforsystemswithalimitedamountofmem-
ory,suchasembeddedsystems. SLOB(whichstandsfor “simplelistofblocks ”)
maintains three lists of objects: small(for objects less than 256 bytes), medium
(for objects less than 1,024 bytes), and large(for all other objects less than the
sizeofapage).Memoryrequestsareallocatedfromanobjectontheappropri-
atelistusing a first-fit policy.
Beginning with Version 2.6.24, the SLUBallocator replaced SLABas the
default allocator for the Linux kernel. SLUBreduced much of the overhead
requiredbythe SLABallocator.Forinstance,whereas SLABstorescertainmeta-
data with each slab, SLUBstores these data in the pagestructure the Linux
kernel uses for each page. Additionally, SLUBdoes not include the per- CPU
queuesthatthe SLABallocatormaintainsforobjectsineachcache.Forsystems
with a large number of processors, the amount of memory allocated to these
queues is significant. Thus, SLUBprovides better performance as the number
of processorsona systemincreases.
10.9 Other Considerations
The major decisions that we make for a paging system are the selections of
a replacement algorithm and an allocation policy, which we discussed earlier
in this chapter. There are many other considerations as well, and we discuss
severalof themhere.
10.9.1 Prepaging
Anobviouspropertyofpuredemandpagingisthelargenumberofpagefaults
that occur when a process is started. This situation results from trying to get
the initial locality into memory. Prepaging is an attempt to prevent this high
levelofinitialpaging.Thestrategyistobringsome—orall—ofthepagesthat
willbe neededinto memoryat one time.
Inasystemusingtheworking-setmodel,forexample,wecouldkeepwith
eachprocessalistofthepagesinitsworkingset.Ifwemustsuspendaprocess
(due to a lack of free frames), we remember the working set for that process.
When the process is to be resumed (because I/Ohas finished or enough free
frames have become available), we automatically bring back into memory its
entire working set before restarting the process.
Prepaging may offer an advantage in some cases. The question is simply
whether the cost of using prepaging is less than the cost of servicing the
corresponding page faults. It may well be the case that many of the pages
brought back into memoryby prepagingwillnot be used.
Assume that spages are prepaged and a fraction αof these spages is
actually used (0 ≤α≤1). The question is whether the cost of the s*αsaved
page faults is greater or less than the cost of prepaging s*(1−α) unnecessary
pages.If αisclose to0, prepagingloses;if αisclose to 1,prepagingwins.
Note also that prepaging an executable program may be difficult, as it
may be unclear exactly what pages should be brought in. Prepaging a file
maybemorepredictable,sincefilesareoftenaccessedsequentially.TheLinux"
3,10.9.1 Prepaging,542,10.9 Other Considerations,"430 Chapter 10 Virtual Memory
referstoitsslabimplementationas SLAB.RecentdistributionsofLinuxinclude
two other kernelmemoryallocators—the SLOBandSLUBallocators.
TheSLOBallocatorisdesignedforsystemswithalimitedamountofmem-
ory,suchasembeddedsystems. SLOB(whichstandsfor “simplelistofblocks ”)
maintains three lists of objects: small(for objects less than 256 bytes), medium
(for objects less than 1,024 bytes), and large(for all other objects less than the
sizeofapage).Memoryrequestsareallocatedfromanobjectontheappropri-
atelistusing a first-fit policy.
Beginning with Version 2.6.24, the SLUBallocator replaced SLABas the
default allocator for the Linux kernel. SLUBreduced much of the overhead
requiredbythe SLABallocator.Forinstance,whereas SLABstorescertainmeta-
data with each slab, SLUBstores these data in the pagestructure the Linux
kernel uses for each page. Additionally, SLUBdoes not include the per- CPU
queuesthatthe SLABallocatormaintainsforobjectsineachcache.Forsystems
with a large number of processors, the amount of memory allocated to these
queues is significant. Thus, SLUBprovides better performance as the number
of processorsona systemincreases.
10.9 Other Considerations
The major decisions that we make for a paging system are the selections of
a replacement algorithm and an allocation policy, which we discussed earlier
in this chapter. There are many other considerations as well, and we discuss
severalof themhere.
10.9.1 Prepaging
Anobviouspropertyofpuredemandpagingisthelargenumberofpagefaults
that occur when a process is started. This situation results from trying to get
the initial locality into memory. Prepaging is an attempt to prevent this high
levelofinitialpaging.Thestrategyistobringsome—orall—ofthepagesthat
willbe neededinto memoryat one time.
Inasystemusingtheworking-setmodel,forexample,wecouldkeepwith
eachprocessalistofthepagesinitsworkingset.Ifwemustsuspendaprocess
(due to a lack of free frames), we remember the working set for that process.
When the process is to be resumed (because I/Ohas finished or enough free
frames have become available), we automatically bring back into memory its
entire working set before restarting the process.
Prepaging may offer an advantage in some cases. The question is simply
whether the cost of using prepaging is less than the cost of servicing the
corresponding page faults. It may well be the case that many of the pages
brought back into memoryby prepagingwillnot be used.
Assume that spages are prepaged and a fraction αof these spages is
actually used (0 ≤α≤1). The question is whether the cost of the s*αsaved
page faults is greater or less than the cost of prepaging s*(1−α) unnecessary
pages.If αisclose to0, prepagingloses;if αisclose to 1,prepagingwins.
Note also that prepaging an executable program may be difficult, as it
may be unclear exactly what pages should be brought in. Prepaging a file
maybemorepredictable,sincefilesareoftenaccessedsequentially.TheLinux"
3,10.9.2 Page Size,543,10.9.1 Prepaging,"10.9 Other Considerations 431
readahead() systemcall prefetchesthe contents of a file into memoryso that
subsequentaccessesto thefilewill takeplacein main memory.
10.9.2 Page Size
The designers of an operating system for an existing machine seldom have
a choice concerning the page size. However, when new machines are being
designed,adecisionregardingthebestpagesizemustbemade.Asyoumight
expect, there is no single best page size. Rather, there is a set of factors that
supportvarioussizes.Pagesizesareinvariablypowersof2,generallyranging
from4,096 (212)to 4,194,304 (222)b y t es .
Howdoweselectapagesize?Oneconcernisthesizeofthepagetable.For
a given virtual memory space, decreasing the page size increases the number
ofpagesandhencethesizeofthepagetable.Foravirtualmemoryof4 MB(222),
for example, there would be 4,096 page s of 1,024 bytes but only 512 pages of
8,192 bytes. Because each active process must have its own copy of the page
table,a largepagesizeisdesirable.
Memory is better utilized with smaller pages, however. If a process is
allocatedmemorystartingatlocation00000andcontinuinguntilithasasmuch
as it needs, it probably will not end exactly on a page boundary. Thus, a part
of the final page must be allocated (because pages are the units of allocation)
butwillbeunused(creatinginternalfragmentation).Assumingindependence
of process size and page size, we can expect that, on the average, half of the
finalpageofeachprocesswillbewasted.Thislossisonly256bytesforapage
of 512 bytes but is 4,096 bytes for a page o f 8,192 bytes. To minimize internal
fragmentation,then,we needasmallpagesize.
Another problem is the time required to read or write a page. As you will
seeinSection11.1,whenthestoragedeviceisan HDD,I/Otimeiscomposedof
seek, latency, and transfer times. Transfer time is proportional to the amount
transferred(thatis,thepagesize)—afactthatwouldseemtoargueforasmall
page size. However, latency and seek time normally dwarf transfer time. At
at r a n s f e rr a t eo f5 0 MBper second, it takes only 0.01 milliseconds to transfer
512 bytes. Latency time, though, is perhaps 3 milliseconds, and seek time 5
milliseconds.Ofthetotal I/Otime(8.01milliseconds),therefore,onlyabout0.1
percent is attributable to the actual tra nsfer. Doubling the page size increases
I/Otime to only 8.02 milliseconds. It takes 8.02 milliseconds to read a single
page of 1,024 bytes but 16.02 milliseconds to read the same amount as two
pagesof512byteseach.Thus,adesiretominimize I/Otimearguesforalarger
pagesize.
Withasmallerpagesize,though,total I/Oshouldbereduced,sincelocality
will be improved. A smaller page size allows each page to match program
locality more accurately. For example, consider a process 200 KBin size, of
which only half (100 KB) is actually used in an execution. If we have only
one large page, we must bring in the entire page, a total of 200 KBtransferred
and allocated. If instead we had pages of only 1 byte, then we could bring in
onlythe100 KBthatareactuallyused,resultinginonly100 KBtransferredand
allocated. With a smaller page size, then, we have better resolution , allowing
us to isolate only the memory that is actually needed.With a larger page size,
we must allocate and transfer not only what is needed but also anything else"
3,10.9.3 TLB Reach,544,10.9.2 Page Size,"432 Chapter 10 Virtual Memory
that happens to be in the page, whether it is needed or not. Thus, a smaller
pagesizeshould resultinless I/Oand lesstotalallocatedmemory.
But did you notice that with a page size of 1 byte, we would have a page
fault for eachbyte? A process of 200 KBthat used only half of that memory
wouldgenerateonlyonepagefaultwithapagesizeof200 KBbut102,400page
faults with a page size of 1 byte. Each page fault generates the large amount
of overhead needed for processing the interrupt, saving registers, replacing
a page, queuing for the paging device, and updating tables. To minimize the
number of pagefaults,weneedto havea largepagesize.
Otherfactorsmustbeconsideredaswell(suchastherelationshipbetween
page size and sector size on the paging device). The problem has no best
answer.Aswehaveseen,somefactors(internalfragmentation,locality)argue
for a small page size, whereas others (table size, I/Otime) argue for a large
page size. Nevertheless, the historical trend is toward larger page sizes, even
formobilesystems.Indeed,thefirsteditionof Operating System Concepts (1983)
used4,096bytesastheupperboundonpagesizes,andthisvaluewasthemost
common page size in 1990. Modern systems may now use much larger page
sizes,asyou willseein thefollowing section.
10.9.3 TLB Reach
I nC h a p t e r9 ,w ei n t r o d u c e dt h e hit ratio of theTLB. Recall that the hit ratio
for the TLBrefers to the percentage of virtual address translations that are
resolved in the TLBrather than the page table. Clearly, the hit ratio is related
to the number of entries in the TLB, and the way to increase the hit ratio is
by increasing the number of entries.This, however,does not come cheaply, as
theassociativememoryusedtoconstructthe TLBisbothexpensiveandpower
hungry.
Related to the hit ratio is a similar metric: the TLB reach.T h eTLBreach
refers to the amount of memory accessible from the TLBand is simply the
number of entries multiplied by the page size. Ideally, the working set for a
process is stored in the TLB. If it is not, the process will spend a considerable
amount of time resolving memory references in the page table rather than
theTLB. If we double the number of entries in the TLB,w ed o u b l et h e TLB
reach.However,forsome memory-intensiveapplications,this maystillprove
insufficient for storing the working set.
Anotherapproachforincreasingthe TLBreachistoeitherincreasethesize
of the page or provide multiple page sizes. If we increase the page size—say,
from4KBto16KB—wequadruplethe TLBreach.However,thismayleadtoan
increaseinfragmentationforsomeapplicationsthatdonotrequiresuchalarge
pagesize.Alternatively,mostarchitecturesprovidesupportformorethanone
pagesize,andanoperatingsystemcanbeconfiguredtotakeadvantageofthis
support.Forexample,thedefaultpagesizeonLinuxsystemsis4 KB;however,
Linuxalsoprovides huge pages ,afeaturethatdesignatesa regionofphysical
memorywherelargerpages(forexample,2 MB)m a yb eu s ed.
Recall from Section 9.7 that the ARMv8 architecture provides support for
pagesandregionsofdifferentsizes.Additionally,each TLBentryinthe ARMv8
contains a contiguous bit . If this bit is set for a particular TLBentry, that entry
mapscontiguous(adjacent)blocksofmemory.Threepossiblearrangementsof"
3,10.9.4 Inverted Page Tables,545,10.9.3 TLB Reach,"10.9 Other Considerations 433
contiguous blocks can be mappedin a single TLBentry,thereby increasingthe
TLBreach:
1.64-KB TLBentry comprising16 ×4KBadjacent blocks.
2.1-GB TLBentrycomprising 32 ×32MBadjacentblocks.
3.2-MB TLBentry comprising either 32 ×64KBadjacent blocks, or 128 ×16
KBadjacent blocks.
Providing support for multiple page sizes may require the operating sys-
tem—ratherthanhardware—tomanagethe TLB.Forexample,oneofthefields
in aTLBentry must indicate the size of the page frame corresponding to the
entry—or, inthe case of ARMarchitectures,mustindicatethatthe entryrefers
toacontiguousblockofmemory.Managingthe TLBin software and not hard-
warecomesatacostinperformance.However,theincreasedhitratioand TLB
reachoffsetthe performance costs.
10.9.4 Inverted Page Tables
Section 9.4.3 introduced the concept of the inverted page table. The purpose
ofthisformofpagemanagementistoreducetheamountofphysicalmemory
needed to track virtual-to-physical address translations. We accomplish this
savings by creating a table that has one entry per page of physical memory,
indexedby the pair <process-id,page-number >.
Becausetheykeepinformationaboutwhichvirtualmemorypageisstored
in each physical frame, inverted page tables reduce the amount of physical
memory needed to store this information. However, the inverted page table
no longer contains complete information about the logical address space of a
process,andthatinformationisrequiredifareferencedpageisnotcurrentlyin
memory.Demandpagingrequiresthisinformation toprocesspagefaults.For
the information to be available, an external page table (one per process) must
be kept. Each such table looks like the traditional per-process page table and
contains information on where each virtualpage islocated.
Butdoexternalpagetablesnegatetheutilityofinvertedpagetables?Since
these tables are referencedonly when a page fault occurs, they do not need to
beavailablequickly.Instead,theyarethemselvespagedinandoutofmemory
as necessary. Unfortunately, a page fault may now cause the virtual memory
managertogenerateanotherpagefaultasitpagesintheexternalpagetableit
needstolocatethevirtualpageonthebackingstore.Thisspecialcaserequires
carefulhandling in thekerneland adelayin thepage-lookupprocessing.
10.9.5 Program Structure
Demand paging is designed to be transparent to the user program. In many
cases,theuseriscompletelyunawareofthepagednatureofmemory.Inother
cases,however,systemperformancecanbeimprovediftheuser(orcompiler)
has an awarenessof the underlyingdemandpaging.
Let’s look at a contrived but informative example. Assume that pages are
128 words in size. Consider a C program whose function is to initialize to 0
each elementof a128-by-128 array.The following codeistypical:"
3,10.9.5 Program Structure,545,10.9.4 Inverted Page Tables,"10.9 Other Considerations 433
contiguous blocks can be mappedin a single TLBentry,thereby increasingthe
TLBreach:
1.64-KB TLBentry comprising16 ×4KBadjacent blocks.
2.1-GB TLBentrycomprising 32 ×32MBadjacentblocks.
3.2-MB TLBentry comprising either 32 ×64KBadjacent blocks, or 128 ×16
KBadjacent blocks.
Providing support for multiple page sizes may require the operating sys-
tem—ratherthanhardware—tomanagethe TLB.Forexample,oneofthefields
in aTLBentry must indicate the size of the page frame corresponding to the
entry—or, inthe case of ARMarchitectures,mustindicatethatthe entryrefers
toacontiguousblockofmemory.Managingthe TLBin software and not hard-
warecomesatacostinperformance.However,theincreasedhitratioand TLB
reachoffsetthe performance costs.
10.9.4 Inverted Page Tables
Section 9.4.3 introduced the concept of the inverted page table. The purpose
ofthisformofpagemanagementistoreducetheamountofphysicalmemory
needed to track virtual-to-physical address translations. We accomplish this
savings by creating a table that has one entry per page of physical memory,
indexedby the pair <process-id,page-number >.
Becausetheykeepinformationaboutwhichvirtualmemorypageisstored
in each physical frame, inverted page tables reduce the amount of physical
memory needed to store this information. However, the inverted page table
no longer contains complete information about the logical address space of a
process,andthatinformationisrequiredifareferencedpageisnotcurrentlyin
memory.Demandpagingrequiresthisinformation toprocesspagefaults.For
the information to be available, an external page table (one per process) must
be kept. Each such table looks like the traditional per-process page table and
contains information on where each virtualpage islocated.
Butdoexternalpagetablesnegatetheutilityofinvertedpagetables?Since
these tables are referencedonly when a page fault occurs, they do not need to
beavailablequickly.Instead,theyarethemselvespagedinandoutofmemory
as necessary. Unfortunately, a page fault may now cause the virtual memory
managertogenerateanotherpagefaultasitpagesintheexternalpagetableit
needstolocatethevirtualpageonthebackingstore.Thisspecialcaserequires
carefulhandling in thekerneland adelayin thepage-lookupprocessing.
10.9.5 Program Structure
Demand paging is designed to be transparent to the user program. In many
cases,theuseriscompletelyunawareofthepagednatureofmemory.Inother
cases,however,systemperformancecanbeimprovediftheuser(orcompiler)
has an awarenessof the underlyingdemandpaging.
Let’s look at a contrived but informative example. Assume that pages are
128 words in size. Consider a C program whose function is to initialize to 0
each elementof a128-by-128 array.The following codeistypical:"
3,10.9.6 I/O Interlock and Page Locking,546,10.9.5 Program Structure,"434 Chapter 10 Virtual Memory
int i, j;
int[128][128] data;
for (j = 0; j < 128; j++)
for (i = 0; i < 128; i++)
data[i][j] = 0;
Notice that the array is stored row major; that is, the array is stored
data[0][0] ,data[0][1] ,···,data[0][127] ,data[1][0] ,data[1][1] ,···,
data[127][127] .For pages of 128 words, each row takes one page. Thus, the
precedingcodezerosonewordineachpage,thenanother wordineachpage,
andsoon.Iftheoperatingsystemallocatesfewerthan128framestotheentire
program,thenitsexecutionwillresultin128 ×128 =16,384 page faults.
In contrast, supposewe change the code to
int i, j;
int[128][128] data;
for (i = 0; i < 128; i++)
for (j = 0; j < 128; j++)
data[i][j] = 0;
This code zeros all the words on one page before starting the next page,
reducingthe numberof page faults to128.
Careful selection of data structures and programming structures can
increase locality and hence lower the page-fault rate and the number of
pages in the working set. For example, a stack has good locality, since access
is always made to the top. A hash table, in contrast, is designed to scatter
references, producing bad locality. Of course, locality of reference is just one
measureoftheefficiencyoftheuseofadatastructure.Otherheavilyweighted
factors include search speed, total number of memory references, and total
number of pagestouched.
At a later stage, the compiler and loader can have a significant effect on
paging. Separating code and data and g enerating reentrant code means that
code pages can be read-only and hence will never be modified. Clean pages
do not have to be paged out to be replaced. The loader can avoid placing
routinesacrosspageboundaries,keepin geachroutinecompletelyinonepage.
Routines that call each other many times can be packed into the same page.
Thispackagingisavariantofthebin-packingproblemofoperationsresearch:
try to pack the variable-sizedload segm ents into the fixed-sizedpages so that
interpagereferencesareminimized.Suchanapproachisparticularlyusefulfor
la r gepa gesiz es.
10.9.6 I/O Interlock and Page Locking
Whendemandpagingisused,wesometimesneedtoallowsomeofthepages
tobe lockedinmemory.Onesuchsituationoccurswhen I/Oisdonetoorfrom
user (virtual) memory. I/Ois often implemented by a separate I/Oprocessor.
Forexample,acontrollerfora USBstoragedeviceisgenerallygiventhenumber"
2,10.10 Operating-System Examples,548,10.9 Other Considerations,"436 Chapter 10 Virtual Memory
memory itself because it has the best knowledge of how it is going to use its
data.Such pinning ofpagesinmemoryisfairlycommon,andmostoperating
systems have a system call allowing an application to request that a region
of its logical address space be pinned. Note that this feature could be abused
andcouldcausestressonthememory-managementalgorithms.Therefore,an
applicationfrequentlyrequiresspecialprivilegesto makesucha request.
Another use for a lock bit involves normal page replacement. Consider
the following sequence of events: A low-priority process faults. Selecting a
replacement frame, the paging system reads the necessary page into memory.
Ready to continue, the low-priority process enters the ready queue and waits
for the CPU. Since it is a low-priority process, it may not be selected by the
CPUschedulerforatime.Whilethelow-priorityprocesswaits,ahigh-priority
process faults. Looking for a replacement, the paging system sees a page that
is in memory but has not been referenced or modified: it is the page that the
low-priorityprocessjustbroughtin.Thispagelookslikeaperfectreplacement.
It is clean and will not need to be written out, and it apparently has not been
usedfora long time.
Whether the high-priority process should be able to replace the low-
priority process is a policy decision. After all, we are simply delaying the
low-priority process for the benefit of the high-priority process. However, we
are wasting the effort spent to bring in the page for the low-priority process.
Ifwedecidetopreventreplacementofanewlybrought-inpageuntilitcanbe
used at least once, then we can use the lock bit to implement this mechanism.
Whenapageisselectedforreplacement,itslockbitisturnedon.Itremainson
until thefaulting processisagain dispatched.
Using a lock bit can be dangerous: the lock bit may get turned on but
neverturnedoff.Shouldthissituationoccur(becauseofabugintheoperating
system,forexample),thelockedframebecomesunusable.Forinstance,Solaris
allows locking “hints, ”but it is free to disregard these hints if the free-frame
poolbecomestoosmallorifanindividualprocessrequeststhattoomanypages
be lockedinmemory.
10.10 Operating-System Examples
In this section, we describe how Linux, Windows and Solaris manage virtual
memory.
10.10.1 Linux
InSection10.8.2,wediscussedhowLinuxmanageskernelmemoryusingslab
allocation. We now cover how Linux manages virtual memory. Linux uses
demandpaging,allocatingpagesfromalistoffreeframes.Inaddition,ituses
aglobalpage-replacementpolicysimilartothe LRU-approximationclockalgo-
rithm described in Section 10.4.5.2. To manage memory, Linux maintains two
typesofpagelists:an active
 listandan inactive
 list.The active
 list
contains the pages that are considered in use, while the inactive
 listcon-
tains pages that have not recently been referenced and are eligible to be
reclaimed."
3,10.10.1 Linux,548,10.10 Operating-System Examples,"436 Chapter 10 Virtual Memory
memory itself because it has the best knowledge of how it is going to use its
data.Such pinning ofpagesinmemoryisfairlycommon,andmostoperating
systems have a system call allowing an application to request that a region
of its logical address space be pinned. Note that this feature could be abused
andcouldcausestressonthememory-managementalgorithms.Therefore,an
applicationfrequentlyrequiresspecialprivilegesto makesucha request.
Another use for a lock bit involves normal page replacement. Consider
the following sequence of events: A low-priority process faults. Selecting a
replacement frame, the paging system reads the necessary page into memory.
Ready to continue, the low-priority process enters the ready queue and waits
for the CPU. Since it is a low-priority process, it may not be selected by the
CPUschedulerforatime.Whilethelow-priorityprocesswaits,ahigh-priority
process faults. Looking for a replacement, the paging system sees a page that
is in memory but has not been referenced or modified: it is the page that the
low-priorityprocessjustbroughtin.Thispagelookslikeaperfectreplacement.
It is clean and will not need to be written out, and it apparently has not been
usedfora long time.
Whether the high-priority process should be able to replace the low-
priority process is a policy decision. After all, we are simply delaying the
low-priority process for the benefit of the high-priority process. However, we
are wasting the effort spent to bring in the page for the low-priority process.
Ifwedecidetopreventreplacementofanewlybrought-inpageuntilitcanbe
used at least once, then we can use the lock bit to implement this mechanism.
Whenapageisselectedforreplacement,itslockbitisturnedon.Itremainson
until thefaulting processisagain dispatched.
Using a lock bit can be dangerous: the lock bit may get turned on but
neverturnedoff.Shouldthissituationoccur(becauseofabugintheoperating
system,forexample),thelockedframebecomesunusable.Forinstance,Solaris
allows locking “hints, ”but it is free to disregard these hints if the free-frame
poolbecomestoosmallorifanindividualprocessrequeststhattoomanypages
be lockedinmemory.
10.10 Operating-System Examples
In this section, we describe how Linux, Windows and Solaris manage virtual
memory.
10.10.1 Linux
InSection10.8.2,wediscussedhowLinuxmanageskernelmemoryusingslab
allocation. We now cover how Linux manages virtual memory. Linux uses
demandpaging,allocatingpagesfromalistoffreeframes.Inaddition,ituses
aglobalpage-replacementpolicysimilartothe LRU-approximationclockalgo-
rithm described in Section 10.4.5.2. To manage memory, Linux maintains two
typesofpagelists:an active
 listandan inactive
 list.The active
 list
contains the pages that are considered in use, while the inactive
 listcon-
tains pages that have not recently been referenced and are eligible to be
reclaimed."
3,10.10.2 Windows,549,10.10.1 Linux,"10.10 Operating-System Examples 437
rear new
page
inactive_listactive_list
referencedreferenced
rear front
front
Figure 10.29 The Linux active
 listandinactive
 liststructures.
Each page has an accessed bit that is set whenever the page is referenced.
(The actual bits used to mark page access vary by architecture.) When a page
is first allocated, its accessed bit is set, and it is added to the rear of the
active
 list. Similarly, whenever a page in the active
 listis referenced,
its accessed bit is set, and the page moves to the rear of the list. Periodically,
the accessed bits for pages in the active
 listare reset. Over time, the least
recentlyused page will be at the front of the active
 list. From there, it may
migrate to the rear of the inactive
 list.I fap a g ei nt h e inactive
 list
is referenced, it moves back to the rear of the active
 list. This pattern is
illustratedinFigure10.29.
Thetwolistsarekeptinrelativebalance,andwhenthe active
 listgrows
much larger than the inactive
 list, pages at the front of the active
 list
move to the inactive
 list, where they become eligible for reclamation. The
Linux kernel has a page-out daemon process kswapdthat periodically awak-
ens and checks the amount of free memory in the system. If free memory
falls below a certain threshold, kswapdbegins scanning pages in the inac-
tive
 listand reclaiming them for the free list. Linux virtual memory man-
agementisdiscussedingreaterdetailinChapter20.
10.10.2 Windows
Windows 10 supports 32- and 64-bit systems running on Intel ( IA-32 and x86-
64)and ARMarchitectures.On32-bitsystems,thedefaultvirtualaddressspace
ofaprocessis2 GB,althoughitcanbeextendedto3 GB.32-bitsystemssupport
4GBof physical memory. On 64-bit systems, Windows 10 has a 128- TBvir-
tual address space and supports up to 24 TBof physical memory. (Versions of
WindowsServersupportupto128 TBofphysicalmemory.)Windows10imple-
mentsmostofthememory-managementfeaturesdescribedthusfar,including
shared libraries, demand paging, copy-on-write, paging, and memory com-
pression."
3,10.10.3 Solaris,550,10.10.2 Windows,"438 Chapter 10 Virtual Memory
Windows10implementsvirtualmemoryusingdemandpagingwith clus-
tering, a strategy that recognizes locality of memory references and therefore
handles page faults by bringing in not only the faulting page but also several
pages immediately preceding and following the faulting page. The size of a
clustervariesby pagetype.Foradatapage,a clustercontains threepages(the
page before and the page after the faulting page); all other page faults have a
clustersizeof seven.
A key component of virtual memory management in Windows 10 is
working-setmanagement.Whenaprocessiscreated,itisassignedaworking-
set minimum of 50 pages and a working-set maximum of 345 pages. The
working-set minimum is the minimum number of pages the process is guar-
anteedto have in memory;if sufficient memory is available,a process may be
assignedasmanypagesasits working-set maximum .Unlessaprocessiscon-
figuredwith hard working-set limits ,thesevaluesmaybeignored.Aprocess
can grow beyond its working-set maximum if sufficient memory is available.
Similarly, the amount of memory allocated to a process can shrink below the
minimum inperiodsof high demandfor memory.
Windowsusesthe LRU-approximationclockalgorithm,asdescribedinSec-
tion10.4.5.2,withacombinationofloca landglobalpage-replacementpolicies.
The virtual memory manager maintains a list of free page frames. Associated
withthislistisathresholdvaluethatin dicateswhethersufficientfreememory
is available. If a page fault occurs for a process that is below its working-
set maximum, the virtual memory manager allocates a page from the list of
free pages. If a process that is at its working-set maximum incurs a page fault
and sufficient memory is available, the process is allocated a free page, which
allowsittogrowbeyonditsworking-setmaximum.Iftheamountoffreemem-
ory is insufficient, however, the kernel must select a page from the process’s
working setfor replacementusing alocal LRUpage-replacementpolicy.
When the amount of free memory falls below the threshold, the vir-
tual memory manager uses a global replacement tactic known as automatic
working-set trimming to restore the value to a level above the threshold.
Automatic working-set trimming works by evaluating the number of pages
allocated to processes. If a process has been allocated more pages than its
working-set minimum, the virtual memory manager removes pages from the
workingsetuntileitherthereissufficientmemoryavailableortheprocesshas
reached its working-set minimum. Larger processes that have been idle are
targeted before smaller, active processes. The trimming procedure continues
until there is sufficient free memory, even if it is necessary to remove pages
from a process already below its working set minimum. Windows performs
working-set trimmingonbothuser-modeand systemprocesses.
10.10.3 Solaris
In Solaris, when a thread incurs a page fault, the kernel assigns a page to
the faulting thread from the list of fre e pages it maintains. Therefore, it is
imperative that the kernel keep a sufficient amount of free memory available.
Associatedwiththislistoffreepagesisaparameter— lotsfree —thatrepre-
sents a threshold to begin paging. The lotsfree parameter is typically set to
1∕64thesizeofthephysicalmemory.Fourtimespersecond,thekernelchecks
whether the amount of free memory is less than lotsfree . If the number of"
2,10.11 Summary,552,10.10 Operating-System Examples,"440 Chapter 10 Virtual Memory
As mentioned above, the pageout process checks memory four times per
second.However,iffreememoryfallsbelowthevalueof desfree (thedesired
amount of free memory in the system), pageout will run a hundred times per
second with the intention of keeping at least desfree free memory available
(Figure 10.30). If the pageout process is unable to keep the amount of free
memory at desfree for a 30-second average, the kernel begins swapping
processes,therebyfreeingallpagesallocatedtoswappedprocesses.Ingeneral,
the kernel looks for processes that have been idle for long periods of time. If
the system is unable to maintain the amount of free memory at minfree ,t h e
pageoutprocessis calledfor everyrequestfora newpage.
The page-scanning algorithm skips pages belonging to libraries that are
beingsharedbyseveralprocesses,eveniftheyareeligibletobeclaimedbythe
scanner.Thealgorithmalsodistinguishesbetweenpagesallocatedtoprocesses
andpagesallocatedtoregulardatafiles.Thisisknownas priority paging and
iscoveredinSection14.6.2.
10.11 Summary
•Virtual memory abstracts physical memory into an extremely large uni-
form arrayof storage.
•Thebenefitsofvirtualmemoryincludethefollowing:(1)aprogramcanbe
largerthanphysicalmemory,(2)aprogramdoesnotneedtobeentirelyin
memory,(3)processescansharememory,and(4)processescanbecreated
more efficiently.
•Demand pagingis atechnique whereby pagesare loadedonly when they
aredemandedduringprogramexecution.Pagesthatareneverdemanded
arethus neverloadedinto memory.
•A page fault occurs when a page that is currently not in memory is
a c c e s s e d .T h ep a g em u s tb eb r o u g h tf r o mt h eb a c k i n gs t o r ei n t oa na v a i l -
ablepageframeinmemory.
•Copy-on-write allows a child process to share the same address space as
itsparent.Ifeitherthechildortheparentprocesswrites(modifies)apage,
ac o p yo ft h ep a g ei sm a de.
•When available memory runs low, a page-replacement algorithm
selects an existing page in memory to replace with a new page. Page-
replacement algorithms include FIFO,o p t i m a l ,a n d LRU.P u r e LRU
algorithms are impractical to implement, and most systems instead use
LRU-approximationalgorithms.
•Globalpage-replacementalgorithms selectapagefromanyprocessinthe
system for replacement, while local page-replacement algorithms select a
pagefromthe faultingprocess.
•Thrashingoccurswhenasystemspends moretimepagingthanexecuting.
•A locality represents a set of pages that are actively used together. As a
processexecutes,itmovesfromlocalityto locality.Aworkingsetisbased
on localityandisdefinedasthesetofpagescurrentlyinusebya process."
2,Practice Exercises,553,10.11 Summary,"Practice Exercises 441
•Memory compression is a memory-management technique that com-
presses a number of pages into a single page. Compressed memory is an
alternative to paging and is used on mobile systems that do not support
paging.
•Kernelmemoryisallocateddifferentlythanuser-modeprocesses;itisallo-
cated in contiguous chunks of varying sizes. Two common techniques for
allocatingkernelmemoryare(1)thebuddysystemand(2)slaballocation.
•TLBreach refers to the amount of memory accessible from the TLBand is
equaltothenumberof entriesinthe TLBmultipliedby thepagesize.One
technique forincreasing TLBreach isto increase the size of pages.
•Linux, Windows, and Solaris manage virtual memory similarly, using
demand paging and copy-on-write, among other features. Each system
also usesa variationof LRUapproximationknown as the clock algorithm.
Practice Exercises
10.1Under what circumstances do page faults occur? Describe the actions
taken by theoperatingsystemwhen apagefault occurs.
10.2Assume that you have a page-reference string for a process with m
frames(initiallyallempty).Thepage-referencestringhaslength p,and
ndistinct page numbers occur in it. Answer these questions for any
page-replacementalgorithms:
a. What isa lowerbound on the number of page faults?
b. What isan upperbound on the number of page faults?
10.3Considerthefollowingpage-replacementalgorithms.Rankthesealgo-
rithms on a five-point scale from “bad”to“perfect ”according to their
page-fault rate. Separate those algorithms that suffer from Belady’s
anomaly fromthose that donot.
a.LRUreplacement
b.FIFOreplacement
c. Optimalreplacement
d. Second-chance replacement
10.4An operating system supports a paged virtual memory. The central
processor has a cycle time of 1 microsecond. It costs an additional 1
microsecond to access a page other than the current one. Pages have
1,000 words, and the paging device is a drum that rotates at 3,000
revolutions per minute and trans fers 1 million words per second. The
following statisticalmeasurementswereobtained fromthe system:
•Onepercentofallinstructionsexecutedaccessedapageotherthan
the currentpage.
•Oftheinstructionsthataccessedanotherpage,80percentaccessed
a pagealreadyinmemory."
2,Further Reading,556,Practice Exercises,"444 Chapter 10 Virtual Memory
consecutive locations for the needed segment. Consider strategies for
systemswheresegmentscannotberelocatedandstrategiesforsystems
where they can.
10.13Considerademand-pagedcomputersystemwherethedegreeofmulti-
programming is currently fixed at four. The system was recently mea-
sured to determine utilization of the CPUand the paging disk. Three
alternativeresultsareshownbelow.Foreachcase,whatishappening?
Can the degreeof multiprogrammingbe increased toincrease the CPU
utilization? Isthepaging helping?
a.CPUutilization13 percent;diskutilization97 percent
b.CPUutilization87 percent;diskutilization3percent
c.CPUutilization13 percent;diskutilization3percent
10.14We have an operating system for a machine that uses base and limit
registers, but we have modified the machine to provide a page table.
Canthe pagetablebesetuptosimulatebase andlimitregisters?How
can itbe, or why can itnot be?
Further Reading
The working-set model was developed by [Denning (1968)]. The
enhanced clock algorithm is discussed by [Carr and Hennessy (1981)].
[Russinovich et al. (2017)] describe how Windows implements vir-
tual memory and memory compression. Compressed memory in
Windows 10 is further discussed in http://www.makeuseof.com/
tag/ram-compression-improves-me mory-responsiveness-windows-10 .
[McDougall and Mauro (2007)] discuss virtual memory in Solaris. Virtual
memory techniques in Linux are described in [Love (2010)] and [Mauerer
(2008)]. FreeBSDisdescribedin[McKusick etal.(2015)].
Bibliography
[Carr and Hennessy (1981)] W .R .C a r ra n dJ .L .H e n n e s s y , “WSClock—ASim-
ple and Effective Algorithm for Virtual Memory Management ”,Proceedings of
the ACM Symposium on Operating Systems Principles (1981), pages87–95.
[Denning (1968)] P.J.Denning, “TheWorkingSetModelforProgramBehavior ”,
Communications of the ACM ,Volume11,Number5 (1968), pages323–333.
[Love (2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library (2010).
[Mauerer (2008)] W. Mauerer, Professional Linux Kernel Architecture , John Wiley
and Sons(2008).
[McDougall and Mauro (2007)] R. McDougall and J. Mauro, Solaris Internals,
SecondEdition, PrenticeHall (2007)."
2,Bibliography,556,Further Reading,"444 Chapter 10 Virtual Memory
consecutive locations for the needed segment. Consider strategies for
systemswheresegmentscannotberelocatedandstrategiesforsystems
where they can.
10.13Considerademand-pagedcomputersystemwherethedegreeofmulti-
programming is currently fixed at four. The system was recently mea-
sured to determine utilization of the CPUand the paging disk. Three
alternativeresultsareshownbelow.Foreachcase,whatishappening?
Can the degreeof multiprogrammingbe increased toincrease the CPU
utilization? Isthepaging helping?
a.CPUutilization13 percent;diskutilization97 percent
b.CPUutilization87 percent;diskutilization3percent
c.CPUutilization13 percent;diskutilization3percent
10.14We have an operating system for a machine that uses base and limit
registers, but we have modified the machine to provide a page table.
Canthe pagetablebesetuptosimulatebase andlimitregisters?How
can itbe, or why can itnot be?
Further Reading
The working-set model was developed by [Denning (1968)]. The
enhanced clock algorithm is discussed by [Carr and Hennessy (1981)].
[Russinovich et al. (2017)] describe how Windows implements vir-
tual memory and memory compression. Compressed memory in
Windows 10 is further discussed in http://www.makeuseof.com/
tag/ram-compression-improves-me mory-responsiveness-windows-10 .
[McDougall and Mauro (2007)] discuss virtual memory in Solaris. Virtual
memory techniques in Linux are described in [Love (2010)] and [Mauerer
(2008)]. FreeBSDisdescribedin[McKusick etal.(2015)].
Bibliography
[Carr and Hennessy (1981)] W .R .C a r ra n dJ .L .H e n n e s s y , “WSClock—ASim-
ple and Effective Algorithm for Virtual Memory Management ”,Proceedings of
the ACM Symposium on Operating Systems Principles (1981), pages87–95.
[Denning (1968)] P.J.Denning, “TheWorkingSetModelforProgramBehavior ”,
Communications of the ACM ,Volume11,Number5 (1968), pages323–333.
[Love (2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library (2010).
[Mauerer (2008)] W. Mauerer, Professional Linux Kernel Architecture , John Wiley
and Sons(2008).
[McDougall and Mauro (2007)] R. McDougall and J. Mauro, Solaris Internals,
SecondEdition, PrenticeHall (2007)."
2,Chapter 10 Exercises,558,Bibliography,"Chapter 10 Exercises
10.15Assumethataprogramhasjustreferencedanaddressinvirtualmem-
ory.Describeascenarioinwhicheachofthefollowingcanoccur.(Ifno
such scenario can occur, explainwhy.)
•TLBmisswith no pagefault
•TLBmisswithpagefault
•TLBhitwithno pagefault
•TLBhitwithpagefault
10.16Asimplifiedviewofthreadstatesis ready,running,and blocked,where
athread iseitherreadyand waiting tobe scheduled,isrunning on the
processor,oris blocked(for example,waitingfor I/O).
ready
blocked running
Assuming a thread is in the running state, answer the following ques-
tions,and explainyour answers:
a. Willthethreadchangestateifitincursapagefault?Ifso,towhat
statewillitchange?
b. Will the thread change state if it generates a TLBmiss that is
resolvedinthepagetable? Ifso, towhat statewillitchange?
c. Willthethreadchange stateifanaddressreferenceisresolvedin
the page table? Ifso, towhat state willitchange?
10.17Considera systemthat usespuredemandpaging.
a. Whenaprocessfirststartsexecution,howwouldyoucharacterize
thepage-faultrate?
b. Once the working set for a process is loaded into memory, how
wouldyou characterize thepage-faultrate?
c. Assumethataprocesschangesitslocalityandthesizeofthenew
working set is too large to be stored in available free memory.
Identify some options system designers could choose from to
handlethis situation.
10.18The following is a page table for a system with 12-bit virtual and
physical addresses and 256-byte pages. Free page frames are to be
allocated in the order 9, F, D . Adash for a page frame indicates that
t h epa g eisn o tinm em o r y .EX-35"
2,Programming Problems,566,Chapter 10 Exercises,"Programming Problems
Programming Problems
10.44Write a program that implements the FIFO,LRU,a n do p t i m a l( OPT)
page-replacementalgorithmspresentedinSection10.4.Haveyourpro-
gram initially generate a random page-reference string where page
numbersrangefrom0to9.Applytherandompage-referencestringto
eachalgorithm,andrecordthenumberofpagefaultsincurredbyeach
algorithm. Pass the number of page frames to the program at startup.
You may implement this program in any programming language of
your choice. (You may find your implementationof either FIFOorLRU
to be helpfulinthe virtualmemorymanager programmingproject.)
Programming Projects
Designing a Virtual Memory Manager
This project consists of writing a program that translates logical to physical
addresses for a virtual address space of size 216= 65,536 bytes. Your program
will read from a file containing logical addresses and, using a TLBand a page
table, will translate eachlogical addres sto its corresponding physical address
and output the value of the byte stored at the translated physical address.
Your learning goal is to use simulation to understand the steps involved in
translatinglogicaltophysicaladdresses.Thiswillincluderesolvingpagefaults
usingdemandpaging,managinga TLB,andimplementingapage-replacement
algorithm.
Specific
Your program will read a file containing several 32-bit integer numbers that
represent logical addresses. However, you need only be concerned with 16-
bit addresses, so you must mask the rightmost 16 bits of each logical address.
These 16 bits are divided into (1) an 8-bit page number and (2) an 8-bit page
offset.Hence,theaddressesarestructuredasshown as:
offset
0 7 8 15 16 31page
number
Otherspecifics include the following:
•28entriesinthe pagetable
•Pagesizeof 28bytes
•16 entriesinthe TLB
•Fra m esiz eo f28bytes
•256 frames
•Physical memoryof 65,536 bytes(256 frames ×256-byteframe size)P-51"
2,Programming Projects,566,Programming Problems,"Programming Problems
Programming Problems
10.44Write a program that implements the FIFO,LRU,a n do p t i m a l( OPT)
page-replacementalgorithmspresentedinSection10.4.Haveyourpro-
gram initially generate a random page-reference string where page
numbersrangefrom0to9.Applytherandompage-referencestringto
eachalgorithm,andrecordthenumberofpagefaultsincurredbyeach
algorithm. Pass the number of page frames to the program at startup.
You may implement this program in any programming language of
your choice. (You may find your implementationof either FIFOorLRU
to be helpfulinthe virtualmemorymanager programmingproject.)
Programming Projects
Designing a Virtual Memory Manager
This project consists of writing a program that translates logical to physical
addresses for a virtual address space of size 216= 65,536 bytes. Your program
will read from a file containing logical addresses and, using a TLBand a page
table, will translate eachlogical addres sto its corresponding physical address
and output the value of the byte stored at the translated physical address.
Your learning goal is to use simulation to understand the steps involved in
translatinglogicaltophysicaladdresses.Thiswillincluderesolvingpagefaults
usingdemandpaging,managinga TLB,andimplementingapage-replacement
algorithm.
Specific
Your program will read a file containing several 32-bit integer numbers that
represent logical addresses. However, you need only be concerned with 16-
bit addresses, so you must mask the rightmost 16 bits of each logical address.
These 16 bits are divided into (1) an 8-bit page number and (2) an 8-bit page
offset.Hence,theaddressesarestructuredasshown as:
offset
0 7 8 15 16 31page
number
Otherspecifics include the following:
•28entriesinthe pagetable
•Pagesizeof 28bytes
•16 entriesinthe TLB
•Fra m esiz eo f28bytes
•256 frames
•Physical memoryof 65,536 bytes(256 frames ×256-byteframe size)P-51"
0,PART FIVE STORAGE MANAGEMENT,571,PART FOUR MEMORY MANAGEMENT,"Part Five
Storage
Management
Computer systems must provide mass storage for permanently storing
ﬁles and data. Modern computers implement mass storage as secondary
storage, using both hard disks an d nonvolatile memory devices.
Secondary storage devices vary in many aspects. Some transfer a
character at a time, and some a block of characters. Some can be
accessed only sequentially, and others randomly. Some transfer data syn-
chronously, and others asynchronously. Some are dedicated, and some
shared. They can be read-only or read–write. And although they vary
greatly in speed, they are in many ways the slowest major component
of the computer.
Because of all this device vari ation, the operating system needs to
provide a wide range of functionality so that applications can control
all aspects of the devices. One key goal of an operating system’s I/O
subsystem is to provide the simplest interface possible to the rest of the
system. Because devices are a perfo rmance bottleneck, another key is
to optimize I/Ofor maximum concurrency."
1,Chapter 11 Mass-Storage Structure,573,PART FIVE STORAGE MANAGEMENT,"11CHAPTER
Mass - Storage
Structure
In this chapter, we discuss how mass storage—the nonvolatile storage sys-
tem of a computer—is structured. The main mass-storage system in modern
computersissecondarystorage,whichisusuallyprovidedbyharddiskdrives
(HDD)andnonvolatilememory( NVM)devices.Somesystemsalsohaveslower,
larger,tertiary storage, generally consisting of magnetic tape, optical disks, or
evencloud storage.
Becausethemostcommonandimportantstoragedevicesinmoderncom-
puter systems are HDDsa n dNVMdevices, the bulk of this chapter is devoted
todiscussingthesetwo typesofstorage.Wefirstdescribetheirphysicalstruc-
ture.Wethenconsiderschedulingalgorithms,whichscheduletheorderof I/Os
to maximize performance. Next, we discuss device formatting and manage-
mentofbootblocks,damagedblocks,andswapspace.Finally,weexaminethe
structureof RAIDsystems.
There are many types of mass storage, and we use the general term non-
volatile storage (NVS) or talk about storage “drives ”when the discussion
includes all types. Particular devices, such as HDDsa n dNVMdevices, are
specifiedas appropriate.
CHAPTER OBJECTIVES
•Describethephysicalstructuresofvarioussecondarystoragedevicesand
the effect of a device’s structure on its uses.
•Explain the performance characteristics of mass-storage devices.
•Evaluate I/Oscheduling algorithms.
•Discuss operating-system services provided for mass storage, including
RAID.
11.1 Overview of Mass-Storage Structure
The bulk of secondary storage for modern computers is provided by hard
disk drives (HDDs)a n d nonvolatile memory (NVM) devices. In this section,
449"
2,11.1 Overview of Mass-Storage Structure,573,Chapter 11 Mass-Storage Structure,"11CHAPTER
Mass - Storage
Structure
In this chapter, we discuss how mass storage—the nonvolatile storage sys-
tem of a computer—is structured. The main mass-storage system in modern
computersissecondarystorage,whichisusuallyprovidedbyharddiskdrives
(HDD)andnonvolatilememory( NVM)devices.Somesystemsalsohaveslower,
larger,tertiary storage, generally consisting of magnetic tape, optical disks, or
evencloud storage.
Becausethemostcommonandimportantstoragedevicesinmoderncom-
puter systems are HDDsa n dNVMdevices, the bulk of this chapter is devoted
todiscussingthesetwo typesofstorage.Wefirstdescribetheirphysicalstruc-
ture.Wethenconsiderschedulingalgorithms,whichscheduletheorderof I/Os
to maximize performance. Next, we discuss device formatting and manage-
mentofbootblocks,damagedblocks,andswapspace.Finally,weexaminethe
structureof RAIDsystems.
There are many types of mass storage, and we use the general term non-
volatile storage (NVS) or talk about storage “drives ”when the discussion
includes all types. Particular devices, such as HDDsa n dNVMdevices, are
specifiedas appropriate.
CHAPTER OBJECTIVES
•Describethephysicalstructuresofvarioussecondarystoragedevicesand
the effect of a device’s structure on its uses.
•Explain the performance characteristics of mass-storage devices.
•Evaluate I/Oscheduling algorithms.
•Discuss operating-system services provided for mass storage, including
RAID.
11.1 Overview of Mass-Storage Structure
The bulk of secondary storage for modern computers is provided by hard
disk drives (HDDs)a n d nonvolatile memory (NVM) devices. In this section,
449"
3,11.1.1 Hard Disk Drives,574,11.1 Overview of Mass-Storage Structure,"450 Chapter 11 Mass-Storage Structure
track t
sector sspindle
cylinder c
platter
armread-write
headarm assembly
rotation
Figure 11.1 HDD moving-head disk mechanism.
we describe the basic mechanisms of these devices and explain how operat-
ing systems translate their physical properties to logical storage via address
mapping.
11.1.1 Hard Disk Drives
Conceptually, HDDs are relatively simple (Figure 11.1). Each disk platterhas
a flat circular shape, like a CD. Common platter diameters range from 1.8 to
3.5 inches. The two surfaces of a platter are coveredwith a magnetic material.
Westoreinformationbyrecordingitmagneticallyontheplatters,andweread
informationby detectingthemagnetic patternontheplatters.
A read–write head “flies ”just above each surface of every platter. The
headsareattachedtoa disk arm thatmovesalltheheadsasaunit.Thesurface
of a platter is logically dividedinto circular tracks, which are subdividedinto
sectors. The set of tracks at a given arm position make up a cylinder .T h e r e
may be thousands of concentric cylinde rs in a disk drive, and each track may
contain hundreds of sectors. Each sector has a fixed size and is the smallest
unit of transfer. The sector size was commonly 512 bytes until around 2010.
Atthatpoint,manymanufacturersstartmigratingto4KBsectors.Thestorage
capacityofcommondiskdrivesismeasuredingigabytesandterabytes.Adisk
drivewiththecoverremovedisshown inFigure11.2.
Adiskdrivemotorspinsitathighspeed.Mostdrivesrotate60to250times
per second, specified in terms of rotations per minute ( RPM). Common drives
spin at 5,400, 7,200, 10,000, and 15,000 RPM. Some drives power down when
not in use and spin up upon receiving an I/Orequest. Rotation speed relates
to transfer rates. The transfer rate is the rate at which data flow between the
driveandthecomputer.Anotherperformanceaspect,the positioning time ,or
random-access time ,consistsoftwoparts:thetimenecessarytomovethedisk
armtothedesiredcylinder,calledthe seek time ,andthetimenecessaryforthe"
3,11.1.2 Nonvolatile Memory Devices,576,11.1.1 Hard Disk Drives,"452 Chapter 11 Mass-Storage Structure
11.1.2 Nonvolatile Memory Devices
Nonvolatile memory ( NVM) devices are growing in importance. Simply
described, NVMdevicesareelectricalratherthanmechanical.Mostcommonly,
such a device is composed of a controller and flash NANDdie semiconductor
chips, which are used to store data. Other NVMtechnologies exist, like
DRAMwith battery backing so it doesn’t lo se its contents, as well as other
semiconductor technology like 3D XPoint, but they are far less common and
so arenot discussedin thisbook.
11.1.2.1 Overview of Nonvolatile Memory Devices
Flash-memory-based NVMis frequentlyused in a disk-drive-likecontainer, in
whichcaseitiscalleda solid-state disk (SSD)(Figure11.3).Inotherinstances,
ittakestheformofa USB drive(alsoknownasathumbdriveorflashdrive)ora
DRAMstick.Itisalsosurface-mountedontomotherboardsasthemainstorage
indeviceslikesmartphones.Inallforms,itactsandcanbetreatedinthesame
way.Our discussion of NVMdevicesfocuses onthis technology.
NVMdevicescanbemorereliablethan HDDsbecausetheyhavenomoving
parts and can be faster because they have no seek time or rotational latency.
In addition, they consume less power. On the negative side, they are more
expensivepermegabytethantraditionalharddisksandhavelesscapacitythan
the larger hard disks. Over time, however, the capacity of NVMdevices has
increasedfasterthan HDDcapacity, and theirprice has droppedmore quickly,
so their use is increasing dramatically. In fact, SSDs and similar devices are
now used in some laptop computers to make them smaller, faster, and more
energy-efficient.
Because NVMdevices can be much faster than hard disk drives, standard
bus interfaces can cause a major limit on throughput. Some NVMdevices
are designed to connect directly to the system bus ( PCIe, for example). This
technology is changing other tradition al aspects of computer design as well.
Figure 11.3 A 3.5-inch SSD circuit board."
3,11.1.3 Volatile Memory,578,11.1.2 Nonvolatile Memory Devices,"454 Chapter 11 Mass-Storage Structure
tracks physical block state—that is, whi ch blocks contain only invalid pages
and therefore can be erased.
Now consider a full SSDwith a pending write request. Because the SSDis
full, all pages have been written to, but there might be a block that contains
no valid data. In that case, the write could wait for the erase to occur, and
then the write could occur. But what if there are no free blocks? There still
could be some space available if individual pages are holding invalid data. In
thatcase, garbage collection couldoccur—gooddatacouldbecopiedtoother
locations, freeing up blocks that could be erased and could then receive the
writes. However, where would the garbage collection store the good data? To
solvethisproblemandimprovewriteperformance,the NVMdeviceuses over-
provisioning .Thedevicesetsasideanumberofpages(frequently20percentof
thetotal)asanareaalwaysavailabletowriteto.Blocksthataretotallyinvalid
by garbage collection, or write operati ons invalidating older versions of the
data, are erased and placed in the over-provisioning space if the device is full
or returnedtothe freepool.
The over-provisioning space can also help with wear leveling .I fs o m e
blocksareerasedrepeatedly,whileothersarenot,thefrequentlyerasedblocks
will wear out faster than the others, and the entire device will have a shorter
lifespan than it would if all the blocks wore out concurrently. The controller
tries to avoid that by using various algorithms to place data on less-erased
blocks so that subsequent erases will happen on those blocks rather than on
th emo r eera sedb lo c ks,levelin gth ew ea ra c r o ssth een tir edevic e.
In terms of data protection, like HDDs,NVMdevices provide error-
correcting codes, which are calculated and stored along with the data during
writing and read with the data to detect errors and correct them if possible.
(Error-correcting codes are discussed in Section 11.5.1.) If a page frequently
has correctible errors, the page might be marked as bad and not used in
subsequent writes. Generally, a single NVMdevice, like an HDD,c a nh a v e
a catastrophic failure in which it corrupts or fails to reply to read or write
requests.Toallowdatatoberecoverableinthoseinstances, RAIDprotectionis
used.
11.1.3 Volatile Memory
It might seem odd to discuss volatile memory in a chapter on mass-storage
structure,butitisjustifiablebecause DRAMisfrequentlyusedasamass-storage
device.Specifically, RAM drives(which are known by many names, including
RAMdisks) act like secondary storage but are created by device drivers that
carve out a section of the system’s DRAMand present it to the rest of the
system as it if were a storage device. These “drives ”can be used as raw block
devices,butmorecommonly,filesystemsarecreatedonthemforstandardfile
operations.
Computers already have buffering and caching, so what is the purpose of
yetanotheruseof DRAMfortemporarydatastorage?Afterall, DRAMisvolatile,
anddataona RAMdrivedoesnotsurviveasystemcrash,shutdown,orpower
down. Caches and buffers are allocated by the programmer or operating sys-
tem, whereas RAMdrives allow the user (as well as the programmer) to place"
3,11.1.4 Secondary Storage Connection Methods,580,11.1.3 Volatile Memory,"456 Chapter 11 Mass-Storage Structure
11.1.4 Secondary Storage Connection Methods
Asecondary storage deviceis attached to a computer by the system bus or an
I/Obus. Several kinds of buses are available, including advanced technology
attachment (ATA),serial ATA(SATA),eSATA,serial attached SCSI(SAS),uni-
versal serial bus (USB), and fibr channel (FC).The mostcommon connection
methodis SATA.Because NVMdevicesaremuchfasterthan HDDs,theindustry
created a special, fast interface for NVMdevices called NVM express(NVMe).
NVMedirectlyconnectsthedevicetothesystem PCIbus,increasingthroughput
and decreasinglatency compared with otherconnection methods.
Thedatatransfersonabusarecarriedoutbyspecialelectronicprocessors
called controllers (orhost-bus adapters (HBA)). The host controller is the
controller at the computer end of the bus. A device controller is built into
each storage device. To perform a mass storage I/Ooperation, the computer
places a command into the host contro ller, typically using memory-mapped
I/Oports, as described in Section 12.2.1. The host controller then sends the
command via messages to the device controller, and the controller operates
thedrivehardwaretocarryoutthecommand.Devicecontrollersusuallyhave
a built-in cache. Data transfer at the drive happens between the cache and the
storage media, and data transfer to the host, at fast electronic speeds, occurs
betweenthe cache host DRAMviaDMA.
11.1.5 Address Mapping
Storage devices are addressed as large one-dimensional arrays of logical
blocks, where the logical block is the smallest unit of transfer. Each logical
block maps to a physical sector or semiconductor page. The one-dimensional
arrayoflogicalblocksismappedontothesectorsorpagesofthedevice.Sector
0couldbethefirstsectorofthefirsttrackontheoutermostcylinderonan HDD,
for example.The mappingproceedsin orderthrough that track, then through
therestofthetracksonthatcylinder,andthenthroughtherestofthecylinders,
from outermost to innermost. For NVMthe mapping is from a tuple (finite
ordered list) of chip, block, and page to an array of logical blocks. A logical
blockaddress( LBA)iseasierforalgorithmstousethanasector,cylinder,head
tupleorchip, block, pagetuple.
By using this mapping on an HDD, we can—at least in theory—convert a
logical block number into an old-style disk address that consists of a cylinder
number, atrack number within that cylinder,and asectornumber within that
track. In practice, it is difficult to perform this translation, for three reasons.
First, most drives have some defective sectors, but the mapping hides this
by substituting spare sectors from elsewhere on the drive. The logical block
addressstays sequential,but thephysical sectorlocation changes. Second,the
numberofsectorspertrackisnotaconstantonsomedrives.Third,diskman-
ufacturers manage LBAto physical address mapping internally, so in current
drives there is little relationship between LBAand physical sectors. In spite
of these physical address vagaries, algorithms that deal with HDDst e n dt o
assumethatlogicaladdressesarerelati velyrelatedtophysicaladdresses.That
is,ascending logicaladdressesten dto meanascendingphysical address.
Let’s look more closely at the second reason. On media that use constant
linear velocity (CLV),thedensityofbitspertrackisuniform.Thefartheratrack
is from the center of the disk, the greater its length, so the more sectors it can"
3,11.1.5 Address Mapping,580,11.1.4 Secondary Storage Connection Methods,"456 Chapter 11 Mass-Storage Structure
11.1.4 Secondary Storage Connection Methods
Asecondary storage deviceis attached to a computer by the system bus or an
I/Obus. Several kinds of buses are available, including advanced technology
attachment (ATA),serial ATA(SATA),eSATA,serial attached SCSI(SAS),uni-
versal serial bus (USB), and fibr channel (FC).The mostcommon connection
methodis SATA.Because NVMdevicesaremuchfasterthan HDDs,theindustry
created a special, fast interface for NVMdevices called NVM express(NVMe).
NVMedirectlyconnectsthedevicetothesystem PCIbus,increasingthroughput
and decreasinglatency compared with otherconnection methods.
Thedatatransfersonabusarecarriedoutbyspecialelectronicprocessors
called controllers (orhost-bus adapters (HBA)). The host controller is the
controller at the computer end of the bus. A device controller is built into
each storage device. To perform a mass storage I/Ooperation, the computer
places a command into the host contro ller, typically using memory-mapped
I/Oports, as described in Section 12.2.1. The host controller then sends the
command via messages to the device controller, and the controller operates
thedrivehardwaretocarryoutthecommand.Devicecontrollersusuallyhave
a built-in cache. Data transfer at the drive happens between the cache and the
storage media, and data transfer to the host, at fast electronic speeds, occurs
betweenthe cache host DRAMviaDMA.
11.1.5 Address Mapping
Storage devices are addressed as large one-dimensional arrays of logical
blocks, where the logical block is the smallest unit of transfer. Each logical
block maps to a physical sector or semiconductor page. The one-dimensional
arrayoflogicalblocksismappedontothesectorsorpagesofthedevice.Sector
0couldbethefirstsectorofthefirsttrackontheoutermostcylinderonan HDD,
for example.The mappingproceedsin orderthrough that track, then through
therestofthetracksonthatcylinder,andthenthroughtherestofthecylinders,
from outermost to innermost. For NVMthe mapping is from a tuple (finite
ordered list) of chip, block, and page to an array of logical blocks. A logical
blockaddress( LBA)iseasierforalgorithmstousethanasector,cylinder,head
tupleorchip, block, pagetuple.
By using this mapping on an HDD, we can—at least in theory—convert a
logical block number into an old-style disk address that consists of a cylinder
number, atrack number within that cylinder,and asectornumber within that
track. In practice, it is difficult to perform this translation, for three reasons.
First, most drives have some defective sectors, but the mapping hides this
by substituting spare sectors from elsewhere on the drive. The logical block
addressstays sequential,but thephysical sectorlocation changes. Second,the
numberofsectorspertrackisnotaconstantonsomedrives.Third,diskman-
ufacturers manage LBAto physical address mapping internally, so in current
drives there is little relationship between LBAand physical sectors. In spite
of these physical address vagaries, algorithms that deal with HDDst e n dt o
assumethatlogicaladdressesarerelati velyrelatedtophysicaladdresses.That
is,ascending logicaladdressesten dto meanascendingphysical address.
Let’s look more closely at the second reason. On media that use constant
linear velocity (CLV),thedensityofbitspertrackisuniform.Thefartheratrack
is from the center of the disk, the greater its length, so the more sectors it can"
2,11.2 HDD Scheduling,581,11.1 Overview of Mass-Storage Structure,"11.2 HDD Scheduling 457
hold. As we move from outer zones to inner zones, the number of sectors per
track decreases. Tracks in the outermost zone typically hold 40 percent more
sectors than do tracks in the innermost zone. The drive increases its rotation
speedastheheadmovesfromtheoutertotheinnertrackstokeepthesamerate
ofdatamovingunderthehead.Thismethodisusedin CD-ROM andDVD-ROM
drives.Alternatively,thediskrotationspeedcanstayconstant;inthiscase,the
densityofbitsdecreasesfrominnertrackstooutertrackstokeepthedatarate
constant (and performance relativelythe same no matter where data is on the
d r i v e ) .T h i sm e t h o di su s e di nh a r dd i s k sa n di sk n o w na s constant angular
velocity (CA V).
The number of sectors per track has been increasing as disk technology
improves,andtheouterzoneofadiskusuallyhasseveralhundredsectorsper
track. Similarly, the number of cylinders per disk has been increasing; large
diskshave tens of thousands of cylinders.
Note that there are more types of storage devices than are reasonable
to cover in an operating systems text. For example, there are “shingled
magnetic recording ”hard drives with higher density but worse perfor-
mance than mainstream HDDs( s e e http://www.tomsitpro.com/articles/
shingled-magnetic-recoding -smr-101-basics,2-933.html ). There are also
combination devices that include NVMandHDDtechnology, or volume
managers (see Section 11.5) that can knit together NVMandHDDdevices into
a storage unit faster than HDDbut lower cost than NVM. These devices have
different characteristics from the more common devices, and might need
differentcaching andscheduling algorithmsto maximizeperformance.
11.2 HDD Scheduling
One of the responsibilities of the operating system is to use the hardware
efficiently.For HDDs,meetingthisresponsibilityentailsminimizingaccesstime
and maximizing datatransferbandwidth.
ForHDDs and other mechanical storage devices that use platters, access
time has two major components, as mentioned in Section 11.1. The seek time
isthetimeforthedevicearmtomovetheheadstothecylindercontainingthe
desiredsector,andtherotationallatencyistheadditionaltimefortheplatterto
rotatethedesiredsectortothehead.Thedevice bandwidth isthetotalnumber
of bytes transferred, divided by the total time between the first request for
serviceandthecompletionofthelasttransfer.Wecanimproveboththeaccess
timeand the bandwidth by managing the orderin which storage I/Orequests
areserviced.
Whenever a process needs I/Oto or from the drive, it issues a system call
tothe operatingsystem.Therequestspecifiesseveralpiecesof information:
•Whether this operationisinput oroutput
•The openfile handleindicating thefileto operateon
•What thememoryaddressfor thetransferis
•The amount of datato transfer"
3,11.2.1 FCFS Scheduling,582,11.2 HDD Scheduling,"458 Chapter 11 Mass-Storage Structure
Ifthedesireddriveandcontrollerareavailable,therequestcanbeserviced
immediately.Ifthedriveorcontrollerisbusy,anynewrequestsforservicewill
beplacedinthequeueofpendingrequestsforthatdrive.Foramultiprogram-
ming system with many processes, the device queue may often have several
pendingrequests.
The existence of a queue of requests to a device that can have its perfor-
mance optimized by avoiding head seeks allows device drivers a chance to
improveperformanceviaqueueordering.
In the past, HDDinterfaces required that the host specify which track and
which head to use, and much effort was spent on disk scheduling algorithms.
Drivesnewerthantheturnofthecenturynotonlydonotexposethesecontrols
to the host, but also map LBAto physical addresses under drive control. The
current goals of disk scheduling inclu de fairness, timeliness, and optimiza-
tions, such as bunching reads or writes that appear in sequence, as drives
perform best with sequential I/O. Therefore some scheduling effort is still
useful. Any one of several disk-scheduling algorithms can be used, and we
discuss them next. Note that absolute knowledge of head location and phys-
ical block/cylinder locations is generally not possible on modern drives. But
as a rough approximation, algorithms can assume that increasing LBAsm e a n
increasingphysicaladdresses,and LBAsclosetogetherequatetophysicalblock
proximity.
11.2.1 FCFS Scheduling
The simplest form of disk scheduling is, of course, the first-come, first-served
(FCFS) algorithm (or FIFO). This algorithm is intrinsically fair, but it generally
does not provide the fastest service.Consider, for example, a disk queue with
requests for I/Otoblocks on cylinders
98, 183, 37, 122, 14, 124, 65, 67,
in that order. If the disk head is initially at cylinder 53, it will first move from
53 to 98, then to 183, 37, 122, 14, 124, 65, and finally to 67, for a total head
movementof640 cylinders.ThisscheduleisdiagrammedinFigure11.6.
Thewildswingfrom122to14andthenbackto124illustratestheproblem
with this schedule. If the requests for cylinders 37 and 14 could be serviced
together,beforeoraftertherequestsfor122and124,thetotalheadmovement
couldbedecreasedsubstantially,andperformancecouldbetherebyimproved.
11.2.2 SCAN Scheduling
In the SCAN algorithm , the disk arm starts at one end of the disk and moves
towardtheotherend,servicingrequestsasitreacheseachcylinder,untilitgets
to theother endof the disk.Atthe otherend,the directionof head movement
is reversed, and servicing continues. The head continuously scans back and
forth across the disk. The SCANalgorithm is sometimes called the elevator
algorithm , since the disk arm behaves just like an elevator in a building, first
servicing all the requests going up and then reversing to service requests the
other way.
Let’sreturntoourexampletoillustrate.Beforeapplying SCANtoschedule
the requestson cylinders98, 183,37,122, 14,124, 65,and 67, we needto know"
3,11.2.2 SCAN Scheduling,582,11.2.1 FCFS Scheduling,"458 Chapter 11 Mass-Storage Structure
Ifthedesireddriveandcontrollerareavailable,therequestcanbeserviced
immediately.Ifthedriveorcontrollerisbusy,anynewrequestsforservicewill
beplacedinthequeueofpendingrequestsforthatdrive.Foramultiprogram-
ming system with many processes, the device queue may often have several
pendingrequests.
The existence of a queue of requests to a device that can have its perfor-
mance optimized by avoiding head seeks allows device drivers a chance to
improveperformanceviaqueueordering.
In the past, HDDinterfaces required that the host specify which track and
which head to use, and much effort was spent on disk scheduling algorithms.
Drivesnewerthantheturnofthecenturynotonlydonotexposethesecontrols
to the host, but also map LBAto physical addresses under drive control. The
current goals of disk scheduling inclu de fairness, timeliness, and optimiza-
tions, such as bunching reads or writes that appear in sequence, as drives
perform best with sequential I/O. Therefore some scheduling effort is still
useful. Any one of several disk-scheduling algorithms can be used, and we
discuss them next. Note that absolute knowledge of head location and phys-
ical block/cylinder locations is generally not possible on modern drives. But
as a rough approximation, algorithms can assume that increasing LBAsm e a n
increasingphysicaladdresses,and LBAsclosetogetherequatetophysicalblock
proximity.
11.2.1 FCFS Scheduling
The simplest form of disk scheduling is, of course, the first-come, first-served
(FCFS) algorithm (or FIFO). This algorithm is intrinsically fair, but it generally
does not provide the fastest service.Consider, for example, a disk queue with
requests for I/Otoblocks on cylinders
98, 183, 37, 122, 14, 124, 65, 67,
in that order. If the disk head is initially at cylinder 53, it will first move from
53 to 98, then to 183, 37, 122, 14, 124, 65, and finally to 67, for a total head
movementof640 cylinders.ThisscheduleisdiagrammedinFigure11.6.
Thewildswingfrom122to14andthenbackto124illustratestheproblem
with this schedule. If the requests for cylinders 37 and 14 could be serviced
together,beforeoraftertherequestsfor122and124,thetotalheadmovement
couldbedecreasedsubstantially,andperformancecouldbetherebyimproved.
11.2.2 SCAN Scheduling
In the SCAN algorithm , the disk arm starts at one end of the disk and moves
towardtheotherend,servicingrequestsasitreacheseachcylinder,untilitgets
to theother endof the disk.Atthe otherend,the directionof head movement
is reversed, and servicing continues. The head continuously scans back and
forth across the disk. The SCANalgorithm is sometimes called the elevator
algorithm , since the disk arm behaves just like an elevator in a building, first
servicing all the requests going up and then reversing to service requests the
other way.
Let’sreturntoourexampletoillustrate.Beforeapplying SCANtoschedule
the requestson cylinders98, 183,37,122, 14,124, 65,and 67, we needto know"
3,11.2.3 C-SCAN Scheduling,584,11.2.2 SCAN Scheduling,"460 Chapter 11 Mass-Storage Structure
11.2.3 C-SCAN Scheduling
Circular SCAN (C-SCAN ) scheduling is a variant of SCANdesignedto provide
amoreuniformwaittime.Like SCAN,C-SCANmovestheheadfromoneendof
thedisktotheother,servicingrequestsalongtheway. Whenthe headreaches
the other end, however, it immediately returns to the beginning of the disk
without servicingany requestsonthe returntrip.
Let’sreturntoourexampletoillustrate.Beforeapplying C-SCANtosched-
ule the requests on cylinders 98, 183, 37, 122, 14, 124, 65, and 67, we need to
know the direction of head movement in which the requests are scheduled.
Assuming that the requests are schedu led when the disk arm is moving from
0to199andthattheinitialheadpositionisagain53,therequestwillbeserved
as depictedinFigure11.8. The C-SCANscheduling algorithm essentiallytreats
the cylinders as a circular list that wraps around from the final cylinder to the
first one.
11.2.4 Selection of a Disk-Scheduling Algorithm
There are many disk-scheduling algorithms not included in this coverage,
because they are rarely used. But how do operating system designers decide
whichtoimplement,anddeployerschosethebesttouse?Foranyparticularlist
of requests, we can define an optimal order of retrieval, but the computation
needed to find an optimal schedule may not justify the savings over SCAN.
Withanyschedulingalgorithm,however,performancedependsheavilyonthe
number and types of requests. For inst ance, suppose that the queue usually
has just one outstanding request. Then, all scheduling algorithms behave the
same,becausetheyhaveonlyonechoiceofwheretomovethediskhead:they
allbehavelike FCFSscheduling.
SCANandC-SCANperformbetterforsystemsthatplaceaheavyloadonthe
disk, because they are less likely to cause a starvation problem. There can still
bestarvationthough,whichdroveLinuxtocreatethe deadline scheduler.This
scheduler maintains separate read and write queues, and gives reads priority
because processes are more likely to block on read than write. The queues are
01 4 37536567 98122124 183 199queue = 98, 183, 37 , 122, 14, 124, 65, 67
head starts at 53
Figure 11.8 C-SCAN disk scheduling."
3,11.2.4 Selection of a Disk-Scheduling Algorithm,584,11.2.3 C-SCAN Scheduling,"460 Chapter 11 Mass-Storage Structure
11.2.3 C-SCAN Scheduling
Circular SCAN (C-SCAN ) scheduling is a variant of SCANdesignedto provide
amoreuniformwaittime.Like SCAN,C-SCANmovestheheadfromoneendof
thedisktotheother,servicingrequestsalongtheway. Whenthe headreaches
the other end, however, it immediately returns to the beginning of the disk
without servicingany requestsonthe returntrip.
Let’sreturntoourexampletoillustrate.Beforeapplying C-SCANtosched-
ule the requests on cylinders 98, 183, 37, 122, 14, 124, 65, and 67, we need to
know the direction of head movement in which the requests are scheduled.
Assuming that the requests are schedu led when the disk arm is moving from
0to199andthattheinitialheadpositionisagain53,therequestwillbeserved
as depictedinFigure11.8. The C-SCANscheduling algorithm essentiallytreats
the cylinders as a circular list that wraps around from the final cylinder to the
first one.
11.2.4 Selection of a Disk-Scheduling Algorithm
There are many disk-scheduling algorithms not included in this coverage,
because they are rarely used. But how do operating system designers decide
whichtoimplement,anddeployerschosethebesttouse?Foranyparticularlist
of requests, we can define an optimal order of retrieval, but the computation
needed to find an optimal schedule may not justify the savings over SCAN.
Withanyschedulingalgorithm,however,performancedependsheavilyonthe
number and types of requests. For inst ance, suppose that the queue usually
has just one outstanding request. Then, all scheduling algorithms behave the
same,becausetheyhaveonlyonechoiceofwheretomovethediskhead:they
allbehavelike FCFSscheduling.
SCANandC-SCANperformbetterforsystemsthatplaceaheavyloadonthe
disk, because they are less likely to cause a starvation problem. There can still
bestarvationthough,whichdroveLinuxtocreatethe deadline scheduler.This
scheduler maintains separate read and write queues, and gives reads priority
because processes are more likely to block on read than write. The queues are
01 4 37536567 98122124 183 199queue = 98, 183, 37 , 122, 14, 124, 65, 67
head starts at 53
Figure 11.8 C-SCAN disk scheduling."
2,11.3 NVM Scheduling,585,11.2 HDD Scheduling,"11.3 NVM Scheduling 461
sortedin LBAorder,essentiallyimplementing C-SCAN.AllI/Orequestsaresent
in a batch in this LBAorder. Deadline keeps four queues: two read and two
write,onesortedby LBAandtheotherby FCFS.Itchecksaftereachbatchtosee
iftherearerequestsinthe FCFSqueuesolderthanaconfiguredage(bydefault,
500ms).Ifso,the LBAqueue(readorwrite)containing thatrequestisselected
forthe nextbatch of I/O.
The deadline I/Oscheduler is the default in the Linux RedHat 7 distribu-
tion,but RHEL7alsoincludestwoothers. NOOPispreferredfor CPU-boundsys-
temsusingfaststoragesuchas NVMdevices,andthe Completely Fair Queue-
ing scheduler (CFQ)isthedefaultfor SATAdrives. CFQmaintainsthreequeues
(withinsertionsorttokeepthemsortedin LBAorder):realtime,besteffort(the
default),andidle.Eachhasexclusivepriorityovertheothers,inthatorder,with
starvation possible. It uses historical data, anticipating if a process will likely
issue more I/Orequests soon. If it so determines, it idles waiting for the new
I/O, ignoring other queued requests. This is to minimize seek time, assuming
localityofreferenceofstorage I/Orequests,perprocess.Detailsofthesesched-
ulers can be found in https://access.redhat.com/site/documentation/en-US
/Red
 Hat
Enterprise
 Linux/7/html/Performance
 Tuning
 Guide/index.html .
11.3 NVM Scheduling
The disk-scheduling algorithms just discussed apply to mechanical platter-
based storage like HDDs. They focus primarily on minimizing the amount of
disk head movement. NVMdevices do not contain moving disk heads and
commonly use a simple FCFSpolicy. For example, the Linux NOOPscheduler
uses an FCFSpolicy but modifies it to merge adjacent requests. The observed
behavior of NVMdevices indicates that the time required to service reads is
uniformbutthat,becauseofthepropertiesofflashmemory,writeservicetime
is not uniform. Some SSDschedulers have exploited this property and merge
only adjacentwriterequests,servicingallreadrequestsin FCFSorder.
Aswehaveseen, I/Ocanoccursequentiallyorrandomly.Sequentialaccess
is optimal for mechanical devices like HDDand tape because the data to be
read or written is near the read/write head. Random-access I/O,w h i c hi s
measuredin input/output operations per second (IOPS),causes HDDdiskhead
movement.Naturally,random access I/Oismuch fasteron NVM.A nHDDcan
produce hundreds of IOPS, while an SSDcan produce hundreds of thousands
ofIOPS.
NVMdevices offer much less of an advantage for raw sequential through-
put, where HDDhead seeks are minimized and reading and writing of data
to the media are emphasized. In those cases, for reads, performance for the
two types of devices can range from equivalent to an order of magnitude
advantagefor NVMdevices.Writingto NVMisslowerthanreading,decreasing
the advantage. Furthermore, while write performance for HDDsi sc o n s i s t e n t
throughout the life of the device, write performance for NVMdevices varies
dependingonhowfullthedeviceis(recalltheneedforgarbagecollectionand
over-provisioning) and how “worn ”it is. An NVMdevice near its end of life
due to many erase cycles generally has much worse performance than a new
device."
2,11.4 Error Detection and Correction,586,11.3 NVM Scheduling,"462 Chapter 11 Mass-Storage Structure
One way to improve the lifespan and performance of NVMdevices over
timeistohavethefilesysteminformthedevicewhenfilesaredeleted,sothat
the device can erase the blocks those files were stored on. This approach is
discussedfurther inSection14.5.6.
Let’slookmorecloselyattheimpactofgarbagecollectiononperformance.
Consider an NVMdevice under random read and write load. Assume that all
blockshavebeenwrittento,butthereisfreespaceavailable.Garbagecollection
must occur to reclaim space taken by invalid data. That means that a write
might cause a read of one or more pages, a write of the good data in those
pagestooverprovisioningspace,aneraseoftheall-invalid-datablock,andthe
placement of that block into overprovisioning space. In summary, one write
request eventually causes a page write (the data), one or more page reads
(by garbage collection), and one or more page writes (of good data from the
garbage-collected blocks). The creation of I/Orequests not by applications
but by the NVMdevice doing garbage collection and space management is
called write amplificatio and can greatly impact the write performance of
the device. In the worst case, several extra I/Osare triggered with each write
request.
11.4 Error Detection and Correction
Error detection and correction are fundamental to many areas of computing,
including memory, networking, and storage. Error detection determines if a
problem has occurred — for example a bit in DRAMspontaneously changed
froma0toa1,thecontentsofanetworkpacketchangedduringtransmission,
orablockofdatachangedbetweenwhenitwaswrittenandwhenitwasread.
By detecting the issue, the system can halt an operation before the error is
propagated, report the error to the user or administrator, or warn of a device
that mightbe startingto failor has alreadyfailed.
Memorysystemshavelong detectedcertainerrorsby using paritybits.In
this scenario, each byte in a memory system has a parity bit associated with
it that records whether the number of bits in the byte set to 1 is even (parity
= 0) or odd (parity = 1). If one of the bits in the byte is damaged (either a 1
becomes a 0, or a 0 becomes a 1), the parity of the byte changes and thus does
not match the stored parity. Similarly, if the stored parity bit is damaged, it
doesnotmatchthecomputedparity.Thus,allsingle-biterrorsaredetectedby
the memory system. A double-bit-error might go undetected, however. Note
that parity is easily calculated by performing an XOR(for “eXclusive OR ”)o f
the bits. Also note that for everybyte of memory, we now need an extra bit of
memoryto storethe parity.
Parity is one form of checksums , which use modular arithmetic to
compute, store, and compare values on fixed-length words. Another
error-detection method, common in networking, is a cyclic redundancy
check(CRCs), which uses a hash function to detect multiple-bit errors (see
http://www.mathpages.com /home/kmath458/kmath458.htm ).
Anerror-correction code (ECC) not only detects the problem, but also
corrects it. The correction is done by using algorithms and extra amounts of
storage.Thecodes varybasedonhow much extrastoragetheyneedand how
manyerrorstheycancorrect.Forexample,disksdrivesuseper-sector ECCand"
2,11.5 Storage Device Management,587,11.4 Error Detection and Correction,"11.5 Storage Device Management 463
flash drives per-page ECC. When the controller writes a sector/page of data
duringnormal I/O,theECCiswrittenwithavaluecalculatedfromallthebytes
inthedatabeingwritten.Whenthesector/pageisread,the ECCisrecalculated
andcomparedwiththe storedvalue.If thestoredand calculatednumbers are
different, this mismatch indicates that the data have become corrupted and
thatthe storage mediamaybe bad (Section11.5.3).The ECCis error correcting
because it contains enough information, if only a few bits of data have been
corrupted, to enable the controller to identify which bits have changed and
calculatewhattheircorrectvaluesshouldbe.Itthenreportsarecoverable soft
error. If too many changes occur, and the ECCcannot correct the error, a non-
correctable hard error is signaled. The controller automatically does the ECC
processingwheneverasector orpageis reador written.
Error detection and correction are frequently differentiators between con-
sumer products and enterprise products. ECCis used in some systems for
DRAMerrorcorrectionand datapathprotection,forexample.
11.5 Storage Device Management
Theoperatingsystemisresponsibleforseveralotheraspectsofstoragedevice
management, too. Here, we discuss drive initialization, booting from a drive,
and bad-block recovery.
11.5.1 Drive Formatting, Partitions, and Volumes
Anewstoragedeviceisablankslate:itisjustaplatterofamagneticrecording
material or a set of uninitialized semiconductor storage cells. Before a storage
device can store data, it must be divided into sectors that the controller can
readandwrite. NVMpagesmustbeinitializedandthe FTLcreated.Thisprocess
is called low-level formatting ,o rphysical formatting . Low-level formatting
fillsthedevicewithaspecialdatastructureforeachstoragelocation.Thedata
structure for a sector or page typically consists of a header, a data area, and a
trailer.Theheaderandtrailercontain informationusedbythecontroller,such
asa sector/pagenumber and anerrordetectionorcorrectioncode.
Most drives are low-level-formatted at the factory as a part of the manu-
facturing process. This formatting enables the manufacturer to test the device
andtoinitializethemappingfromlogicalblocknumberstodefect-freesectors
orpagesonthemedia.Itisusuallypossibletochooseamongafewsectorsizes,
such as 512 bytes and 4KB. Formatting a disk with a larger sector size means
that fewer sectors can fit on each track, but it also means that fewer headers
andtrailersarewrittenoneachtrackandmorespaceisavailableforuserdata.
Someoperatingsystemscan handleonly one specific sectorsize.
Before it can use a drive to hold files, the operating system still needs to
recorditsown datastructuresonthedevice.Itdoessointhreesteps.
The first step is to partition the device into one or more groups of blocks
or pages. The operating system can treat each partition as though it were a
separatedevice.Forinstance,onepartitioncanholdafilesystemcontaining a
copy of the operating system’s executable code, another the swap space, and
another a file system containing the user files. Some operating systems and
filesystemsperformthepartitioningaut omaticallywhenanentiredeviceisto"
3,"11.5.1 Drive Formatting, Partitions, and Volumes",587,11.5 Storage Device Management,"11.5 Storage Device Management 463
flash drives per-page ECC. When the controller writes a sector/page of data
duringnormal I/O,theECCiswrittenwithavaluecalculatedfromallthebytes
inthedatabeingwritten.Whenthesector/pageisread,the ECCisrecalculated
andcomparedwiththe storedvalue.If thestoredand calculatednumbers are
different, this mismatch indicates that the data have become corrupted and
thatthe storage mediamaybe bad (Section11.5.3).The ECCis error correcting
because it contains enough information, if only a few bits of data have been
corrupted, to enable the controller to identify which bits have changed and
calculatewhattheircorrectvaluesshouldbe.Itthenreportsarecoverable soft
error. If too many changes occur, and the ECCcannot correct the error, a non-
correctable hard error is signaled. The controller automatically does the ECC
processingwheneverasector orpageis reador written.
Error detection and correction are frequently differentiators between con-
sumer products and enterprise products. ECCis used in some systems for
DRAMerrorcorrectionand datapathprotection,forexample.
11.5 Storage Device Management
Theoperatingsystemisresponsibleforseveralotheraspectsofstoragedevice
management, too. Here, we discuss drive initialization, booting from a drive,
and bad-block recovery.
11.5.1 Drive Formatting, Partitions, and Volumes
Anewstoragedeviceisablankslate:itisjustaplatterofamagneticrecording
material or a set of uninitialized semiconductor storage cells. Before a storage
device can store data, it must be divided into sectors that the controller can
readandwrite. NVMpagesmustbeinitializedandthe FTLcreated.Thisprocess
is called low-level formatting ,o rphysical formatting . Low-level formatting
fillsthedevicewithaspecialdatastructureforeachstoragelocation.Thedata
structure for a sector or page typically consists of a header, a data area, and a
trailer.Theheaderandtrailercontain informationusedbythecontroller,such
asa sector/pagenumber and anerrordetectionorcorrectioncode.
Most drives are low-level-formatted at the factory as a part of the manu-
facturing process. This formatting enables the manufacturer to test the device
andtoinitializethemappingfromlogicalblocknumberstodefect-freesectors
orpagesonthemedia.Itisusuallypossibletochooseamongafewsectorsizes,
such as 512 bytes and 4KB. Formatting a disk with a larger sector size means
that fewer sectors can fit on each track, but it also means that fewer headers
andtrailersarewrittenoneachtrackandmorespaceisavailableforuserdata.
Someoperatingsystemscan handleonly one specific sectorsize.
Before it can use a drive to hold files, the operating system still needs to
recorditsown datastructuresonthedevice.Itdoessointhreesteps.
The first step is to partition the device into one or more groups of blocks
or pages. The operating system can treat each partition as though it were a
separatedevice.Forinstance,onepartitioncanholdafilesystemcontaining a
copy of the operating system’s executable code, another the swap space, and
another a file system containing the user files. Some operating systems and
filesystemsperformthepartitioningaut omaticallywhenanentiredeviceisto"
3,11.5.2 Boot Block,589,"11.5.1 Drive Formatting, Partitions, and Volumes","11.5 Storage Device Management 465
Figure 11.9 Windows 7 Disk Management tool showing devices, partitions, volumes,
and file systems.
the exact location where each database record is stored. Raw I/Obypasses all
thefile-systemservices,suchasthebuffercache,filelocking,prefetching,space
allocation, file names, and directories.We can make certain applications more
efficient by allowing them to implement their own special-purpose storage
services on a raw partition, but most applications use a provided file system
rather than managing data themselves. Note that Linux generally does not
support raw I/Obut can achieve similar access by using the DIRECTflag to
theopen()systemcall.
11.5.2 Boot Block
For a computer to start running—for instance, when it is powered up or
rebooted—itmusthaveaninitialprogramtorun.Thisinitial bootstrap loader
tends to be simple. For most computers, the bootstrap is stored in NVMflash
memoryfirmwareonthesystemmotherboardandmappedtoaknown mem-
ory location. It can be updated by product manufacturers as needed, but also
can be written to by viruses, infecting the system. It initializes all aspects of
the system, from CPUregisters to device controllers and the contents of main
memory.
This tiny bootstrap loader program is also smart enough to bring in a
full bootstrap program from secondary storage. The full bootstrap program
is stored in the “boot blocks ”at a fixed location on the device. The default
Linuxbootstraploaderisgrub2( https://www.gnu.org/software/grub/manual/
grub.html/ ). Adevice that has a boot partition is called a boot disk orsystem
disk.
The code in the bootstrap NVMinstructs the storage controller to read the
boot blocks into memory (no devicedri versare loaded at this point) and then
starts executing that code. The full bootstrap program is more sophisticated
than the bootstrap loader: it is able to load the entire operating system from a
non-fixed location on the deviceand to startthe operatingsystemrunning.
Let’sconsider as anexamplethe boot processinWindows. First,note that
Windows allows a drive to be divided into partitions, and one partition—
identified as the boot partition —contains the operating system and device
drivers. The Windows system places its boot code in the first logical block on
the hard disk or first page of the NVMdevice, which it terms the master boot"
3,11.5.3 Bad Blocks,590,11.5.2 Boot Block,"466 Chapter 11 Mass-Storage Structure
MBR
partition 1
partition 2
partition 3
partition 4boot
code
partition
table
boot partition
Figure 11.10 Booting from a storage device in Windows.
record,orMBR.Bootingbeginsbyrunningcodethatisresidentinthesystem’s
firmware. This code directs the system to read the boot code from the MBR,
understanding just enough about the storage controller and storage device to
load a sector from it. In addition to containing boot code, the MBRcontains a
table listing the partitions for the drive and a flag indicating which partition
thesystemistobebootedfrom,asillustratedinFigure11.10.Oncethesystem
identifies the boot partition, it reads the first sector/page from that partition
(calledthe boot sector ),whichdirectsittothekernel.Itthencontinueswiththe
remainderofthebootprocess,whichinc ludesloadingthevarioussubsystems
and systemservices.
11.5.3 Bad Blocks
Because disks have moving parts and small tolerances (recall that the disk
headfliesjustabovethedisksurface),theyarepronetofailure.Sometimesthe
failure is complete; in this case, the disk needs to be replaced and its contents
restored from backup media to the new disk. More frequently, one or more
sectors become defective. Most disks even come from the factory with bad
blocks. Dependingon thediskand controllerinuse, theseblocks arehandled
ina varietyof ways.
On older disks, such as some disks with IDEcontrollers, bad blocks are
handled manually. One strategy is to scan the disk to find bad blocks while
the diskis being formatted.Any bad blocks that arediscoveredareflagged as
unusablesothatthefilesystemdoesnotallocatethem.Ifblocksgobadduring
normaloperation,aspecialprogram(suchastheLinux badblocks command)
mustberunmanuallytosearchforthebadblocksandtolockthemaway.Data
that residedon the bad blocks usuallyare lost.
More sophisticated disks are smarter about bad-block recovery. The con-
troller maintains a list of bad blocks on the disk. The list is initialized during
thelow-levelformattingatthefactoryandisupdatedoverthelifeofthedisk.
Low-level formatting also sets aside spare sectors not visible to the operating
system.Thecontrollercanbetoldtoreplaceeachbadsectorlogicallywithone
of thesparesectors.Thisscheme isknown as sector sparing orforwarding .
Atypicalbad-sectortransaction mightbe as follows:
•Theoperatingsystemtriestoreadlogicalblock 87."
2,11.6 Swap-Space Management,591,11.5 Storage Device Management,"11.6 Swap-Space Management 467
•Thecontrollercalculatesthe ECCandfindsthatthesectorisbad.Itreports
this finding to theoperatingsystemas an I/Oerror.
•The devicecontrollerreplacesthe badsector withaspare.
•After that, whenever the system requests logical block 87, the request is
translated into the replacementsector’s addressby the controller.
Note that such a redirection by the controller could invalidate any opti-
mizationbytheoperatingsystem’sdisk-schedulingalgorithm!Forthisreason,
most disks are formatted to provide a few spare sectors in each cylinder and
a spare cylinder as well. When a bad bloc k is remapped, the controller uses a
sparesector fromthe samecylinder,if possible.
As an alternative to sector sparing, some controllers can be instructed to
replaceabadblockby sector slipping .Hereisanexample:Supposethatlogical
block 17 becomes defective and the first available spare follows sector 202.
Sector slipping then remaps all the sectors from 17 to 202, moving them all
downonespot.Thatis,sector202iscopi edintothespare,thensector201into
202,then200into201,andsoon,untilsector18iscopiedintosector19.Slipping
the sectors in this way frees up the space of sector 18 so that sector 17 can be
mappedto it.
Recoverablesofterrorsmaytriggeradeviceactivityinwhichacopyofthe
block data is made and the block is sparedor slipped.An unrecoverable hard
error, however, results in lost data. Whatever file was using that block must
berepaired(forinstance,by restorationfromabackup tape),andthatrequires
manual intervention.
NVMdevicesalsohavebits,bytes,andevenpagesthateitherarenonfunc-
tionalatmanufacturingtimeorgobadovertime.Managementofthosefaulty
a r e a si ss i m p l e rt h a nf o r HDDs because there is no seek time performance loss
tobe avoided.Eithermultiplepagescanbe setasideand usedas replacement
locations, or space from the over-provisioning area can be used (decreasing
the usable capacity of the over-provisioning area). Either way, the controller
maintainsatableofbadpagesandneversetsthosepagesasavailabletowrite
to,sothey areneveraccessed.
11.6 Swap-Space Management
SwappingwasfirstpresentedinSection9.5,wherewediscussedmovingentire
processesbetweensecondarystorageandmainmemory.Swappinginthatset-
tingoccurswhentheamountofphysicalmemoryreachesacriticallylowpoint
andprocessesaremovedfrommemorytoswapspacetofreeavailablememory.
In practice, very few modern operating systems implement swapping in this
fashion. Rather, systems now combine swapping with virtual memory tech-
niques (Chapter 10) and swap pages, not necessarily entire processes. In fact,
some systems now use the terms “swapping ”and “paging ”interchangeably,
reflecting the merging of these two concepts.
Swap-space management is another low-level task of the operating sys-
tem. Virtual memory uses secondary storage space as an extension of main
memory. Since drive access is much slower than memory access, using swap"
3,11.6.1 Swap-Space Use,592,11.6 Swap-Space Management,"468 Chapter 11 Mass-Storage Structure
spacesignificantlydecreasessystemperf ormance.Themaingoalforthedesign
andimplementationofswapspaceistopr ovidethebestthroughputforthevir-
tualmemorysystem.Inthissection,wediscusshowswapspaceisused,where
swap spaceis locatedon storagedevices,and how swapspace ismanaged.
11.6.1 Swap-Space Use
Swapspaceisusedinvariouswaysbydifferentoperatingsystems,depending
on the memory-management algorithms in use. For instance, systems that
implement swapping may use swap space to hold an entire process image,
includingthecodeanddatasegments.Pagingsystemsmaysimplystorepages
thathavebeenpushedoutofmainmemory.Theamountofswapspaceneeded
onasystemcanthereforevaryfromafewmegabytesofdiskspacetogigabytes,
dependingontheamountofphysicalmemory,theamountofvirtualmemory
itisbacking, and the way in which the virtualmemoryisused.
Notethatitmaybesafertooverestimatethantounderestimatetheamount
of swap space required, because if a system runs out of swap space it may
be forced to abort processes or may crash entirely. Overestimation wastes
secondary storage space that could otherwise be used for files, but it does no
other harm. Some systems recommend the amount to be set aside for swap
space. Solaris, for example, suggests s etting swap space equal to the amount
by which virtual memory exceeds pageable physical memory. In the past,
Linux has suggested setting swap space to double the amount of physical
memory.Today,thepagingalgorithmshavechanged,andmostLinuxsystems
use considerably lessswap space.
Some operating systems—including Linux—allow the use of multiple
swap spaces, including both files and d edicated swap partitions. These swap
spaces are usually placed on separate storage devices so that the load placed
on theI/Osystem by paging and swapping can be spread over the system’s
I/Obandwidth.
11.6.2 Swap-Space Location
Aswapspacecanresideinoneoftwoplaces:itcanbecarvedoutofthenormal
filesystem,oritcanbeinaseparatepartition.Iftheswapspaceissimplyalarge
filewithin thefile system,normal file-systemroutinescan beusedto createit,
name it,and allocate itsspace.
Alternatively, swap space can be created in a separate raw partition .N o
file system or directory structure is pl aced in this space. Rather, a separate
swap-space storage manager is used to allocate and deallocate the blocks
from the raw partition. This manager uses algorithms optimized for speed
rather than for storage efficiency, because swap space is accessed much more
frequentlythanfilesystems,whenitisused(recallthatswapspaceisusedfor
swapping and paging). Internal fragmentation may increase, but this trade-
off is acceptable because the life of data in the swap space generally is much
shorter than that of files in the file system. Since swap space is reinitialized
at boot time, any fragmentation is short-lived. The raw-partition approach
creates a fixed amount of swap space during disk partitioning. Adding more
swap space requires either repartitioning the device (which involves moving"
3,11.6.2 Swap-Space Location,592,11.6.1 Swap-Space Use,"468 Chapter 11 Mass-Storage Structure
spacesignificantlydecreasessystemperf ormance.Themaingoalforthedesign
andimplementationofswapspaceistopr ovidethebestthroughputforthevir-
tualmemorysystem.Inthissection,wediscusshowswapspaceisused,where
swap spaceis locatedon storagedevices,and how swapspace ismanaged.
11.6.1 Swap-Space Use
Swapspaceisusedinvariouswaysbydifferentoperatingsystems,depending
on the memory-management algorithms in use. For instance, systems that
implement swapping may use swap space to hold an entire process image,
includingthecodeanddatasegments.Pagingsystemsmaysimplystorepages
thathavebeenpushedoutofmainmemory.Theamountofswapspaceneeded
onasystemcanthereforevaryfromafewmegabytesofdiskspacetogigabytes,
dependingontheamountofphysicalmemory,theamountofvirtualmemory
itisbacking, and the way in which the virtualmemoryisused.
Notethatitmaybesafertooverestimatethantounderestimatetheamount
of swap space required, because if a system runs out of swap space it may
be forced to abort processes or may crash entirely. Overestimation wastes
secondary storage space that could otherwise be used for files, but it does no
other harm. Some systems recommend the amount to be set aside for swap
space. Solaris, for example, suggests s etting swap space equal to the amount
by which virtual memory exceeds pageable physical memory. In the past,
Linux has suggested setting swap space to double the amount of physical
memory.Today,thepagingalgorithmshavechanged,andmostLinuxsystems
use considerably lessswap space.
Some operating systems—including Linux—allow the use of multiple
swap spaces, including both files and d edicated swap partitions. These swap
spaces are usually placed on separate storage devices so that the load placed
on theI/Osystem by paging and swapping can be spread over the system’s
I/Obandwidth.
11.6.2 Swap-Space Location
Aswapspacecanresideinoneoftwoplaces:itcanbecarvedoutofthenormal
filesystem,oritcanbeinaseparatepartition.Iftheswapspaceissimplyalarge
filewithin thefile system,normal file-systemroutinescan beusedto createit,
name it,and allocate itsspace.
Alternatively, swap space can be created in a separate raw partition .N o
file system or directory structure is pl aced in this space. Rather, a separate
swap-space storage manager is used to allocate and deallocate the blocks
from the raw partition. This manager uses algorithms optimized for speed
rather than for storage efficiency, because swap space is accessed much more
frequentlythanfilesystems,whenitisused(recallthatswapspaceisusedfor
swapping and paging). Internal fragmentation may increase, but this trade-
off is acceptable because the life of data in the swap space generally is much
shorter than that of files in the file system. Since swap space is reinitialized
at boot time, any fragmentation is short-lived. The raw-partition approach
creates a fixed amount of swap space during disk partitioning. Adding more
swap space requires either repartitioning the device (which involves moving"
3,11.6.3 Swap-Space Management: An Example,593,11.6.2 Swap-Space Location,"11.7 Storage Attachment 469
the other file-system partitions or destroying them and restoring them from
backup) or addinganother swap space elsewhere.
Some operating systems are flexible and can swap both in raw partitions
and in file-system space. Linux is an example: the policy and implementa-
tion are separate, allowing the machine’s administrator to decide which type
of swapping to use. The trade-off is between the convenience of allocation
and management in the file system and the performance of swapping in raw
partitions.
11.6.3 Swap-Space Management: An Example
We can illustrate how swap space is used by following the evolution of swap-
ping and paging in various UNIXsystems. The traditional UNIXkernel started
with an implementation of swapping that copied entire processes between
contiguous disk regions and memory. UNIXlater evolved to a combination of
swappingand paging aspaging hardware became available.
In Solaris 1 ( SunOS), the designers changed standard UNIXmethods to
improve efficiency and reflect technological developments. When a process
executes, text-segment pages containing code are brought in from the file
system, accessed in main memory, and thrown away if selected for pageout.
It is more efficient to reread a page from the file system than to write it to
swapspaceandthenrereaditfromthere.Swapspaceisonlyusedasabacking
storeforpagesof anonymous memory(memorynotbackedbyanyfile),which
includes memory allocated for the stack, heap, and uninitialized data of a
process.
More changes were made in later versions of Solaris. The biggest change
is that Solaris now allocates swap space only when a page is forced out of
physical memory, rather than when the v irtual memory page is first created.
Thisschemegivesbetterperformanceonmoderncomputers,whichhavemore
physicalmemorythan oldersystemsand tendtopageless.
Linux is similar to Solaris in that swap space is now used only for anony-
mousmemory.Linuxallowsoneormoreswapareastobeestablished.Aswap
area may be in either a swap file on a regular file system or a dedicated swap
partition.Eachswapareaconsistsofaseriesof4- KBpage slots ,whichareused
to hold swapped pages. Associated with each swap area is a swap map —an
array of integer counters, each corresponding to a page slot in the swap area.
If the value of a counter is 0, the corresponding page slot is available. Values
greater than 0 indicate that the page slot is occupied by a swapped page. The
value of the counter indicates the number of mappings to the swapped page.
For example, a value of 3 indicates that the swapped page is mapped to three
differentprocesses(whichcanoccuriftheswappedpageisstoringaregionof
memorysharedbythreeprocesses).ThedatastructuresforswappingonLinux
systemsareshown inFigure11.11.
11.7 Storage Attachment
Computers access secondary storage in three ways: via host-attached storage,
network-attachedstorage,and cloudstorage."
2,11.7 Storage Attachment,593,11.6 Swap-Space Management,"11.7 Storage Attachment 469
the other file-system partitions or destroying them and restoring them from
backup) or addinganother swap space elsewhere.
Some operating systems are flexible and can swap both in raw partitions
and in file-system space. Linux is an example: the policy and implementa-
tion are separate, allowing the machine’s administrator to decide which type
of swapping to use. The trade-off is between the convenience of allocation
and management in the file system and the performance of swapping in raw
partitions.
11.6.3 Swap-Space Management: An Example
We can illustrate how swap space is used by following the evolution of swap-
ping and paging in various UNIXsystems. The traditional UNIXkernel started
with an implementation of swapping that copied entire processes between
contiguous disk regions and memory. UNIXlater evolved to a combination of
swappingand paging aspaging hardware became available.
In Solaris 1 ( SunOS), the designers changed standard UNIXmethods to
improve efficiency and reflect technological developments. When a process
executes, text-segment pages containing code are brought in from the file
system, accessed in main memory, and thrown away if selected for pageout.
It is more efficient to reread a page from the file system than to write it to
swapspaceandthenrereaditfromthere.Swapspaceisonlyusedasabacking
storeforpagesof anonymous memory(memorynotbackedbyanyfile),which
includes memory allocated for the stack, heap, and uninitialized data of a
process.
More changes were made in later versions of Solaris. The biggest change
is that Solaris now allocates swap space only when a page is forced out of
physical memory, rather than when the v irtual memory page is first created.
Thisschemegivesbetterperformanceonmoderncomputers,whichhavemore
physicalmemorythan oldersystemsand tendtopageless.
Linux is similar to Solaris in that swap space is now used only for anony-
mousmemory.Linuxallowsoneormoreswapareastobeestablished.Aswap
area may be in either a swap file on a regular file system or a dedicated swap
partition.Eachswapareaconsistsofaseriesof4- KBpage slots ,whichareused
to hold swapped pages. Associated with each swap area is a swap map —an
array of integer counters, each corresponding to a page slot in the swap area.
If the value of a counter is 0, the corresponding page slot is available. Values
greater than 0 indicate that the page slot is occupied by a swapped page. The
value of the counter indicates the number of mappings to the swapped page.
For example, a value of 3 indicates that the swapped page is mapped to three
differentprocesses(whichcanoccuriftheswappedpageisstoringaregionof
memorysharedbythreeprocesses).ThedatastructuresforswappingonLinux
systemsareshown inFigure11.11.
11.7 Storage Attachment
Computers access secondary storage in three ways: via host-attached storage,
network-attachedstorage,and cloudstorage."
3,11.7.1 Host-Attached Storage,594,11.7 Storage Attachment,"470 Chapter 11 Mass-Storage Structure
swap area
page
slot
swap partition
or swap file 
swap map 10301
Figure 11.11 The data structures for swapping on Linux systems.
11.7.1 Host-Attached Storage
Host-attached storage isstorageaccessedthroughlocal I/Oports.Theseports
use several technologies, the most common being SATA, as mentioned earlier.
Atypicalsystemhas oneor a few SATAports.
To allow a system to gain access to more storage, either an individual
storage device, a device in a chassis, or multiple drives in a chassis can be
connected via USBFireWireor Thunderboltportsand cables.
High-end workstations and servers generally need more storage or need
to share storage, so use more sophisticated I/Oarchitectures, such as fibr
channel (FC),ahigh-speedserialarchitecturethatcanoperateoveropticalfiber
or overa four-conductor coppercable.B ecauseof the largeaddressspaceand
theswitchednatureofthecommunication ,multiplehostsandstoragedevices
can attach to the fabric, allowing greatflexibilityin I/Ocommunication.
A wide variety of storage devices are suitable for use as host-attached
storage. Among these are HDDs;NVMdevices; CD,DVD,B l u - r a y ,a n dt a p e
drives; and storage-area networks ( SANs) (discussed in Section 11.7.4). The
I/Ocommandsthatinitiatedatatransferstoahost-attachedstoragedeviceare
readsandwritesoflogicaldatablocksdirectedtospecificallyidentifiedstorage
units (such as bus IDortargetlogicalunit).
11.7.2 Network-Attached Storage
Network-attached storage (NAS) (Figure 11.12) provides access to storage
acrossanetwork.An NASdevicecanbeeitheraspecial-purposestoragesystem
or a general computer system that provides its storage to other hosts across
thenetwork.Clientsaccessnetwork-attachedstorageviaaremote-procedure-
call interface such as NFSforUNIXand Linux systems or CIFSfor Windows
machines. The remote procedure calls ( RPCs) are carried via TCPorUDPover
anIPnetwork—usuallythesamelocal-areanetwork( LAN)thatcarriesalldata
traffictotheclients.Thenetwork-attachedstorageunitisusuallyimplemented
as a storage arraywith software thatimplementsthe RPCinterface.
CIFSandNFSprovidevariouslockingfeatures,allowingthesharingoffiles
betweenhostsaccessinga NASwiththoseprotocols.Forexample,auserlogged
intomultiple NASclientscanaccessherhomedirectoryfromallofthoseclients,
simultaneously."
3,11.7.2 Network-Attached Storage,594,11.7.1 Host-Attached Storage,"470 Chapter 11 Mass-Storage Structure
swap area
page
slot
swap partition
or swap file 
swap map 10301
Figure 11.11 The data structures for swapping on Linux systems.
11.7.1 Host-Attached Storage
Host-attached storage isstorageaccessedthroughlocal I/Oports.Theseports
use several technologies, the most common being SATA, as mentioned earlier.
Atypicalsystemhas oneor a few SATAports.
To allow a system to gain access to more storage, either an individual
storage device, a device in a chassis, or multiple drives in a chassis can be
connected via USBFireWireor Thunderboltportsand cables.
High-end workstations and servers generally need more storage or need
to share storage, so use more sophisticated I/Oarchitectures, such as fibr
channel (FC),ahigh-speedserialarchitecturethatcanoperateoveropticalfiber
or overa four-conductor coppercable.B ecauseof the largeaddressspaceand
theswitchednatureofthecommunication ,multiplehostsandstoragedevices
can attach to the fabric, allowing greatflexibilityin I/Ocommunication.
A wide variety of storage devices are suitable for use as host-attached
storage. Among these are HDDs;NVMdevices; CD,DVD,B l u - r a y ,a n dt a p e
drives; and storage-area networks ( SANs) (discussed in Section 11.7.4). The
I/Ocommandsthatinitiatedatatransferstoahost-attachedstoragedeviceare
readsandwritesoflogicaldatablocksdirectedtospecificallyidentifiedstorage
units (such as bus IDortargetlogicalunit).
11.7.2 Network-Attached Storage
Network-attached storage (NAS) (Figure 11.12) provides access to storage
acrossanetwork.An NASdevicecanbeeitheraspecial-purposestoragesystem
or a general computer system that provides its storage to other hosts across
thenetwork.Clientsaccessnetwork-attachedstorageviaaremote-procedure-
call interface such as NFSforUNIXand Linux systems or CIFSfor Windows
machines. The remote procedure calls ( RPCs) are carried via TCPorUDPover
anIPnetwork—usuallythesamelocal-areanetwork( LAN)thatcarriesalldata
traffictotheclients.Thenetwork-attachedstorageunitisusuallyimplemented
as a storage arraywith software thatimplementsthe RPCinterface.
CIFSandNFSprovidevariouslockingfeatures,allowingthesharingoffiles
betweenhostsaccessinga NASwiththoseprotocols.Forexample,auserlogged
intomultiple NASclientscanaccessherhomedirectoryfromallofthoseclients,
simultaneously."
3,11.7.3 Cloud Storage,595,11.7.2 Network-Attached Storage,"11.7 Storage Attachment 471
NASclient
NAS
clientclientLAN/WAN
Figure 11.12 Network-attached storage.
Network-attachedstorageprovidesaconvenientwayforallthecomputers
on aLANto share a pool of storage with the same ease of naming and access
enjoyed with local host-attached storage. However, it tends to be less efficient
andhave lowerperformancethan somedirect-attachedstorageoptions.
iSCSIisthelatestnetwork-attachedstorageprotocol.Inessence,itusesthe
IPnetwork protocol to carry the SCSIprotocol. Thus, networks—rather than
SCSIcables—canbeusedastheinterconnectsbetweenhostsandtheirstorage.
As a result, hosts can treat their storage as if it were directly attached, even if
thestorageisdistantfromthehost.Whereas NFSandCIFSpresentafilesystem
andsendpartsoffilesacrossthenetwork, iSCSIsendslogicalblocksacrossthe
network and leaves it to the client to use the blocks directly or create a file
systemwiththem.
11.7.3 Cloud Storage
Section 1.10.5 discussed cloud computing. One offering from cloud providers
iscloud storage . Similar to network-attached storage, cloud storage provides
accesstostorageacrossanetwork.Unlike NAS,thestorageisaccessedoverthe
Internetoranother WANtoaremotedatacenterthatprovidesstorageforafee
(orevenfor free).
Another difference between NASand cloud storage is how the storage is
accessed and presented to users. NASis accessed as just another file system if
theCIFSorNFSprotocolsareused,orasarawblockdeviceifthe iSCSIprotocolis
used.Mostoperatingsystemshavetheseprotocolsintegratedandpresent NAS
storageinthesamewayasotherstorage.Incontrast,cloudstorageis APIbased,
andprogramsusethe APIstoaccessthestorage.Amazon S3isaleadingcloud
storage offering. Dropbox is an example of a company that provides apps to
connecttothecloudstoragethatitprovides.OtherexamplesincludeMicrosoft
OneDriveand AppleiCloud.
One reason that APIs are used instead of existing protocols is the latency
and failure scenarios of a WAN.NASprotocols were designed for use in LANs,
whichhavelowerlatencythan WANsandaremuchlesslikelytoloseconnectiv-
ity between the storage user and the storage device. If a LANconnection fails,
a system using NFSorCIFSmight hang until it recovers. With cloud storage,
failures like that are more likely, so an application simply pauses access until
connectivityisrestored."
2,11.7.4 Storage-Area Networks and Storage Arrays,596,11.7 Storage Attachment,"472 Chapter 11 Mass-Storage Structure
LAN/WAN
storage
arraystorage
array
data-processing
center
web content
providerserverclient
client
clientserver
tape
librarySAN
Figure 11.13 Storage-area network.
11.7.4 Storage-Area Networks and Storage Arrays
One drawback of network-attached storage systems is that the storage I/O
operations consume bandwidth on the data network, thereby increasing the
latency of network communication. This problem can be particularly acute
in large client–server installations— the communication between servers and
clients competes for bandwidth with the communication among servers and
storagedevices.
Astorage-area network (SAN)isaprivatenetwork(usingstorageprotocols
rather than networking protocols) connecting servers and storage units, as
shown in Figure 11.13. The powerof a SANliesinitsflexibility.Multiplehosts
and multiple storage arrays can attach to the same SAN, and storage can be
dynamically allocated to hosts. The storage arrays can be RAIDprotected or
unprotected drives ( Just a Bunch of Disks (JBOD)). ASANswitch allows or
prohibitsaccessbetweenthehostsandthestorage.Asoneexample,ifahostis
runninglowondiskspace,the SANcanbeconfiguredtoallocatemorestorage
to that host. SANs make it possible for clusters of servers to share the same
storage and for storage arrays to include multiple direct host connections.
SANs typically have more ports—and cost more—than storage arrays. SAN
connectivity isovershort distancesand typicallyhas no routing,so a NAScan
have many more connected hosts than a SAN.
A storage array is a purpose-built device (see Figure 11.14) that includes
SANports,networkports,orboth.Italsocontainsdrivestostoredataandacon-
troller(orredundantsetofcontrollers)tomanagethestorageandallowaccess
to the storage across the networks. The controllers are composed of CPUs,
memory, and software that implement the features of the array, which can
include network protocols, user interfaces, RAIDprotection, snapshots, repli-
cation, compression, deduplication, and encryption. Some of those functions
arediscussedinChapter14.
Somestoragearraysinclude SSDs.Anarraymaycontain only SSDs,result-
ing in maximum performance but smaller capacity, or may include a mix of
SSDsa n dHDDs, with the array software (or the administrator) selecting the
best medium for a given use or using the SSDs as a cache and HDDsa sb u l k
storage."
2,11.8 RAID Structure,597,11.7.4 Storage-Area Networks and Storage Arrays,"11.8 RAID Structure 473
Figure 11.14 A storage array.
FCis the most common SANinterconnect, although the simplicity of i SCSI
is increasing its use. Another SANinterconnect is InfiniBan (IB)—aspecial-
purpose bus architecture that provides hardware and software support for
high-speedinterconnection networksfor serversand storage units.
11.8 RAID Structure
Storage devices have continued to get smaller and cheaper, so it is now eco-
nomically feasible to attach many drives to a computer system. Having a
large number of drives in a system presents opportunities for improving the
rate at which data can be read or written, if the drives are operated in paral-
lel. Furthermore, this setup offers the potential for improving the reliability
of data storage, because redundant information can be stored on multiple
drives. Thus, failure of one drive does not lead to loss of data. A variety of
disk-organization techniques, collectively called redundant arrays of inde-
pendent disks (RAIDs), are commonly used to address the performance and
reliabilityissues.
In the past, RAIDs composed of small, cheap disks were viewed as a cost-
effective alternative to large, expensive disks. Today, RAIDsa r eu s e df o rt h e i r
higher reliability and higher data-transfer rate rather than for economic rea-
sons.Hence,the IinRAID ,whichoncestoodfor “inexpensive, ”nowstandsfor
“independent. ”
11.8.1 Improvement of Reliability via Redundancy
Let’sfirstconsiderthereliabilityofa RAIDofHDDs.Thechancethatsomedisk
out of a set of Ndisks will fail is much greater than the chance that a specific
single disk will fail. Suppose that the mean time between failures (MTBF)o f
a single disk is 100,000 hours. Then the MTBFof some disk in an array of 100"
3,11.8.1 Improvement of Reliability via Redundancy,597,11.8 RAID Structure,"11.8 RAID Structure 473
Figure 11.14 A storage array.
FCis the most common SANinterconnect, although the simplicity of i SCSI
is increasing its use. Another SANinterconnect is InfiniBan (IB)—aspecial-
purpose bus architecture that provides hardware and software support for
high-speedinterconnection networksfor serversand storage units.
11.8 RAID Structure
Storage devices have continued to get smaller and cheaper, so it is now eco-
nomically feasible to attach many drives to a computer system. Having a
large number of drives in a system presents opportunities for improving the
rate at which data can be read or written, if the drives are operated in paral-
lel. Furthermore, this setup offers the potential for improving the reliability
of data storage, because redundant information can be stored on multiple
drives. Thus, failure of one drive does not lead to loss of data. A variety of
disk-organization techniques, collectively called redundant arrays of inde-
pendent disks (RAIDs), are commonly used to address the performance and
reliabilityissues.
In the past, RAIDs composed of small, cheap disks were viewed as a cost-
effective alternative to large, expensive disks. Today, RAIDsa r eu s e df o rt h e i r
higher reliability and higher data-transfer rate rather than for economic rea-
sons.Hence,the IinRAID ,whichoncestoodfor “inexpensive, ”nowstandsfor
“independent. ”
11.8.1 Improvement of Reliability via Redundancy
Let’sfirstconsiderthereliabilityofa RAIDofHDDs.Thechancethatsomedisk
out of a set of Ndisks will fail is much greater than the chance that a specific
single disk will fail. Suppose that the mean time between failures (MTBF)o f
a single disk is 100,000 hours. Then the MTBFof some disk in an array of 100"
3,11.8.2 Improvement in Performance via Parallelism,599,11.8.1 Improvement of Reliability via Redundancy,"11.8 RAID Structure 475
protectedfromdatalossduringpowerfailures,sothewritecanbeconsidered
complete at that point, assuming the cache has some kind of error protection
and correction, such as ECCor mirroring.
11.8.2 Improvement in Performance via Parallelism
Now let’s consider how parallel access to multiple drives improves perfor-
mance. With mirroring, the rate at which read requests can be handled is
doubled, since read requests can be sent to either drive (as long as both in a
pairarefunctional,asisalmostalwaysthecase).Thetransferrateofeachread
is the same as in a single-drive system, but the number of reads per unit time
has doubled.
Withmultipledrives,wecanimprovethetransferrateaswell(orinstead)
by striping data across the drives. In its simplest form, data striping consists
of splitting the bits of each byte across multiple drives; such striping is called
bit-level striping . For example, if we have an array of eight drives, we write
bitiof each byte to drive i.The array of eight drives can be treated as a single
drive with sectors that are eight times the normal size and, more important,
haveeighttimestheaccess rate.Everydriveparticipatesineveryaccess (read
or write);so the number of accesses that can be processed per second is about
thesameasonasingledrive,buteachaccesscanreadeighttimesasmanydata
inthe sametimeasona singledrive.
Bit-level striping can be generalized to include a number of drives that
either is a multiple of 8 or divides 8. For example, if we use an array of four
drives,bits iand4+iofeachbytegotodrive i.Further,stripingneednotoccur
atthebit level.In block-level striping ,forinstance, blocksof afilearestriped
acrossmultipledrives;with ndrives,block iofafilegoestodrive( imod n)+1.
Other levelsof striping, such as bytes of a sector or sectors of a block, also are
possible.Block-levelstripingis theonly commonly availablestriping.
Parallelisminastoragesystem,asachievedthroughstriping,hastwomain
goals:
1.Increasethethroughputofmultiplesmallaccesses(thatis,pageaccesses)
by load balancing.
2.Reducetheresponsetimeoflargeaccesses.
11.8.3 RAID Levels
Mirroring provides high reliability, but it is expensive. Striping provides high
data-transfer rates, but it does not improve reliability. Numerous schemes
to provide redundancy at lower cost by using disk striping combined with
“parity ”bits (which we describe shortly) ha ve been proposed. These schemes
have different cost–performance trade-offs and are classified according to
levels called RAID levels. We describe only the most common levels here;
Figure 11.15 shows them pictorially (in the figure, Pindicates error-correcting
bits and Cindicates a second copy of the data). In all cases depicted in the
figure, four drives’ worth of data are stored, and the extra drives are used to
storeredundantinformation forfailurerecovery."
3,11.8.3 RAID Levels,599,11.8.2 Improvement in Performance via Parallelism,"11.8 RAID Structure 475
protectedfromdatalossduringpowerfailures,sothewritecanbeconsidered
complete at that point, assuming the cache has some kind of error protection
and correction, such as ECCor mirroring.
11.8.2 Improvement in Performance via Parallelism
Now let’s consider how parallel access to multiple drives improves perfor-
mance. With mirroring, the rate at which read requests can be handled is
doubled, since read requests can be sent to either drive (as long as both in a
pairarefunctional,asisalmostalwaysthecase).Thetransferrateofeachread
is the same as in a single-drive system, but the number of reads per unit time
has doubled.
Withmultipledrives,wecanimprovethetransferrateaswell(orinstead)
by striping data across the drives. In its simplest form, data striping consists
of splitting the bits of each byte across multiple drives; such striping is called
bit-level striping . For example, if we have an array of eight drives, we write
bitiof each byte to drive i.The array of eight drives can be treated as a single
drive with sectors that are eight times the normal size and, more important,
haveeighttimestheaccess rate.Everydriveparticipatesineveryaccess (read
or write);so the number of accesses that can be processed per second is about
thesameasonasingledrive,buteachaccesscanreadeighttimesasmanydata
inthe sametimeasona singledrive.
Bit-level striping can be generalized to include a number of drives that
either is a multiple of 8 or divides 8. For example, if we use an array of four
drives,bits iand4+iofeachbytegotodrive i.Further,stripingneednotoccur
atthebit level.In block-level striping ,forinstance, blocksof afilearestriped
acrossmultipledrives;with ndrives,block iofafilegoestodrive( imod n)+1.
Other levelsof striping, such as bytes of a sector or sectors of a block, also are
possible.Block-levelstripingis theonly commonly availablestriping.
Parallelisminastoragesystem,asachievedthroughstriping,hastwomain
goals:
1.Increasethethroughputofmultiplesmallaccesses(thatis,pageaccesses)
by load balancing.
2.Reducetheresponsetimeoflargeaccesses.
11.8.3 RAID Levels
Mirroring provides high reliability, but it is expensive. Striping provides high
data-transfer rates, but it does not improve reliability. Numerous schemes
to provide redundancy at lower cost by using disk striping combined with
“parity ”bits (which we describe shortly) ha ve been proposed. These schemes
have different cost–performance trade-offs and are classified according to
levels called RAID levels. We describe only the most common levels here;
Figure 11.15 shows them pictorially (in the figure, Pindicates error-correcting
bits and Cindicates a second copy of the data). In all cases depicted in the
figure, four drives’ worth of data are stored, and the extra drives are used to
storeredundantinformation forfailurerecovery."
3,11.8.4 Selecting a RAID Level,604,11.8.3 RAID Levels,"480 Chapter 11 Mass-Storage Structure
accepts commands from the servers and manages access to the storage.
It could provide mirroring, for example, by writing each block to two
separatestoragedevices.
Other features, such as snapshots and replication, can be implemented at
each of these levels as well. A snapshot is a view of the file system before the
lastupdatetookplace.(SnapshotsarecoveredmorefullyinChapter14.) Repli-
cationinvolves the automatic duplication o f writes betweenseparate sites for
redundancy and disaster recovery. Replication can be synchronous or asyn-
chronous. In synchronous replication, each block must be written locally and
remotely before the write is considered complete, whereas in asynchronous
replication, the writes are grouped together and written periodically. Asyn-
chronous replication can result in data loss if the primary site fails, but it is
faster and has no distance limitations. Increasingly, replication is also used
within a data center or even within a host. As an alternative to RAIDprotec-
tion,replicationprotectsagainstdatalo ssandalsoincreasesreadperformance
(by allowing readsfrom each of the replicacopies).Itdoesof course use more
storagethan mosttypesof RAID.
The implementation of these features differs depending on the layer at
whichRAIDisimplemented.Forexample,if RAIDisimplementedinsoftware,
then each host may need to carry out and manage its own replication. If
replication is implemented in the storage array or in the SANinterconnect,
however, then whatever the host operating system or its features, the host’s
datacan be replicated.
One other aspect of most RAIDimplementations is a hot spare drive or
drives. A hot spare is not used for data but is configured to be used as a
replacement in case of drive failure. For instance, a hot spare can be used to
rebuildamirroredpairshouldoneofthedrivesinthepairfail.Inthisway,the
RAIDlevel can be reestablished automatically, without waiting for the failed
drivetobereplaced.Allocatingmorethanonehotspareallowsmorethanone
failuretobe repairedwithout human intervention.
11.8.4 Selecting a RAID Level
Given the many choices they have, how do system designers choose a RAID
level? One consideration is rebuild performance. If a drive fails, the time
needed to rebuild its data can be significant. This may be an important factor
if a continuous supply of data is required, as it is in high-performance or
interactivedatabasesystems.Furthermore,rebuildperformanceinfluencesthe
meantimebetweenfailures.
Rebuildperformancevarieswiththe RAIDlevelused.Rebuildingiseasiest
forRAIDlevel 1, since data can be copied from another drive. For the other
levels, we need to access all the other drives in the array to rebuild data in a
faileddrive.Rebuildtimescanbehoursfor RAIDlevel5rebuildsoflargedrive
sets.
RAIDlevel 0 is used in high-performance applications where data loss is
not critical. For example, in scientific computing where a data set is loaded
and explored, RAIDlevel 0 works well because any drive failures would just
require a repair and reloading of the data from its source. RAIDlevel 1 is
popular for applications that requir e high reliability with fast recovery. RAID"
3,11.8.5 Extensions,605,11.8.4 Selecting a RAID Level,"11.8 RAID Structure 481
THE InServ STORAGE ARRAY
Innovation,inanefforttoprovidebetter,faster,andlessexpensivesolutions,
frequentlyblursthelinesthatseparate dprevioustechnologies.Considerthe
InServ storage array from HP3Par. Unlike most other storage arrays, InServ
does not require that a set of drives be configured at a specific RAIDlevel.
Rather,eachdriveisbrokeninto256- MB“chunklets. ”RAIDisthenappliedat
thechunkletlevel.Adrivecanthusparticipateinmultipleandvarious RAID
levelsas its chunkletsare used formultiple volumes.
InServ also provides snapshots similar to those created by the WAFLfile
system. The format of InServ snapshots can be read–write as well as read-
only, allowing multiple hosts to mount copies of a given file system without
needingtheirowncopiesoftheentire filesystem.Anychangesahostmakes
initsowncopyarecopy-on-writeandsoarenotreflectedintheothercopies.
A further innovation is utility storage . Some file systems do not expand
orshrink.Onthesesystems,theorigin alsizeistheonlysize,andanychange
requires copying data. An administrator can configure InServ to provide a
host with a large amount of logical storage that initially occupies only a
smallamountofphysicalstorage.Asthe hoststartsusingthestorage,unused
drivesareallocatedtothehost,uptot heoriginallogical level.Thehostthus
canbelievethatithasalargefixedstoragespace,createitsfilesystemsthere,
andsoon.DrivescanbeaddedtoorremovedfromthefilesystembyInServ
without the file system’s noticing the change. This feature can reduce the
number of drives needed by hosts, or at least delay the purchase of drives
until theyarereallyneeded.
0 +1 and 1 +0 are usedwhere both performanceand reliabilityareimportant
—for example, for small databases. Due to RAID1’s high space overhead,
RAID5 is often preferred for storing moderate volumes of data. RAID6a n d
multidimensional RAID6arethemostcommonformatsinstoragearrays.They
offergoodperformance andprotection without largespace overhead.
RAIDsystemdesignersandadministratorsofstoragehavetomakeseveral
other decisions as well. For example, how many drives should be in a given
RAIDset?Howmanybitsshouldbeprotectedbyeachparitybit?Ifmoredrives
areinanarray,data-transferratesarehigher,butthesystemismoreexpensive.
Ifmorebitsareprotectedbyaparitybit,thespaceoverheadduetoparitybits
islower,butthechancethataseconddri vewillfailbeforethefirstfaileddrive
isrepairedisgreater,and that willresultindata loss.
11.8.5 Extensions
Theconceptsof RAIDhavebeengeneralizedtootherstoragedevices,including
arraysoftapes,andeventothebroadcastofdataoverwirelesssystems.When
appliedto arrays of tapes, RAIDstructures are able to recoverdata evenif one
ofthetapesinanarrayisdamaged.Whenappliedtobroadcastofdata,ablock
ofdataissplitintoshortunitsandisbroadcastalongwithaparityunit.Ifone
oftheunitsisnotreceivedforanyreason,itcanbereconstructedfromtheother"
3,11.8.6 Problems with RAID,606,11.8.5 Extensions,"482 Chapter 11 Mass-Storage Structure
units.Commonly,tape-driverobotscontainingmultipletapedriveswillstripe
dataacross all thedrivestoincreasethroughput and decreasebackup time.
11.8.6 Problems with RAID
Unfortunately, RAIDdoes not always assure that data are available for the
operatingsystemanditsusers.Apointertoafilecouldbewrong,forexample,
orpointerswithin thefilestructurecouldbewrong. Incompletewrites(called
“torn writes ”), if not properly recovered, could result in corrupt data. Some
otherprocesscouldaccidentallywriteoverafilesystem’sstructures,too. RAID
protects against physical media errors, but not other hardware and software
errors.Afailureof thehardware RAIDcontroller,orabuginthesoftware RAID
code, could result in total data loss. As large as is the landscape of software
and hardware bugs, that is how numerous are the potential perils for data on
a system.
The Solaris ZFSfile system takes an innovative approach to solving these
problems through the use of checksums. ZFSmaintains internal checksums
of all blocks, including data and metadata. These checksums are not kept
with the block that is being checksummed. Rather, they are stored with the
pointer to that block. (See Figure 11.17.) Consider an inode—adatastructure
for storing file system metadata—with pointers to its data. Within the inode
is the checksum of each block of data. If there is a problem with the data,
the checksum will be incorrect, and the file system will know about it. If the
data are mirrored, and there is a block with a correct checksum and one with
an incorrect checksum, ZFSwill automatically update the bad block with the
good one. Similarly, the directory entry that points to the inode has a check-
sum for the inode. Any problem in the inode is detected when the directory
is accessed. This checksumming takes places throughout all ZFSstructures,
providing a much higher level of consistency, error detection, and error cor-
metadata block 1
address 1
checksum MB2 checksumaddress 2
metadata block 2
address
checksum D1 checksum D2
data 1 data 2address
Figure 11.17 ZFS checksums all metadata and data."
3,11.8.7 Object Storage,607,11.8.6 Problems with RAID,"11.8 RAID Structure 483
rection than is found in RAIDdrive sets or standard file systems. The extra
overhead that is created by the checksum calculation and extra block read-
modify-writecyclesisnotnoticeablebecausetheoverallperformanceof ZFSis
veryfast.(Asimilarchecksum feature is found in the Linux BTRFSfile system.
Seehttps://btrfs.wiki.kern el.org/index.php/Btrfs
 design.)
Another issue with most RAIDimplementations is lack of flexibility. Con-
sider a storage array with twenty drives divided into four sets of five drives.
Each set of five drives is a RAIDlevel 5 set. As a result, there are four separate
volumes, each holding a file system. But what if one file system is too large
to fit on a five-drive RAIDlevel 5 set? And what if another file system needs
very little space? If such factors are known ahead of time, then the drives and
volumes can be properly allocated. Very frequently, however, drive use and
requirementschange overtime.
Even if the storage array allowed the entire set of twenty drives to be
created as one large RAIDset, other issues could arise. Several volumes of
various sizes could be built on the set. But some volume managers do not
allowustochangeavolume’ssize.Inthatcase,wewouldbeleftwiththesame
issuedescribedabove—mismatchedfile-systemsizes.Somevolumemanagers
allow size changes, but some file systems do not allow for file-system growth
orshrinkage.Thevolumescouldchangesizes,butthefilesystemswouldneed
tobe recreatedto take advantage of those changes.
ZFScombines file-system management and volume management into a
unit providing greater functionality than the traditional separation of those
functionsallows.Drives,orpartitionsofdrives,aregatheredtogethervia RAID
sets into poolsof storage. A pool can hold one or more ZFSfile systems. The
entirepool’sfreespaceisavailabletoallfilesystemswithinthatpool. ZFSuses
the memory model of malloc() andfree()to allocate and release storage
for each file system as blocks are used and freed within the file system. As
a result, there are no artificial limits on storage use and no need to relocate
file systems between volumes or resize volumes. ZFSprovides quotas to limit
the size of a file system and reservations to assure that a file system can grow
by a specified amount, but those variables can be changed by the file-system
owneratanytime.OthersystemslikeLinuxhavevolumemanagersthatallow
thelogicaljoiningofmultiplediskstocreatelarger-than-diskvolumestohold
largefilesystems.Figure11.18(a)depictstraditionalvolumesandfilesystems,
and Figure 11.18(b) shows the ZFSmodel.
11.8.7 Object Storage
General-purposecomputerstypicallyusefilesystemstostorecontentforusers.
Another approach to data storage is to start with a storage pool and place
objects in that pool. This approach differs from file systems in that there is
no way to navigate the pool and find those objects. Thus, rather than being
user-oriented, object storage is computer-oriented, designed to be used by
programs.Atypicalsequenceis:
1.Createan object within thestoragepool,and receivean object ID.
2.Accessthe objectwhen neededviathe object ID.
3.Deletethe object viatheobject ID."
2,11.9 Summary,609,11.8 RAID Structure,"Practice Exercises 485
Forthehistoryofobjectstoressee http://www.theregister.co.uk/2016/07/15
/the
 history
 boys
 cas
and
 object
 storage
 map.
11.9 Summary
•Harddiskdrivesandnonvolatilememorydevicesarethemajorsecondary
storage I/Ounits on most computers. Modern secondary storage is struc-
turedaslargeone-dimensionalarrays of logicalblocks.
•Drivesofeithertypemaybeattachedtoacomputersysteminoneofthree
ways: (1) through the local I/Oports on the host computer, (2) directly
connected to motherboards, or (3) through a communications network or
storage network connection.
•Requests for secondary storage I/Oare generated by the file system and
by the virtual memory system. Each request specifies the address on the
deviceto bereferencedintheform of alogical block number.
•Disk-schedulingalgorithmscanimprovetheeffectivebandwidthof HDDs,
the average response time, and the variance in response time. Algo-
rithms such as SCANandC-SCANare designed to make such improve-
ments through strategies for disk-queue ordering. Performance of disk-
schedulingalgorithmscanvarygreatlyonharddisks.Incontrast,because
solid-state disks have no moving parts, performance varies little among
scheduling algorithms,and quiteoftenasimple FCFSstrategyis used.
•Datastorageandtransmissionarecomplexandfrequentlyresultinerrors.
Error detection attempts to spot such problems to alert the system for
corrective action and to avoid error propagation. Error correction can
detect and repair problems, depending on the amount of correction data
available and the amount ofdata that was corrupted.
•Storage devices are partitioned into one or more chunks of space. Each
partition can hold a volume or be part of a multidevice volume. File
systemsarecreatedinvolumes.
•The operating system manages the st orage device’s blocks. New devices
typically come pre-formatted. The device is partitioned, file systems are
created, and boot blocks are allocated to store the system’s bootstrap pro-
gramifthedevicewillcontain an operatingsystem.Finally,when ablock
orpageiscorrupted,thesystemmusthaveawaytolockoutthatblockor
to replaceit logicallywitha spare.
•An efficient swap space is a key to good performance in some systems.
Somesystemsdedicatearawpartitiontoswapspace,andothersuseafile
withinthefilesysteminstead.Stillothersystemsallowtheuserorsystem
administratorto makethedecision byprovidingboth options.
•Because of the amount of storage required on large systems, and because
storage devices fail in various ways, secondary storage devices are fre-
quently made redundant via RAIDalgorithms. These algorithms allow
morethanonedrivetobeusedforagivenoperationandallowcontinued"
2,Practice Exercises,610,11.9 Summary,"486 Chapter 11 Mass-Storage Structure
operationand evenautomatic recoveryinthe face of a drivefailure. RAID
algorithms are organized into different levels; each level provides some
combination of reliabilityandhigh transferrates.
•Object storage is used for big data problems such as indexing the Inter-
net and cloud photo storage. Objects are self-defining collections of data,
addressed by object IDrather than file name. Typically it uses replication
for data protection, computes based on the data on systems where a copy
of the data exists, and is horizontally scalable for vast capacity and easy
expansion.
Practice Exercises
11.1Is disk scheduling, other than FCFSscheduling, useful in a single-user
environment?Explainyour answer.
11.2Explain why SSTFscheduling tends to favor middle cylinders over the
innermostand outermostcylinders.
11.3Why is rotational latency usually not considered in disk scheduling?
How would you modify SSTF,SCAN,a n dC-SCANto include latency
optimization?
11.4Why is it important to balance file-system I/Oamong the disks and
controllersona systemina multitaskingenvironment?
11.5What are the tradeoffs involved in rereading code pages from the file
systemversususingswap space tostorethem?
11.6Is there any way to implement truly stable storage? Explain your
answer.
11.7It is sometimes said that tape is a sequential-access medium, whereas
a hard disk is a random-access medium. In fact, the suitability of a
storage device for random access depends on the transfer size. The
term streaming transfer rate denotesthe rate for a data transfer that is
underway, excluding the effect of access latency. In contrast, the effec-
tive transfer rate is the ratio of total bytes to total seconds, including
overheadtimesuch as accesslatency.
Supposewehaveacomputerwiththefollowingcharacteristics:the
level-2 cache has an access latency of 8 nanoseconds and a streaming
transfer rate of 800 megabytes per second, the main memory has an
access latency of 60 nanoseconds and a streaming transfer rate of 80
megabytes per second, the hard disk has an access latency of 15 mil-
lisecondsandastreamingtransferrateof5megabytespersecond,and
atapedrivehasanaccesslatencyof60secondsandastreamingtransfer
rateof 2 megabytespersecond.
a. Random access causes the effective transfer rate of a device to
decrease, because no data are transferred during the access time.
For the disk described, what is the effective transfer rate if an"
2,Further Reading,611,Practice Exercises,"Further Reading 487
averageaccessisfollowedbyastreamingtransferof(1)512bytes,
(2) 8 kilobytes,(3) 1 megabyte,and (4) 16 megabytes?
b. The utilization of a device is the ratio of effective transfer rate to
streamingtransferrate.Calculatetheutilizationofthediskdrive
for eachof thefour transfersizesgiveninparta.
c. Suppose that a utilization of 25 percent (or higher) is considered
acceptable. Using the performance figures given, compute the
smallesttransfer sizefor a diskthat givesacceptableutilization.
d. Complete the following sentence: A disk is a random-
access device for transfers larger than
 bytes and is a
sequential-accessdevicefor smallertransfers.
e. Computetheminimumtransfersizesthatgiveacceptableutiliza-
tion forcache, memory,and tape.
f. When is a tape a random-access device, and when is it a
sequential-accessdevice?
11.8Could a RAIDlevel1 organization achieve better performance for read
requeststhan a RAIDlevel0 organization(withnonredundant striping
of data)? Ifso,how?
11.9Givethreereasons touse HDDs assecondary storage.
11.10Givethreereasons touse NVMdevicesas secondarystorage.
Further Reading
[Services (2012)] provides an overview of data storage in a variety of modern
computing environments. Discussion s of redundant arrays of independent
disks (RAIDs) are presented by [Patterson et al. (1988)]. [Kim et al. (2009)]
discussdisk-schedulingalgorithmsfor SSDs.Object-basedstorageisdescribed
by [Mesnieretal.(2003)].
[Russinovich et al. (2017)], [McDougall and Mauro (2007)], and [Love
(2010)]discussfile-systemdetailsinWindows,Solaris,andLinux,respectively.
Storagedevicesarecontinuouslyevolving,withgoalsofincreasingperfor-
mance,increasingcapacity,orboth.Foronedirectionincapacityimprovement
seehttp://www.tomsitpro.com/articles/sh ingled-magnetic-recoding-smr-101-
basics,2-933.html ).
RedHat (and other) Linux distributions have multiple, selectable disk
schedulingalgorithms.Fordetailssee https://access.redhat.com/site/docume
ntation/en-US/Red
 Hat
Enterprise
 Linux/7/html/Performance
 Tuning
 Guide/in
dex.html .
Learn more about the default Linux bootstrap loader at
https://www.gnu.org/software/grub/manual/grub.html/ .
Arelativelynewfilesystem, BTRFS,isdetailedin https://btrfs.wiki.kernel.or
g/index.php/Btrfs
 design.
Forthehistoryofobjectstoressee http://www.theregister.co.uk/2016/07/15
/the
 history
 boys
 cas
and
 object
 storage
 map."
2,Bibliography,612,Further Reading,"488 Chapter 11 Mass-Storage Structure
Bibliography
[Kim et al. (2009)] J .K i m ,Y .O h ,E .K i m ,J .C .D .L e e ,a n dS .N o h , “Disk Sched-
ulersforSolidStateDrivers ”,Proceedings of the seventh ACM international confer-
ence on Embedded software (2009), pages295–304.
[Love (2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library (2010).
[McDougall and Mauro (2007)] R. McDougall and J. Mauro, Solaris Internals,
SecondEdition, PrenticeHall (2007).
[Mesnier et al. (2003)] M. Mesnier, G. Ganger,and E. Ridel, “Object-basedstor-
age”,IEEE Communications Magazine ,Volume41,Number8(2003),pages84–99.
[Patterson et al. (1988)] D .A .P a t t e r s o n ,G .G i b s o n ,a n dR .H .K a t z , “AC a s e
for Redundant Arrays of Inexpensive Disks (RAID) ”,Proceedings of the ACM
SIGMOD International Conference on the Management of Data (1988), pages 109–
116.
[Russinovich et al. (2017)] M.Russinovich,D.A.Solomon,andA.Ionescu, Win-
dows Internals–Part 1, SeventhEdition, MicrosoftPress (2017).
[Services (2012)] E. E. Services, Information Storage and Management: Storing,
Managing, and Protecting Digital Information in Classic, Virtualized, and Cloud Envi-
ronments , Wiley (2012)."
2,Chapter 11 Exercises,613,Bibliography,"Chapter 11 Exercises
11.11Noneofthedisk-schedulingdisciplines,except FCFS,istrulyfair(star-
vationmay occur).
a. Explainwhy thisassertionistrue.
b. Describe a way to modify algorithms such as SCANto ensure
fairness.
c. Explainwhyfairnessisanimportantgoalinamulti-usersystems.
d. Give three or more examples of circumstances in which it is
important that the operating system be unfair in serving I/O
requests.
11.12Explainwhy NVMdevicesoftenusean FCFSdisk-schedulingalgorithm.
11.13Supposethatadiskdrivehas5,000cylinders,numbered0to4,999.The
drive is currently serving a request at cylinder 2,150, and the previous
request was at cylinder 1,805. The queue of pending requests, in FIFO
order,is:
2,069;1,212; 2,296;2,800;544; 1,618; 356;1,523; 4,965;3,681
Starting from the current head position, what is the total distance (in
cylinders) that the disk arm moves to satisfy all the pending requests
foreach of the following disk-schedulingalgorithms?
a.FCFS
b.SCAN
c.C-SCAN
11.14Elementaryphysicsstatesthatwhenanobjectissubjectedtoaconstant
acceleration a,the relationship between distance dand time tis given
byd=1
2at2. Suppose that, during a seek, the disk in Exercise 11.14
accelerates the disk arm at a constant rate for the first half of the seek,
thendeceleratesthediskarmatthesamerateforthesecondhalfofthe
seek. Assume that the disk can perform a seek to an adjacent cylinder
in 1 millisecond and a full-stroke seek over all 5,000 cylinders in 18
milliseconds.
a. The distance of a seek is the number of cylinders over which the
head moves. Explain why the seek time is proportional to the
squareroot ofthe seekdistance.
b. Write an equation for the seek time as a function of the seek
distance.Thisequationshouldbeoftheform t=x+y√
L,where t
isthetimeinmillisecondsand Listheseekdistanceincylinders.
c. Calculatethe totalseektimefor each of the schedulesin Exercise
11.14. Determine which schedule is the fastest (has the smallest
total seektime).EX-43"
2,Programming Problems,616,Chapter 11 Exercises,"Chapter 11 Mass-Storage Structure
Programming Problems
11.27Write a program that implements the following disk-scheduling algo-
rithms:
a.FCFS
b.SCAN
c.C-SCAN
Your program will service a disk with 5,000 cylinders numbered 0 to
4,999. The program will generate a random series of 1,000 cylinder
requests and service them according to each of the algorithms listed
above.Theprogramwillbepassedtheinitialpositionofthediskhead
(as a parameter on the command line) and report the total amount of
headmovementrequiredby eachalgorithm.P-55"
1,Chapter 12 I/O Systems,617,Chapter 11 Mass-Storage Structure,"12CHAPTER
I/O Systems
The two main jobs of a computer are I/Oand computing. In many cases, the
main job is I/O, and the computing or processing is merely incidental. For
instance, when we browse a web page or edit a file, our immediate interest
istoreador entersome information,not to compute an answer.
The role of the operating system in computer I/Ois to manage and con-
trolI/Ooperations and I/Odevices. Although related topics appear in other
chapters, here we bring together the pieces to paint a complete picture of
I/O. First, we describe the basics of I/Ohardware, because the nature of the
hardwareinterfaceplacesconstraints on theinternalfacilitiesoftheoperating
system. Next, we discuss the I/Oservices provided by the operating system
and the embodiment of these services in the application I/Ointerface. Then,
we explain how the operating system bridges the gap between the hardware
interface and the application interface. We also discuss the UNIXSystem V
STREAMS mechanism, which enables an application to assemble pipelines of
driver code dynamically. Finally, we discuss the performance aspects of I/O
andthe principlesof operating-systemdesignthat improve I/Operformance.
CHAPTER OBJECTIVES
•Explore the structure of an operating system’s I/Osubsystem.
Discuss the principles and complexities of I/Ohardware.
Explain the performance aspects of I/Ohardware and software.
12.1 Overview
The control of devices connected to the computer is a major concern of
operating-systemdesigners.Because I/Odevicesvarysowidelyintheirfunc-
tion and speed (consider a mouse, a hard disk, a flash drive, and a tape
robot), varied methods are needed to control them. These methods form the
I/Osubsystem of the kernel, which separ ates the rest of the kernel from the
complexitiesof managing I/Odevices.
489"
2,12.1 Overview,617,Chapter 12 I/O Systems,"12CHAPTER
I/O Systems
The two main jobs of a computer are I/Oand computing. In many cases, the
main job is I/O, and the computing or processing is merely incidental. For
instance, when we browse a web page or edit a file, our immediate interest
istoreador entersome information,not to compute an answer.
The role of the operating system in computer I/Ois to manage and con-
trolI/Ooperations and I/Odevices. Although related topics appear in other
chapters, here we bring together the pieces to paint a complete picture of
I/O. First, we describe the basics of I/Ohardware, because the nature of the
hardwareinterfaceplacesconstraints on theinternalfacilitiesoftheoperating
system. Next, we discuss the I/Oservices provided by the operating system
and the embodiment of these services in the application I/Ointerface. Then,
we explain how the operating system bridges the gap between the hardware
interface and the application interface. We also discuss the UNIXSystem V
STREAMS mechanism, which enables an application to assemble pipelines of
driver code dynamically. Finally, we discuss the performance aspects of I/O
andthe principlesof operating-systemdesignthat improve I/Operformance.
CHAPTER OBJECTIVES
•Explore the structure of an operating system’s I/Osubsystem.
Discuss the principles and complexities of I/Ohardware.
Explain the performance aspects of I/Ohardware and software.
12.1 Overview
The control of devices connected to the computer is a major concern of
operating-systemdesigners.Because I/Odevicesvarysowidelyintheirfunc-
tion and speed (consider a mouse, a hard disk, a flash drive, and a tape
robot), varied methods are needed to control them. These methods form the
I/Osubsystem of the kernel, which separ ates the rest of the kernel from the
complexitiesof managing I/Odevices.
489"
2,12.2 I/O Hardware,618,12.1 Overview,"490 Chapter 12 I/O Systems
I/O-devicetechnologyexhibitstwoconflictingtrends.Ontheonehand,we
seeincreasingstandardizationofsoftwareandhardwareinterfaces.Thistrend
helps us to incorporate improved device generations into existing computers
andoperatingsystems.Ontheotherhand,weseeanincreasinglybroadvariety
ofI/Odevices. Some new devices are so unlike previous devices that it is
a challenge to incorporate them into our computers and operating systems.
This challenge is met by a combination of hardware and software techniques.
Thebasic I/Ohardwareelements,suchasports,buses,anddevicecontrollers,
accommodate a wide variety of I/Odevices. To encapsulate the details and
oddities of different devices, the kernel of an operating system is structured
to use device-driver modules. The device drivers present a uniform device-
accessinterfacetothe I/Osubsystem,muchassystemcallsprovideastandard
interfacebetweenthe applicationand the operatingsystem.
12.2 I/O Hardware
Computers operate a great many kinds of devices. Most fit into the general
categoriesofstoragedevices(disks,tape s),transmissiondevices(networkcon-
nections, Bluetooth), and human-interface devices (screen, keyboard, mouse,
audio in and out). Other devices are more specialized, such as those involved
inthesteeringof ajet.Intheseaircraft,a humangivesinputto theflight com-
puterviaajoystickandfootpedals,andthecomputersendsoutputcommands
thatcausemotorstomoveruddersandflapsandfuelstotheengines.Despite
the incredible variety of I/Odevices, though, we need only a few concepts to
understandhowthedevicesareattachedandhowthesoftwarecancontrolthe
hardware.
Adevice communicates with a computer system by sending signals over
a cable or even through the air. The device communicates with the machine
via a connection point, or port—for example, a serial port. (The term PHY,
shorthand for the OSImodel physical layer, is also used in reference to ports
butismorecommon indata-centernomenclature.)Ifdevicesshare acommon
setofwires,theconnectioniscalledabus.A bus,likethe PCIbususedinmost
computers today, is a set of wires and a rigidly defined protocol that specifies
a set of messages that can be sent on the wires. In terms of the electronics, the
messages are conveyed by patterns of electrical voltages applied to the wires
withdefinedtimings.Whendevice Ahasacable thatplugsintodevice B,and
device Bhasacablethatplugsintodevice C,anddevice Cplugsintoaporton
the computer, this arrangement is called a daisy chain . Adaisy chain usually
operatesas a bus.
Buses are used widely in computer architecture and vary in their signal-
ing methods, speed, throughput, and connection methods. A typical PCbus
structure appears in Figure 12.1. In the figure, a PCIe bus(the common PC
system bus) connects the processor–memory subsystem to fast devices, and
anexpansion bus connects relatively slow devices, such as the keyboard and
serial and USBports. In the lower-left portion of the figure, four disks are
connected together on a serial-attached SCSI(SAS) bus plugged into an SAS
controller. PCIei safl e x i b l eb u st h a ts e n d sd a t ao v e ro n eo rm o r e “lanes. ”A
lane is composed of two signaling pairs, one pair for receiving data and the
otherfortransmitting.Eachlaneisthereforecomposedoffourwires,andeach"
3,12.2.1 Memory-Mapped I/O,619,12.2 I/O Hardware,"12.2 I/O Hardware 491
expansion busPCIe bus
disk diskcache
memoryprocessor
bridge/memory
controllermonitor
SAS controllerexpansion bus
interfacegraphics
controller
keyboard
USB
portUSB
portdisk disk
Figure 12.1 A typical PC bus structure.
laneisusedasafull-duplexbytestream,transportingdatapacketsinaneight-
bit byte format simultaneously in both directions. Physically, PCIe links may
contain1,2,4,8,12,16,or32lanes,assignifiedbyan “x”prefix.A PCIecardor
connectorthatuses8lanesisdesignatedx8,forexample.Inaddition, PCIehas
gone through multiple “generations, ”with more coming in the future. Thus,
for example, a card might be “PCIeg e n 3x 8 ”, which means it works with gen-
eration 3 of PCIe and uses 8 lanes. Such a device has maximum throughput of
8gigabytespersecond.Detailsabout PCIec a nb ef o u n da t https://pcisig.com .
Acontroller is a collection of electronics that can operate a port, a bus, or
adevice.Aserial-portcontrollerisasimpledevicecontroller.Itisasinglechip
(or portion of a chip) in the computer that controls the signals on the wires
of a serial port. By contrast, a fibr channel (FC) bus controller is not simple.
Because the FCprotocol is complex and used in data centers rather than on
PCs, theFCbus controller is often implemented as a separate circuit board
—or a host bus adapter (HBA)—that connects to a bus in the computer. It
typicallycontainsaprocessor,microcode,andsomeprivatememorytoenable
it to process the FCprotocol messages. Some devices have their own built-in
controllers. If you look at a disk drive, you will see a circuit board attached
to one side. This board is the disk controller. It implements the disk side of
the protocol for some kinds of connection— SASandSATA,f o ri n s t a n c e .I th a s
microcode and a processor to do many tasks, such as bad-sector mapping,
prefetching,buffering,and caching.
12.2.1 Memory-Mapped I/O
Howdoestheprocessorgivecommandsanddatatoacontrollertoaccomplish
anI/Otransfer?Theshortansweristhatthecontrollerhasoneormoreregisters
for data and control signals. The processor communicates with the controller
by reading and writing bit patterns in these registers. One way in which
this communication can occur is through the use of special I/Oinstructions"
3,12.2.2 Polling,621,12.2.1 Memory-Mapped I/O,"12.2 I/O Hardware 493
munication, another bit enables pari ty checking, a third bit sets the word
length to 7 or 8 bits, and other bits select one of the speeds supported by
the serialport.
The data registers are typically 1 to 4 bytes in size. Some controllers have
FIFOchips that can hold several bytes of input or output data to expand the
capacity of the controller beyond the size of the data register. A FIFOchip can
holda smallburst of datauntilthe deviceorhost isable toreceivethosedata.
12.2.2 Polling
The complete protocol for interaction between the host and a controller can
be intricate, but the basic handshaking notion is simple. We explain hand-
shaking with an example. Assume that 2 bits are used to coordinate the
producer–consumerrelationshipbetw eenthecontrollerandthehost.Thecon-
trollerindicatesitsstatethroughthe busybitinthe statusregister.(Recallthat
toseta bit means to write a 1 into the bit and to clearab i tm e a n st ow r i t ea
0 into it.) The controller sets the busyb i tw h e ni ti sb u s yw o r k i n ga n dc l e a r s
thebusybit when it is ready to accept the next command. The host signals its
wishes via the command-ready bit in the command register. The host sets the
command-ready bitwhenacommandisavailableforthecontrollertoexecute.
Forthisexample,thehostwritesoutputthroughaport,coordinatingwiththe
controllerby handshaking asfollows.
1.Thehost repeatedlyreadsthe busybit untilthat bit becomesclear.
2.Thehostsetsthe writebitinthe command registerandwritesabyteinto
thedata-out register.
3.The host setsthe command-ready bit.
4.When the controller notices that the command-ready b i ti ss e t ,i ts e t st h e
busybit.
5.Thecontrollerreadsthecommandregisterandseesthe writecommand.
It reads the data-out register to get the byte and does the I/Oto the
device.
6.The controller clears the command-ready bit, clears the errorbit in the
status register to indicate that the device I/Osucceeded, and clears the
busybit toindicate that itisfinished.
Thisloop isrepeatedfor eachbyte.
In step 1, the host is busy-waiting orpolling: it is in a loop, reading the
statusregisteroverandoveruntilthe busybitbecomesclear.Ifthecontroller
anddevicearefast,thismethodisareasonableone.Butifthewaitmaybelong,
thehostshouldprobablyswitchtoanothertask.How,then,doesthehostknow
when the controller has become idle? For some devices, the host must service
the device quickly, or data will be lost. For instance, when data are streaming
in on a serial port or from a keyboard, the small buffer on the controller will
overflowanddatawillbelostifthehostwaitstoolongbeforereturningtoread
thebytes."
3,12.2.3 Interrupts,622,12.2.2 Polling,"494 Chapter 12 I/O Systems
Inmanycomputerarchitectures,three CPU-instructioncyclesaresufficient
to poll a device: reada device register, logical-and to extract a status bit,
and branchif not zero. Clearly, the basic polling operation is efficient. But
polling becomes inefficient when it is a ttempted repeatedly yet rarely finds a
devicereadyforservice,whileotheruseful CPUprocessingremainsundone.In
s u c hi n s t a n c e s ,i tm a yb em o r ee f fi c i e n tt oa r r a n g ef o rt h eh a r d w a r ec o n t r o l l e r
to notify the CPUwhen the device becomes ready for service, rather than
to require the CPUto poll repeatedly for an I/Ocompletion. The hardware
mechanism that enablesa deviceto notifythe CPUiscalledan interrupt .
12.2.3 Interrupts
The basic interrupt mechanism works as follows. The CPUhardware has a
wirecalledthe interrupt-request line thatthe CPUsensesafterexecutingevery
instruction. When the CPUdetects that a controller has asserted a signal on
the interrupt-request line, the CPUperforms a state save and jumps to the
interrupt-handler routine at a fixed address in memory. The interrupt han-
dlerdeterminesthe cause of the interrupt,performsthe necessaryprocessing,
performs a state restore, and executes a return from interrupt instruction
to return the CPUto the execution state prior to the interrupt. We say that
the device controller raisesan interrupt by asserting a signal on the interrupt
request line, the CPU catchesthe interrupt and dispatches it to the interrupt
device driver initiates I/O
CPU receiving interrupt,
transfers control to
interrupt handler
CPU resumes
processing of
interrupted taskCPU
1I/O controller
CPU executing checks for
interrupts between instructions
5
interrupt handler
processes data,
returns from interruptinitiates I/O
32
4
7input ready, output
complete, or error
generates interrupt signal
6
Figure 12.3 Interrupt-driven I/O cycle."
3,12.2.4 Direct Memory Access,626,12.2.3 Interrupts,"498 Chapter 12 I/O Systems
completes a disk read. The high-priority handler records the I/Ostatus, clears
the device interrupt, starts the next pending I/O, and raises a low-priority
interrupttocompletethework.Later,whenthe CPUisnotoccupiedwithhigh-
prioritywork,thelow-priorityinterruptwillbedispatched.Thecorresponding
handlercompletestheuser-level I/Obycopyingdatafromkernelbufferstothe
applicationspaceandthencallingtheschedulertoplacetheapplicationonthe
readyqueue.
Athreaded kernel architecture is wel l suited to implement multiple inter-
rupt priorities and to enforce the precedence of interrupt handling over back-
ground processing in kernel and applicat ion routines. We illustrate this point
with the Solaris kernel. In Solaris, interrupt handlers are executed as kernel
threads. A range of high scheduling priorities is reserved for these threads.
Theseprioritiesgiveinterrupthandlersprecedenceoverapplicationcodeand
kernel housekeeping and implement the priority relationships among inter-
rupthandlers.TheprioritiescausetheSolaristhreadschedulertopreemptlow-
priority interrupt handlers in favor of higher-priority ones, and the threaded
implementationenablesmultiprocessorhardwaretorunseveralinterrupthan-
dlers concurrently. We describe the interrupt architecture of Linux in Chapter
20, Windows10 inChapter21, and UNIXinAppendixC.
Insummary,interruptsareusedthroughoutmodernoperatingsystemsto
handle asynchronous events and to trap to supervisor-mode routines in the
kernel. To enable the most urgent work to be done first, modern computers
use a system of interrupt priorities. Device controllers, hardware faults, and
system calls all raise interrupts to trigger kernel routines. Because interrupts
are used so heavily for time-sensitive processing, efficient interrupt handling
is required for good system performance. Interrupt-driven I/Ois now much
morecommon than polling,with pollingbeing usedfor high-throughput I/O.
Sometimesthetwoareusedtogether.Somedevicedriversuseinterruptswhen
theI/Orate is low and switch to polling when the rate increases to the point
wherepollingis fasterandmoreefficient.
12.2.4 Direct Memory Access
For a device that does large transfers, such as a disk drive, it seems waste-
ful to use an expensive general-purpose processor to watch status bits and
to feed data into a controller register one byte at a time—a process termed
programmed I/O(PIO).Computersavoidburdeningthemain CPUwithPIOby
offloading some of this work to a special-purpose processor called a direct-
memory-access (DMA) controller. To initiate a DMAtransfer, the host writes a
DMAcommandblockintomemory.Thisblockcontainsapointertothesource
of a transfer, a pointer to the destination of the transfer, and a count of the
number of bytes to be transferred. A command block can be more complex,
including a list of sources and destinations addresses that are not contiguous.
This scatter–gather methodallowsmultipletransferstobeexecutedviaasin-
gleDMAcommand. The CPUwrites the address of this command block to the
DMAcontroller, then goes on with other work. The DMAcontroller proceeds
to operate the memory bus directly, placing addresses on the bus to perform
transfers without the help of the main CPU.As i m p l e DMAcontroller is a stan-
dardcomponent in allmoderncomputers,fromsmartphones to mainframes."
3,12.2.5 I/O Hardware Summary,628,12.2.4 Direct Memory Access,"500 Chapter 12 I/O Systems
othersperform direct virtual memory access (DVMA),usingvirtualaddresses
that undergo translation to physical addresses. DVMAcan perform a transfer
betweentwomemory-mappeddeviceswithout theinterventionofthe CPUor
theuse ofmainmemory.
On protected-mode kernels, the operating system generally prevents pro-
cesses from issuing device commands directly. This discipline protects data
fromaccess-controlviolationsandalsoprotectsthesystemfromerroneoususe
of device controllers, which could cause a system crash. Instead, the operat-
ing system exports functions that a sufficiently privileged process can use to
access low-level operations on the underlying hardware. On kernels without
memoryprotection,processescanaccessdevicecontrollersdirectly.Thisdirect
accesscanbeusedtoachievehighperfor mance,sinceitcanavoidkernelcom-
munication, context switches, and layers of kernel software. Unfortunately, it
interferes with system security and sta bility. Common general-purpose oper-
atingsystemsprotectmemoryanddevicessothatthesystemcantrytoguard
against erroneousor maliciousapplications.
12.2.5 I/O Hardware Summary
Although the hardware aspects of I/Oare complex when considered at the
level of detail of electronics-hardware design, the concepts that we have just
describedare sufficient to enable us to understand many I/Ofeatures of oper-
ating systems.Let’sreviewthemainconcepts:
•Abus
•Acontroller
•AnI/Oportand itsregisters
•The handshaking relationshipbetweenthe host and a devicecontroller
•Theexecution ofthis handshaking in apolling loopor viainterrupts
•The offloading of thiswork to a DMAcontroller forlargetransfers
We gave a basic example of the handshaking that takes place between a
devicecontrollerandthehostearlierinthissection.Inreality,thewidevariety
ofavailabledevicesposesaproblemforoperating-systemimplementers.Each
kind of device has its own set of capabilities, control-bit definitions, and pro-
tocols for interacting with the host—and they are all different. How can the
operating system be designed so that we can attach new devices to the com-
puter without rewriting the operating system? And when the devices vary so
widely,howcantheoperatingsystemgiveaconvenient,uniform I/Ointerface
to applications?Weaddressthosequestionsnext.
12.3 Application I/O Interface
In this section, we discuss structuring techniques and interfaces for the oper-
ating system that enable I/Odevicesto be treatedin a standard, uniform way.
We explain,for instance, how an application can open a file on a disk without"
2,12.3 Application I/O Interface,628,12.2 I/O Hardware,"500 Chapter 12 I/O Systems
othersperform direct virtual memory access (DVMA),usingvirtualaddresses
that undergo translation to physical addresses. DVMAcan perform a transfer
betweentwomemory-mappeddeviceswithout theinterventionofthe CPUor
theuse ofmainmemory.
On protected-mode kernels, the operating system generally prevents pro-
cesses from issuing device commands directly. This discipline protects data
fromaccess-controlviolationsandalsoprotectsthesystemfromerroneoususe
of device controllers, which could cause a system crash. Instead, the operat-
ing system exports functions that a sufficiently privileged process can use to
access low-level operations on the underlying hardware. On kernels without
memoryprotection,processescanaccessdevicecontrollersdirectly.Thisdirect
accesscanbeusedtoachievehighperfor mance,sinceitcanavoidkernelcom-
munication, context switches, and layers of kernel software. Unfortunately, it
interferes with system security and sta bility. Common general-purpose oper-
atingsystemsprotectmemoryanddevicessothatthesystemcantrytoguard
against erroneousor maliciousapplications.
12.2.5 I/O Hardware Summary
Although the hardware aspects of I/Oare complex when considered at the
level of detail of electronics-hardware design, the concepts that we have just
describedare sufficient to enable us to understand many I/Ofeatures of oper-
ating systems.Let’sreviewthemainconcepts:
•Abus
•Acontroller
•AnI/Oportand itsregisters
•The handshaking relationshipbetweenthe host and a devicecontroller
•Theexecution ofthis handshaking in apolling loopor viainterrupts
•The offloading of thiswork to a DMAcontroller forlargetransfers
We gave a basic example of the handshaking that takes place between a
devicecontrollerandthehostearlierinthissection.Inreality,thewidevariety
ofavailabledevicesposesaproblemforoperating-systemimplementers.Each
kind of device has its own set of capabilities, control-bit definitions, and pro-
tocols for interacting with the host—and they are all different. How can the
operating system be designed so that we can attach new devices to the com-
puter without rewriting the operating system? And when the devices vary so
widely,howcantheoperatingsystemgiveaconvenient,uniform I/Ointerface
to applications?Weaddressthosequestionsnext.
12.3 Application I/O Interface
In this section, we discuss structuring techniques and interfaces for the oper-
ating system that enable I/Odevicesto be treatedin a standard, uniform way.
We explain,for instance, how an application can open a file on a disk without"
3,12.3.1 Block and Character Devices,631,12.3 Application I/O Interface,"12.3 Application I/O Interface 503
tionsincludeblock I/O,character-stream I/O,memory-mappedfileaccess,and
networksockets.Operatingsystemsalsoprovidespecialsystemcallstoaccess
a few additional devices, such as a time-of-day clock and a timer. Some oper-
ating systems provide a set of system calls for graphical display, video, and
audiodevices.
Most operating systems also have an escape(orback door ) that transpar-
ently passes arbitrary commands from an application to a device driver. In
UNIX, this system call is ioctl() (for “I/Ocontrol ”). The ioctl() system call
enablesan applicationto accessany functionality thatcan beimplementedby
any devicedriver,without the need to invent a new system call. The ioctl()
system call has three arguments. The first is a device identifier that connects
theapplicationtothedriverbyreferringtoahardwaredevicemanagedbythat
driver.Thesecondisanintegerthatselectsoneofthecommandsimplemented
in the driver. The third is a pointer to an arbitrary data structure in memory
that enables the application and driver to communicate any necessary control
information ordata.
The device identifier in UNIXand Linux is a tuple of “major and minor ”
device numbers. The major number is the device type, and the second is the
instanceofthatdevice.Forexample,considerthese SSDdevicesonasystem.If
oneissuesa command:
% ls -l /dev/sda*
thenthe following output
brw-rw---- 1 root disk 8, 0 Mar 16 09:18 /dev/sda
brw-rw---- 1 root disk 8, 1 Mar 16 09:18 /dev/sda1
brw-rw---- 1 root disk 8, 2 Mar 16 09:18 /dev/sda2
brw-rw---- 1 root disk 8, 3 Mar 16 09:18 /dev/sda3
shows that 8 is the major device number. The operating system uses that
information to route I/Orequests to the appropriate device driver. The minor
numbers0,1,2,and3indicatetheinstanceofthedevice,allowingrequestsfor
I/Otoa deviceentryto selecttheexact deviceforthe request.
12.3.1 Block and Character Devices
Theblock-device interface capturesalltheaspectsnecessaryforaccessingdisk
drivesandotherblock-orienteddevices.Thedeviceisexpectedtounderstand
commands such as read()and write() . If it is a random-access device, it
is also expected to have a seek()command to specify which block to trans-
fer next. Applications normally access such a device through a file-system
interface. We can see that read(),write() ,a n d seek()capture the essential
behaviorsofblock-storage devices,so thatapplications areinsulatedfromthe
low-leveldifferencesamong thosedevices.
The operating system itself, as well as special applications such as
database-management systems, may prefer to access a block device as a
simplelineararrayofblocks.Thismodeofaccessissometimescalled raw I/O.
If the application performs its own buffering, then using a file system would
cause extra, unneeded buffering. Likewise, if an application provides its
own locking of blocks or regions, then an y operating-system locking services
would be redundant at the least and contradictory at the worst. To avoid"
3,12.3.2 Network Devices,632,12.3.1 Block and Character Devices,"504 Chapter 12 I/O Systems
these conflicts, raw-device access passes control of the device directly to the
application,lettingtheoperatingsystemstepoutoftheway.Unfortunately,no
operating-system services are then performed on this device. A compromise
that is becoming common is for the operating system to allow a mode of
operation on a file that disablesbuffering and locking. In the UNIXworld, this
iscalled direct I/O.
Memory-mappedfileaccesscanbelayeredontopofblock-devicedrivers.
Rather than offering read and write operations, a memory-mapped interface
provides access to disk storage via an array of bytes in main memory. The
system call that maps a file into memory returns the virtual memory address
that contains a copy of the file. The actual data transfers are performed only
when needed to satisfy access to the memory image. Because the transfers
are handled by the same mechanism as that used for demand-paged virtual
memory access, memory-mapped I/Ois efficient. Memory mapping is also
convenient for programmers—access to a memory-mapped file is as simple
as reading from and writing to memory. Operating systems that offer virtual
memorycommonlyusethemappinginterfac eforkernelservices.Forinstance,
to executea program,the operatingsystemmaps the executableinto memory
andthentransferscontroltotheentryaddressoftheexecutable.Themapping
interfaceisalso commonly usedfor kernelaccess to swap spaceon disk.
Akeyboardisanexampleofadevicethatisaccessedthrougha character-
stream interface . The basic systemcalls in this interface enable an application
toget()orput()one character. On top of this interface, libraries can be
built that offer line-at-a-time access, with buffering and editing services (for
example, when a user types a backspace, the preceding character is removed
fromtheinputstream).Thisstyleofaccessisconvenientforinputdevicessuch
askeyboards,mice,andmodemsthatproducedataforinput “spontaneously ”
—thatis,attimesthatcannotnecessarilybepredictedbytheapplication.This
access styleisalsogoodfor outputdevicessuch asprintersandaudioboards,
which naturally fit theconcept of a linearstreamof bytes.
12.3.2 Network Devices
Because the performance and addressing characteristics of network I/Odiffer
significantlyfromthoseofdisk I/O,mostoperatingsystemsprovideanetwork
I/Ointerface that is different from the read()–write() –seek()interface
used for disks. One interface available in many operating systems, including
UNIXand Windows, isthe network socketinterface.
Think of a wall socket for electricity: any electrical appliance can be
plugged in. By analogy, the system calls in the socket interface enable an
application to create a socket, to connect a local socket to a remote address
(which plugs this application into a socket created by another application), to
listen for any remote application to plug into the local socket, and to send
and receive packets over the connection. To support the implementation of
networkservers,thesocketinterfacealsoprovidesafunctioncalled select()
that manages a set of sockets. A call to select() returns information about
which sockets have a packet waiting to be received and which sockets have
roomtoacceptapackettobesent.Theuseof select() eliminatesthepolling
and busy waiting that would otherwise be necessary for network I/O.T h e s e
functions encapsulate the essential behav iors of networks, greatly facilitating"
3,12.3.3 Clocks and Timers,633,12.3.2 Network Devices,"12.3 Application I/O Interface 505
the creation of distributed applicatio ns that can use any underlying network
hardware and protocol stack.
Manyotherapproachestointerprocesscommunicationandnetworkcom-
munication have been implemented. For instance, Windows provides one
interface to the network interface card and a second interface to the network
protocols. In UNIX, which has a long history as a proving ground for network
technology,wefindhalf-duplexpipes,full-duplex FIFOs,full-duplex STREAMS ,
message queues, and sockets. Information on UNIXnetworking is given in
SectionC.9.
12.3.3 Clocks and Timers
Most computers have hardware clocks and timers that provide three basic
functions:
•Givethecurrent time.
•Givetheelapsedtime.
•Setatimertotriggeroperation Xattime T.
These functions are used heavily by the operating system, as well as by time-
sensitive applications. Unfortunately, the system calls that implement these
functions arenot standardizedacross operatingsystems.
The hardware to measure elapsed time and to trigger operations is called
aprogrammable interval timer . It can be set to wait a certain amount of time
and then generate an interrupt, and it can be set to do this once or to repeat
theprocesstogenerateperiodicinterrupts.Theschedulerusesthismechanism
to generate an interrupt that will preempt a process at the end of its time
slice. The disk I/Osubsystem uses it to invoke the periodic flushing of dirty
cache buffers to disk, and the network subsystem uses it to cancel operations
that are proceeding too slowly because of network congestion or failures.The
operatingsystemmayalsoprovideaninterfaceforuserprocessestousetimers.
The operating system can support more timer requests than the number of
timer hardware channels by simulating virtual clocks. To do so, the kernel
(or the timer device driver) maintains a list of interrupts wanted by its own
routinesandbyuserrequests,sortedinearliest-time-firstorder.Itsetsthetimer
fortheearliesttime.Whenthetimerinterrupts,thekernelsignalstherequester
andreloadsthetimerwiththenextearliesttime.
Computers have clock hardware that is used for a variety of purposes.
Modern PCsi n c l u d ea high-performance event timer (HPET), which runs at
rates in the 10-megahertz range. It has several comparators that can be set
to trigger once or repeatedly when the value they hold matches that of the
HPET. The trigger generates an interrupt, and the operating system’s clock
management routines determine what the timer was for and what action to
take.Theprecisionoftriggersislimitedbytheresolutionofthetimer,together
withtheoverheadofmaintainingvirtual clocks.Furthermore,ifthetimerticks
are used to maintain the system time-of-day clock, the system clock can drift.
Driftcanbecorrectedviaprotocolsdesignedforthatpurpose,suchas NTP,the
network time protocol , which uses sophisticated latency calculations to keep
acomputer’sclock accurate almost toatomic-clock levels.Inmostcomputers,"
3,12.3.4 Nonblocking and Asynchronous I/O,634,12.3.3 Clocks and Timers,"506 Chapter 12 I/O Systems
the hardware clock is constructed from a high-frequency counter. In some
computers,thevalueofthiscountercanbereadfromadeviceregister,inwhich
casethecountercanbeconsideredahigh-resolutionclock.Althoughthisclock
doesnotgenerateinterrupts,itoffersaccuratemeasurementsoftimeintervals.
12.3.4 Nonblocking and Asynchronous I/O
Anotheraspectofthesystem-callinterfa cerelatestothechoicebetweenblock-
ingI/Oand nonblocking I/O. When an application issues a blocking system
call,theexecutionofthecallingthreadissuspended.Thethreadismovedfrom
the operating system’s run queue to a wait queue. After the system call com-
pletes,thethreadismovedbacktotherunqueue,whereitiseligibletoresume
execution. When it resumes execution, it will receive the values returned by
the system call. The physical actions performed by I/Odevices are generally
asynchronous—they take a varying or unpredictable amount of time. Nev-
ertheless, operating systems provide blocking system calls for the application
interface,becauseblockingapplicationc odeiseasiertowritethannonblocking
applicationcode.
Some user-level processes need nonblocking I/O. One example is a user
interface that receives keyboard and mouse input while processing and dis-
playing data on the screen. Another example is a video application that reads
framesfromafileondiskwhilesimultaneouslydecompressinganddisplaying
theoutput on the display.
One way an application writer can overlap execution with I/Ois to write
amultithreadedapplication.Somethreadscanperformblockingsystemcalls,
whileotherscontinueexecuting.Someop eratingsystemsprovidenonblocking
I/Osystemcalls.Anonblockingcalldoesnothalttheexecutionofthethreadfor
anextendedtime.Instead,itreturnsquic kly,withareturnvaluethatindicates
how many bytesweretransferred.
An alternative to a nonblocking system call is an asynchronous system
call.Anasynchronous callreturnsimmediately,withoutwaitingforthe I/Oto
complete. The thread continues to execute its code. The completion of the I/O
at some future time is communicated to the thread, either through the setting
of some variable in the address space of the thread or through the triggering
of a signal or software interruptor a call-back routine that is executedoutside
the linear control flow of the thread. The difference between nonblocking and
asynchronous system calls is that a nonblocking read()returns immediately
with whatever data are available—the full number of bytes requested, fewer,
or none at all. An asynchronous read()call requests a transfer that will be
performedinitsentiretybutwillcompleteatsomefuturetime.Thesetwo I/O
methodsare shown in Figure12.9.
Asynchronousactivitiesoccurthroughoutmodernoperatingsystems.Fre-
quently,theyarenotexposedtousersorapplicationsbutratherarecontained
withintheoperating-systemoperation.Secondarystoragedeviceandnetwork
I/Oare useful examples. By default, when an application issues a network
send request or a storage device write request, the operating system notes
the request, buffers the I/O, and returns to the application. When possible,
to optimize overall system performance, the operating system completes the
request. If a system failure occurs in the interim, the application will lose any
“in-flight ”requests. Therefore, operating systems usually put a limit on how"
3,12.3.5 Vectored I/O,635,12.3.4 Nonblocking and Asynchronous I/O,"12.3 Application I/O Interface 507
Figure 12.9 Two I/O methods: (a) synchronous and (b) asynchronous.
long they will buffer a request. Some versions of UNIXflush their secondary
storagebuffersevery30seconds,forexample,oreachrequestisflushedwithin
30 seconds of its occurrence. Systems provide a way to allow applications to
requestaflushofsomebuffers(likesecondarystoragebuffers)sothedatacan
be forced to secondary storage without waiting for the buffer flush interval.
Dataconsistencywithinapplicationsis maintainedbythekernel,whichreads
datafromitsbuffers beforeissuing I/Orequeststo devices,ensuringthatdata
notyetwrittenareneverthelessreturnedtoarequestingreader.Notethatmul-
tiplethreadsperforming I/Otothesamefilemightnotreceiveconsistentdata,
dependingonhowthekernelimplementsits I/O.Inthissituation,thethr eads
may need to use locking protocols. Some I/Orequests need to be performed
immediately, so I/Osystem calls usually have a way to indicate that a given
request, or I/Otoa specificdevice,should beperformedsynchronously.
Agood example of nonblocking behavior is the select() system call for
network sockets. This system call takes an argument that specifies a maxi-
mum waiting time. By setting it to 0, a thread can poll for network activity
without blocking. But using select() introduces extra overhead, because
theselect() call only checks whether I/Ois possible. For a data transfer,
select() must be followed by some kind of read()orwrite() command.
Avariation on this approach, found in Mach, is a blocking multiple-read call.
It specifies desired reads for several devices in one system call and returns as
soon as any one ofthem completes.
12.3.5 Vectored I/O
Someoperatingsystemsprovideanothermajorvariationof I/Oviatheirappli-
cation interfaces. Vectored I/Oallows one system call to perform multiple I/O
operations involving multiple locations. For example, the UNIX readvsys-
tem call accepts a vector of multiple buffers and either reads from a source
to that vector or writes from that vector to a destination. The same transfer"
2,12.4 Kernel I/O Subsystem,636,12.3 Application I/O Interface,"508 Chapter 12 I/O Systems
could be caused by several individual invocations of system calls, but this
scatter–gather method isusefulfor avarietyof reasons.
Multiple separate buffers can have their contents transferred via one sys-
tem call, avoiding context-switching and system-call overhead. Without vec-
toredI/O, the data might first need to be transferred to a larger buffer in
the right order and then transmitted, wh ich is inefficient. In addition, some
versions of scatter–gather provide atomicity, assuring that all the I/Ois done
withoutinterruption(andavoidingcorruptionofdataifotherthreadsarealso
performing I/Oinvolving those buffers). When possible, programmers make
useofscatter–gather I/Ofeaturestoincreasethroughputanddecreasesystem
overhead.
12.4 Kernel I/O Subsystem
Kernels provide many services related to I/O. Several services—scheduling,
buffering,caching,spooling,devicereservation,anderrorhandling—arepro-
vided by the kernel’s I/Osubsystem and build on the hardware and device-
driverinfrastructure.The I/Osubsystemisalsoresponsibleforprotectingitself
from errantprocessesand malicious users.
12.4.1 I/O Scheduling
To schedule a set of I/Orequestsmeanstodetermineagoodorderinwhichto
execute them. The order in which applic ations issue system calls rarely is the
best choice. Scheduling can improve overall system performance, can share
deviceaccessfairlyamongprocesses,andcanreducetheaveragewaitingtime
forI/Otocomplete.Hereisasimpleexampletoillustrate.Supposethatadisk
arm is near the beginning of a disk and that three applications issue blocking
read calls to that disk. Application 1 requests a block near the end of the disk,
application 2 requests one near the beginning, and application 3 requests one
inthemiddleofthedisk.Theoperatingsystemcanreducethedistancethatthe
disk arm travels by serving the applications in the order 2, 3, 1. Rearranging
theorderof serviceinthisway isthe essenceof I/Oscheduling.
Operating-system developers implement scheduling by maintaining a
wait queueof requestsfor eachdevice.When anapplicationissuesa blocking
I/Osystem call, the request is placed on the queue for that device. The I/O
schedulerrearrangestheorderofthequeuetoimprovetheoverallsystemeffi-
ciencyandtheaverageresponsetimeexperiencedbyapplications.Theoperat-
ingsystemmayalsotrytobefair,sothatnooneapplicationreceivesespecially
poor service, or it may give priority service for delay-sensitive requests. For
instance, requests from the virtual memory subsystem may take priority over
applicationrequests.Severalschedulingalgorithmsfordisk I/Oweredetailed
inSection11.2.
When a kernel supports asynchronous I/O,i tm u s tb ea b l et ok e e pt r a c k
of many I/Orequestsatthesametime.Forthis purpose,theoperatingsystem
might attach the wait queue to a device-status table . The kernel manages this
table, which contains an entry for each I/Odevice, as shown in Figure 12.10.
Eachtableentryindicatesthedevice’sty pe,address,andstate(notfunctioning,"
3,12.4.1 I/O Scheduling,636,12.4 Kernel I/O Subsystem,"508 Chapter 12 I/O Systems
could be caused by several individual invocations of system calls, but this
scatter–gather method isusefulfor avarietyof reasons.
Multiple separate buffers can have their contents transferred via one sys-
tem call, avoiding context-switching and system-call overhead. Without vec-
toredI/O, the data might first need to be transferred to a larger buffer in
the right order and then transmitted, wh ich is inefficient. In addition, some
versions of scatter–gather provide atomicity, assuring that all the I/Ois done
withoutinterruption(andavoidingcorruptionofdataifotherthreadsarealso
performing I/Oinvolving those buffers). When possible, programmers make
useofscatter–gather I/Ofeaturestoincreasethroughputanddecreasesystem
overhead.
12.4 Kernel I/O Subsystem
Kernels provide many services related to I/O. Several services—scheduling,
buffering,caching,spooling,devicereservation,anderrorhandling—arepro-
vided by the kernel’s I/Osubsystem and build on the hardware and device-
driverinfrastructure.The I/Osubsystemisalsoresponsibleforprotectingitself
from errantprocessesand malicious users.
12.4.1 I/O Scheduling
To schedule a set of I/Orequestsmeanstodetermineagoodorderinwhichto
execute them. The order in which applic ations issue system calls rarely is the
best choice. Scheduling can improve overall system performance, can share
deviceaccessfairlyamongprocesses,andcanreducetheaveragewaitingtime
forI/Otocomplete.Hereisasimpleexampletoillustrate.Supposethatadisk
arm is near the beginning of a disk and that three applications issue blocking
read calls to that disk. Application 1 requests a block near the end of the disk,
application 2 requests one near the beginning, and application 3 requests one
inthemiddleofthedisk.Theoperatingsystemcanreducethedistancethatthe
disk arm travels by serving the applications in the order 2, 3, 1. Rearranging
theorderof serviceinthisway isthe essenceof I/Oscheduling.
Operating-system developers implement scheduling by maintaining a
wait queueof requestsfor eachdevice.When anapplicationissuesa blocking
I/Osystem call, the request is placed on the queue for that device. The I/O
schedulerrearrangestheorderofthequeuetoimprovetheoverallsystemeffi-
ciencyandtheaverageresponsetimeexperiencedbyapplications.Theoperat-
ingsystemmayalsotrytobefair,sothatnooneapplicationreceivesespecially
poor service, or it may give priority service for delay-sensitive requests. For
instance, requests from the virtual memory subsystem may take priority over
applicationrequests.Severalschedulingalgorithmsfordisk I/Oweredetailed
inSection11.2.
When a kernel supports asynchronous I/O,i tm u s tb ea b l et ok e e pt r a c k
of many I/Orequestsatthesametime.Forthis purpose,theoperatingsystem
might attach the wait queue to a device-status table . The kernel manages this
table, which contains an entry for each I/Odevice, as shown in Figure 12.10.
Eachtableentryindicatesthedevice’sty pe,address,andstate(notfunctioning,"
3,12.4.2 Buffering,637,12.4.1 I/O Scheduling,"12.4 Kernel I/O Subsystem 509
device: keyboard
status: idle
device: laser printer
status: busy
device: mouse
status: idle
device: disk unit 1
status: idle
device: disk unit 2
status: busy
...request for
laser printer
address: 38546
length: 1372
request for
disk unit 2
file: xxx
operation: read
address: 43046
length: 20000request for
disk unit 2
file: yyy
operation: write
address: 03458
length: 500
Figure 12.10 Device-status table.
idle,orbusy).Ifthedeviceisbusywitharequest,thetypeofrequestandother
parameterswillbestoredinthetableentryfor that device.
Scheduling I/Ooperationsisonewayinwhichthe I/Osubsystemimproves
the efficiency of the computer. Another way is by using storage space in main
memory or elsewhere in the storage hierarchy via buffering, caching, and
spooling.
12.4.2 Buffering
Abuffer,ofcourse,isamemoryareathatstoresdatabeingtransferredbetween
twodevicesorbetweenadeviceandanapplication.Bufferingisdoneforthree
reasons. One reason is to cope with a speed mismatch between the producer
and consumer of a data stream. Suppose, for example, that a file is being
received via Internet for storage on an SSD. The network speed may be a
thousand times slower than the drive. So a buffer is created in main memory
to accumulate the bytes received from the network. When an entire buffer of
data has arrived, the buffer can be written to the drive in a single operation.
Sincethedrivewriteisnotinstantaneousandthenetworkinterfacestillneedsa
placetostoreadditionalincomingdata,twobuffersareused.Afterthenetwork
fillsthe first buffer,the drivewrite isrequested.Thenetwork thenstartsto fill
the second buffer while the first buffer is written to storage. By the time the
network has filled the second buffer, the drive write from the first one should
have completed, so the network can switch back to the first buffer while the
drivewritesthesecondone.This double buffering decouplestheproducerof
datafromtheconsumer,thusrelaxing timingrequirementsbetweenthem.The
needforthisdecouplingisillustratedinFigure12.11,whichliststheenormous
differencesindevicespeedsfor typicalcomputerhardwareand interfaces.
A second use of buffering is to provide adaptations for devices that
have different data-transfer sizes. Such disparities are especially common in
computer networking, where buffers are used widely for fragmentation and"
3,12.4.3 Caching,638,12.4.2 Buffering,"510 Chapter 12 I/O Systems
Figure 12.11 Common PC and data-center I/O device and interface speeds.
reassembly of messages. At the sending side, a large message is fragmented
into small network packets. The packets are sent over the network, and the
receivingsideplacestheminareassemblybuffertoformanimageofthesource
data.
Athird use of buffering is to support copy semantics for application I/O.
An example will clarify the meaning of “copy semantics. ”Suppose that an
application has a buffer of data that it wishes to write to disk. It calls the
write() systemcall,providingapointertothebufferandanintegerspecifying
the number of bytes to write. After the system call returns, what happens
if the application changes the contents of the buffer? With copy semantics ,
the version of the data written to disk is guaranteed to be the version at the
time of the application system call, inde pendent of any subsequent changes
in the application’s buffer. A simple way in which the operating system can
guaranteecopysemanticsisforthe write() systemcalltocopytheapplication
data into a kernel buffer before returning control to the application. The disk
write is performed from the kernel buffer, so that subsequent changes to the
applicationbuffer have no effect.Copying of data betweenkernelbuffers and
application data space is common in operating systems, despite the overhead
that thisoperation introduces,because of the clean semantics. The same effect
canbeobtainedmoreefficientlybycleveruseofvirtualmemorymappingand
copy-on-write page protection.
12.4.3 Caching
Acacheis a region of fast memory that holds copies of data. Access to the
cached copy is more efficient than access to the original. For instance, the
instructions of the currently running process are stored on disk, cached in
physicalmemory,andcopiedagaininthe CPU’ssecondaryandprimarycaches."
3,12.4.4 Spooling and Device Reservation,639,12.4.3 Caching,"12.4 Kernel I/O Subsystem 511
The differencebetweenabufferand acache isthata buffermayhold the only
existing copy of a data item, whereas a cache, by definition, holds a copy on
fasterstorageofan itemthat resideselsewhere.
Caching and buffering are distinct functions, but sometimes a region of
memorycanbeusedforbothpurposes.Forinstance,topreservecopyseman-
tics and to enable efficient scheduling of disk I/O, the operating system uses
buffers in main memory to hold disk data. These buffers are also used as a
cache, to improve the I/Oefficiency for files that are shared by applications or
that are being written and reread rapidly. When the kernel receives a file I/O
request, the kernel first accesses the buffer cache to see whether that region
of the file is already available in main memory. If it is, a physical disk I/O
can be avoided or deferred. Also, disk writes are accumulated in the buffer
cacheforseveralseconds,sothatlargetransfersaregatheredtoallowefficient
write schedules. This strategy of delaying writes to improve I/Oefficiency is
discussed,inthe contextof remotefileaccess,inSection19.8.
12.4.4 Spooling and Device Reservation
Aspoolisabufferthatholdsoutputforadevice,suchasaprinter,thatcannot
acceptinterleaveddatastreams.Althoughaprintercanserveonlyonejobata
time,severalapplicationsmaywishtoprinttheiroutputconcurrently,without
havingtheiroutputmixedtogether.The operatingsystemsolvesthisproblem
by intercepting all output to the printer. Each application’s output is spooled
toaseparatesecondarystoragefile.Whenanapplicationfinishesprinting,the
spooling system queues the corresponding spool file for output to the printer.
Thespoolingsystemcopiesthequeuedspoolfilestotheprinteroneatatime.In
someoperatingsystems,spoolingismanagedbyasystemdaemonprocess.In
others,itishandledbyanin-kernelthread.Ineithercase,theoperatingsystem
provides a control interface that enables users and system administrators to
display the queue, remove unwanted jobs before those jobs print, suspend
printingwhilethe printerisserviced,and soon.
Some devices, such as tape drives and printers, cannot usefully multiplex
theI/Orequests of multiple concurrent applications. Spooling is one way
operatingsystemscancoordinateconcurrentoutput.Anotherwaytodealwith
concurrentdeviceaccessistoprovideexp licitfacilitiesforcoordination.Some
operatingsystems(including VMS)providesupportforexclusivedeviceaccess
by enabling a process to allocate an idle device and to deallocate that device
when it is no longer needed. Other operating systems enforce a limit of one
open file handle to such a device. Many operating systems provide functions
that enable processes to coordinate exclusive access among themselves. For
instance,Windowsprovidessystemcalls towaituntiladeviceobjectbecomes
available. It also has a parameter to the OpenFile() system call that declares
the types of access to be permitted to other concurrent threads. On these
systems,itisup tothe applicationsto avoiddeadlock.
12.4.5 Error Handling
An operating system that uses protected memory can guard against many
kinds of hardware and application errors, so that a complete system failure
isnot the usualresultof eachminor mechanical malfunction. Devicesand I/O
transferscanfailinmanyways,eitherfortransientreasons,aswhenanetwork"
3,12.4.5 Error Handling,639,12.4.4 Spooling and Device Reservation,"12.4 Kernel I/O Subsystem 511
The differencebetweenabufferand acache isthata buffermayhold the only
existing copy of a data item, whereas a cache, by definition, holds a copy on
fasterstorageofan itemthat resideselsewhere.
Caching and buffering are distinct functions, but sometimes a region of
memorycanbeusedforbothpurposes.Forinstance,topreservecopyseman-
tics and to enable efficient scheduling of disk I/O, the operating system uses
buffers in main memory to hold disk data. These buffers are also used as a
cache, to improve the I/Oefficiency for files that are shared by applications or
that are being written and reread rapidly. When the kernel receives a file I/O
request, the kernel first accesses the buffer cache to see whether that region
of the file is already available in main memory. If it is, a physical disk I/O
can be avoided or deferred. Also, disk writes are accumulated in the buffer
cacheforseveralseconds,sothatlargetransfersaregatheredtoallowefficient
write schedules. This strategy of delaying writes to improve I/Oefficiency is
discussed,inthe contextof remotefileaccess,inSection19.8.
12.4.4 Spooling and Device Reservation
Aspoolisabufferthatholdsoutputforadevice,suchasaprinter,thatcannot
acceptinterleaveddatastreams.Althoughaprintercanserveonlyonejobata
time,severalapplicationsmaywishtoprinttheiroutputconcurrently,without
havingtheiroutputmixedtogether.The operatingsystemsolvesthisproblem
by intercepting all output to the printer. Each application’s output is spooled
toaseparatesecondarystoragefile.Whenanapplicationfinishesprinting,the
spooling system queues the corresponding spool file for output to the printer.
Thespoolingsystemcopiesthequeuedspoolfilestotheprinteroneatatime.In
someoperatingsystems,spoolingismanagedbyasystemdaemonprocess.In
others,itishandledbyanin-kernelthread.Ineithercase,theoperatingsystem
provides a control interface that enables users and system administrators to
display the queue, remove unwanted jobs before those jobs print, suspend
printingwhilethe printerisserviced,and soon.
Some devices, such as tape drives and printers, cannot usefully multiplex
theI/Orequests of multiple concurrent applications. Spooling is one way
operatingsystemscancoordinateconcurrentoutput.Anotherwaytodealwith
concurrentdeviceaccessistoprovideexp licitfacilitiesforcoordination.Some
operatingsystems(including VMS)providesupportforexclusivedeviceaccess
by enabling a process to allocate an idle device and to deallocate that device
when it is no longer needed. Other operating systems enforce a limit of one
open file handle to such a device. Many operating systems provide functions
that enable processes to coordinate exclusive access among themselves. For
instance,Windowsprovidessystemcalls towaituntiladeviceobjectbecomes
available. It also has a parameter to the OpenFile() system call that declares
the types of access to be permitted to other concurrent threads. On these
systems,itisup tothe applicationsto avoiddeadlock.
12.4.5 Error Handling
An operating system that uses protected memory can guard against many
kinds of hardware and application errors, so that a complete system failure
isnot the usualresultof eachminor mechanical malfunction. Devicesand I/O
transferscanfailinmanyways,eitherfortransientreasons,aswhenanetwork"
3,12.4.6 I/O Protection,640,12.4.5 Error Handling,"512 Chapter 12 I/O Systems
becomes overloaded, or for “permanent ”reasons, as when a disk controller
becomes defective. Operating systems can often compensate effectively for
transient failures.For instance, a disk read()failureresultsina read()retry,
and a network send()errorresultsina resend() ,if the protocol so specifies.
Unfortunately,ifanimportantcompone ntexperiencesapermanentfailure,the
operatingsystemisunlikelytorecover.
As a general rule, an I/Osystem call will return one bit of information
about the status of the call, signifying either success or failure. In the UNIX
operatingsystem,anadditionalintegervariablenamed errnoisusedtoreturn
anerrorcode—oneofaboutahundredvalues—indicatingthegeneralnature
of the failure (for example, argument out of range, bad pointer, or file not
open). By contrast, some hardware can provide highly detailed error infor-
mation, although many current operatingsystemsarenot designedto convey
this information to the application. For instance, a failure of a SCSIdevice is
reported by the SCSIprotocol in three levels of detail: a sense key that iden-
tifies the general nature of the failure, such as a hardware error or an illegal
request; an additional sense code that states the category of failure, such as a
bad command parameter or a self-test failure; and an additional sense-code
qualifie that givesevenmoredetail,such aswhich command parameterwas
in error or which hardware subsystem failed its self-test. Further, many SCSI
devicesmaintaininternalpagesoferror-loginformationthatcanberequested
by the host—but seldomare.
12.4.6 I/O Protection
Errors are closely related to the issue of protection. A user process may acci-
dentally or purposely attempt to disrupt the normal operation of a system by
attemptingtoissueillegal I/Oinstructions.Wecanusevariousmechanismsto
ensure that such disruptionscannot take place in the system.
Topreventusersfromperformingillegal I/O,wedefineall I/Oinstructions
tobeprivilegedinstructions.Thus,userscannotissue I/Oinstructionsdirectly;
they must do it through the operating system. To do I/O,au s e rp r o g r a m
executes a system call to request that the operating system perform I/Oon its
behalf(Figure12.12).Theoperatingsystem,executinginmonitormode,checks
that the request is valid and, if it is, does the I/Orequested. The operating
systemthenreturnstothe user.
In addition, any memory-mapped and I/Oport memory locations must
be protected from user access by the memory-protection system. Note that a
kernel cannot simply deny all user access. Most graphics games and video
editingandplaybacksoftwareneeddirectaccesstomemory-mappedgraphics
controllermemorytospeedtheperformanceofthegraphics,forexample.The
kernel might in this case provide a locking mechanism to allow a section of
graphics memory (representing a window on screen) to be allocated to one
processat atime.
12.4.7 Kernel Data Structures
Thekernelneedstokeepstateinformationabouttheuseof I/Ocomponents.It
doessothroughavarietyofin-kerneldatastructures,suchastheopen-filetable"
3,12.4.7 Kernel Data Structures,640,12.4.6 I/O Protection,"512 Chapter 12 I/O Systems
becomes overloaded, or for “permanent ”reasons, as when a disk controller
becomes defective. Operating systems can often compensate effectively for
transient failures.For instance, a disk read()failureresultsina read()retry,
and a network send()errorresultsina resend() ,if the protocol so specifies.
Unfortunately,ifanimportantcompone ntexperiencesapermanentfailure,the
operatingsystemisunlikelytorecover.
As a general rule, an I/Osystem call will return one bit of information
about the status of the call, signifying either success or failure. In the UNIX
operatingsystem,anadditionalintegervariablenamed errnoisusedtoreturn
anerrorcode—oneofaboutahundredvalues—indicatingthegeneralnature
of the failure (for example, argument out of range, bad pointer, or file not
open). By contrast, some hardware can provide highly detailed error infor-
mation, although many current operatingsystemsarenot designedto convey
this information to the application. For instance, a failure of a SCSIdevice is
reported by the SCSIprotocol in three levels of detail: a sense key that iden-
tifies the general nature of the failure, such as a hardware error or an illegal
request; an additional sense code that states the category of failure, such as a
bad command parameter or a self-test failure; and an additional sense-code
qualifie that givesevenmoredetail,such aswhich command parameterwas
in error or which hardware subsystem failed its self-test. Further, many SCSI
devicesmaintaininternalpagesoferror-loginformationthatcanberequested
by the host—but seldomare.
12.4.6 I/O Protection
Errors are closely related to the issue of protection. A user process may acci-
dentally or purposely attempt to disrupt the normal operation of a system by
attemptingtoissueillegal I/Oinstructions.Wecanusevariousmechanismsto
ensure that such disruptionscannot take place in the system.
Topreventusersfromperformingillegal I/O,wedefineall I/Oinstructions
tobeprivilegedinstructions.Thus,userscannotissue I/Oinstructionsdirectly;
they must do it through the operating system. To do I/O,au s e rp r o g r a m
executes a system call to request that the operating system perform I/Oon its
behalf(Figure12.12).Theoperatingsystem,executinginmonitormode,checks
that the request is valid and, if it is, does the I/Orequested. The operating
systemthenreturnstothe user.
In addition, any memory-mapped and I/Oport memory locations must
be protected from user access by the memory-protection system. Note that a
kernel cannot simply deny all user access. Most graphics games and video
editingandplaybacksoftwareneeddirectaccesstomemory-mappedgraphics
controllermemorytospeedtheperformanceofthegraphics,forexample.The
kernel might in this case provide a locking mechanism to allow a section of
graphics memory (representing a window on screen) to be allocated to one
processat atime.
12.4.7 Kernel Data Structures
Thekernelneedstokeepstateinformationabouttheuseof I/Ocomponents.It
doessothroughavarietyofin-kerneldatastructures,suchastheopen-filetable"
3,12.4.8 Power Management,642,12.4.7 Kernel Data Structures,"514 Chapter 12 I/O Systems
active-inode 
table
network-
information
tableper-process
open-file table
user-process memorysystem-wide open-file table
kernel memory




file-system record
inode pointer
pointer to read and write functions
pointer to select function
pointer to ioctl function
pointer to close function
networking (socket) record
pointer to network info
pointer to read and write functions
pointer to select function
pointer to ioctl function
pointer to close functionfile descriptor
Figure 12.13 UNIX I/O kernel structure.
12.4.8 Power Management
Computers residing in data centers may seem far removed from issues of
power use, but as power costs increase and the world becomes increasingly
troubled about the long-term effects of greenhouse gas emissions, data cen-
ters have become a cause for concern and a target for increased efficiencies.
Electricity use generates heat, and computer components can fail due to high
temperatures, so cooling is part of the equation as well. Consider that cool-
ing a modern data center may use twice as much electricity as powering the
equipment does. Many approaches to data-center power optimization are in
use, ranging from interchanging data-c enter air without sideair, chilling with
natural sourcessuch as lake water,and solar panels.
Operating systems play a role in power use (and therefore heat gener-
ation and cooling). In cloud computing environments, processing loads can
be adjusted by monitoring and management tools to evacuate all user pro-
cesses from systems, idling those systems and powering them off until the
loadrequirestheiruse.Anoperatingsystemcouldanalyzeitsloadand,ifsuf-
ficiently low and hardware-enabled, power off components such as CPUsand
external I/Odevices.
CPUcores can be suspended when the system load does not require them
and resumed when the load increases and more cores are needed to run the
queue of threads. Their state, of course, needs to be saved on suspend and
restoredonresume.Thisfeatureisneededinserversbecauseadatacenterfull"
3,12.4.9 Kernel I/O Subsystem Summary,644,12.4.8 Power Management,"516 Chapter 12 I/O Systems
ensurethat thesystemdoesnot gotosleepuntiltheupdateiscomplete.Once
complete, the Android Market will release the wakelock, allowing the system
to enterpower collapse.
Power management in general is based on device management, which is
morecomplicatedthanwehavesofarportrayedit.Atboottime,thefirmware
systemanalyzesthesystemhardwareandcreatesadevicetreein RAM.Theker-
nelthenusesthatdevicetreetoloaddevicedriversandmanagedevices.Many
additional activities pertaining to d evices must be managed, though, includ-
ing addition and subtraction of devices from a running system ( “hot-plug ”),
understanding and changing device states, and power management. Modern
general-purpose computers use another set of firmware code, advanced con-
figuratio and power interface (ACPI), to manage these aspects of hardware.
ACPIisanindustrystandard( http://www.acpi.info )withmanyfeatures.Itpro-
videscodethatrunsasroutinescallablebythekernelfordevicestatediscovery
and management, device error management, and power management. For
example, when the kernel needs to quiesce a device, it calls the device driver,
which calls the ACPIroutines,which thentalkto thedevice.
12.4.9 Kernel I/O Subsystem Summary
Insummary,the I/Osubsystemcoordinatesanextensivecollectionofservices
that are available to applications and to other parts of the kernel. The I/O
subsystemsupervisestheseprocedures:
•Managementof the name space forfiles and devices
•Accesscontrol to filesand devices
•Operationcontrol (for example,a modemcannot seek())
•File-systemspace allocation
•Deviceallocation
•Buffering,caching, and spooling
•I/Oscheduling
•Device-statusmonitoring,errorhandling, and failurerecovery
•Device-driverconfiguration andinitialization
•Power managementof I/Odevices
The upper levels of the I/Osubsystem access devices via the uniform
interfaceprovidedby the devicedrivers.
12.5 Transforming I/O Requests to Hardware
Operations
Earlier, we described the handshaking between a device driver and a device
controller,butwedidnotexplainhowtheoperatingsystemconnectsanappli-
cation request to a set of network wires or to a specific disk sector. Consider,"
2,12.5 Transforming I/O Requests to Hardware Operations,644,12.4 Kernel I/O Subsystem,"516 Chapter 12 I/O Systems
ensurethat thesystemdoesnot gotosleepuntiltheupdateiscomplete.Once
complete, the Android Market will release the wakelock, allowing the system
to enterpower collapse.
Power management in general is based on device management, which is
morecomplicatedthanwehavesofarportrayedit.Atboottime,thefirmware
systemanalyzesthesystemhardwareandcreatesadevicetreein RAM.Theker-
nelthenusesthatdevicetreetoloaddevicedriversandmanagedevices.Many
additional activities pertaining to d evices must be managed, though, includ-
ing addition and subtraction of devices from a running system ( “hot-plug ”),
understanding and changing device states, and power management. Modern
general-purpose computers use another set of firmware code, advanced con-
figuratio and power interface (ACPI), to manage these aspects of hardware.
ACPIisanindustrystandard( http://www.acpi.info )withmanyfeatures.Itpro-
videscodethatrunsasroutinescallablebythekernelfordevicestatediscovery
and management, device error management, and power management. For
example, when the kernel needs to quiesce a device, it calls the device driver,
which calls the ACPIroutines,which thentalkto thedevice.
12.4.9 Kernel I/O Subsystem Summary
Insummary,the I/Osubsystemcoordinatesanextensivecollectionofservices
that are available to applications and to other parts of the kernel. The I/O
subsystemsupervisestheseprocedures:
•Managementof the name space forfiles and devices
•Accesscontrol to filesand devices
•Operationcontrol (for example,a modemcannot seek())
•File-systemspace allocation
•Deviceallocation
•Buffering,caching, and spooling
•I/Oscheduling
•Device-statusmonitoring,errorhandling, and failurerecovery
•Device-driverconfiguration andinitialization
•Power managementof I/Odevices
The upper levels of the I/Osubsystem access devices via the uniform
interfaceprovidedby the devicedrivers.
12.5 Transforming I/O Requests to Hardware
Operations
Earlier, we described the handshaking between a device driver and a device
controller,butwedidnotexplainhowtheoperatingsystemconnectsanappli-
cation request to a set of network wires or to a specific disk sector. Consider,"
2,12.6 STREAMS,647,12.5 Transforming I/O Requests to Hardware Operations,"12.6 STREAMS 519
4.The device driver allocates kernel buffer space to receive the data and
schedules the I/O. Eventually, the driver sends commands to the device
controllerby writing intothe device-controlregisters.
5.The device controller operates the device hardware to perform the data
transfer.
6.The driver may poll for status and data, or it may have set up a DMA
transfer into kernel memory. We a ssume that the transfer is managed
by aDMAcontroller, which generates an interrupt when the transfer
completes.
7.The correct interrupt handler receives the interrupt via the interrupt-
vector table, stores any necessary data, signals the device driver, and
returnsfromthe interrupt.
8.The device driver receives the signal, determines which I/Orequest has
completed, determines the request’s status, and signals the kernel I/O
subsystemthat therequesthas beencompleted.
9.The kernel transfers data or return codes to the address space of the
requesting process and moves the process from the wait queue back to
thereadyqueue.
10.Moving the process to the ready queue unblocks the process. When the
scheduler assigns the process to the CPU, the process resumes execution
atthe completionof thesystemcall.
12.6 STREAMS
UNIXSystemV(andmanysubsequent UNIXreleases)hasaninterestingmech-
anism, called STREAMS , that enables an application to assemble pipelines of
drivercodedynamically.Astreamisafull-duplexconnectionbetweenadevice
driverandauser-levelprocess.Itconsistsofa stream head thatinterfaceswith
theuserprocess,a driver end thatcontrolsthedevice,andzeroormore stream
modules between the stream head and the driver end. Each of these compo-
nents contains a pair of queues—a read queue and a write queue. Message
passing is used to transfer data between queues. The STREAMS structure is
shown inFigure 12.15.
Modulesprovidethefunctionalityof STREAMS processing;theyare pushed
onto a stream by use of the ioctl() system call. For example, a process can
open a USBdevice (like a keyboard) via a stream and can push on a module
to handle input editing. Because messages are exchanged between queues in
adjacentmodules,aqueueinonemodulemayoverflowanadjacentqueue.To
preventthis from occurring, a queue may support flo control . Without flow
control, a queue accepts all messages and immediately sends them on to the
queue in the adjacent module without buffering them. Aqueue that supports
flowcontrolbuffersmessagesanddoesnotacceptmessageswithoutsufficient
buffer space. This process involves exchanges of control messages between
queuesinadjacentmodules."
2,12.7 Performance,649,12.6 STREAMS,"12.7 Performance 521
Thebenefitofusing STREAMS isthatitprovidesaframeworkforamodular
and incremental approach to writing device drivers and network protocols.
Modules may be used by different streams and hence by different devices.
Forexample,anetworking modulemaybeusedbybothanEthernetnetwork
card and a 802.11 wireless network card. Furthermore, rather than treating
character-device I/Oas an unstructured byte stream, STREAMS allows sup-
port for message boundaries and control information when communicating
betweenmodules.Most UNIXvariantssupport STREAMS ,anditisthepreferred
methodforwritingprotocolsanddevicedrivers.Forexample,SystemV UNIX
andSolarisimplementthe socketmechanism using STREAMS .
12.7 Performance
I/Ois a major factor in system performance. It places heavy demands on
theCPUto execute device-driver code and to schedule processes fairly and
efficiently as they block and unblock. The resulting context switches stress
theCPUand its hardware caches. I/Oalso exposes any inefficiencies in the
interrupt-handlingmechanismsinthe kernel.Inaddition, I/Oloadsdownthe
memorybusduringdatacopiesbetweencontrollersandphysicalmemoryand
againduringcopiesbetweenkernelbuffersandapplicationdataspace.Coping
gracefully with all these demands is one of the major concerns of a computer
architect.
Althoughmoderncomputerscanhandlemanythousandsofinterruptsper
second,interrupthandlingisarelativelyexpensivetask.Eachinterruptcauses
the system to perform a state change, to execute the interrupt handler, and
then to restore state. Programmed I/Oc a nb em o r ee f fi c i e n tt h a ni n t e r r u p t -
drivenI/O, if the number of cycles spent in busy waiting is not excessive. An
I/Ocompletion typically unblocks a process, leading to the full overhead of a
contextswitch.
Network traffic can also cause a high context-switch rate. Consider, for
instance, a remote login from one machine to another. Each character typed
on the local machine must be transported to the remote machine. On the local
machine, the character is typed; a keyboard interrupt is generated; and the
character is passed through the interrupt handler to the device driver, to the
kernel, and then to the user process. The user process issues a network I/O
system call to send the character to the remote machine. The character then
flowsintothelocalkernel,throughthen etworklayersthatconstructanetwork
packet,andintothenetworkdevicedriver.Thenetworkdevicedrivertransfers
the packet to the network controller, which sends the character and generates
an interrupt. The interrupt is passed back up through the kernel to cause the
network I/Osystemcall tocomplete.
Now, the remote system’s network hardware receives the packet, and an
interrupt is generated. The characte r is unpacked from the network proto-
cols and is given to the appropriate network daemon. The network daemon
identifies which remote login session is involved and passes the packet to the
appropriate subdaemon for that session. Throughout this flow, there are con-
textswitchesandstateswitches(Figure12.16).Usually,thereceiverechoesthe
character back to the sender;that approach doublesthe work."
2,12.8 Summary,652,12.7 Performance,"524 Chapter 12 I/O Systems
Figure 12.18 I/O performance of storage (and network latency).
opment time (months rather than days), and the decreased flexibility. For
instance, a hardware RAIDcontroller may not provide any means for the
kernel to influence the order or location of individual block reads and
writes,evenif the kernel has special information about the workload that
would enable itto improvethe I/Operformance.
Over time, as with other aspects of computing, I/Odevices have been
increasing in speed. Nonvolatile memory devices are growing in popularity
and in the variety of devices available. The speed of NVMd e v i c e sv a r i e sf r o m
hightoextraordinary,withnext-generationdevicesnearingthespeedof DRAM.
These developments are increasing pressure on I/Osubsystems as well as
operating system algorithms to take advantage of the read/write speeds now
available. Figure 12.18 shows CPUand storage devices in two dimensions:
capacityandlatencyof I/Ooperations.Addedtothefigureisarepresentation
ofnetworkinglatencytorevealtheperformance “tax”networkingaddsto I/O.
12.8 Summary
•Thebasichardwareelementsinvolvedin I/Oarebuses,devicecontrollers,
and thedevicesthemselves.
•Theworkofmovingdatabetweendevicesandmainmemoryisperformed
by theCPUas programmed I/Oor isoffloadedtoa DMAcontroller.
•The kernel module that controls a device is a device driver. The system-
call interface provided to applications is designed to handle several basic
categoriesofhardware,includingblockdevices,character-streamdevices,
memory-mappedfiles,networksockets,andprogrammedintervaltimers.
Thesystemcallsusuallyblocktheprocessesthatissuethem,butnonblock-
ingandasynchronouscallsareusedbythekernelitselfandbyapplications
that mustnot sleepwhile waiting foran I/Ooperationtocomplete."
2,Practice Exercises,653,12.8 Summary,"Practice Exercises 525
•Thekernel’s I/Osubsystemprovidesnumerousservices.Amongtheseare
I/Oscheduling,buffering,caching,spoo ling,devicereservation,errorhan-
dling. Another service, name translation, makes the connections between
hardware devices and the symbolic file names used by applications. It
involves several levels of mapping that translate from character-string
names, to specific device drivers and device addresses, and then to phys-
ical addresses of I/Oports or bus controllers. This mapping may occur
withinthefile-systemnamespace,asitdoesin UNIX,orinaseparatedevice
name space,as itdoesin MS-DOS.
•STREAMS is an implementation and methodology that provides a frame-
work for a modular and incremental approach to writing device drivers
and network protocols. Through STREAMS , drivers can be stacked, with
datapassingthroughthemsequentiallyandbidirectionallyforprocessing.
•I/Osystem calls are costly in terms of CPUconsumption because of the
many layers of software between a physical device and an application.
These layers imply overhead from several sources: context switching to
cross the kernel’s protection boundary, signal and interrupt handling to
service the I/Odevices, and the load on the CPUand memory system to
copy data betweenkernelbuffers and applicationspace.
Practice Exercises
12.1State three advantages of placing functionality in a device controller,
rather thaninthe kernel.Statethreedisadvantages.
12.2The example of handshaking in Section 12.2 used two bits: a busy bit
anda command-readybit.Isitpossibletoimplementthishandshaking
withonlyonebit?Ifitis,describetheprotocol.Ifitisnot,explainwhy
one bit isinsufficient.
12.3Whymightasystemuseinterrupt-driven I/Otomanageasingleserial
portandpolling I/Otomanageafront-endprocessor,suchasaterminal
concentrator?
12.4Polling for an I/Ocompletion can waste a large number of CPUcycles
iftheprocessoriteratesabusy-waitingloopmanytimesbeforethe I/O
completes.Butifthe I/Odeviceisreadyforservice,pollingcanbemuch
more efficient than catching and dispatching an interrupt. Describe a
hybrid strategythat combines po lling,sleeping,and interruptsfor I/O
device service. For each of these three strategies (pure polling, pure
interrupts, hybrid), describe a computing environment in which that
strategyismoreefficient thaneitherof theothers.
12.5How does DMAincrease system concurrency? How does it complicate
hardware design?
12.6Why is it important to scale up system-bus and device speeds as CPU
speedincreases?
12.7Distinguish between a driver end and a stream module in a STREAMS
operation."
2,Further Reading,654,Practice Exercises,"526 Chapter 12 I/O Systems
Further Reading
[Hennessy and Patterson (2012)] describe multiprocessor systems and cache-
consistency issues. [Intel (2011)] is a good source of information for Intel pro-
cessors.
Detailsabout PCIecanbefoundat https://pcisig.com .Formoreabout ACPI
seehttp://www.acpi.info .
The use of FUSEfor user-mode file systems can create performance prob-
lems. An analysis of those issues can be found in https://www.usenix.org
/conference/fast17/technical-sessions/presentation/vangoor .
Bibliography
[Hennessy and Patterson (2012)] J.HennessyandD.Patterson, Computer Archi-
tecture: A Quantitative Approach, Fifth Edition, MorganKaufmann(2012).
[Intel (2011)] Intel 64 and IA-32 Architectures So ftware Developer’s Manual, Com-
bined Volumes: 1, 2A, 2B, 3A and 3B . IntelCorporation(2011)."
2,Bibliography,654,Further Reading,"526 Chapter 12 I/O Systems
Further Reading
[Hennessy and Patterson (2012)] describe multiprocessor systems and cache-
consistency issues. [Intel (2011)] is a good source of information for Intel pro-
cessors.
Detailsabout PCIecanbefoundat https://pcisig.com .Formoreabout ACPI
seehttp://www.acpi.info .
The use of FUSEfor user-mode file systems can create performance prob-
lems. An analysis of those issues can be found in https://www.usenix.org
/conference/fast17/technical-sessions/presentation/vangoor .
Bibliography
[Hennessy and Patterson (2012)] J.HennessyandD.Patterson, Computer Archi-
tecture: A Quantitative Approach, Fifth Edition, MorganKaufmann(2012).
[Intel (2011)] Intel 64 and IA-32 Architectures So ftware Developer’s Manual, Com-
bined Volumes: 1, 2A, 2B, 3A and 3B . IntelCorporation(2011)."
2,Chapter 12 Exercises,655,Bibliography,"Exercises
Chapter 12 Exercises
12.8When multiple interrupts from different devices appear at about the
same time, a priority scheme could be used to determine the order in
whichtheinterruptswouldbeserviced.Discusswhatissuesneedtobe
consideredinassigning prioritiesto differentinterrupts.
12.9What are the advantages and disadvantages of supporting memory-
mapped I/Otodevice-controlregisters?
12.10Considerthefollowing I/Oscenarios ona single-user PC:
a. Amouseusedwith a graphical userinterface
b. Atape driveon a multitasking operating system (with no device
preallocationavailable)
c. Adiskdrivecontaining userfiles
d. A graphics card with direct bus connection, accessible through
memory-mapped I/O
For each of these scenarios, would you design the operating system
to use buffering, spooling, caching, or a combination? Would you use
polledI/Oorinterrupt-driven I/O?G i ver ea s o n sf o ry o u rc h o i c es .
12.11In most multiprogrammed systems, user programs access memory
throughvirtualaddresses,whiletheoperatingsystemusesrawphysi-
caladdressestoaccessmemory.Whataretheimplicationsofthisdesign
for the initiation of I/Ooperations by the user program and their exe-
cution by theoperatingsystem?
12.12What are the various kinds of performance overhead associated with
servicinganinterrupt?
12.13Describe three circumstances under which blocking I/Oshould be
used. Describe three circumstances under which nonblocking I/O
should be used. Why not just implement nonblocking I/Oand have
processesbusy-wait until theirdevicesareready?
12.14Typically, at the completion of a device I/O, a singleinterruptis raised
and appropriately handled by the host processor. In certain settings,
however, the code that is to be executed at the completion of the I/O
can be broken into two separate pieces. The first piece executes imme-
diately after the I/Ocompletes and schedules a second interrupt for
the remaining piece of code to be executed at a later time. What is the
purposeof using thisstrategyin thedesignof interrupthandlers?
12.15SomeDMAcontrollers support direct virtual memory access, where
the targets of I/Ooperations are specified as virtual addresses and
a translation from virtual to physical address is performed during
theDMA. How does this design complicate the design of the DMA
controller? What aretheadvantagesof providingsuch functionality?
12.16 UNIXcoordinatestheactivitiesofthekernel I/Ocomponentsbymanip-
ulatingsharedin-kerneldatastructures,whereasWindowsusesobject-EX-46"
0,PART SIX FILE SYSTEM,657,PART FIVE STORAGE MANAGEMENT,"Part Six
File System
Aﬁleis a collection of related information deﬁned by its creator. Files are
mapped by the operating system onto physical mass-storage devices. A
ﬁle system describes how ﬁles are mapped onto physical devices, as well
as how they are accessed and manipulated by both users and programs.
Accessing physical storage can of ten be slow, so ﬁle systems must
be designed for efﬁcient access. Other requirements may be important
as well, including providing support for ﬁle sharing and remote access to
ﬁles."
1,Chapter 13 File-System Interface,659,PART SIX FILE SYSTEM,"13CHAPTER
File - System
Interface
For most users, the file system is the most visible aspect of a general-purpose
operatingsystem.It providesthemechanism for on-line storageof and access
to both data and programs of the operating system and all the users of the
computer system.The file system consists of two distinct parts:a collection of
files,each storing relateddata,and adi rectorystructure,which organizesand
providesinformationaboutallthefilesinthesystem.Mostfilesystemsliveon
storagedevices,whichwedescribedinCh apter11andwillcontinuetodiscuss
inthenextchapter.Inthischapter,weconsiderthevariousaspectsoffilesand
the major directory structures. We also discuss the semantics of sharing files
among multiple processes, users, and computers. Finally, we discuss ways to
handle file protection, necessary when we have multiple users and want to
control who may access filesand how filesmaybe accessed.
CHAPTER OBJECTIVES
•Explain the function of file systems.
•Describe the interfaces to file systems.
•Discuss file-system design tradeoffs, including access methods, file shar-
ing, file locking, and directory structures.
•Explore file-system protection.
13.1 File Concept
Computers can store information on various storage media, such as NVM
devices, HDDs,magnetictapes,andopticaldisks.Sothatthecomputersystem
will be convenient to use, the operating system provides a uniform logical
view of stored information. The operating system abstracts from the physical
propertiesofitsstoragedevicestodefinealogicalstorageunit,the fil.Filesare
mappedbytheoperatingsystemontophysicaldevices.Thesestoragedevices
areusuallynonvolatile,sothecontentsarepersistentbetweensystemreboots.
529"
2,13.1 File Concept,659,Chapter 13 File-System Interface,"13CHAPTER
File - System
Interface
For most users, the file system is the most visible aspect of a general-purpose
operatingsystem.It providesthemechanism for on-line storageof and access
to both data and programs of the operating system and all the users of the
computer system.The file system consists of two distinct parts:a collection of
files,each storing relateddata,and adi rectorystructure,which organizesand
providesinformationaboutallthefilesinthesystem.Mostfilesystemsliveon
storagedevices,whichwedescribedinCh apter11andwillcontinuetodiscuss
inthenextchapter.Inthischapter,weconsiderthevariousaspectsoffilesand
the major directory structures. We also discuss the semantics of sharing files
among multiple processes, users, and computers. Finally, we discuss ways to
handle file protection, necessary when we have multiple users and want to
control who may access filesand how filesmaybe accessed.
CHAPTER OBJECTIVES
•Explain the function of file systems.
•Describe the interfaces to file systems.
•Discuss file-system design tradeoffs, including access methods, file shar-
ing, file locking, and directory structures.
•Explore file-system protection.
13.1 File Concept
Computers can store information on various storage media, such as NVM
devices, HDDs,magnetictapes,andopticaldisks.Sothatthecomputersystem
will be convenient to use, the operating system provides a uniform logical
view of stored information. The operating system abstracts from the physical
propertiesofitsstoragedevicestodefinealogicalstorageunit,the fil.Filesare
mappedbytheoperatingsystemontophysicaldevices.Thesestoragedevices
areusuallynonvolatile,sothecontentsarepersistentbetweensystemreboots.
529"
3,13.1.1 File Attributes,660,13.1 File Concept,"530 Chapter 13 File-System Interface
Afile is a named collection of related information that is recorded on sec-
ondary storage. From a user’s perspective, a file is the smallest allotment of
logical secondary storage; that is, data cannot be written to secondary storage
unlesstheyarewithinafile.Commonly,filesrepresentprograms(bothsource
and object forms) and data. Data files may be numeric, alphabetic, alphanu-
meric,orbinary.Filesmaybefreeform,suchastextfiles,ormaybeformatted
rigidly.Ingeneral,afileisasequenceofbits,bytes,lines,orrecords,themean-
ing of which is defined by the file’s creator and user. The concept of a file is
thus extremelygeneral.
Because files are themethod users and applications use to store and
retrievedata,and because theyaresogeneralpurpose,theirusehas stretched
beyond its original confines. For example, UNIX, Linux, and some other oper-
ating systems provide a procfile system that uses file-system interfaces to
provideaccess tosysteminformation(such asprocessdetails).
The information in a file is defined by its creator. Many different types of
information may be stored in a file—source or executable programs, numeric
ortextdata,photos,music,video,andsoon.Afilehasacertaindefinedstruc-
ture,whichdependsonitstype.A text filisasequenceofcharactersorganized
intolines(andpossiblypages).A source fil isasequenceoffunctions,eachof
which is furtherorganized asdeclarati ons followedby executablestatements.
Anexecutable fil is a series of code sections that the loader can bring into
memoryand execute.
13.1.1 File Attributes
Afile is named, for the convenience of its human users, and is referred to by
its name. A name is usually a string of characters, such as example.c .S o m e
systems differentiate between uppercase and lowercase characters in names,
whereas other systems do not. When a file is named, it becomes independent
of the process, the user, and even the syst em that created it. For instance, one
user might create the file example.c , and another user might edit that file
by specifying its name. The file’s owner might write the file to a USBdrive,
send it as an e-mail attachment, or copy it across a network, and it could still
be called example.c on the destination system. Unless there is a sharing and
synchonization method, that second copy is now independent of the first and
can be changed separately.
Afile’s attributesvary from one operating systemto another but typically
consist of these:
•Name. The symbolic file name is the only information kept in human-
readableform.
•Identifie .Thisuniquetag,usuallyanumber,identifiesthefilewithinthe
file system;it isthe non-human-readable name forthe file.
•Type. This information is neededfor systems that support different types
of files.
•Location . This information is a pointer to a device and to the location of
thefile onthat device."
3,13.1.2 File Operations,662,13.1.1 File Attributes,"532 Chapter 13 File-System Interface
13.1.2 File Operations
Afileisanabstractdatatype.Todefineafileproperly,weneedtoconsiderthe
operations that can be performed on files. The operating system can provide
system calls to create, write, read, reposi tion, delete, and truncate files. Let’s
examine what the operating system must do to perform each of these seven
basicfileoperations.Itshouldthenbeeasytoseehowothersimilaroperations,
such asrenaming a file,can be implemented.
•Creating a fil . Two steps are necessary to create a file. First, space in the
filesystemmustbefoundforthefile.Wediscusshowtoallocatespacefor
the file in Chapter14. Second, an entryfor the new file must be made in a
directory.
•Opening a fil . Rather than have all file operations specify a file name,
causing the operating system to evaluate the name, check access permis-
sions, and so on, all operations except create and delete require a file
open()first.Ifsuccessful,theopencallreturnsafilehandlethatisusedas
an argumentin the othercalls.
•Writing a fil . To write a file, we make a system call specifying both the
open file handle and the information to be written to the file. The system
must keep a write pointer to the location in the file where the next write
is to take place if it is sequential. The write pointer must be updated
wheneverawriteoccurs.
•Reading a fil . To read from a file, we use a system call that specifies the
file handle and where (in memory) the next block of the file should be
put. Again, the system needs to keep a read pointer to the location in
the file where the next read is to take place, if sequential. Once the read
has taken place, the read pointer is updated. Because a process is usually
either reading from or writing to a file, the current operation location can
be kept as a per-process current-file-positio pointer . Both the read and
writeoperationsuse thissame pointer,saving spaceand reducing system
complexity.
•Repositioning within a file. The current-file-position pointer of the open
file is repositioned to a given value. Repositioning within a file need not
involveany actual I/O.Thisfile operationisalso known as afile seek.
•Deleting a fil .Todeleteafile,we searchthedirectoryfor thenamedfile.
Having found the associated directory entry, we release all file space, so
that it can be reusedby other files, and erase or mark as freethe directory
entry. Note that some systems allow hard links —multiple names (direc-
tory entries) for the same file. In this case the actual file contents is not
deleteduntilthelast linkisdeleted.
•Truncating a fil . The user may want to erase the contents of a file but
keep its attributes. Rather than forcing the user to delete the file and then
recreateit,thisfunctionallowsallattributestoremainunchanged—except
for file length. The file can then be reset to length zero, and its file space
canbe released."
3,13.1.3 File Types,666,13.1.2 File Operations,"536 Chapter 13 File-System Interface
accessing thelockedfile.For example,assume aprocessacquiresanexclusive
lock on the file system.log . If we attempt to open system.log from another
process—forexample,atexteditor—theoperatingsystemwillpreventaccess
untiltheexclusivelockisreleased.Alternatively,ifthelockisadvisory,thenthe
operatingsystemwillnotpreventthetexteditorfromacquiringaccessto sys-
tem.log .Rather,thetexteditormustbewrittensothatitmanuallyacquiresthe
lock before accessing the file. In other words, if the locking scheme is manda-
tory, the operating system ensures locking integrity. For advisory locking, it
is up to software developers to ensure that locks are appropriately acquired
andreleased.Asageneralrule,Windowsoperatingsystemsadoptmandatory
locking, and UNIXsystemsemployadvisorylocks.
Theuseoffilelocksrequiresthesameprecautionsasordinaryprocesssyn-
chronization.Forexample,programmersdevelopingonsystemswithmanda-
tory locking must be careful to hold exclusive file locks only while they are
accessingthefile.Otherwise,theywillpreventotherprocessesfromaccessing
thefileaswell.Furthermore,somemeasuresmustbetakentoensurethattwo
ormoreprocessesdonotbecomeinvolvedinadeadlockwhiletryingtoacquire
file locks.
13.1.3 File Types
When we design a file system—indeed, an entire operating system—we
always consider whether the operating system should recognize and support
filetypes.Ifanoperatingsystemrecognizesthetypeofafile,itcanthenoperate
onthefileinreasonableways.Forexample,acommonmistakeoccurswhena
usertriestooutputthebinary-objectformofaprogram.Thisattemptnormally
produces garbage; however, the attempt can succeed if the operating system
has been toldthatthe fileisa binary-object program.
A common technique for implementing file types is to include the type
as part of the file name. The name is split into two parts—a name and an
extension, usually separated by a period (Figure 13.3). In this way, the user
and the operating system can tell from the name alone what the type of a file
is. Most operating systems allow users to specify a file name as a sequence
of characters followed by a period and terminated by an extension made
up of additional characters. Examples include resume.docx ,server.c ,a n d
ReaderThread.cpp .
The system uses the extension to indicate the type of the file and the type
ofoperationsthatcanbedoneonthatfile.Onlyafilewitha .com,.exe,or.sh
extensioncanbeexecuted,forinstance.The .comand.exefilesaretwoforms
of binary executable files, whereas the .shfile is a shell script containing, in
ASCIIformat, commands to the operating system. Application programs also
useextensionstoindicatefiletypesinwhich theyareinterested.Forexample,
Javacompilersexpectsourcefilestohavea .javaextension,andtheMicrosoft
Word word processor expects its files to end with a .docor.docxextension.
These extensionsare not always required,so a user may specify a file without
the extension (to save typing), and the application will look for a file with
the given name and the extension it expects. Because these extensions are
not supported by the operating system, they can be considered “hints ”to the
applications that operateon them.
Consider, too, the mac OSoperating system. In this system, each file has
a type, such as .app(for application). Each file also has a creator attribute"
3,13.1.4 File Structure,667,13.1.3 File Types,"13.1 File Concept 537
file type usual extension function
ready-to-run machine-
language program executable exe, com, bin
or none 
compiled, machine
language, not linked object obj, o
binary file containing
audio or A/V information   multimedia mpeg, mov, mp3,
mp4, avirelated files grouped into
one file, sometimes com-
pressed, for archiving
or storagearchive rar, zip, tarASCII or binary file in a
format for printing or
viewingprint or view gif, pdf, jpglibraries of routines for
programmerslibrary lib, a, so, dllvarious word-processor
formatsword processor
docxcommands to the command
interpreterbatch bat, sh
textual data, documents markup xml, html, texsource code in various
languagessource code c, cc, java, perl,
asm
xml, rtf,
Figure 13.3 Common file types.
containing the name of the program that created it. This attribute is set by
the operating system during the create() call, so its use is enforced and
supported by the system. For instance, a file produced by a word processor
hasthewordprocessor’snameasitscreator.Whentheuseropensthatfile,by
double-clickingthemouseontheiconrepresentingthefile,thewordprocessor
isinvokedautomatically,and thefile isloaded,readyto beedited.
TheUNIXsystem uses a magic number stored at the beginning of some
binary files to indicate the type of data in the file (for example, the format
of an image file). Likewise, it uses a text magic number at the start of text
files to indicate the type of file (which shell language a script is written in)
and so on. (For more details on magic numbers and other computer jargon,
seehttp://www.catb.org/esr/jargon/ .) Not all files have magic numbers, so
system features cannot be based solely on this information. UNIXdoes not
record the name of the creating program, either. UNIXdoes allow file-name-
extensionhints,buttheseextensionsareneitherenforcednordependedonby
theoperatingsystem;theyaremeant mostlyto aidusersindeterminingwhat
typeofcontentsthefilecontains.Extensionscanbeusedorignoredbyagiven
application,but that isupto the application’s programmer.
13.1.4 File Structure
File types also can be used to indicate the internal structure of the file. Source
and object files have structures that match the expectations of the programs
thatreadthem.Further,certainfilesmustconformtoarequiredstructurethat"
3,13.1.5 Internal File Structure,668,13.1.4 File Structure,"538 Chapter 13 File-System Interface
is understood by the operating system. For example, the operating system
requiresthatanexecutablefilehaveaspecificstructuresothatitcandetermine
where in memory to load the file and what the location of the first instruction
is. Some operating systems extend this idea into a set of system-supported
filestructures,withsetsofspecialoperationsformanipulatingfileswiththose
structures.
This point brings us to one of the disadvantages of having the operating
system support multiple file structures: it makes the operating system large
andcumbersome.Iftheoperatingsystemdefinesfivedifferentfilestructures,it
needstocontainthecodetosupportthesefilestructures.Inaddition,itmaybe
necessarytodefineeveryfileasoneofthefiletypessupportedbytheoperating
system. When new applications require information structured in ways not
supportedby the operatingsystem,severeproblemsmay result.
For example, assume that a system supports two types of files: text files
(composed of ASCIIcharacters separated by a carriage return and line feed)
and executable binary files. Now, if we (as users) want to define an encrypted
file to protect the contents from being read by unauthorized people, we may
findneitherfiletypetobeappropriate.Theencryptedfileisnot ASCIItextlines
but rather is (apparently) random bits. Although it may appear to be a binary
file, it is not executable.As a result,we may have to circumvent or misuse the
operatingsystem’sfile-typemechanism orabandon our encryption scheme.
Some operating systems impose (and support) a minimal number of file
structures. This approach has been adopted in UNIX,W i n d o w s ,a n do t h e r s .
UNIXconsiders each file to be a sequence of 8-bit bytes; no interpretation of
these bits is made by the operating system. This scheme provides maximum
flexibility but little support. Each application program must include its own
code to interpret an input file as to the appropriate structure. However, all
operating systems must support at least one structure—that of an executable
file—so that thesystemisableto loadand run programs.
13.1.5 Internal File Structure
Internally,locating an offset within a file can be complicated for the operating
system. Disk systems typically have a well-defined block size determined by
the size of a sector. All disk I/Ois performed in units of one block (physical
record), and all blocks are the same size. It is unlikely that the physical record
sizewillexactlymatchthelengthofthedesiredlogicalrecord.Logicalrecords
may even vary in length. Packing a number of logical records into physical
blocks is acommon solution tothis problem.
For example, the UNIXoperating system defines all files to be simply
streams of bytes. Each byte is individually addressable by its offset from the
beginning (or end) of the file. In this case, the logical record size is 1 byte. The
filesystemautomaticallypacksandunpacksbytesintophysicaldiskblocks—
say,512 bytesperblock—as necessary.
The logical record size, physical block size, and packing technique deter-
minehowmanylogicalrecordsareineachphysicalblock.Thepackingcanbe
done either by the user’s application program or by the operating system. In
either case, the file may be considered a sequence of blocks. All the basic I/O
functions operate in terms of blocks. The conversion from logical records to
physical blocks isa relativelysimplesoftware problem."
2,13.2 Access Methods,669,13.1 File Concept,"13.2 Access Methods 539
Because disk space is always allocated in blocks, some portion of the last
blockofeachfileisgenerallywasted.Ifeachblockwere512bytes,forexample,
then a file of 1,949 bytes would be allocated four blocks (2,048 bytes); the last
99 bytes would be wasted. The waste incurred to keep everything in units
of blocks (instead of bytes) is internal fragmentation. All file systems suffer
from internal fragmentation; the larger the block size, the greater the internal
fragmentation.
13.2 Access Methods
Filesstoreinformation.Whenitisused,thisinformationmustbeaccessedand
read into computer memory. The information in the file can be accessed in
several ways. Some systems provide only one access method for files. Others
(such as mainframe operating systems) support many access methods, and
choosing the rightone for a particularapplicationis amajor designproblem.
13.2.1 Sequential Access
The simplest access method is sequential access . Information in the file is
processed in order, one record after the other. This mode of access is by far
the most common; for example, editors and compilers usually access files in
thisfashion.
Reads and writes make up the bulk of the operations on a file. A read
operation— read
 next()—readsthenextportionofthefileandautomatically
advances a file pointer, which tracks the I/Olocation. Similarly, the write
operation— write
 next()—appendstotheendofthefileandadvancestothe
endofthenewlywrittenmaterial(thenewendoffile).Suchafilecanbereset
tothebeginning,andonsomesystems,aprogrammaybeabletoskipforward
or backward nrecords for some integer n—perhapsonlyfor n=1 .S e q u e n t i a l
access, which is depicted in Figure 13.4, is based on a tape model of a file and
works aswellon sequential-accessdevicesasit doeson random-access ones.
13.2.2 Direct Access
Another method is direct access (orrelative access ). Here, a file is made up
of fixed-length logical records that allow programs to read and write records
rapidly in no particular order. The direct-access method is based on a disk
model of a file, since disks allow random access to any file block. For direct
access, the file is viewed as a numbered sequence of blocks or records. Thus,
beginning endcurrent position
rewind
read or write
Figure 13.4 Sequential-access file."
3,13.2.1 Sequential Access,669,13.2 Access Methods,"13.2 Access Methods 539
Because disk space is always allocated in blocks, some portion of the last
blockofeachfileisgenerallywasted.Ifeachblockwere512bytes,forexample,
then a file of 1,949 bytes would be allocated four blocks (2,048 bytes); the last
99 bytes would be wasted. The waste incurred to keep everything in units
of blocks (instead of bytes) is internal fragmentation. All file systems suffer
from internal fragmentation; the larger the block size, the greater the internal
fragmentation.
13.2 Access Methods
Filesstoreinformation.Whenitisused,thisinformationmustbeaccessedand
read into computer memory. The information in the file can be accessed in
several ways. Some systems provide only one access method for files. Others
(such as mainframe operating systems) support many access methods, and
choosing the rightone for a particularapplicationis amajor designproblem.
13.2.1 Sequential Access
The simplest access method is sequential access . Information in the file is
processed in order, one record after the other. This mode of access is by far
the most common; for example, editors and compilers usually access files in
thisfashion.
Reads and writes make up the bulk of the operations on a file. A read
operation— read
 next()—readsthenextportionofthefileandautomatically
advances a file pointer, which tracks the I/Olocation. Similarly, the write
operation— write
 next()—appendstotheendofthefileandadvancestothe
endofthenewlywrittenmaterial(thenewendoffile).Suchafilecanbereset
tothebeginning,andonsomesystems,aprogrammaybeabletoskipforward
or backward nrecords for some integer n—perhapsonlyfor n=1 .S e q u e n t i a l
access, which is depicted in Figure 13.4, is based on a tape model of a file and
works aswellon sequential-accessdevicesasit doeson random-access ones.
13.2.2 Direct Access
Another method is direct access (orrelative access ). Here, a file is made up
of fixed-length logical records that allow programs to read and write records
rapidly in no particular order. The direct-access method is based on a disk
model of a file, since disks allow random access to any file block. For direct
access, the file is viewed as a numbered sequence of blocks or records. Thus,
beginning endcurrent position
rewind
read or write
Figure 13.4 Sequential-access file."
3,13.2.2 Direct Access,669,13.2.1 Sequential Access,"13.2 Access Methods 539
Because disk space is always allocated in blocks, some portion of the last
blockofeachfileisgenerallywasted.Ifeachblockwere512bytes,forexample,
then a file of 1,949 bytes would be allocated four blocks (2,048 bytes); the last
99 bytes would be wasted. The waste incurred to keep everything in units
of blocks (instead of bytes) is internal fragmentation. All file systems suffer
from internal fragmentation; the larger the block size, the greater the internal
fragmentation.
13.2 Access Methods
Filesstoreinformation.Whenitisused,thisinformationmustbeaccessedand
read into computer memory. The information in the file can be accessed in
several ways. Some systems provide only one access method for files. Others
(such as mainframe operating systems) support many access methods, and
choosing the rightone for a particularapplicationis amajor designproblem.
13.2.1 Sequential Access
The simplest access method is sequential access . Information in the file is
processed in order, one record after the other. This mode of access is by far
the most common; for example, editors and compilers usually access files in
thisfashion.
Reads and writes make up the bulk of the operations on a file. A read
operation— read
 next()—readsthenextportionofthefileandautomatically
advances a file pointer, which tracks the I/Olocation. Similarly, the write
operation— write
 next()—appendstotheendofthefileandadvancestothe
endofthenewlywrittenmaterial(thenewendoffile).Suchafilecanbereset
tothebeginning,andonsomesystems,aprogrammaybeabletoskipforward
or backward nrecords for some integer n—perhapsonlyfor n=1 .S e q u e n t i a l
access, which is depicted in Figure 13.4, is based on a tape model of a file and
works aswellon sequential-accessdevicesasit doeson random-access ones.
13.2.2 Direct Access
Another method is direct access (orrelative access ). Here, a file is made up
of fixed-length logical records that allow programs to read and write records
rapidly in no particular order. The direct-access method is based on a disk
model of a file, since disks allow random access to any file block. For direct
access, the file is viewed as a numbered sequence of blocks or records. Thus,
beginning endcurrent position
rewind
read or write
Figure 13.4 Sequential-access file."
3,13.2.3 Other Access Methods,670,13.2.2 Direct Access,"540 Chapter 13 File-System Interface
wemayreadblock14,thenreadblock53,andthenwriteblock7.Thereareno
restrictions on the order of reading or writing for a direct-access file.
Direct-access files are of great use for immediate access to large amounts
of information. Databases are often of this type. When a query concerning a
particular subject arrives, we compute which block contains the answer and
thenreadthat block directlytoprovidethedesiredinformation.
As a simple example, on an airline-reservation system, we might store all
the information about a particular flight (for example, flight 713) in the block
identified by the flight number. Thus, the number of available seats for flight
713 is stored in block 713 of the reservation file. To store information about a
larger set, such as people, we might compute a hash function on the people’s
names or search a small in-memory index to determine a block to read and
search.
For the direct-access method, the file operations must be modified to
include the block number as a parameter. Thus, we have read(n) ,w h e r e
nis the block number, rather than read
 next(),a n d write(n) rather
than write
 next(). An alternative approach is to retain read
 next()and
write
 next()and to add an operation position
 file(n) where nis the
block number. Then, to effect a read(n) ,w ew o u l d position
 file(n) and
then read
 next().
Theblocknumberprovidedbytheusertotheoperatingsystemisnormally
arelative block number . A relative block number is an index relative to the
beginning of the file. Thus, the first relative block of the file is 0, the next is
1, and so on, even though the absolute disk address may be 14703 for the
first block and 3192 for the second. The use of relative block numbers allows
the operating system to decide where the file should be placed (called the
allocation problem ,aswediscussinChapter14)andhelpstopreventtheuser
fromaccessingportionsofthefilesystemthatmaynotbepartofherfile.Some
systemsstarttheirrelativeblock numbers at 0;others startat1.
How,then,doesthesystemsatisfyarequestforrecord Ninafile?Assum-
ing we have a logical record length L,the request for record Nis turned into
anI/Orequest for Lbytesstarting at location L∗(N)within the file (assuming
the first record is N= 0). Since logical records are of a fixed size, it is also easy
to read, write, or delete a record.
Not all operating systems support both sequential and direct access for
files. Some systems allow only sequential file access; others allow only direct
access.Somesystemsrequirethatafilebedefinedassequentialordirectwhen
it is created. Such a file can be accessed only in a manner consistent with its
declaration. We can easily simulate sequential access on a direct-access file by
simply keeping a variable cpthat defines our current position, as shown in
Figure13.5.Simulatingadirect-accessfileonasequential-accessfile,however,
isextremelyinefficientand clumsy.
13.2.3 Other Access Methods
Other access methods can be built on top of a direct-access method. These
methodsgenerallyinvolvetheconstructionofanindexforthefile.The index,
like an index in the back of a book, contains pointers to the various blocks. To
find a record in the file, we first search the index and then use the pointer to
access the file directlyand to find the desiredrecord."
2,13.3 Directory Structure,671,13.2 Access Methods,"13.3 Directory Structure 541
sequential access
reset
read_next
write_nextcp  0;
read cp;
cp  cp  1;
write cp;
cp  cp  1;implementation for direct access
Figure 13.5 Simulation of sequential access on a direct-access file.
Forexample,aretail-pricefilemightlisttheuniversalproductcodes( UPCs)
foritems,withtheassociatedprices.Eachrecordconsistsofa10-digit UPCand
a 6-digit price, for a 16-byte record. If our disk has 1,024 bytes per block, we
can store 64 records per block. A file of 120,000 records would occupy about
2,000blocks(2millionbytes).Bykeepingthefilesortedby UPC,wecandefine
anindexconsistingofthefirst UPCineachblock.Thisindexwouldhave2,000
entriesof10digitseach,or20,000bytes,andthuscouldbekeptinmemory.To
find the price of a particular item, we can make a binary search of the index.
Fromthissearch,welearnexactlywhichblockcontainsthedesiredrecordand
accessthatblock.Thisstructureallowsustosearchalargefiledoinglittle I/O.
With large files, the index file itself may become too large to be kept in
memory.Onesolutionistocreateanindexfortheindexfile.Theprimaryindex
file contains pointers to secondary inde x files, which point to the actual data
items.
For example, IBM’s indexed sequential-access method ( ISAM) uses a small
master index that points to disk blocks of a secondary index. The secondary
indexblocks point to the actual fileblocks. The file is keptsortedon a defined
key.Tofindaparticularitem,wefirstmakeabinarysearchofthemasterindex,
which provides the block number of the secondary index. This block is read
in, and again a binary search is used to find the block containing the desired
record. Finally, this block is searched sequentially. In this way, any record can
belocatedfromitskeybyatmosttwodirect-accessreads.Figure13.6showsa
similarsituationas implementedby OpenVMSindexand relativefiles.
13.3 Directory Structure
T h ed i r e c t o r yc a nb ev i e w e da sas y m b o lt able that translates file names into
their file control blocks. If we take such a view, we see that the directory itself
can be organized in many ways. The organization must allow us to insert
entries, to delete entries, to search for a named entry, and to list all the entries
in the directory. In this section, we examine several schemes for defining the
logicalstructureofthe directorysystem.
Whenconsideringaparticulardirectorystructure,weneedtokeepinmind
theoperationsthat areto beperformedon a directory:
•Search for a fil .Weneedtobe abletosearch a directorystructureto find
theentryforaparticularfile.Sincefileshavesymbolicnames,andsimilar"
3,13.3.1 Single-Level Directory,672,13.3 Directory Structure,"542 Chapter 13 File-System Interface
index file relative fileSmithlast name
smith, john social-security agelogical record
number
Adams
Arthur
Asher



Figure 13.6 Example of index and relative files.
namesmayindicatearelationshipamongfiles,wemaywanttobeableto
find allfileswhose names match a particular pattern.
•Create a fil .Newfilesneedtobe createdand addedtothe directory.
•Delete a file.Whenafileisnolongerneeded,wewanttobeabletoremove
it from the directory. Note a deleteleaves a hole in the directory structure
and the file system may have a method to defragement the directory
structure.
•List a directory . We need to be able to list the files in a directory and the
contents of the directoryentryfor each file in the list.
•Rename a file.Becausethenameofafilerepresentsitscontentstoitsusers,
we must be able to change the name when the contents or use of the file
changes. Renaming a file may also allow its position within the directory
structureto be changed.
•Traverse the file system .Wemaywishtoaccesseverydirectoryandevery
filewithinadirectorystructure.Forreliability,itisagoodideatosavethe
contents and structure of the entire file system at regular intervals. Often,
wedothisbycopyingallfilestomagnet ictape,othersecondarystorage,or
across a network to another system or the cloud. This technique provides
abackupcopyincaseofsystemfailure.Inaddition,ifafileisnolongerin
u s e ,t h efi l ec a nb ec o p i e dt h eb a c k u pt a r g e ta n dt h ed i s ks p a c eo ft h a tfi l e
releasedfor reuseby another file.
In the following sections, we describe the most common schemes for defining
th elo gic a lstr u c tu r eo fadir ec to ry .
13.3.1 Single-Level Directory
The simplest directory structure is the single-level directory. All files are con-
tainedinthe samedirectory,which is easy tosupport andunderstand (Figure
13.7)."
3,13.3.2 Two-Level Directory,673,13.3.1 Single-Level Directory,"13.3 Directory Structure 543
cat
filesdirectory bo a test data mail cont hex records
Figure 13.7 Single-level directory.
A single-level directory has significant limitations, however, when the
numberoffilesincreasesorwhenthesystemhasmorethanoneuser.Sinceall
files are in the same directory,they must have unique names. If two users call
their data file test.txt , then the unique-name rule is violated. For example,
in one programming class, 23 students called the program for their second
assignment prog2.c ; another 11 called it assign2.c . Fortunately, most file
systems support file names of up to 255 characters, so it is relatively easy to
selectuniquefile names.
Evenasingleuseronasingle-leveldirectorymayfinditdifficulttoremem-
berthenamesofallthefilesasthenumberoffilesincreases.Itisnotuncommon
for a user to have hundreds of files on one computer system and an equal
numberofadditionalfilesonanothersystem.Keepingtrackofsomanyfilesis
adaunting task.
13.3.2 Two-Level Directory
Aswehaveseen,asingle-leveldirectoryoftenleadstoconfusionoffilenames
among different users. The standard solution is to create a separate directory
foreach user.
In the two-level directory structure, each user has his own user fil direc-
tory(UFD). TheUFDs have similar structures, but each lists only the files of
a single user. When a user job starts or a user logs in, the system’s master
fil directory (MFD)i ss e a r c h e d .T h e MFDis indexed by user name or account
number, and each entrypoints tothe UFDfor that user(Figure13.8).
Whenauserreferstoaparticularfile,onlyhisown UFDissearched.Thus,
differentusersmayhavefileswiththesamename,aslongasallthefilenames
within each UFDare unique. To create a file for a user, the operating system
searches only that user’s UFDto ascertain whether another file of that name
cat bo a test x data a auser 1 user 2 user 3 user 4
data a testuser file
directorymaster file
directory
Figure 13.8 Two-level directory structure."
3,13.3.3 Tree-Structured Directories,675,13.3.2 Two-Level Directory,"13.3 Directory Structure 545
require 5 MB, then supporting 12 users would require 5 ×12 = 60 MBjust for
copiesof thesystemfiles.)
The standard solution is to complicate the search procedure slightly. A
special user directory is defined to contain the system files (for example, user
0). Whenever a file name is given to be loaded, the operating system first
searchesthelocal UFD.Ifthefileisfound,itisused.Ifitisnotfound,thesystem
automaticallysearchesthespecialuserdirectorythatcontainsthesystemfiles.
The sequence of directories searched when a file is named is called the search
path.Thesearchpathcanbeextendedtocontainanunlimitedlistofdirectories
to search when a command name is given. This method is the one most used
inUNIXand Windows. Systems can also be designedso that each user has his
o w nsea r c hpa th .
13.3.3 Tree-Structured Directories
Once we have seen how to view a two-level directory as a two-level tree,
the natural generalization is to extend the directory structure to a tree of
arbitrary height (Figure 13.9). This generalization allows users to create their
own subdirectories and to organize their files accordingly. A tree is the most
commondirectorystructure.Thetreehasarootdirectory,andeveryfileinthe
systemhas a uniquepathname.
A directory (or subdirectory) contains a set of files or subdirectories. In
many implementations, a directory is simply another file, but it is treated in
a special way. All directories have the same internal format. One bit in each
directory entry defines the entry as a file (0) or as a subdirectory (1). Special
list obj spellfind count hex reorder stat mail distroot
spell binprograms
p e mail
reorder list find prog copy prt exp
last firsthex count
all
Figure 13.9 Tree-structured directory structure."
3,13.3.4 Acyclic-Graph Directories,677,13.3.3 Tree-Structured Directories,"13.3 Directory Structure 547
isissuedinerror,alargenumberoffilesanddirectorieswillneedtoberestored
(assuminga backup exists).
With a tree-structureddirectorysystem, users can be allowed to access, in
additionto theirfiles, the files of other users.For example,user B can access a
fileofuserAbyspecifyingitspathname.UserBcanspecifyeitheranabsolute
orarelativepathname.Alternatively,userBcanchange hercurrentdirectory
tobe userA’sdirectoryand accessthe fileby itsfile name.
13.3.4 Acyclic-Graph Directories
Considertwoprogrammerswhoareworkingonajointproject.Thefilesasso-
ciated with that project can be stored in a subdirectory, separating them from
other projects and files of the two programmers. But since both programmers
areequallyresponsiblefortheproject,bothwantthesubdirectorytobeintheir
o w nd i r e c t o r i e s .I nt h i ss i t u a t i o n ,t h ec o m m o ns u b d i r e c t o r ys h o u l db e shared.
A shared directory or file exists in the file system in two (or more) places at
once.
A tree structure prohibits the sharing of files or directories. An acyclic
graph—that is, a graph with no cycles—allows directories to share subdirec-
tories and files (Figure 13.10). The same file or subdirectory may be in two
different directories. The acyclic graph is a natural generalization of the tree-
structureddirectoryscheme.
Itisimportanttonotethatasharedfile(ordirectory)isnotthesameastwo
copiesofthefile.Withtwocopies,eachprogrammercanviewthecopyrather
thanthe original,butifoneprogrammerchanges thefile,the changeswillnot
appearintheother’scopy.Withasharedfile,onlyoneactualfileexists,soany
changes made by one person are immediately visible to the other. Sharing is
listallw countwordslist
listradew7countroot
dictspell
Figure 13.10 Acyclic-graph directory structure."
3,13.3.5 General Graph Directory,679,13.3.4 Acyclic-Graph Directories,"13.3 Directory Structure 549
deletedand another file of thesame nameis created,beforea symbolic linkto
theoriginalfileisused.)Inthecaseof UNIX,symboliclinksareleftwhenafile
is deleted,and it is up to the user to realizethat the original file is gone or has
beenreplaced.MicrosoftWindows usesthesameapproach.
Another approach to deletion is to preserve the file until all references to
it are deleted. To implement this approach, we must have some mechanism
for determining that the last reference to the file has been deleted. We could
keepa listof allreferencesto a file (directoryentriesor symbolic links).When
a link or a copy of the directory entry i s established, a new entry is added to
the file-reference list. When a link or directory entry is deleted, we remove its
entryonthelist.Thefile isdeletedwhenitsfile-referencelistisempty.
The troublewiththis approach isthevariableand potentiallylargesizeof
the file-reference list. However, we really do not need to keep the entire list
—we need to keep only a count of the number of references. Adding a new
linkordirectoryentryincrementsthereferencecount.Deletingalinkorentry
decrementsthecount.Whenthecountis0,thefilecanbedeleted;thereareno
remaining references to it. The UNIXoperating system uses this approach for
nonsymbolic links (or hard links ), keeping a reference count in the file infor-
mation block (or inode; see Section C.7.2). By effectively prohibiting multiple
referencestodirectories,we maintainanacyclic-graph structure.
To avoid problems such as the ones just discussed, some systems simply
donot allow shareddirectoriesor links.
13.3.5 General Graph Directory
Aseriousproblemwithusinganacyclic-graphstructureisensuringthatthere
are no cycles. If we start with a two-level directory and allow users to create
subdirectories,atree-structureddirectoryresults.Itshouldbefairlyeasytosee
that simply adding new files and subdirectories to an existing tree-structured
directory preserves the tree-structured nature. However, when we add links,
the tree structure is destroyed, resulting in a simple graph structure (Figure
13.11).
The primaryadvantage of anacyclic graphisthe relativesimplicityof the
algorithms to traverse the graph and to determine when there are no more
references to a file. We want to avoid traversing shared sections of an acyclic
graphtwice,mainlyforperformancereasons.Ifwehavejustsearchedamajor
shared subdirectory for a particular file without finding it, we want to avoid
searchingthatsubdirectoryagain;thesecondsearchwouldbeawasteoftime.
If cycles are allowed to exist in the directory, we likewise want to avoid
searching any component twice, for reasons of correctness as well as perfor-
mance.Apoorlydesignedalgorithmmightresultinaninfiniteloopcontinually
searching through the cycle and never terminating. One solution is to limit
arbitrarilythenumber of directoriesthat willbe accessedduringa search.
A similar problem exists when we are trying to determine when a file
can be deleted. With acyclic-graph directory structures, a value of 0 in the
referencecountmeansthattherearenomorereferencestothefileordirectory,
and the file can be deleted. However, when cycles exist, the reference count
may not be 0 even when it is no longer possible to refer to a directory or file.
This anomaly results from the possibilit y of self-referencing (or a cycle) in the
directorystructure.Inthiscase,wegenerallyneedtousea garbage collection"
2,13.4 Protection,680,13.3 Directory Structure,"550 Chapter 13 File-System Interface
textmail
avicount unhexhexcountbook bookmailunhexhyproot
avi tcjim
Figure 13.11 General graph directory.
scheme to determine when the last reference has been deleted and the disk
space can be reallocated. Garbage collection involves traversing the entire file
system,marking everythingthatcan beaccessed.Then, asecond passcollects
everything that is not marked onto a list of free space. (A similar marking
procedurecanbeusedtoensurethatatraversalorsearchwillcovereverything
in the file systemonce and only once.) Garbage collection for a disk-basedfile
system,however,isextremelytimeconsuming and isthus seldomattempted.
Garbagecollectionisnecessaryonlybecauseofpossiblecyclesinthegraph.
Thus,anacyclic-graphstructureismucheasiertoworkwith.Thedifficultyisto
avoidcyclesasnewlinksareaddedtothestructure.Howdoweknowwhena
newlinkwillcompleteacycle?Therearealgorithmstodetectcyclesingraphs;
however,theyarecomputationallyexpensive,especiallywhenthegraphison
disk storage. A simpler algorithm in the special case of directories and links
is to bypass links during directory traversal. Cycles are avoided, and no extra
overheadis incurred.
13.4 Protection
When information is stored in a computer system, we want to keep it safe
from physical damage (the issue of reliability) and improper access (the issue
of protection).
Reliabilityisgenerallyprovidedbyduplicatecopiesoffiles.Manycomput-
ers have systems programs that automatically (or through computer-operator
intervention)copy diskfilestotapeatregularintervals(onceperdayorweek
or month) to maintain a copy should a file system be accidentally destroyed.
Filesystemscanbedamagedbyhardwareproblems(suchaserrorsinreading
orwriting),powersurgesorfailures,headcrashes,dirt,temperatureextremes,"
3,13.4.1 Types of Access,681,13.4 Protection,"13.4 Protection 551
andvandalism.Filesmaybedeletedaccidentally.Bugsinthefile-systemsoft-
ware can also cause file contents to be lost. Reliability was covered in more
detailinChapter11.
Protection can be provided in many ways. For a laptop system running
a modern operating system, we might provide protection by requiring a user
nameandpasswordauthenticationtoaccessit,encryptingthesecondarystor-
age so even someone opening the laptop and removing the drive would have
adifficulttimeaccessingitsdata,andfirewallingnetworkaccesssothatwhen
it is in use it is difficult to break in via its network connection. In multiuser
system, even valid access of the system needs more advanced mechanisms to
allowonly valid access ofthe data.
13.4.1 Types of Access
The need to protect files is a direct result of the ability to access files. Systems
thatdonotpermitaccesstothefilesofotherusersdonotneedprotection.Thus,
wecouldprovidecompleteprotectionbyprohibitingaccess.Alternatively,we
couldprovidefreeaccesswithnoprotection.Bothapproachesaretooextreme
forgeneraluse.What isneedediscontrolledaccess.
Protection mechanisms provide controlled access by limiting the types of
file access that can be made. Access is permitted or denied depending on
several factors, one of which is the type of access requested. Several different
typesof operationsmay becontrolled:
•Read. Read fromthe file.
•Write. Write or rewritethe file.
•Execute. Load the file into memoryand executeit.
•Append.Write new information atthe end of the file.
•Delete. Deletethefile and freeitsspacefor possiblereuse.
•List. Listthe nameand attributesof thefile.
•Attribute change . Changing the attributesof the file.
Otheroperations,suchasrenaming,copying,andeditingthefile,mayalso
be controlled. For many systems, however, these higher-level functions may
be implemented by a system program that makes lower-level system calls.
Protectionisprovidedatonlythelowerlevel.Forinstance,copyingafilemay
beimplementedsimplybyasequenceofreadrequests.Inthiscase,auserwith
readaccess can alsocause the file tobe copied,printed,and so on.
Many protection mechanisms have been proposed. Each has advantages
and disadvantages and must be appropriate for its intended application. A
smallcomputersystemthatisusedbyonlyafewmembersofaresearchgroup,
for example, may not need the same types of protection as a large corporate
computer that is used for research, finance, and personnel operations. We
discuss some approaches to protection in the following sections and present
amorecompletetreatmentinChapter17."
3,13.4.2 Access Control,682,13.4.1 Types of Access,"552 Chapter 13 File-System Interface
13.4.2 Access Control
Themostcommonapproachtotheprotectionproblemistomakeaccessdepen-
dent on the identity of the user. Different users may need different types of
access to a file or directory. The most general scheme to implement identity-
dependentaccess isto associate witheachfileand directoryan access-control
list(ACL)specifyingusernamesandthetypesofaccessallowedforeachuser.
When a user requests access to a particular file, the operating system checks
the access list associated with that file. If that user is listed for the requested
access,theaccessisallowed.Otherwise,aprotectionviolationoccurs, andthe
userjobisdeniedaccess to thefile.
This approach has the advantage of enabling complex access methodolo-
gies. The main problem with access lists is their length. If we want to allow
everyone to read a file, we must list all users with read access. This technique
has two undesirableconsequences:
•Constructingsuchalistmaybeatediousandunrewardingtask,especially
ifwe donot know inadvancethelistof usersinthesystem.
•Thedirectoryentry,previouslyoffixedsize,nowmustbeofvariablesize,
resultingin morecomplicatedspacemanagement.
These problems can be resolved by use of a condensed version of the access
list.
To condense the length of the access-control list, many systems recognize
three classifications of usersin connection with each file:
•Owner.Theuserwho createdthe fileisthe owner.
•Group.Asetof userswho aresharing the fileand needsimilaraccess isa
group,orwork group.
•Other.Allotherusersinthesystem.
The most common recent approach is to combine access-control lists with
themoregeneral(andeasiertoimplement)owner,group,anduniverseaccess-
controlschemejustdescribed.Forexample,Solarisusesthethreecategoriesof
accessbydefaultbutallowsaccess-controlliststobeaddedtospecificfilesand
directorieswhen more fine-grained access control is desired.
To illustrate, consider a person, Sara, who is writing a new book. She has
hiredthreegraduatestudents(Jim,Dawn,andJill)tohelpwiththeproject.The
text of the book is kept in a file named book.tex. The protection associated
with this fileisas follows:
•Sarashould beable toinvokealloperations on thefile.
•Jim, Dawn, and Jill should be able only to read and write the file; they
should not be allowed todeletethe file.
•All other users should be able to read, but not write, the file. (Sara is
interested in letting as many people as possible read the text so that she
can obtain feedback.)"
3,13.4.3 Other Protection Approaches,684,13.4.2 Access Control,"554 Chapter 13 File-System Interface
fileowner,forthefile’sgroup,andforallotherusers.Inthisscheme,ninebits
perfileareneededtorecordprotectioninformation.Thus,forourexample,the
protectionfieldsforthefile book.tex areasfollows:fortheownerSara,allbits
a r es e t ;f o rt h eg r o u p text,t h e randwbits are set; and for the universe, only
therbit isset.
One difficultyin combining approaches comes inthe userinterface.Users
must be able to tell when the optional ACLpermissions are set on a file. In the
Solarisexample,a “+”is appendedtothe regularpermissions,as in:
19 -rw-r--r--+ 1 jim staff 130 May 25 22:13 file1
A separate set of commands, setfacl andgetfacl , is used to manage the
ACLs.
Windows users typically manage access-control lists via the GUI.F i g u r e
13.12 shows a file-permission window on Windows 7 NTFSfile system. In this
example,user “guest ”isspecificallydeniedaccesstothefile ListPanel.java .
Another difficulty is assigning precedence when permission and ACLs
conflict. For example,if Walter is in a file’s group, which has read permission,
but the file has an ACLgranting Walter read and write permission, should a
write by Walter be granted or denied? Solaris and other operating systems
giveACLs precedence (as they are more fine-grained and are not assigned by
default).This follows thegeneralrule that specificity shouldhavepriority.
13.4.3 Other Protection Approaches
Another approach to the protection problem is to associate a password with
each file. Just as access to the computer system is often controlled by a pass-
word, access to each file can be controlled in the same way. If the passwords
are chosen randomly and changed often, this scheme may be effective in lim-
iting access to a file. The use of passwords has a few disadvantages, however.
First, the number of passwords that a user needs to remember may become
large,makingtheschemeimpractical.S econd,ifonlyonepasswordisusedfor
all the files, then once it is discovered, all files are accessible; protection is on
an all-or-none basis. Some systems allow a user to associate a password with
a subdirectory, rather than with an individual file, to address this problem.
More commonly encryption of a partition or individual files provides strong
protection,but passwordmanagement iskey.
In a multileveldirectory structure, we need to protect not only individual
files but also collections of files in subdirectories; that is, we need to provide
a mechanism for directory protection. The directory operations that must be
protected are somewhat different from the file operations. We want to control
the creation and deletionof files in a directory.In addition, we probably want
to control whether a user can determine the existence of a file in a directory.
Sometimes, knowledge of the existence and name of a file is significant in
itself. Thus, listing the contents of a directory must be a protected operation.
Similarly,ifapathnamereferstoafileinadirectory,theusermustbeallowed
access to both the directory and the file. In systems where files may have
numerous path names (such as acyclic and general graphs), a given user may
have different access rights to a particular file, depending on the path name
used."
2,13.5 Memory-Mapped Files,685,13.4 Protection,"13.5 Memory-Mapped Files 555
Figure 13.12 Windows 10 access-control list management.
13.5 Memory-Mapped Files
There is one other method of accessing files, and it is very commonly used.
Consider a sequential read of a file on disk using the standard system calls
open(),read(),and write() .Eachfileaccessrequiresasystemcallanddisk
access. Alternatively, we can use the virtual memory techniques discussed in
Chapter10totreatfile I/Oasroutinememoryaccesses.Thisapproach,known
asmemory mapping a file, allows a part of the virtual address space to be
logically associated with the file. As we shall see, this can lead to significant
performance increases.
13.5.1 Basic Mechanism
Memorymappingafileisaccomplishedbymappingadiskblocktoapage(or
pages)inmemory.Initialaccesstothefileproceedsthroughordinarydemand"
3,13.5.1 Basic Mechanism,685,13.5 Memory-Mapped Files,"13.5 Memory-Mapped Files 555
Figure 13.12 Windows 10 access-control list management.
13.5 Memory-Mapped Files
There is one other method of accessing files, and it is very commonly used.
Consider a sequential read of a file on disk using the standard system calls
open(),read(),and write() .Eachfileaccessrequiresasystemcallanddisk
access. Alternatively, we can use the virtual memory techniques discussed in
Chapter10totreatfile I/Oasroutinememoryaccesses.Thisapproach,known
asmemory mapping a file, allows a part of the virtual address space to be
logically associated with the file. As we shall see, this can lead to significant
performance increases.
13.5.1 Basic Mechanism
Memorymappingafileisaccomplishedbymappingadiskblocktoapage(or
pages)inmemory.Initialaccesstothefileproceedsthroughordinarydemand"
3,13.5.2 Shared Memory in the Windows API,686,13.5.1 Basic Mechanism,"556 Chapter 13 File-System Interface
paging, resulting in a page fault. However, a page-sized portion of the file is
read from the file system into a physical page (some systems may opt to read
in more than a page-sizedchunk of memory at a time). Subsequent reads and
writes to the file are handled as routine memory accesses. Manipulating files
through memory rather than incurring the overhead of using the read()and
write() systemcallssimplifiesand speedsupfile access andusage.
Note that writes to the file mapped in memory are not necessarily imme-
diate(synchronous)writestothefileonsecondarystorage.Generally,systems
update the file based on changes to the memory image only when the file is
closed. Under memory pressure, systems will have any intermediate changes
to swap space to not lose them when freeing memory for other uses. When
the file is closed, all the memory-mapped data are written back to the file on
secondary storageandremovedfromthe virtualmemoryof the process.
Someoperatingsystemsprovidememorymappingonlythroughaspecific
system call and use the standard system calls to perform all other file I/O.
However,somesystemschoosetomemory-mapafileregardlessofwhetherthe
filewasspecifiedasmemory-mapped.Let’stakeSolarisasanexample.Ifafile
is specified as memory-mapped (using the mmap()system call), Solaris maps
the file into the address space of the process. If a file is opened and accessed
usingordinarysystemcalls,suchas open(),read(),and write() ,Solarisstill
memory-mapsthefile;however,thefileismappedtothekerneladdressspace.
Regardlessofhowthefileisopened,then,Solaristreatsallfile I/Oasmemory-
mapped,allowingfileaccesstotakeplaceviatheefficientmemorysubsystem
and avoiding system call overhead caused by each traditional read()and
write() .
Multiple processes may be allowed to map the same file concurrently, to
allowsharingofdata.Writesbyanyoftheprocessesmodifythedatainvirtual
memory and can be seen by all others that map the same section of the file.
Given our earlier discussions of virtual memory, it should be clear how the
sharing of memory-mapped sections of memory is implemented: the virtual
memory map of each sharing process points to the same page of physical
memory—thepagethatholdsacopyofthediskblock.Thismemorysharingis
illustratedinFigure13.13.Thememory-mappingsystemcallscanalsosupport
copy-on-write functionality, allowing processes to share a file in read-only
mode but to have their own copies of any data they modify. So that access
to the shareddata is coordinated, the processesinvolvedmight use one of the
mechanisms for achievingmutual exclusiondescribedinChapter6.
Quite often, shared memory is in fact implemented by memory mapping
files. Under this scenario, processes can communicate using shared mem-
ory by having the communicating processes memory-map the same file into
their virtual address spaces. The memory-mapped file serves as the region
of shared memory between the communicating processes (Figure 13.14). We
have already seen this in Section 3.5, where a POSIXshared-memory object
is created and each communicating process memory-maps the object into its
address space. In the following section, we discuss support in the Windows
APIforsharedmemoryusing memory-mappedfiles.
13.5.2 Shared Memory in the Windows API
The general outline for creating a region of shared memory using memory-
mappedfilesintheWindows APIinvolvesfirstcreatinga fil mapping forthe"
2,13.6 Summary,690,13.5 Memory-Mapped Files,"560 Chapter 13 File-System Interface
somewhat simpler than the one shown in Figure 13.15, as all that is necessary
is for the process to create a mapping to the existing named shared-memory
object. The consumer process must also create a view of the mapped file, just
astheproducerprocessdidintheprograminFigure13.15.Theconsumerthen
reads from shared memory the message “Shared memory message ”thatwas
writtenby the producerprocess.
Finally, both processes remove the view of the mapped file with a call to
UnmapViewOfFile() . We provide a programming exercise at the end of this
chapter usingsharedmemorywith memorymapping in theWindows API.
13.6 Summary
•Afile is an abstract data type defined and implemented by the operating
system. It is a sequence of logical records. Alogical record may be a byte,
a line (of fixed or variable length), or a more complex data item. The
operating system may specifically support various record types or may
leavethat supporttothe applicationprogram.
•A major task for the operating system is to map the logical file concept
onto physical storage devices such as hard disk or NVMdevice. Since the
physicalrecordsizeofthedevicemaynotbethesameasthelogicalrecord
size, it may be necessary to order logical records into physical records.
Again, this task may be supported by the operating system or left for the
applicationprogram.
•Within a file system, it is useful to create directories to allow files to be
organized. A single-level directory in a multiuser system causes naming
problems, since each file must have a unique name. Atwo-level directory
solves this problem by creating a separate directory for each user’s files.
The directorylists the files by name and includes the file’s location on the
disk,length,type,owner,timeof creation,timeoflast use,and so on.
•The natural generalization of a two-level directory is a tree-structured
directory.Atree-structureddirectoryallowsausertocreatesubdirectories
to organize files. Acyclic-graph directory structures enable users to share
subdirectories and files but complicate searching and deletion. Ageneral
graphstructureallowscompleteflexibilityinthesharingoffilesanddirec-
tories but sometimes requires garbage collection to recover unused disk
space.
•Remote file systems present challenges in reliability, performance, and
security. Distributed information systems maintain user, host, and access
informationsothatclientsandserverscansharestateinformationtoman-
age use and access.
•Sincefilesarethemaininformation-storagemechanisminmostcomputer
systems, file protection is needed on multiuser systems. Access to files
canbecontrolledseparatelyforeachtypeofaccess—read,write,execute,
append,delete,listdirectory,andsoon.Fileprotectioncanbeprovidedby
access lists,passwords,or othertechniques."
2,Practice Exercises,690,13.6 Summary,"560 Chapter 13 File-System Interface
somewhat simpler than the one shown in Figure 13.15, as all that is necessary
is for the process to create a mapping to the existing named shared-memory
object. The consumer process must also create a view of the mapped file, just
astheproducerprocessdidintheprograminFigure13.15.Theconsumerthen
reads from shared memory the message “Shared memory message ”thatwas
writtenby the producerprocess.
Finally, both processes remove the view of the mapped file with a call to
UnmapViewOfFile() . We provide a programming exercise at the end of this
chapter usingsharedmemorywith memorymapping in theWindows API.
13.6 Summary
•Afile is an abstract data type defined and implemented by the operating
system. It is a sequence of logical records. Alogical record may be a byte,
a line (of fixed or variable length), or a more complex data item. The
operating system may specifically support various record types or may
leavethat supporttothe applicationprogram.
•A major task for the operating system is to map the logical file concept
onto physical storage devices such as hard disk or NVMdevice. Since the
physicalrecordsizeofthedevicemaynotbethesameasthelogicalrecord
size, it may be necessary to order logical records into physical records.
Again, this task may be supported by the operating system or left for the
applicationprogram.
•Within a file system, it is useful to create directories to allow files to be
organized. A single-level directory in a multiuser system causes naming
problems, since each file must have a unique name. Atwo-level directory
solves this problem by creating a separate directory for each user’s files.
The directorylists the files by name and includes the file’s location on the
disk,length,type,owner,timeof creation,timeoflast use,and so on.
•The natural generalization of a two-level directory is a tree-structured
directory.Atree-structureddirectoryallowsausertocreatesubdirectories
to organize files. Acyclic-graph directory structures enable users to share
subdirectories and files but complicate searching and deletion. Ageneral
graphstructureallowscompleteflexibilityinthesharingoffilesanddirec-
tories but sometimes requires garbage collection to recover unused disk
space.
•Remote file systems present challenges in reliability, performance, and
security. Distributed information systems maintain user, host, and access
informationsothatclientsandserverscansharestateinformationtoman-
age use and access.
•Sincefilesarethemaininformation-storagemechanisminmostcomputer
systems, file protection is needed on multiuser systems. Access to files
canbecontrolledseparatelyforeachtypeofaccess—read,write,execute,
append,delete,listdirectory,andsoon.Fileprotectioncanbeprovidedby
access lists,passwords,or othertechniques."
2,Further Reading,691,Practice Exercises,"Further Reading 561
Practice Exercises
13.1Somesystemsautomaticallydeletealluserfileswhenauserlogsoffor
a job terminates, unless the user explicitly requests that they be kept.
Other systems keep all files unless the user explicitly deletes them.
Discuss therelativemeritsof each approach.
13.2Why dosomesystemskeeptrackofthetypeofafile,whilestillothers
leave it to the user and others simply do not implement multiple file
types?Which systemis “better ”?
13.3Similarly, some systems support many types of structures for a file’s
data, while others simply support a stream of bytes. What are the
advantagesand disadvantagesof each approach?
13.4Couldyousimulateamultileveldirectorystructurewithasingle-level
directorystructureinwhicharbitrarilylongnamescanbeused?Ifyour
answer is yes, explain how you can do so, and contrast this scheme
withthemultileveldirectoryscheme.Ifyouranswerisno,explainwhat
preventsyoursimulation’ssuccess.Howwouldyouranswerchangeif
file nameswerelimitedtosevencharacters?
13.5Explainthe purpose ofthe open()andclose() operations.
13.6In some systems, a subdirectory can be read and written by an autho-
rizeduser,justas ordinaryfilescan be.
a. Describethe protectionproblemsthat couldarise.
b. Suggest a scheme for dealing with each of these protection prob-
lems.
13.7Considerasystemthatsupports5,000users.Supposethatyouwantto
allow 4,990 of theseuserstobe ableto access one file.
a. How wouldyou specifythis protectionschemein UNIX?
b. Canyousuggestanotherprotectionschemethatcanbeusedmore
effectivelyforthis purposethanthe schemeprovidedby UNIX?
13.8Researchers have suggested that, i nstead of having an access-control
listassociatedwitheachfile(specifyingwhichuserscanaccessthefile,
andhow),weshouldhavea user control list associatedwitheachuser
(specifyingwhichfilesausercanaccess,andhow).Discusstherelative
meritsof thesetwo schemes.
Further Reading
Amultileveldirectorystructurewasfirstimplementedonthe MULTICS system
([Organick (1972)]). Most operating systems now implement multileveldirec-
tory structures. These include Linux ([Love (2010)]), mac OS([Singh (2007)]),
Solaris([McDougalland Mauro(2007)]),and allversionsofWindows ([Russi-
novich etal.(2017)])."
2,Bibliography,692,Further Reading,"562 Chapter 13 File-System Interface
A general discussion of Solaris file systems is found in the Sun Sys-
tem Administration Guide: Devices and File Systems (http://docs.sun.com/app/
docs/doc/817-5093 ).
The network file system ( NFS), designed by Sun Microsystems, allows
directory structures to be spread across networked computer systems. NFS
Version4 isdescribedin RFC3505 ( http://www.ietf.org/rfc/rfc3530.txt ).
Agreatsourceofthemeaningsofcomputerjargonis http://www.catb.org/
esr/jargon/ .
Bibliography
[Love (2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library (2010).
[McDougall and Mauro (2007)] R. McDougall and J. Mauro, Solaris Internals,
SecondEdition, PrenticeHall (2007).
[Organick (1972)] E.I.Organick, The Multics System: An Examination of Its Struc-
ture, MITPress (1972).
[Russinovich et al. (2017)] M.Russinovich,D.A.Solomon,andA.Ionescu, Win-
dows Internals–Part 1, SeventhEdition, MicrosoftPress (2017).
[Singh (2007)] A. Singh, Mac OS X Internals: A Systems Approach , Addison-
Wesley (2007)."
2,Chapter 13 Exercises,693,Bibliography,"Exercises
Chapter 13 Exercises
13.9Consider a file systemin which a file can be deletedand its diskspace
reclaimedwhilelinkstothatfilestillexist.Whatproblemsmayoccurif
anewfileiscreatedinthesamestorageareaorwiththesameabsolute
pathname? How cantheseproblemsbeavoided?
13.10The open-file table is used to maintain information about files that are
currentlyopen.Shouldtheoperatingsystemmaintaina separatetable
for each userormaintain justone tablethat contains referencesto files
that are currently being accessed by all users? If the same file is being
accessed by two different programs or users, should there be separate
entriesintheopen-filetable?Explain.
13.11What are the advantages and disadvantages of providing mandatory
locks insteadof advisorylocks whose useis leftto users’discretion?
13.12Provide examples of applications that typically access files according
to the following methods:
•Sequential
•Random
13.13Somesystemsautomaticallyopenafilewhenitisreferencedforthefirst
timeandclosethefilewhenthejobte rminates.Discusstheadvantages
and disadvantagesof this scheme compared with the more traditional
one, where the userhas toopen and close the file explicitly.
13.14If the operating system knew that a c ertain application was going
to access file data in a sequential manner, how could it exploit this
information toimproveperformance?
13.15Give an example of an application that could benefit from operating-
systemsupportfor random access toindexedfiles.
13.16Some systems provide file sharing by maintaining a single copy of a
file. Other systems maintain several copies, one for each of the users
sharing the file.Discuss the relativemeritsof each approach.EX-48"
1,Chapter 14 File-System Implementation,694,Chapter 13 File-System Interface,"14CHAPTER
File - System
Implementation
As we saw in Chapter 13, the file system provides the mechanism for on-
line storage and access to file contents, including data and programs. File
systems usually reside permanently on s econdary storage, which is designed
toholdalargeamountofdata.Thischapterisprimarilyconcernedwithissues
surrounding file storage and access on the most common secondary-storage
media, hard disk drives and nonvolatile memory devices. We explore ways
to structure file use, to allocate storage space, to recover freed space, to track
the locations of data, and to interface other parts of the operating system to
secondarystorage.Performanceissues areconsideredthroughoutthechapter.
A given general-purpose operating system provides several file systems.
Additionally,manyoperatingsystemsallowadministratorsoruserstoaddfile
systems.Whysomany?Filesystemsvaryinmanyrespects,includingfeatures,
performance,reliability,anddesigngoals,anddifferentfilesystemsmayserve
differentpurposes.Forexample,atemporaryfilesystemisusedforfaststorage
and retrieval of nonpersistent files, while the default secondary storage file
system(such as Linuxext4)sacrifices performancefor reliabilityand features.
As we’veseenthroughout this study of operating systems,thereare plenty of
choicesandvariations,makingthoroughcoverageachallenge.Inthischapter,
we concentrate on the common denominators.
CHAPTER OBJECTIVES
•Describethedetailsofimplementinglocalfilesystemsanddirectorystruc-
tures.
•Discuss block allocation and free-block algorithms and trade-offs.
•Explore file system efficiency and performance issues.
•Look at recovery from file system failures.
•Describe the WAFLfile system as a concrete example.
563"
2,14.1 File-System Structure,695,Chapter 14 File-System Implementation,"564 Chapter 14 File-System Implementation
14.1 File-System Structure
Disks provide most of the secondary storage on which file systems are main-
tained.Two characteristics maket hemconvenient for thispurpose:
1.A disk can be rewritten in place; it is possible to read a block from the
disk,modifythe block, and write itback into the same block.
2.Adiskcanaccessdirectlyanyblockofinformationitcontains.Thus,itis
simple to access any file either sequen tially or randomly, and switching
from one file to another requiresthe drivemoving the read–writeheads
and waiting for themediatorotate.
Nonvolatile memory ( NVM) devices are increasingly used for file storage
andthusasalocationforfilesystems.Theydifferfromharddisksinthatthey
cannot be rewritten in place and they have different performance characteris-
tics.We discussdiskand NVM-devicestructureindetailinChapter11.
To improve I/Oefficiency, I/Otransfersbetweenmemoryandmassstorage
are performed in units of blocks. Each block on a hard disk drive has one or
more sectors. Depending on the disk drive, sector size is usually 512 bytes or
4,096 bytes. NVMdevices usually have blocks of 4,096 bytes, and the transfer
methodsusedaresimilarto those usedby diskdrives.
File systems provide efficient and convenient access to the storage device
byallowingdatatobestored,located,andretrievedeasily.Afilesystemposes
two quite different design problems. The first problem is defining how the
file system should look to the user. This task involves defining a file and its
attributes, the operations allowed on a file, and the directory structure for
organizingfiles.Thesecondproblemiscreatingalgorithmsanddatastructures
to mapthe logicalfilesystemonto the ph ysicalsecondary-storage devices.
The file system itself is generally composed of many different levels. The
structureshowninFigure14.1isanexampleofalayereddesign.Eachlevelin
the design uses the features of lower levels to create new features for use by
higher levels.
The I/Ocontrollevel consists of device drivers and interrupt handlers
to transfer information between the main memory and the disk system. A
device driver can be thought of as a translator. Its input consists of high-
level commands, such as “retrieveblock 123. ”Its output consists of low-level,
hardware-specificinstructionsthatareusedbythehardwarecontroller,which
interfaces the I/Odevice to the rest of the system. The device driver usually
writes specific bit patterns to special locations in the I/Ocontroller’s memory
to tell the controller which device location to act on and what actions to take.
Thedetailsofdevicedriversandthe I/OinfrastructurearecoveredinChapter
12.
The basicfile system (called the “blockI/Osubsystem ”in Linux) needs
only to issue generic commands to the appropriate device driver to read and
write blocks on the storage device. It issues commands to the drive based
on logical block addresses. It is also concerned with I/Orequest scheduling.
Thislayeralsomanagesthememorybuffersandcachesthatholdvariousfile-
system,directory,anddatablocks.Ablockinthebufferisallocatedbeforethe
transfer of a mass storage block can occur. When the buffer is full, the buffer
manager must find more buffer memory or free up buffer space to allow a"
2,14.2 File-System Operations,697,14.1 File-System Structure,"566 Chapter 14 File-System Implementation
BerkeleyFastFileSystem( FFS).Windowssupportsdiskfile-systemformatsof
FAT,FAT32,and NTFS(orWindows NTFileSystem),aswellas CD-ROM andDVD
file-system formats. Although Linux supports over 130 different file systems,
the standard Linux file system is known as the extended file system ,w i t h
the most common versions being ext3 and ext4. There are also distributed file
systems in which a file system on a server is mounted by one or more client
computersacross a network.
File-system research continues to be an active area of operating-system
design and implementation. Google created its own file system to meet
the company’s specific storage and retrieval needs, which include high-
performance access from many clients across a very large number of disks.
Anotherinterestingprojectisthe FUSEfilesystem,whichprovidesflexibilityin
file-systemdevelopmentanduseby implementingandexecutingfilesystems
as user-level rather than kernel-level code. Using FUSE, a user can add a new
file system to a variety of operating systems and can use that file system to
manage herfiles.
14.2 File-System Operations
As was described in Section 13.1.2, operating systems implement open()and
close() systems calls for processes to request access to file contents. In this
section, we delve into the structures and operations used to implement file-
systemoperations.
14.2.1 Overview
Several on-storage and in-memory structures are used to implement a file
system. These structuresvary dependingon the operating system and the file
system,but somegeneralprinciplesapply.
On storage, the file system may contain information about how to boot
an operating system stored there, the total number of blocks, the number and
location of free blocks, the directory structure, and individual files. Many of
these structures are detailed throughout the remainder of this chapter. Here,
we describethembriefly:
•Aboot control block (pervolume)cancontaininformationneededbythe
systemtobootanoperatingsystemfromthatvolume.Ifthediskdoesnot
contain an operating system, this block can be empty. It is typically the
first block of a volume.In UFS, itis calledthe boot block .InNTFS,i ti st h e
partition boot sector .
•Avolume control block (pervolume)containsvolumedetails,suchasthe
number of blocks in the volume, the size of the blocks, a free-block count
andfree-blockpointers,andafree- FCBcountand FCBpointers.In UFS,this
iscalleda superblock .InNTFS,i ti ss t o r e di nt h e master fil table .
•Adirectory structure (per file system) is used to organize the files. In UFS,
thisincludesfilenamesandassociatedinodenumbers.In NTFS,itisstored
inthemasterfiletable."
3,14.2.1 Overview,697,14.2 File-System Operations,"566 Chapter 14 File-System Implementation
BerkeleyFastFileSystem( FFS).Windowssupportsdiskfile-systemformatsof
FAT,FAT32,and NTFS(orWindows NTFileSystem),aswellas CD-ROM andDVD
file-system formats. Although Linux supports over 130 different file systems,
the standard Linux file system is known as the extended file system ,w i t h
the most common versions being ext3 and ext4. There are also distributed file
systems in which a file system on a server is mounted by one or more client
computersacross a network.
File-system research continues to be an active area of operating-system
design and implementation. Google created its own file system to meet
the company’s specific storage and retrieval needs, which include high-
performance access from many clients across a very large number of disks.
Anotherinterestingprojectisthe FUSEfilesystem,whichprovidesflexibilityin
file-systemdevelopmentanduseby implementingandexecutingfilesystems
as user-level rather than kernel-level code. Using FUSE, a user can add a new
file system to a variety of operating systems and can use that file system to
manage herfiles.
14.2 File-System Operations
As was described in Section 13.1.2, operating systems implement open()and
close() systems calls for processes to request access to file contents. In this
section, we delve into the structures and operations used to implement file-
systemoperations.
14.2.1 Overview
Several on-storage and in-memory structures are used to implement a file
system. These structuresvary dependingon the operating system and the file
system,but somegeneralprinciplesapply.
On storage, the file system may contain information about how to boot
an operating system stored there, the total number of blocks, the number and
location of free blocks, the directory structure, and individual files. Many of
these structures are detailed throughout the remainder of this chapter. Here,
we describethembriefly:
•Aboot control block (pervolume)cancontaininformationneededbythe
systemtobootanoperatingsystemfromthatvolume.Ifthediskdoesnot
contain an operating system, this block can be empty. It is typically the
first block of a volume.In UFS, itis calledthe boot block .InNTFS,i ti st h e
partition boot sector .
•Avolume control block (pervolume)containsvolumedetails,suchasthe
number of blocks in the volume, the size of the blocks, a free-block count
andfree-blockpointers,andafree- FCBcountand FCBpointers.In UFS,this
iscalleda superblock .InNTFS,i ti ss t o r e di nt h e master fil table .
•Adirectory structure (per file system) is used to organize the files. In UFS,
thisincludesfilenamesandassociatedinodenumbers.In NTFS,itisstored
inthemasterfiletable."
3,14.2.2 Usage,699,14.2.1 Overview,"568 Chapter 14 File-System Implementation
ating systems, including Windows, implement separate system calls for files
and directories and treat directories as entities separate from files. Whatever
thelargerstructuralissues,thelogicalfilesystemcancallthefile-organization
moduletomapthedirectory I/Ointostorageblocklocations,whicharepassed
onto thebasic filesystemand I/Ocontrol system.
14.2.2 Usage
Now that a file has been created, it can be used for I/O. First, though, it must
be opened. The open()call passes a file name to the logical file system. The
open()systemcallfirstsearchesthesystem-wideopen-filetabletoseeifthefile
isalreadyinusebyanotherprocess.Ifitis,aper-processopen-filetableentryis
createdpointingtotheexistingsystem-wideopen-filetable.Thisalgorithmcan
savesubstantialoverhead.Ifthefileisnotalreadyopen,thedirectorystructure
is searched for the givenfile name. Parts of the directory structure are usually
cached in memory to speed directory ope rations. Once the file is found, the
FCBiscopiedintoasystem-wideopen-filetableinmemory.Thistablenotonly
storesthe FCBbut also tracksthe number of processesthat have the file open.
Next, an entry is made in the per-process open-file table, with a pointer
to the entry in the system-wide open-fil e table and some other fields. These
otherfieldsmayincludeapointertothecurrentlocationinthefile(forthenext
read()orwrite() operation) and the access mode in which the file is open.
Theopen()call returns a pointer to the appropriate entry in the per-process
file-system table. All file operations are then performed via this pointer. The
file name may not be part of the open-file table, as the system has no use for
it once the appropriate FCBis located on disk. It could be cached, though, to
save time on subsequent opens of the same file. The name given to the entry
varies. UNIXsystems refer to it as a fil descriptor ; Windows refers to it as a
fil handle .
Whenaprocessclosesthefile,theper-processtableentryisremoved,and
the system-wide entry’s open count is decremented.When all users that have
openedthefilecloseit,anyupdatedmetadataarecopiedbacktothedisk-based
directorystructure,andthe system-wideopen-filetableentryis removed.
The caching aspects of file-system structures should not be overlooked.
Mostsystemskeepallinformationaboutanopenfile,exceptforitsactualdata
blocks,inmemory.The BSDUNIX systemistypicalinitsuseofcacheswherever
diskI/Ocanbesaved.Itsaveragecache hitrateof85percentshowsthatthese
techniques are well worth implementing. The BSD UNIX system is described
fullyinAppendixC.
The operating structures of a file-systemimplementationare summarized
inFigure14.3.
14.3 Directory Implementation
The selection of directory-allocation and directory-management algorithms
significantly affects the efficiency, performance, and reliability of the file sys-
tem.Inthissection,wediscussthetrade-offsinvolvedinchoosingoneofthese
algorithms."
2,14.3 Directory Implementation,699,14.2 File-System Operations,"568 Chapter 14 File-System Implementation
ating systems, including Windows, implement separate system calls for files
and directories and treat directories as entities separate from files. Whatever
thelargerstructuralissues,thelogicalfilesystemcancallthefile-organization
moduletomapthedirectory I/Ointostorageblocklocations,whicharepassed
onto thebasic filesystemand I/Ocontrol system.
14.2.2 Usage
Now that a file has been created, it can be used for I/O. First, though, it must
be opened. The open()call passes a file name to the logical file system. The
open()systemcallfirstsearchesthesystem-wideopen-filetabletoseeifthefile
isalreadyinusebyanotherprocess.Ifitis,aper-processopen-filetableentryis
createdpointingtotheexistingsystem-wideopen-filetable.Thisalgorithmcan
savesubstantialoverhead.Ifthefileisnotalreadyopen,thedirectorystructure
is searched for the givenfile name. Parts of the directory structure are usually
cached in memory to speed directory ope rations. Once the file is found, the
FCBiscopiedintoasystem-wideopen-filetableinmemory.Thistablenotonly
storesthe FCBbut also tracksthe number of processesthat have the file open.
Next, an entry is made in the per-process open-file table, with a pointer
to the entry in the system-wide open-fil e table and some other fields. These
otherfieldsmayincludeapointertothecurrentlocationinthefile(forthenext
read()orwrite() operation) and the access mode in which the file is open.
Theopen()call returns a pointer to the appropriate entry in the per-process
file-system table. All file operations are then performed via this pointer. The
file name may not be part of the open-file table, as the system has no use for
it once the appropriate FCBis located on disk. It could be cached, though, to
save time on subsequent opens of the same file. The name given to the entry
varies. UNIXsystems refer to it as a fil descriptor ; Windows refers to it as a
fil handle .
Whenaprocessclosesthefile,theper-processtableentryisremoved,and
the system-wide entry’s open count is decremented.When all users that have
openedthefilecloseit,anyupdatedmetadataarecopiedbacktothedisk-based
directorystructure,andthe system-wideopen-filetableentryis removed.
The caching aspects of file-system structures should not be overlooked.
Mostsystemskeepallinformationaboutanopenfile,exceptforitsactualdata
blocks,inmemory.The BSDUNIX systemistypicalinitsuseofcacheswherever
diskI/Ocanbesaved.Itsaveragecache hitrateof85percentshowsthatthese
techniques are well worth implementing. The BSD UNIX system is described
fullyinAppendixC.
The operating structures of a file-systemimplementationare summarized
inFigure14.3.
14.3 Directory Implementation
The selection of directory-allocation and directory-management algorithms
significantly affects the efficiency, performance, and reliability of the file sys-
tem.Inthissection,wediscussthetrade-offsinvolvedinchoosingoneofthese
algorithms."
3,14.3.1 Linear List,700,14.3 Directory Implementation,"14.3 Directory Implementation 569
directory structure
directory structureopen (file name)
kernel memory user space
index(a)file-control block
secondary storage
data blocks
per-process
open-file tablesystem-wide
open-file tableread (index)
kernel memory user space
(b)file-control block
secondary storage
Figure 14.3 In-memory file-system structures. (a) File open. (b) File read.
14.3.1 Linear List
The simplest method of implementing a directory is to use a linear list of file
names with pointers to the data blocks. This method is simple to program
but time-consuming to execute. To create a new file, we must first search the
directorytobesurethatnoexistingfilehasthesamename.Then,weaddanew
entryattheendofthedirectory.Todeleteafile,wesearchthedirectoryforthe
named file and then release the space allocated to it. To reuse the directory
entry, we can do one of several things. We can mark the entry as unused (by
assigning it a special name, such as an a ll-blank name, assigning it an invalid
inodenumber(suchas0),orbyincludingaused–unusedbitineachentry),or
we can attach it to a list of free directory entries. Athird alternative is to copy
thelastentryinthedirectoryintothef reedlocationandtodecreasethelength
of the directory.Alinked list can also be used to decrease the time requiredto
deleteafile.
The real disadvantage of a linear list o f directory entries is that finding a
filerequiresalinearsearch.Directoryinformationisusedfrequently,andusers
will notice if access to it is slow. In fact, many operating systems implement
a software cache to store the most recently used directory information. A
cachehitavoidstheneedtoconstantlyrereadtheinformationfromsecondary
storage. Asorted list allows a binary search and decreases the average search
time. However, the requirement that the list be kept sorted may complicate
creatinganddeletingfiles,sincewemayhavetomovesubstantialamountsof"
3,14.3.2 Hash Table,701,14.3.1 Linear List,"570 Chapter 14 File-System Implementation
directoryinformationtomaintainasorteddirectory.Amoresophisticatedtree
data structure, such as a balanced tree, might help here. An advantage of the
sortedlististhatasorteddirectorylistingcanbeproducedwithoutaseparate
sortstep.
14.3.2 Hash Table
Anotherdatastructureusedforafiledirec toryisahashtable.Here,alinearlist
storesthedirectoryentries,butahashdatastructureisalsoused.Thehashtable
takesavaluecomputedfromthefilenameandreturnsapointertothefilename
in the linear list. Therefore, it can great ly decrease the directory search time.
Insertionanddeletionarealsofairlystraightforward,althoughsomeprovision
must be made for collisions—situations in which two file names hash to the
same location.
The major difficulties with a hash table are its generally fixed size and the
dependence of the hash function on that size. For example, assume that we
make a linear-probinghash table that holds64entries.The hash function con-
vertsfilenamesintointegersfrom0to63(forinstance,byusingtheremainder
ofadivisionby64).Ifwelatertrytocreatea65thfile,wemustenlargethedirec-
tory hash table—say, to 128 entries. As a result, we need a new hash function
that must map file names to the range 0 to 127, and we must reorganize the
existingdirectoryentriestoreflecttheirnewhash-function values.
Alternatively, we can use a chained-overflow hash table. Each hash entry
canbealinkedlistinsteadofanindividualvalue,andwecanresolvecollisions
byaddingthenewentrytothelinkedlist.Lookupsmaybesomewhatslowed,
because searching for a name might require stepping through a linked list of
collidingtableentries.Still,thismethodislikelytobemuchfasterthanalinear
search through the entire directory.
14.4 Allocation Methods
The direct-access nature of secondary storage gives us flexibility in the imple-
mentation of files. In almost every case, many files are stored on the same
device.Themainproblemishowtoallocatespacetothesefilessothatstorage
spaceisutilizedeffectivelyandfilescanbeaccessedquickly.Threemajormeth-
ods of allocating secondary storage space are in wide use: contiguous, linked,
andindexed.Eachmethodhasadvantagesanddisadvantages.Althoughsome
systems support all three, it is more common for a system to use one method
for allfileswithina file-systemtype.
14.4.1 Contiguous Allocation
Contiguous allocation requiresthateachfileoccupyasetofcontiguousblocks
onthedevice.Deviceaddressesdefinealinearorderingonthedevice.Withthis
ordering,assumingthatonlyone jobis accessingthedevice,accessingblock b
+1afterblock bnormallyrequiresnoheadmovement.Whenheadmovement
is needed (from the last sector of one cylinder to the first sector of the next
cylinder),theheadneedonlymovefromonetracktothenext.Thus,for HDDs,
the number of disk seeks requiredfor accessing contiguously allocated files is"
2,14.4 Allocation Methods,701,14.3 Directory Implementation,"570 Chapter 14 File-System Implementation
directoryinformationtomaintainasorteddirectory.Amoresophisticatedtree
data structure, such as a balanced tree, might help here. An advantage of the
sortedlististhatasorteddirectorylistingcanbeproducedwithoutaseparate
sortstep.
14.3.2 Hash Table
Anotherdatastructureusedforafiledirec toryisahashtable.Here,alinearlist
storesthedirectoryentries,butahashdatastructureisalsoused.Thehashtable
takesavaluecomputedfromthefilenameandreturnsapointertothefilename
in the linear list. Therefore, it can great ly decrease the directory search time.
Insertionanddeletionarealsofairlystraightforward,althoughsomeprovision
must be made for collisions—situations in which two file names hash to the
same location.
The major difficulties with a hash table are its generally fixed size and the
dependence of the hash function on that size. For example, assume that we
make a linear-probinghash table that holds64entries.The hash function con-
vertsfilenamesintointegersfrom0to63(forinstance,byusingtheremainder
ofadivisionby64).Ifwelatertrytocreatea65thfile,wemustenlargethedirec-
tory hash table—say, to 128 entries. As a result, we need a new hash function
that must map file names to the range 0 to 127, and we must reorganize the
existingdirectoryentriestoreflecttheirnewhash-function values.
Alternatively, we can use a chained-overflow hash table. Each hash entry
canbealinkedlistinsteadofanindividualvalue,andwecanresolvecollisions
byaddingthenewentrytothelinkedlist.Lookupsmaybesomewhatslowed,
because searching for a name might require stepping through a linked list of
collidingtableentries.Still,thismethodislikelytobemuchfasterthanalinear
search through the entire directory.
14.4 Allocation Methods
The direct-access nature of secondary storage gives us flexibility in the imple-
mentation of files. In almost every case, many files are stored on the same
device.Themainproblemishowtoallocatespacetothesefilessothatstorage
spaceisutilizedeffectivelyandfilescanbeaccessedquickly.Threemajormeth-
ods of allocating secondary storage space are in wide use: contiguous, linked,
andindexed.Eachmethodhasadvantagesanddisadvantages.Althoughsome
systems support all three, it is more common for a system to use one method
for allfileswithina file-systemtype.
14.4.1 Contiguous Allocation
Contiguous allocation requiresthateachfileoccupyasetofcontiguousblocks
onthedevice.Deviceaddressesdefinealinearorderingonthedevice.Withthis
ordering,assumingthatonlyone jobis accessingthedevice,accessingblock b
+1afterblock bnormallyrequiresnoheadmovement.Whenheadmovement
is needed (from the last sector of one cylinder to the first sector of the next
cylinder),theheadneedonlymovefromonetracktothenext.Thus,for HDDs,
the number of disk seeks requiredfor accessing contiguously allocated files is"
3,14.4.1 Contiguous Allocation,701,14.4 Allocation Methods,"570 Chapter 14 File-System Implementation
directoryinformationtomaintainasorteddirectory.Amoresophisticatedtree
data structure, such as a balanced tree, might help here. An advantage of the
sortedlististhatasorteddirectorylistingcanbeproducedwithoutaseparate
sortstep.
14.3.2 Hash Table
Anotherdatastructureusedforafiledirec toryisahashtable.Here,alinearlist
storesthedirectoryentries,butahashdatastructureisalsoused.Thehashtable
takesavaluecomputedfromthefilenameandreturnsapointertothefilename
in the linear list. Therefore, it can great ly decrease the directory search time.
Insertionanddeletionarealsofairlystraightforward,althoughsomeprovision
must be made for collisions—situations in which two file names hash to the
same location.
The major difficulties with a hash table are its generally fixed size and the
dependence of the hash function on that size. For example, assume that we
make a linear-probinghash table that holds64entries.The hash function con-
vertsfilenamesintointegersfrom0to63(forinstance,byusingtheremainder
ofadivisionby64).Ifwelatertrytocreatea65thfile,wemustenlargethedirec-
tory hash table—say, to 128 entries. As a result, we need a new hash function
that must map file names to the range 0 to 127, and we must reorganize the
existingdirectoryentriestoreflecttheirnewhash-function values.
Alternatively, we can use a chained-overflow hash table. Each hash entry
canbealinkedlistinsteadofanindividualvalue,andwecanresolvecollisions
byaddingthenewentrytothelinkedlist.Lookupsmaybesomewhatslowed,
because searching for a name might require stepping through a linked list of
collidingtableentries.Still,thismethodislikelytobemuchfasterthanalinear
search through the entire directory.
14.4 Allocation Methods
The direct-access nature of secondary storage gives us flexibility in the imple-
mentation of files. In almost every case, many files are stored on the same
device.Themainproblemishowtoallocatespacetothesefilessothatstorage
spaceisutilizedeffectivelyandfilescanbeaccessedquickly.Threemajormeth-
ods of allocating secondary storage space are in wide use: contiguous, linked,
andindexed.Eachmethodhasadvantagesanddisadvantages.Althoughsome
systems support all three, it is more common for a system to use one method
for allfileswithina file-systemtype.
14.4.1 Contiguous Allocation
Contiguous allocation requiresthateachfileoccupyasetofcontiguousblocks
onthedevice.Deviceaddressesdefinealinearorderingonthedevice.Withthis
ordering,assumingthatonlyone jobis accessingthedevice,accessingblock b
+1afterblock bnormallyrequiresnoheadmovement.Whenheadmovement
is needed (from the last sector of one cylinder to the first sector of the next
cylinder),theheadneedonlymovefromonetracktothenext.Thus,for HDDs,
the number of disk seeks requiredfor accessing contiguously allocated files is"
3,14.4.2 Linked Allocation,704,14.4.1 Contiguous Allocation,"14.4 Allocation Methods 573
fragmentation can still be a problem if the extents are too large, and external
fragmentation can become a problem as ex tents of varying sizes are allocated
and deallocated. The commercial Symantec Veritas file system uses extents
to optimize performance. Veritas is a high-performance replacement for the
standard UNIX UFS .
14.4.2 Linked Allocation
Linked allocation solves all problems of contiguous allocation. With linked
allocation,eachfileisalinkedlistofsto rageblocks;theblocksmaybescattered
anywhere on the device. The directory contains a pointer to the first and last
blocks of the file. For example, a file of five blocks might start at block 9 and
continue at block 16, then block 1, then block 10, and finally block 25 (Figure
14.5). Each block contains a pointer to the next block. These pointers are not
madeavailableto the user.Thus, if each block is 512 bytes in size, and a block
address(the pointer)requires4 bytes,thentheuserseesblocks of 508 bytes.
To create a new file, we simply create a new entry in the directory. With
linked allocation, each directory entr y has a pointer to the first block of the
file. This pointer is initializedto null(the end-of-list pointer value) to signify
an empty file. The size field is also set to 0. Awrite to the file causes the free-
space management system to find a free block, and this new block is written
to and is linked to the end of the file. To read a file, we simply read blocks by
followingthepointersfromblocktoblock.Thereisnoexternalfragmentation
with linked allocation, and any free block on the free-space list can be used to
satisfyarequest.Thesizeofafileneednotbedeclaredwhenthefileiscreated.
Afile can continue to grow as long as free blocks are available. Consequently,
itisnevernecessary tocompact diskspace.
Linked allocation does have disadvantages, however. The major problem
is that it can be used effectively only for sequential-access files. To find the ith
01 2 3
45 7
8 9 10 11
12 13 14
16 17 18 19
20 21 22 23
24 25 26 27
28 29 30 31156file
jeepstart
9directory
end
25
Figure 14.5 Linked allocation of disk space."
3,14.4.3 Indexed Allocation,706,14.4.2 Linked Allocation,"14.4 Allocation Methods 575
• • •directory entry
test 217
start block name
0
217 618
339
618 339
number of disk blocks    –1
FAT
Figure 14.6 File-allocation table.
14.4.3 Indexed Allocation
Linkedallocationsolvestheexternal-fragmentationandsize-declarationprob-
lemsofcontiguous allocation.However,intheabsenceofa FAT,linkedalloca-
tion cannot support efficient direct access, since the pointers to the blocks are
scattered with the blocks themselves all over the disk and must be retrieved
in order. Indexed allocation solves this problem by bringing all the pointers
togetherinto one location: the index block .
Each file has its own index block, which is an array of storage-block
addresses. The ith entry in the index block points to the ith block of the file.
Thedirectorycontainstheaddressoftheindexblock(Figure14.7).Tofindand
readthe ithblock,weusethepointerinthe ithindex-blockentry.Thisscheme
issimilartothe pagingscheme describedinSection 9.3.
When the file is created, all pointers in the index block are set to null.
When the ith block is first written, a block is obtained from the free-space
manager,and itsaddressisputinthe ith index-blockentry.
Indexedallocation supports directaccess, without suffering from external
fragmentation, because any free block on the storage device can satisfy a
request for more space. Indexed allocation does suffer from wasted space,
however.Thepointeroverheadoftheindexblockisgenerallygreaterthanthe
pointer overhead of linked allocation. Consider a common case in which we
havea fileof onlyone ortwo blocks.With linkedallocation,we lose thespace
of only one pointer per block. With indexed allocation, an entire index block
mustbe allocated,evenifonly one ortwo pointerswillbe non- null.
Thispointraisesthequestionofhowlargetheindexblockshouldbe.Every
file must have an index block, so we want the index block to be as small as"
3,14.4.4 Performance,708,14.4.3 Indexed Allocation,"14.4 Allocation Methods 577
direct blocksfile
metadata
single indirect
blocks
double indirect
blocks
triple indirect
blocksdata
data
data
data
. . .
data
data
data
data
. . .. . .. . . . . .
. . .
. . .. . . . . .
. . .. . .
. . .data
data
data
data
data
data
data
data
Figure 14.8 The UNIX inode.
Underthis method, the number of blocks that can be allocated to a file
exceeds the amount of space addressable by the 4-byte file pointers used
by many operating systems. A 32-bit file pointer reaches only 232bytes,
or 4GB.M a n y UNIXand Linux implementations now support 64-bit file
pointers,whichallowsfilesandfilesystemstobeseveralexbibytesinsize.
TheZFSfilesystemsupports128-bit filepointers.
Indexed-allocation schemes suffer from some of the same performance
problemsasdoeslinkedallocation.Speci fically,theindexblockscanbecached
inmemory,but thedatablocks may be spreadallovera volume.
14.4.4 Performance
Theallocationmethodsthatwehavediscussedvaryintheirstorageef ficiency
anddata-blockaccesstimes.Bothareimportantcriteriainselectingtheproper
methodormethodsfor anoperatingsystemto implement.
Before selecting an allocation method, we need to determine how the
systems will be used. Asystem with mostly sequential access should not use
thesamemethodas a systemwithmostly randomaccess.
For any type of access, contiguous allocation requires only one access to
get a block. Since we can easily keep the initial address of the file in memory,
we can calculate immediately the address of the ith block (or the next block)
a n dr ea ditdir ec tly .
For linked allocation, we can also keep the address of the next block in
memoryandreaditdirectly.Thismethodisfineforsequentialaccess;fordirect
access, however, an access to the ith block might require iblock reads. This"
2,14.5 Free-Space Management,709,14.4 Allocation Methods,"578 Chapter 14 File-System Implementation
problemindicateswhylinkedallocation shouldnotbeusedforanapplication
requiringdirectaccess.
As a result, some systems support direct-access files by using contiguous
allocation and sequential-access files by using linked allocation. For these
systems,thetypeofaccesstobemademustbedeclaredwhenthefileiscreated.
Afilecreatedforsequentialaccesswillbelinkedandcannotbeusedfordirect
access.Afilecreatedfordirectaccesswillbecontiguousandcansupportboth
direct access and sequential access, but its maximum length must be declared
when it is created. In this case, the operating system must have appropriate
datastructuresandalgorithmstosupportbothallocationmethods.Filescanbe
convertedfromone typetoanotherbythecreationofanewfileofthedesired
type, into which the contents of the old file are copied. The old file may then
be deletedand thenewfile renamed.
Indexed allocation is more complex. If the index block is already in mem-
ory, then the access can be made directly. However, keeping the index block
in memory requires considerable space. If this memory space is not avail-
able, then we may have to read first the index block and then the desired
data block. For a two-level index, two index-block reads might be necessary.
For an extremely large file, accessing a block near the end of the file would
require reading in all the index blocks before the needed data block finally
could be read. Thus, the performance of indexed allocation depends on the
indexstructure,onthesizeofthefile,andonthepositionoftheblockdesired.
Some systems combine contiguous allocation with indexed allocation by
usingcontiguousallocationforsmallfiles(uptothreeorfourblocks)andauto-
maticallyswitching toanindexedalloca tion ifthefilegrowslarge.Sincemost
files are small, and contiguous allocation is efficient for small files, average
performance can be quitegood.
Many other optimizations are in use. Given the disparity between CPU
speedanddiskspeed,itisnotunreasonab letoaddthousandsofextrainstruc-
tions to the operating system to save just a few disk-head movements. Fur-
thermore, this disparity is increasing over time, to the point where hundreds
ofthousandsofinstructionscouldreasonablybeusedtooptimizeheadmove-
ments.
ForNVMdevices, there are no disk head seeks, so different algorithms
and optimizations are needed. Using an old algorithm that spends many CPU
cyclestryingtoavoidanonexistentheadmovementwouldbeveryinefficient.
Existing file systems are being modified and new ones being created to attain
maximum performance from NVMstorage devices. These developments aim
to reduce the instruction count and overall path between the storage device
and applicationaccess to thedata.
14.5 Free-Space Management
Since storage space is limited, we need to reuse the space from deleted files
for new files,if possible.(Write-once optical disksallow only one write to any
given sector, and thus reuse is not physically possible.) To keep track of free
disk space, the system maintains a free-space list . The free-space list records
allfreedeviceblocks—thosenotallocatedtosomefileordirectory.Tocreatea
file,wesearchthefree-spacelistfortherequiredamountofspaceandallocate"
3,14.5.1 Bit Vector,710,14.5 Free-Space Management,"14.5 Free-Space Management 579
that space to the new file. This space is then removed from the free-space list.
When a file is deleted, its space is added to the free-space list. The free-space
list, despite its name, is not necessarily implemented as a list, as we discuss
next.
14.5.1 Bit Vector
Frequently, the free-space list is implemented as a bitmaporbit vector .E a c h
block is represented by 1 bit. If the block is free, the bit is 1; if the block is
allocated,thebit is0.
For example, consider a disk where blocks 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 17,
18,25,26,and27arefreeandtherestoftheblocksareallocated.Thefree-space
bitmapwould be
0011110011111 10001100000011100000 ...
The main advantage of this approach is its relative simplicity and its effi-
ciency in finding the first free block or nc o n s e c u t i v ef r e eb l o c k so nt h ed i s k .
Indeed,manycomputerssupplybit-manip ulationinstructionsthatcanbeused
effectively for that purpose. One technique for finding the first free block on
a system that uses a bit vector to allocate space is to sequentially check each
word in the bitmap to see whether that value is not 0, since a 0-valued word
contains only 0 bits and represents a set of allocated blocks. The first non-0
word is scanned for the first 1 bit, which is the location of the first free block.
The calculation ofthe block number is
(number of bitsperword) ×(number of0-valuewords) +offsetof first 1bit.
Again, we see hardware features driving software functionality. Unfortu-
nately,bitvectorsareinefficientunlesstheentirevectoriskeptinmainmemory
(and is written to the device containing the file system occasionally for recov-
ery needs). Keeping it in main memory is possible for smaller devices but not
necessarily for larger ones. A 1.3- GBdisk with 512-byte blocks would need a
bitmapofover332 KBtotrackitsfreeblocks,althoughclusteringtheblocksin
groupsoffourreducesthisnumbertoaround83 KBperdisk.A1- TBdiskwith
4-KBblocks would require 32 MB(240/212=228bits = 225bytes = 25MB) to
storeitsbitmap.Giventhatdisksizeconstantlyincreases,theproblemwithbit
vectorswill continue to escalateas well.
14.5.2 Linked List
Another approach to free-space management is to link together all the free
blocks, keeping a pointer to the first free block in a special location in the file
system and caching it in memory. This first block contains a pointer to the
nextfreeblock,andsoon.Recallourear lierexample(Section14.5.1),inwhich
blocks 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 17, 18, 25, 26, and 27 were free and the
rest of the blocks were allocated. In this situation, we would keep a pointer to
block2asthefirstfreeblock.Block2wouldcontainapointertoblock3,which
would point to block 4, which would point to block 5, which would point to
block 8, and so on (Figure 14.9). This scheme is not efficient; to traverse the
list, we must read each block, which requires substantial I/Otime on HDDs.
Fortunately, however, traversing the free list is not a frequent action. Usually,"
3,14.5.2 Linked List,710,14.5.1 Bit Vector,"14.5 Free-Space Management 579
that space to the new file. This space is then removed from the free-space list.
When a file is deleted, its space is added to the free-space list. The free-space
list, despite its name, is not necessarily implemented as a list, as we discuss
next.
14.5.1 Bit Vector
Frequently, the free-space list is implemented as a bitmaporbit vector .E a c h
block is represented by 1 bit. If the block is free, the bit is 1; if the block is
allocated,thebit is0.
For example, consider a disk where blocks 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 17,
18,25,26,and27arefreeandtherestoftheblocksareallocated.Thefree-space
bitmapwould be
0011110011111 10001100000011100000 ...
The main advantage of this approach is its relative simplicity and its effi-
ciency in finding the first free block or nc o n s e c u t i v ef r e eb l o c k so nt h ed i s k .
Indeed,manycomputerssupplybit-manip ulationinstructionsthatcanbeused
effectively for that purpose. One technique for finding the first free block on
a system that uses a bit vector to allocate space is to sequentially check each
word in the bitmap to see whether that value is not 0, since a 0-valued word
contains only 0 bits and represents a set of allocated blocks. The first non-0
word is scanned for the first 1 bit, which is the location of the first free block.
The calculation ofthe block number is
(number of bitsperword) ×(number of0-valuewords) +offsetof first 1bit.
Again, we see hardware features driving software functionality. Unfortu-
nately,bitvectorsareinefficientunlesstheentirevectoriskeptinmainmemory
(and is written to the device containing the file system occasionally for recov-
ery needs). Keeping it in main memory is possible for smaller devices but not
necessarily for larger ones. A 1.3- GBdisk with 512-byte blocks would need a
bitmapofover332 KBtotrackitsfreeblocks,althoughclusteringtheblocksin
groupsoffourreducesthisnumbertoaround83 KBperdisk.A1- TBdiskwith
4-KBblocks would require 32 MB(240/212=228bits = 225bytes = 25MB) to
storeitsbitmap.Giventhatdisksizeconstantlyincreases,theproblemwithbit
vectorswill continue to escalateas well.
14.5.2 Linked List
Another approach to free-space management is to link together all the free
blocks, keeping a pointer to the first free block in a special location in the file
system and caching it in memory. This first block contains a pointer to the
nextfreeblock,andsoon.Recallourear lierexample(Section14.5.1),inwhich
blocks 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 17, 18, 25, 26, and 27 were free and the
rest of the blocks were allocated. In this situation, we would keep a pointer to
block2asthefirstfreeblock.Block2wouldcontainapointertoblock3,which
would point to block 4, which would point to block 5, which would point to
block 8, and so on (Figure 14.9). This scheme is not efficient; to traverse the
list, we must read each block, which requires substantial I/Otime on HDDs.
Fortunately, however, traversing the free list is not a frequent action. Usually,"
3,14.5.3 Grouping,711,14.5.2 Linked List,"580 Chapter 14 File-System Implementation
01 2 3
45 7
8 9 10 11
12 13 14
16 17 18 19
20 21 22 23
24 25 26 27
28 29 30 31156free-space list head
Figure 14.9 Linked free-space list on disk.
theoperatingsystemsimplyneedsafreeblocksothatitcanallocatethatblock
to a file, so the first block in the free list is used. The FATmethod incorporates
free-blockaccountingintotheallocationdatastructure.Noseparatemethodis
needed.
14.5.3 Grouping
A modification of the free-list approach stores the addresses of nfree blocks
in the first free block. The first n−1 of these blocks are actually free. The last
blockcontainstheaddressesofanother nfreeblocks,andsoon.Theaddresses
ofalargenumberoffreeblockscannowbefoundquickly,unlikethesituation
when thestandardlinked-listapproachisused.
14.5.4 Counting
Another approach takes advantage of the fact that, generally,several contigu-
ous blocks may be allocated or freed simultaneously, particularly when space
is allocated with the contiguous-allocation algorithm or through clustering.
Thus, rather than keeping a list of nfree block addresses, we can keep the
addressofthefirstfreeblockandthenumber( n)offreecontiguousblocksthat
follow thefirstblock. Eachentryin thefree-spacelistthen consists ofadevice
address and a count. Although each entry requires more space than would a
simplediskaddress,theoveralllistisshorter,aslongasthecountisgenerally
greater than 1. Note that this method of tracking free space is similar to the
extent method of allocating blocks. These entries can be stored in a balanced
tree,ratherthan alinkedlist,for effici entlookup, insertion,anddeletion."
3,14.5.4 Counting,711,14.5.3 Grouping,"580 Chapter 14 File-System Implementation
01 2 3
45 7
8 9 10 11
12 13 14
16 17 18 19
20 21 22 23
24 25 26 27
28 29 30 31156free-space list head
Figure 14.9 Linked free-space list on disk.
theoperatingsystemsimplyneedsafreeblocksothatitcanallocatethatblock
to a file, so the first block in the free list is used. The FATmethod incorporates
free-blockaccountingintotheallocationdatastructure.Noseparatemethodis
needed.
14.5.3 Grouping
A modification of the free-list approach stores the addresses of nfree blocks
in the first free block. The first n−1 of these blocks are actually free. The last
blockcontainstheaddressesofanother nfreeblocks,andsoon.Theaddresses
ofalargenumberoffreeblockscannowbefoundquickly,unlikethesituation
when thestandardlinked-listapproachisused.
14.5.4 Counting
Another approach takes advantage of the fact that, generally,several contigu-
ous blocks may be allocated or freed simultaneously, particularly when space
is allocated with the contiguous-allocation algorithm or through clustering.
Thus, rather than keeping a list of nfree block addresses, we can keep the
addressofthefirstfreeblockandthenumber( n)offreecontiguousblocksthat
follow thefirstblock. Eachentryin thefree-spacelistthen consists ofadevice
address and a count. Although each entry requires more space than would a
simplediskaddress,theoveralllistisshorter,aslongasthecountisgenerally
greater than 1. Note that this method of tracking free space is similar to the
extent method of allocating blocks. These entries can be stored in a balanced
tree,ratherthan alinkedlist,for effici entlookup, insertion,anddeletion."
3,14.5.5 Space Maps,712,14.5.4 Counting,"14.5 Free-Space Management 581
14.5.5 Space Maps
Oracle’s ZFSfile system (found in Solaris and some other operating systems)
was designed to encompass huge numbers of files, directories, and even file
systems (in ZFS, we can create file-system hierarchies). On these scales, meta-
dataI/Ocan have a large performance impact. Consider, for example, that if
thefree-spacelistisimplementedasabitmap,bitmapsmustbemodifiedboth
when blocks are allocated and when they are freed. Freeing 1 GBof data on a
1-TBdisk could cause thousands of blocks of bitmaps to be updated, because
those data blocks could be scattered over the entire disk. Clearly, the data
structuresfor such a systemcouldbe largeand inefficient.
In its management of free space, ZFSuses a combination of techniques to
control the size of data structures and minimize the I/Oneeded to manage
thosestructures.First, ZFScreates metaslabs to dividethe space onthe device
into chunks of manageable size. A gi ven volume may contain hundreds of
metaslabs. Each metaslab has an associated space map. ZFSuses the counting
algorithm to store information about fr ee blocks. Rather than write counting
structurestodisk,ituseslog-structuredfile-systemtechniquestorecordthem.
The space map is a log of all block activity (allocating and freeing), in time
order, in counting format. When ZFSdecides to allocate or free space from a
metaslab, it loads the associated spac e map into memory in a balanced-tree
structure (for very efficient operation), indexed by offset, and replays the log
into that structure. The in-memory spac e map is then an accurate representa-
tionoftheallocatedandfreespaceinthemetaslab. ZFSalsocondensesthemap
as much as possible by combining contiguous free blocks into a single entry.
Finally,thefree-spacelistisupdatedondiskaspartofthetransaction-oriented
operations of ZFS. During the collection and sorting phase, block requests can
stilloccur,and ZFSsatisfiestheserequestsfromthelog.Inessence,thelogplus
the balanced tree isthe freelist.
14.5.6 TRIMing Unused Blocks
HDDsandotherstoragemediathatallowblockstobeoverwrittenforupdates
needonlythefreelistformanagingfreespace.Blocksdonotneedtobetreated
specially when freed. Afreed block typically keeps its data (but without any
filepointerstothe block)untilthedataareoverwrittenwhenthe blockisnext
allocated.
Storage devices that do not allow overwrite, such as NVMflash-based
storage devices, suffer badly when these same algorithms are applied. Recall
from Section 11.1.2 that such devices must be erased before they can again
be written to, and that those erases must be made in large chunks (blocks,
composed of pages) and take a relatively long time compared with reads or
writes.
Anewmechanism isneededtoallowthefilesystemtoinform thestorage
devicethatapageisfreeandcanbeconsideredforerasure(oncetheblockcon-
taining the page is entirely free). That mechanism varies based on the storage
controller.For ATA-attacheddrives,itis TRIM,whilefor NVMe-basedstorage,it
is the unallocate command. Whatever the specific controller command, this
mechanism keepsstorage space availabl e for writing. Without such a capabil-
ity,thestoragedevicegetsfullandneedsgarbagecollectionandblockerasure,
leadingtodecreasesinstorage I/Owriteperformance(knownas “awritecliff ”)."
3,14.5.6 TRIMing Unused Blocks,712,14.5.5 Space Maps,"14.5 Free-Space Management 581
14.5.5 Space Maps
Oracle’s ZFSfile system (found in Solaris and some other operating systems)
was designed to encompass huge numbers of files, directories, and even file
systems (in ZFS, we can create file-system hierarchies). On these scales, meta-
dataI/Ocan have a large performance impact. Consider, for example, that if
thefree-spacelistisimplementedasabitmap,bitmapsmustbemodifiedboth
when blocks are allocated and when they are freed. Freeing 1 GBof data on a
1-TBdisk could cause thousands of blocks of bitmaps to be updated, because
those data blocks could be scattered over the entire disk. Clearly, the data
structuresfor such a systemcouldbe largeand inefficient.
In its management of free space, ZFSuses a combination of techniques to
control the size of data structures and minimize the I/Oneeded to manage
thosestructures.First, ZFScreates metaslabs to dividethe space onthe device
into chunks of manageable size. A gi ven volume may contain hundreds of
metaslabs. Each metaslab has an associated space map. ZFSuses the counting
algorithm to store information about fr ee blocks. Rather than write counting
structurestodisk,ituseslog-structuredfile-systemtechniquestorecordthem.
The space map is a log of all block activity (allocating and freeing), in time
order, in counting format. When ZFSdecides to allocate or free space from a
metaslab, it loads the associated spac e map into memory in a balanced-tree
structure (for very efficient operation), indexed by offset, and replays the log
into that structure. The in-memory spac e map is then an accurate representa-
tionoftheallocatedandfreespaceinthemetaslab. ZFSalsocondensesthemap
as much as possible by combining contiguous free blocks into a single entry.
Finally,thefree-spacelistisupdatedondiskaspartofthetransaction-oriented
operations of ZFS. During the collection and sorting phase, block requests can
stilloccur,and ZFSsatisfiestheserequestsfromthelog.Inessence,thelogplus
the balanced tree isthe freelist.
14.5.6 TRIMing Unused Blocks
HDDsandotherstoragemediathatallowblockstobeoverwrittenforupdates
needonlythefreelistformanagingfreespace.Blocksdonotneedtobetreated
specially when freed. Afreed block typically keeps its data (but without any
filepointerstothe block)untilthedataareoverwrittenwhenthe blockisnext
allocated.
Storage devices that do not allow overwrite, such as NVMflash-based
storage devices, suffer badly when these same algorithms are applied. Recall
from Section 11.1.2 that such devices must be erased before they can again
be written to, and that those erases must be made in large chunks (blocks,
composed of pages) and take a relatively long time compared with reads or
writes.
Anewmechanism isneededtoallowthefilesystemtoinform thestorage
devicethatapageisfreeandcanbeconsideredforerasure(oncetheblockcon-
taining the page is entirely free). That mechanism varies based on the storage
controller.For ATA-attacheddrives,itis TRIM,whilefor NVMe-basedstorage,it
is the unallocate command. Whatever the specific controller command, this
mechanism keepsstorage space availabl e for writing. Without such a capabil-
ity,thestoragedevicegetsfullandneedsgarbagecollectionandblockerasure,
leadingtodecreasesinstorage I/Owriteperformance(knownas “awritecliff ”)."
2,14.6 Efficiency and Performance,713,14.5 Free-Space Management,"582 Chapter 14 File-System Implementation
With the TRIMmechanism and similar capabilities, the garbage collection and
erase steps can occur before the device is nearly full, allowing the device to
providemoreconsistentperformance.
14.6 Efﬁciency and Performance
Now that we have discussed various block-allocation and directory-
management options, we can further consider their effect on performance
and efficient storageuse.Disks tendto representa major bottleneckin system
performance,sincetheyaretheslowestmaincomputercomponent.Even NVM
devicesare slow compared with CPUand mainmemory,so theirperformance
must be optimized as well. In this section, we discuss a variety of techniques
used toimprovethe efficiency and performance of secondarystorage.
14.6.1 Efﬁciency
The efficient use of storage device space depends heavily on the allocation
and directory algorithms in use. For instance, UNIXinodes are preallocated
on a volume. Even an empty disk has a percentage of its space lost to inodes.
However, by preallocating the inodes and spreading them across the volume,
weimprovethefilesystem’sperformance.Thisimprovedperformanceresults
from the UNIXallocation and free-space algorithms, which try to keep a file’s
datablocks nearthat file’s inodeblock to reduceseektime.
As another example, let’s reconsider the clustering scheme discussed in
Section14.4,whichimprovesfile-seekandfile-transferperformanceatthecost
of internal fragmentation. To reduce this fragmentation, BSD UNIX varies the
cluster size as a file grows. Large clusters are used where they can be filled,
and small clusters are used for small files and the last cluster of a file. This
systemisdescribedinAppendixC.
The types of data normally kept in a file’s directory (or inode) entry also
require consideration. Commonly, a “last write date ”is recorded to supply
information to the user and to determine whether the file needs to be backed
up. Some systems also keep a “last access date, ”so that a user can determine
when the file was last read. The result of keeping this information is that,
whenever the file is read, a field in the directory structure must be written to.
That means the block must be read into memory, a section changed, and the
blockwrittenbackouttothedevice,becauseoperationson secondarystorage
occuronlyinblock(orcluster)chunks.Soanytimeafileisopenedforreading,
itsFCBmustbereadandwrittenaswell.Thisrequirementcanbeinefficientfor
frequentlyaccessedfiles,sowemustweighitsbenefitagainstitsperformance
cost when designing a file system. Generally, every data item associated with
a fileneedstobe consideredfor itseffectonefficiency andperformance.
Consider,forinstance,howefficiencyisaffectedbythesizeofthepointers
used to access data. Most systemsuse either 32-bit or 64-bit pointers through-
outtheoperatingsystem.Using32-bitpointerslimitsthesizeofafileto232,or4
GB.Using64-bitpointersallowsverylargefilesizes,but64-bitpointersrequire
more space to store. As a result, the allocation and free-space-management
methods(linkedlists,indexes,and soon) usemorestoragespace."
3,14.6.1 Efficiency,713,14.6 Efficiency and Performance,"582 Chapter 14 File-System Implementation
With the TRIMmechanism and similar capabilities, the garbage collection and
erase steps can occur before the device is nearly full, allowing the device to
providemoreconsistentperformance.
14.6 Efﬁciency and Performance
Now that we have discussed various block-allocation and directory-
management options, we can further consider their effect on performance
and efficient storageuse.Disks tendto representa major bottleneckin system
performance,sincetheyaretheslowestmaincomputercomponent.Even NVM
devicesare slow compared with CPUand mainmemory,so theirperformance
must be optimized as well. In this section, we discuss a variety of techniques
used toimprovethe efficiency and performance of secondarystorage.
14.6.1 Efﬁciency
The efficient use of storage device space depends heavily on the allocation
and directory algorithms in use. For instance, UNIXinodes are preallocated
on a volume. Even an empty disk has a percentage of its space lost to inodes.
However, by preallocating the inodes and spreading them across the volume,
weimprovethefilesystem’sperformance.Thisimprovedperformanceresults
from the UNIXallocation and free-space algorithms, which try to keep a file’s
datablocks nearthat file’s inodeblock to reduceseektime.
As another example, let’s reconsider the clustering scheme discussed in
Section14.4,whichimprovesfile-seekandfile-transferperformanceatthecost
of internal fragmentation. To reduce this fragmentation, BSD UNIX varies the
cluster size as a file grows. Large clusters are used where they can be filled,
and small clusters are used for small files and the last cluster of a file. This
systemisdescribedinAppendixC.
The types of data normally kept in a file’s directory (or inode) entry also
require consideration. Commonly, a “last write date ”is recorded to supply
information to the user and to determine whether the file needs to be backed
up. Some systems also keep a “last access date, ”so that a user can determine
when the file was last read. The result of keeping this information is that,
whenever the file is read, a field in the directory structure must be written to.
That means the block must be read into memory, a section changed, and the
blockwrittenbackouttothedevice,becauseoperationson secondarystorage
occuronlyinblock(orcluster)chunks.Soanytimeafileisopenedforreading,
itsFCBmustbereadandwrittenaswell.Thisrequirementcanbeinefficientfor
frequentlyaccessedfiles,sowemustweighitsbenefitagainstitsperformance
cost when designing a file system. Generally, every data item associated with
a fileneedstobe consideredfor itseffectonefficiency andperformance.
Consider,forinstance,howefficiencyisaffectedbythesizeofthepointers
used to access data. Most systemsuse either 32-bit or 64-bit pointers through-
outtheoperatingsystem.Using32-bitpointerslimitsthesizeofafileto232,or4
GB.Using64-bitpointersallowsverylargefilesizes,but64-bitpointersrequire
more space to store. As a result, the allocation and free-space-management
methods(linkedlists,indexes,and soon) usemorestoragespace."
3,14.6.2 Performance,714,14.6.1 Efficiency,"14.6 Efficienc and Performance 583
Oneofthedifficultiesinchoosingapointersize—or,indeed,anyfixedallo-
cationsizewithinanoperatingsystem—isplanningfortheeffectsofchanging
technology.Considerthatthe IBMPCXT hada10- MBharddriveandan MS-DOS
FATfile system that could support only 32 MB.( E a c h FATentry was 12 bits,
pointing to an 8- KBcluster.) As disk capacities increased, larger disks had to
be split into 32- MBpartitions, because the file system could not track blocks
beyond 32 MB. Ashard disks with capacities of over100 MBbecame common,
thediskdatastructuresandalgorithmsin MS-DOShadtobemodifiedtoallow
larger file systems. (Each FATentry was expanded to 16 bits and later to 32
bits.) The initial file-system decisions were made for efficiency reasons; how-
ever, with the advent of MS-DOSVersion 4, millions of computer users were
inconveniencedwhenthey hadtoswitchtothenew,largerfilesystem.Solaris’s
ZFSfilesystemuses128-bitpointers,whic htheoreticallyshouldneverneedto
beextended.(Theminimummassofadevicecapableofstoring2128bytesusing
atomic-levelstoragewouldbe about 272 trillionkilograms.)
As another example, consider the evolution of the Solaris operating sys-
tem.Originally,manydatastructureswereoffixedlength,allocatedatsystem
startup. These structures included the process table and the open-file table.
Whentheprocesstablebecamefull,nomoreprocessescouldbecreated.When
thefiletablebecamefull,nomorefilescouldbeopened.Thesystemwouldfail
toprovideservicestousers.Tablesizescouldbeincreasedonlybyrecompiling
the kernel and rebooting the system. With later releases of Solaris, (as with
modernLinuxkernels)almostallkernelstructureswereallocateddynamically,
eliminating these artificial limits on system performance. Of course, the algo-
rithms that manipulate these tables a re more complicated, and the operating
system is a little slower because it must dynamically allocate and deallocate
table entries;but that price isthe usual one formore generalfunctionality.
14.6.2 Performance
Even after the basic file-system algorithms have been selected, we can still
improveperformanceinseveralways.AswasdiscussedinChapter12,storage
devicecontrollersincludelocalmemorytoformanon-boardcachethatislarge
enough to store entire tracks or blocks at a time. On an HDD, once a seek is
performed,thetrackisreadintothedis kcachestartingatthesectorunderthe
diskhead(reducinglatencytime).Thedis kcontrollerthentransfersanysector
requeststotheoperatingsystem.Onceblocksmakeitfromthediskcontroller
intomain memory,theoperatingsystemmaycache theblocks there.
Some systems maintain a separate section of main memory for a buffer
cache, where blocks are kept under the assumption that they will be used
again shortly. Other systems cache file data using a page cache .T h ep a g e
cache uses virtual memory techniques to cache file data as pages rather than
as file-system-oriented blocks. Caching fi le data using virtual addresses is far
more efficientthan caching through physical diskblocks, as accesses interface
with virtual memory rather than the file system. Several systems—including
Solaris, Linux, and Windows—use page caching to cache both process pages
an dfi ledata.Th isiskn ow nas unifie virtual memory .
Some versions of UNIXand Linux provide a unifie buffer cache .T o
illustratethebenefitsoftheunifiedbuffe rcache,considerthetwoalternatives"
2,14.7 Recovery,717,14.6 Efficiency and Performance,"586 Chapter 14 File-System Implementation
data to disk when convenient. The user process sees very fast writes. When
data are read from a disk file, the block I/Osystem does some read-ahead;
however, writes are much more nearly asynchronous than are reads. Thus,
outputtothediskthroughthefilesystemisoftenfasterthanisinputforsmall
transfers, counter to intuition. No matter how much buffering and caching is
available, large, continuous I/Ocan overrun the capacity and end up bottle-
necked on the device’s performance. Consider writing a large movie file to a
HDD. If the file is larger than the page cache (or the part of the page cache
available to the process) then the page cache will fill and all I/Owill occur at
drive speed. Current HDDs read faster than they write, so in this instance the
performanceaspects arereversedfrom smaller I/Operformance.
14.7 Recovery
Filesanddirectoriesarekeptbothinmainmemoryandonthestoragevolume,
andcaremustbetakentoensurethatasystemfailuredoesnotresultinlossof
dataorindatainconsistency.Asystemcrashcan causeinconsistenciesamong
on-storage file-system data structures, such as directory structures, free-block
pointers, and free FCBpointers. Many file systems apply changes to these
structures in place. A typical operation, such as creating a file, can involve
manystructuralchangeswithinthefilesystemonthedisk.Directorystructures
aremodified, FCBs are allocated,data blocks areallocated,and thefreecounts
for all of these blocks are decreased. These changes can be interrupted by a
crash, and inconsistencies among the structures can result. For example, the
freeFCBcountmightindicatethatan FCBhadbeenallocated,butthedirectory
structuremightnotpointtothe FCB.Compoundingthisproblemisthecaching
thatoperatingsystemsdotooptimize I/Operformance.Somechangesmaygo
directly to storage, while others may be cached. If the cached changes do not
reach the storage devicebefore a crash occurs, more corruption ispossible.
In addition to crashes, bugs in file-system implementation, device con-
trollers,andevenuserapplicationscancorruptafilesystem.Filesystemshave
varying methods to deal with corruption, depending on the file-system data
structuresandalgorithms.We dealwiththeseissuesnext.
14.7.1 Consistency Checking
Whatever the cause of corruption, a file system must first detect the problems
and then correct them. For detection, a scan of all the metadata on each file
system can confirm or deny the consistency of the system. Unfortunately, this
scancantakeminutesorhoursandshouldoccureverytimethesystemboots.
Alternatively,afilesystemcanrecorditsstatewithinthefile-systemmetadata.
At the start of any metadata change, a status bit is set to indicate that the
metadataisinflux.Ifallupdatestothemetadatacompletesuccessfully,thefile
system can clear that bit. If, however, the status bit remains set, a consistency
checker isrun.
The consistency checker —a systems program such as fsckinUNIX—
compares the data in the directory structure and other metadata with the
state on storage and tries to fix any inconsistencies it finds. The allocation
and free-space-management algorithms dictate what types of problems the"
3,14.7.1 Consistency Checking,717,14.7 Recovery,"586 Chapter 14 File-System Implementation
data to disk when convenient. The user process sees very fast writes. When
data are read from a disk file, the block I/Osystem does some read-ahead;
however, writes are much more nearly asynchronous than are reads. Thus,
outputtothediskthroughthefilesystemisoftenfasterthanisinputforsmall
transfers, counter to intuition. No matter how much buffering and caching is
available, large, continuous I/Ocan overrun the capacity and end up bottle-
necked on the device’s performance. Consider writing a large movie file to a
HDD. If the file is larger than the page cache (or the part of the page cache
available to the process) then the page cache will fill and all I/Owill occur at
drive speed. Current HDDs read faster than they write, so in this instance the
performanceaspects arereversedfrom smaller I/Operformance.
14.7 Recovery
Filesanddirectoriesarekeptbothinmainmemoryandonthestoragevolume,
andcaremustbetakentoensurethatasystemfailuredoesnotresultinlossof
dataorindatainconsistency.Asystemcrashcan causeinconsistenciesamong
on-storage file-system data structures, such as directory structures, free-block
pointers, and free FCBpointers. Many file systems apply changes to these
structures in place. A typical operation, such as creating a file, can involve
manystructuralchangeswithinthefilesystemonthedisk.Directorystructures
aremodified, FCBs are allocated,data blocks areallocated,and thefreecounts
for all of these blocks are decreased. These changes can be interrupted by a
crash, and inconsistencies among the structures can result. For example, the
freeFCBcountmightindicatethatan FCBhadbeenallocated,butthedirectory
structuremightnotpointtothe FCB.Compoundingthisproblemisthecaching
thatoperatingsystemsdotooptimize I/Operformance.Somechangesmaygo
directly to storage, while others may be cached. If the cached changes do not
reach the storage devicebefore a crash occurs, more corruption ispossible.
In addition to crashes, bugs in file-system implementation, device con-
trollers,andevenuserapplicationscancorruptafilesystem.Filesystemshave
varying methods to deal with corruption, depending on the file-system data
structuresandalgorithms.We dealwiththeseissuesnext.
14.7.1 Consistency Checking
Whatever the cause of corruption, a file system must first detect the problems
and then correct them. For detection, a scan of all the metadata on each file
system can confirm or deny the consistency of the system. Unfortunately, this
scancantakeminutesorhoursandshouldoccureverytimethesystemboots.
Alternatively,afilesystemcanrecorditsstatewithinthefile-systemmetadata.
At the start of any metadata change, a status bit is set to indicate that the
metadataisinflux.Ifallupdatestothemetadatacompletesuccessfully,thefile
system can clear that bit. If, however, the status bit remains set, a consistency
checker isrun.
The consistency checker —a systems program such as fsckinUNIX—
compares the data in the directory structure and other metadata with the
state on storage and tries to fix any inconsistencies it finds. The allocation
and free-space-management algorithms dictate what types of problems the"
3,14.7.2 Log-Structured File Systems,718,14.7.1 Consistency Checking,"14.7 Recovery 587
checker can find and how successful it will be in fixing them. For instance,
if linked allocation is used and there is a link from any block to its next
block, then the entire file can be reconstructed from the data blocks, and the
directory structure can be recreated. In contrast, the loss of a directory entry
on an indexed allocation system can be disastrous, because the data blocks
have no knowledge of one another. For this reason, some UNIXfile systems
cachedirectoryentriesforreads,butanywritethatresultsinspaceallocation,
or other metadata changes, is done synchronously, before the corresponding
data blocks are written. Of course, problems can still occur if a synchronous
writeisinterruptedbyacrash.Some NVMstoragedevicescontainabatteryor
supercapacitor to provide enough power, even during a power loss, to write
datafromdevicebufferstothestoragemediasothedataarenotlost.Buteven
those precautions donot protectagainst corruptiondue to acrash.
14.7.2 Log-Structured File Systems
Computer scientists often find that al gorithms and technologies originally
used in one area are equally useful in other areas. Such is the case with the
database log-based recovery algorithm s. These logging algorithms have been
applied successfully to the problem of consistency checking. The resulting
implementationsareknownas log-based transaction-oriented (orjournaling )
filesystems.
Note that with the consistency-checking approach discussed in the pre-
ceding section, we essentially allow s tructures to break and repair them on
recovery.However,thereareseveralproblemswiththis approach. Oneis that
the inconsistency may be irreparable. The consistency check may not be able
to recover the structures, resulting in loss of files and even entire directories.
Consistencycheckingcanrequirehumaninterventiontoresolveconflicts,and
that is inconvenient if no human is ava ilable. The system can remain unavail-
able until the human tells it how to proc eed. Consistency checking also takes
system and clock time. To check terabytes of data, hours of clock time may be
required.
The solution to this problem is to apply log-based recovery techniques to
file-system metadata updates. Both NTFSand the Veritas file system use this
method,anditisincludedinrecentversionsof UFSonSolaris.Infact,itisnow
common on many file systemsincludingext3,ext4,and ZFS.
Fundamentally, all metadata changes are written sequentially to a log.
Each set of operations for performing a specific task is a transaction .O n c e
the changes are written to this log, they are considered to be committed,
and the system call can return to the user process, allowing it to continue
execution. Meanwhile, these log entries are replayed across the actual file-
system structures. As the changes are made, a pointer is updated to indicate
which actions have completed and whic h are stillincomplete. When an entire
committed transaction is completed, and entry is made in the log indicating
that. The log file is is actually a circular buffer. A circular buffer writes to the
endofitsspaceandthencontinues atthebeginning,overwritingoldervalues
as it goes. We would not want the buffer to write over data that had not yet
beensaved,sothatscenarioisavoided.Thelogmaybeinaseparatesectionof
thefilesystemor evenona separatestoragedevice."
3,14.7.3 Other Solutions,719,14.7.2 Log-Structured File Systems,"588 Chapter 14 File-System Implementation
If the system crashes, the log file will contain zero or more transactions.
Anytransactionsitcontainswerenotcompletedtothefilesystem,eventhough
theywerecommittedbytheoperatingsystem,sotheymustnowbecompleted.
The transactions can be executed from the pointer until the work is complete
so that the file-system structures remain consistent. The only problem occurs
whenatransactionwasaborted—thatis,wasnotcommittedbeforethesystem
crashed. Any changes from such a transaction that were applied to the file
system must be undone, again preserving the consistency of the file system.
Thisrecoveryisallthatisneededafteracrash,eliminatinganyproblemswith
consistency checking.
A side benefit of using logging on disk metadata updates is that those
updates proceed much faster than when they are applied directly to the on-
disk data structures. The reason is found in the performance advantage of
sequential I/Oover random I/O. The costly synchronous random metadata
writes are turned into much less costly synchronous sequential writes to the
log-structured file system’s logging area. Those changes, in turn, are replayed
asynchronously via random writes to the appropriate structures. The overall
result is a significant gain in performan ce of metadata-oriented operations,
such asfile creationand deletion,on HDDstorage.
14.7.3 Other Solutions
Another alternative to consistency checking is employed by Network Appli-
ance’sWAFLfile system and the Solaris ZFSfile system. These systems never
overwriteblockswithnewdata.Rather,atransactionwritesalldataandmeta-
data changes to new blocks. When the tra nsaction is complete, the metadata
structuresthatpointedtotheoldversionsoftheseblocksareupdatedtopoint
to the new blocks. The file system can then remove the old pointers and the
old blocks and make them available for reuse. If the old pointers and blocks
are kept, a snapshot is created; the snapshot is a view of the file system at a
specific point in time (before any updates after that time were applied). This
solution should require no consistency checking if the pointer update is done
atomically. WAFLdoes have a consistency checker, however, so some failure
scenarios can still cause metadata corruption. (See Section 14.8 for details of
theWAFLfilesystem.)
ZFStakesanevenmoreinnovativeapproachtodiskconsistency.Like WAFL,
itneveroverwritesblocks.However, ZFSgoesfurtherandprovideschecksum-
ming of all metadata and data blocks. This solution (when combined with
RAID) assures that data are always correct. ZFStherefore has no consistency
checker.(Moredetailson ZFSarefound inSection 11.8.6.)
14.7.4 Backup and Restore
Storagedevicessometimesfail,andcaremustbetakentoensurethatthedata
lost in such a failure are not lost forever. To this end, system programs can be
used to back up data from one storage device to another, such as a magnetic
tapeorothersecondarystoragedevice.Recoveryfromthelossofanindividual
file, or of an entire device, may then be a matter of restoring the data from
backup.
To minimize the copying needed, we can use information from each file’s
directory entry. For instance, if the backup program knows when the last"
3,14.7.4 Backup and Restore,719,14.7.3 Other Solutions,"588 Chapter 14 File-System Implementation
If the system crashes, the log file will contain zero or more transactions.
Anytransactionsitcontainswerenotcompletedtothefilesystem,eventhough
theywerecommittedbytheoperatingsystem,sotheymustnowbecompleted.
The transactions can be executed from the pointer until the work is complete
so that the file-system structures remain consistent. The only problem occurs
whenatransactionwasaborted—thatis,wasnotcommittedbeforethesystem
crashed. Any changes from such a transaction that were applied to the file
system must be undone, again preserving the consistency of the file system.
Thisrecoveryisallthatisneededafteracrash,eliminatinganyproblemswith
consistency checking.
A side benefit of using logging on disk metadata updates is that those
updates proceed much faster than when they are applied directly to the on-
disk data structures. The reason is found in the performance advantage of
sequential I/Oover random I/O. The costly synchronous random metadata
writes are turned into much less costly synchronous sequential writes to the
log-structured file system’s logging area. Those changes, in turn, are replayed
asynchronously via random writes to the appropriate structures. The overall
result is a significant gain in performan ce of metadata-oriented operations,
such asfile creationand deletion,on HDDstorage.
14.7.3 Other Solutions
Another alternative to consistency checking is employed by Network Appli-
ance’sWAFLfile system and the Solaris ZFSfile system. These systems never
overwriteblockswithnewdata.Rather,atransactionwritesalldataandmeta-
data changes to new blocks. When the tra nsaction is complete, the metadata
structuresthatpointedtotheoldversionsoftheseblocksareupdatedtopoint
to the new blocks. The file system can then remove the old pointers and the
old blocks and make them available for reuse. If the old pointers and blocks
are kept, a snapshot is created; the snapshot is a view of the file system at a
specific point in time (before any updates after that time were applied). This
solution should require no consistency checking if the pointer update is done
atomically. WAFLdoes have a consistency checker, however, so some failure
scenarios can still cause metadata corruption. (See Section 14.8 for details of
theWAFLfilesystem.)
ZFStakesanevenmoreinnovativeapproachtodiskconsistency.Like WAFL,
itneveroverwritesblocks.However, ZFSgoesfurtherandprovideschecksum-
ming of all metadata and data blocks. This solution (when combined with
RAID) assures that data are always correct. ZFStherefore has no consistency
checker.(Moredetailson ZFSarefound inSection 11.8.6.)
14.7.4 Backup and Restore
Storagedevicessometimesfail,andcaremustbetakentoensurethatthedata
lost in such a failure are not lost forever. To this end, system programs can be
used to back up data from one storage device to another, such as a magnetic
tapeorothersecondarystoragedevice.Recoveryfromthelossofanindividual
file, or of an entire device, may then be a matter of restoring the data from
backup.
To minimize the copying needed, we can use information from each file’s
directory entry. For instance, if the backup program knows when the last"
2,14.8 Example: The WAFL File System,720,14.7 Recovery,"14.8 Example: The WAFL File System 589
backupofafilewasdone,andthefile’slas twritedateinthedirectoryindicates
that the file has not changed since that date, then the file does not need to be
copiedagain. Atypicalbackup schedule may then be as follows:
•Day 1.Copytoabackupmediumallfilesfromthefilesystem.Thisiscalled
afull backup .
•Day 2. Copy to another medium all files changed since day 1. This is an
incremental backup .
•Day 3. Copytoanother mediumallfileschanged since day2.
...
•Day N.Copytoanothermediumallfileschangedsinceday N−1.Thengo
back to day1.
Thenewcyclecanhaveitsbackupwrittenovertheprevioussetorontoanew
setof backup media.
Usingthismethod,wecanrestoreanentirefilesystembystartingrestores
withthefullbackupandcontinuingthrougheachoftheincrementalbackups.
Ofcourse,thelargerthevalueof N,thegreaterthenumberofmediathatmust
bereadforacompleterestore.Anaddedadvantageofthisbackupcycleisthat
we can restore any file accidentally deleted during the cycle by retrieving the
deletedfile fromthe backup of thepreviousday.
The length of the cycle is a compromise between the amount of backup
neededand the number of days coveredby a restore.To decrease the number
oftapesthatmustbereadtodoarestore,anoptionistoperformafullbackup
andtheneachdaybackupallfilesthathavechanged since thefullbackup. In
thisway,arestorecanbedoneviathemostrecentincrementalbackupandthe
full backup, with no other incremental backups needed. The trade-off is that
more files will be modified each day, so each successive incremental backup
involvesmorefilesand morebackup media.
Auser may notice that a particular file is missing or corrupted long after
the damage was done. For this reason, we usually plan to take a full backup
from time to time that will be saved “forever. ”It is a good idea to store these
permanent backups far away from the regular backups to protect against
hazard, such as a fire that destroys the computer and all the backups too. In
the TV show “Mr. Robot, ”hackers not only attacked the primary sources of
banks’ data but also their backup sites. Having multiple backup sites might
not bea bad ideaif yourdata areimportant.
14.8 Example: The WAFL File System
Becausesecondary-storage I/Ohassuchahugeimpactonsystemperformance,
file-systemdesignandimplementationcommandquitealotofattentionfrom
system designers. Some file systems are general purpose, in that they can
provide reasonable performance and functionality for a wide variety of file
sizes, file types, and I/Oloads. Others are optimized for specific tasks in an
attempt to provide better performance in those areas than general-purpose"
2,14.9 Summary,724,14.8 Example: The WAFL File System,"14.9 Summary 593
Finally,notethatthe ZFSfilesystemsupportssimilarlyefficientsnapshots,
clones, and replication, and those features are becoming more common in
variousfilesystemsastimegoesby.
14.9 Summary
•Mostfilesystemsresideonsecondarystorage,whichisdesignedtoholda
large amount of data permanently. The most common secondary-storage
mediumisthedisk,but theuseof NVMdevicesisincreasing.
•Storage devicesare segmentedinto partitions to control mediause and to
allowmultiple,possiblyvarying,filesystemsonasingledevice.Thesefile
systems are mounted onto a logical file system architecture to make them
availablefor use.
•File systems are often implemented in a layered or modular structure.
The lower levels deal with the physical properties of storage devices and
communicatingwiththem.Upperlevelsdealwithsymbolicfilenamesand
logical propertiesof files.
•Thevariousfileswithinafilesystemcanbeallocatedspaceonthestorage
device in three ways: through contigu ous, linked, or indexed allocation.
Contiguous allocation can suffer from external fragmentation. Direct
access is very inefficient with linked allocation. Indexed allocation may
require substantial overhead for its index block. These algorithms can
be optimized in many ways. Contiguous space can be enlarged through
extents to increase flexibility and to decrease external fragmentation.
Indexed allocation can be done in clusters of multiple blocks to increase
throughput and to reduce the number of index entries needed. Indexing
inlargeclustersissimilartocontiguous allocationwithextents.
•Free-space allocation methods also influence the efficiency of disk-space
use, the performance of the file system , and the reliability of secondary
storage. The methods used include bit vectors and linked lists. Optimiza-
tionsincludegrouping,counting,andthe FAT,whichplacesthelinkedlist
in one contiguous area.
•Directory-management routines must consider efficiency, performance,
and reliability. Ahash table is a commonly used method, as it is fast and
efficient.Unfortunately,damagetothetableorasystemcrashcanresultin
inconsistency betweenthe directory information and the disk’scontents.
•A consistency checker can be used to repair damaged file-system struc-
tures.Operating-systembackup toolsallowdatatobecopiedtomagnetic
tape or other storage devices, enabling the user to recover from data loss
or even entire device loss due to hardware failure, operating system bug,
or usererror.
•Due to the fundamental role that file systems play in system operation,
theirperformanceandreliabilityarecr ucial.Techniquessuchaslogstruc-
tures and caching help improve performance, while log structures and
RAIDimprove reliability.The WAFLfile system is an example of optimiza-
tion of performance to match a specific I/Oload."
2,Practice Exercises,725,14.9 Summary,"594 Chapter 14 File-System Implementation
Practice Exercises
14.1Consider a file currently consisting of 100 blocks. Assume that the
file-control block (and the index block, in the case of indexed alloca-
tion) is already in memory. Calculate how many disk I/Ooperations
are required for contiguous, linked, and indexed (single-level) alloca-
tion strategies, if, for one block, the following conditions hold. In the
contiguous-allocationcase,assumethatthereisnoroomtogrowatthe
beginning but there is room to grow at the end. Also assume that the
block information tobe addedis storedin memory.
a. The block isaddedatthe beginning.
b. Theblock isaddedinthe middle.
c. Theblock isaddedatthe end.
d. Theblock isremovedfrom thebeginning.
e. Theblock isremovedfrom themiddle.
f. Theblock isremovedfrom theend.
14.2Whymustthebitmapforfileallocationbekeptonmassstorage,rather
than inmainmemory?
14.3Consider a system that supports the strategies of contiguous, linked,
andindexedallocation.Whatcriteriashouldbeusedindecidingwhich
strategyisbestutilizedfor a particularfile?
14.4One problem with contiguous allocation is that the user must preallo-
cate enough space for each file. If the file grows to be larger than the
space allocated for it, special actions must be taken. One solution to
this problem is to define a file structure consisting of an initial con-
tiguous area of a specified size. If this area is filled, the operating sys-
tem automatically defines an overflow area that is linked to the initial
contiguous area. If the overflow area is filled, another overflow area
is allocated. Compare this implementation of a file with the standard
contiguous andlinkedimplementations.
14.5How do caches help improve performance? Why do systems not use
moreor largercaches iftheyareso useful?
14.6Whyisitadvantageoustotheuserforanoperatingsystemtodynami-
callyallocateitsinternaltables?Whatarethepenaltiestotheoperating
systemfordoing so?
Further Reading
The internals of the BSD UNIX system are covered in full in [McKusick et al.
(2015)].DetailsconcerningfilesystemsforLinuxcanbefoundin[Love(2010)].
The Google file system is described in [Ghemawat et al. (2003)]. FUSEcan be
found at http://fuse.sourceforge.net ."
2,Further Reading,725,Practice Exercises,"594 Chapter 14 File-System Implementation
Practice Exercises
14.1Consider a file currently consisting of 100 blocks. Assume that the
file-control block (and the index block, in the case of indexed alloca-
tion) is already in memory. Calculate how many disk I/Ooperations
are required for contiguous, linked, and indexed (single-level) alloca-
tion strategies, if, for one block, the following conditions hold. In the
contiguous-allocationcase,assumethatthereisnoroomtogrowatthe
beginning but there is room to grow at the end. Also assume that the
block information tobe addedis storedin memory.
a. The block isaddedatthe beginning.
b. Theblock isaddedinthe middle.
c. Theblock isaddedatthe end.
d. Theblock isremovedfrom thebeginning.
e. Theblock isremovedfrom themiddle.
f. Theblock isremovedfrom theend.
14.2Whymustthebitmapforfileallocationbekeptonmassstorage,rather
than inmainmemory?
14.3Consider a system that supports the strategies of contiguous, linked,
andindexedallocation.Whatcriteriashouldbeusedindecidingwhich
strategyisbestutilizedfor a particularfile?
14.4One problem with contiguous allocation is that the user must preallo-
cate enough space for each file. If the file grows to be larger than the
space allocated for it, special actions must be taken. One solution to
this problem is to define a file structure consisting of an initial con-
tiguous area of a specified size. If this area is filled, the operating sys-
tem automatically defines an overflow area that is linked to the initial
contiguous area. If the overflow area is filled, another overflow area
is allocated. Compare this implementation of a file with the standard
contiguous andlinkedimplementations.
14.5How do caches help improve performance? Why do systems not use
moreor largercaches iftheyareso useful?
14.6Whyisitadvantageoustotheuserforanoperatingsystemtodynami-
callyallocateitsinternaltables?Whatarethepenaltiestotheoperating
systemfordoing so?
Further Reading
The internals of the BSD UNIX system are covered in full in [McKusick et al.
(2015)].DetailsconcerningfilesystemsforLinuxcanbefoundin[Love(2010)].
The Google file system is described in [Ghemawat et al. (2003)]. FUSEcan be
found at http://fuse.sourceforge.net ."
2,Bibliography,726,Further Reading,"Further Reading 595
Log-structuredfileorganizationsforenhancingbothperformanceandcon-
sistency are discussed in [Rosenblum and Ousterhout (1991)], [Seltzer et al.
(1993)], and [Seltzer et al. (1995)]. Log-structured designs for networked file
systemsareproposedin[HartmanandOusterhout(1995)]and[Thekkathetal.
(1997)].
TheZFSsourcecodeforspacemapscanbefoundat http://src.opensolaris.o
rg/source/xref/onnv/onnv-gate/usr /src/uts/common/ fs/zfs/space
 map.c.
ZFSdocumentationcanbefoundat http://www.opensolaris.org/os/commu
nity/ZFS/docs .
TheNTFSfile systemis explainedin[Solomon(1998)], the Ext3file system
used in Linux is described in [Mauerer (2008)], and the WAFLfile system is
coveredin[Hitz etal.(1995)].
Bibliography
[Ghemawat et al. (2003)] S .G h e m a w a t ,H .G o b i o f f ,a n dS . - T .L e u n g , “The
Google File System ”,Proceedings of the ACM Symposium on Operating Systems
Principles (2003).
[Hartman and Ousterhout (1995)] J. H. Hartman and J. K. Ousterhout, “The
Zebra Striped Network File System ”,ACM Transactions on Computer Systems ,
Volume13,Number3 (1995), pages274–310.
[Hitz et al. (1995)] D .H i t z ,J .L a u ,a n dM .M a l c o l m , “File System Design for an
NFS File ServerAppliance ”,Technicalreport,NetApp(1995).
[Love (2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library(2010).
[Mauerer (2008)] W. Mauerer, Professional Linux Kernel Architecture , John Wiley
andSons (2008).
[McKusick et al. (2015)] M. K. McKusick, G. V. Neville-Neil, and R. N. M. Wat-
son,The Design and Implementation of the FreeBSD UNIX Operating System–Second
Edition, Pearson(2015).
[Rosenblum and Ousterhout (1991)] M.RosenblumandJ.K.Ousterhout, “The
Designand Implementationof a Log-StructuredFile System ”,Proceedings of the
ACM Symposium on Operating Systems Principles (1991), pages1–15.
[Seltzer et al. (1993)] M. I. Seltzer, K. Bostic, M. K . McKusick, and C. Staelin,
“AnImplementationofaLog-StructuredFileSystemforUNIX ”,USENIX Winter
(1993), pages307–326.
[Seltzer et al. (1995)] M. I. Seltzer, K. A. Smith, H. Balakrishnan, J. Chang,
S. McMains, and V. N. Padmanabhan, “File System Logging Versus Clustering:
APerformanceComparison ”,USENIX Winter (1995), pages 249–264.
[Solomon (1998)] D.A.Solomon, Inside Windows NT, SecondEdition,Microsoft
Press (1998)."
2,Chapter 14 Exercises,728,Bibliography,"Chapter 14 Exercises
14.7Consider a file system that uses a modified contiguous-allocation
scheme with support for extents. Afile is a collection of extents, with
each extent corresponding to a contiguous set of blocks. A key issue
in such systems is the degree of variability in the size of the extents.
Whataretheadvantagesanddisadvantagesofthefollowingschemes?
a. Allextentsareof thesame size,and thesizeispredetermined.
b. Extentscan be ofany size and are allocated dynamically.
c. Extents can be of a few fixed sizes, and these sizes are predeter-
mined.
14.8Contrast the performance of the three techniques for allocating disk
blocks (contiguous, linked, and ind exed) for both sequential and ran-
domfile access.
14.9What are the advantages of the variant of linked allocation that uses a
FATto chain togetherthe blocks of a file?
14.10Considera systemwherefreespace iskeptinafree-spacelist.
a. Suppose that the pointer to the free-space list is lost. Can the
systemreconstruct thefree-spacelist?Explainyour answer.
b. Consider a file system similar to the one used by UNIXwith
indexed allocation. How many disk I/Ooperations might be
required to read the contents of a small local file at /a/b/c?
Assumethat none ofthe diskblocks iscurrentlybeing cached.
c. Suggestaschemetoensurethatthepointerisneverlostasaresult
of memoryfailure.
14.11Some file systems allow disk storage to be allocated at different levels
of granularity. For instance, a file system could allocate 4 KBof disk
space as a single 4- KBblock or as eight 512-byte blocks. How could
we take advantage of this flexibility to improve performance? What
modifications would have to be made to the free-space management
schemeinordertosupportthis feature?
14.12Discusshowperformanceoptimizationsforfilesystemsmightresultin
difficulties in maintaining the consistency of the systems in the event
of computercrashes.
14.13Discuss the advantages and disadvantages of supporting links to files
thatcrossmountpoints(thatis,thefilelinkreferstoafilethatisstored
ina differentvolume).
14.14Consider a file system on a disk that has both logical and physical
block sizes of 512 bytes. Assume that the information about each file
is already in memory. For each of the three allocation strategies (con-
tiguous,linked,and indexed),answer thesequestions:EX-49"
1,Chapter 15 File-System Internals,730,Chapter 14 File-System Implementation,"15CHAPTER
File - System
Internals
As we saw in Chapter 13, the file system provides the mechanism for on-line
storageandaccesstofilecontents,includingdataandprograms.Thischapteris
primarilyconcernedwiththeinternalstructuresandoperationsoffilesystems.
We explore in detail ways to structure file use, to allocate storage space, to
recover freed space, to track the locations of data, and to interface other parts
ofthe operatingsystemtosecondary storage.
CHAPTER OBJECTIVES
•Delve into the details of file systems and their implementation.
•Explore booting and file sharing.
•Describe remote file systems, using NFSas an example.
15.1 File Systems
Certainly,nogeneral-purposecomputerstoresjustonefile.Therearetypically
thousands,millions,evenbillionsoffileswithinacomputer.Filesarestoredon
random-access storage devices, including hard disk drives, optical disks, and
nonvolatile memorydevices.
As you have seen in the preceding chapters, a general-purpose computer
system can have multiple storage devices, and those devices can be sliced up
intopartitions,whichholdvolumes,whichinturnholdfilesystems.Depend-
ing on the volume manager, a volume may span multiple partitions as well.
Figure15.1 shows a typicalfile-systemorganization.
Computer systems may also have varying numbers of file systems, and
thefilesystemsmaybeofvaryingtypes.Forexample,atypicalSolarissystem
may have dozens of file systems of a dozen different types, as shown in the
file-systemlistinFigure15.2.
In this book, we consider only general-purpose file systems. It is worth
noting,though,thattherearemanyspecial-purposefilesystems.Considerthe
typesof filesystemsintheSolarisexamplementionedabove:
597"
2,15.1 File Systems,730,Chapter 15 File-System Internals,"15CHAPTER
File - System
Internals
As we saw in Chapter 13, the file system provides the mechanism for on-line
storageandaccesstofilecontents,includingdataandprograms.Thischapteris
primarilyconcernedwiththeinternalstructuresandoperationsoffilesystems.
We explore in detail ways to structure file use, to allocate storage space, to
recover freed space, to track the locations of data, and to interface other parts
ofthe operatingsystemtosecondary storage.
CHAPTER OBJECTIVES
•Delve into the details of file systems and their implementation.
•Explore booting and file sharing.
•Describe remote file systems, using NFSas an example.
15.1 File Systems
Certainly,nogeneral-purposecomputerstoresjustonefile.Therearetypically
thousands,millions,evenbillionsoffileswithinacomputer.Filesarestoredon
random-access storage devices, including hard disk drives, optical disks, and
nonvolatile memorydevices.
As you have seen in the preceding chapters, a general-purpose computer
system can have multiple storage devices, and those devices can be sliced up
intopartitions,whichholdvolumes,whichinturnholdfilesystems.Depend-
ing on the volume manager, a volume may span multiple partitions as well.
Figure15.1 shows a typicalfile-systemorganization.
Computer systems may also have varying numbers of file systems, and
thefilesystemsmaybeofvaryingtypes.Forexample,atypicalSolarissystem
may have dozens of file systems of a dozen different types, as shown in the
file-systemlistinFigure15.2.
In this book, we consider only general-purpose file systems. It is worth
noting,though,thattherearemanyspecial-purposefilesystems.Considerthe
typesof filesystemsintheSolarisexamplementionedabove:
597"
2,15.2 File-System Mounting,731,15.1 File Systems,"598 Chapter 15 File-System Internals
Figure 15.1 A typical storage device organization.
•tmpfs—a “temporary ”filesystemthatiscreatedinvolatilemainmemory
and has itscontents erasedif thesystemrebootsor crashes
•objfs—a “virtual ”file system (essentially an interface to the kernel that
lookslikea filesystem)that givesdebuggersaccess to kernelsymbols
•ctfs—a virtual file system that maintains “contract ”information to man-
agewhichprocessesstartwhenthesystembootsandmustcontinuetorun
duringoperation
•lofs—a “loop back ”file system that allows one file system to be accessed
in placeof another one
•procfs—avirtualfilesystemthatpresentsinformationonallprocessesas
a filesystem
•ufs, zfs—general-purposefile systems
The file systems of computers, then, can be extensive. Even within a file
system,itis useful to segregatefiles into groups and manage and act on those
groups.This organizationinvolvestheuse ofdirectories(seeSection14.3).
15.2 File-System Mounting
Just as a file must be opened before it can be used, a file system must be
mountedbeforeitcanbeavailabletoprocessesonthesystem.Morespecifically,
the directory structure may be built out of multiple file-system-containing
volumes, which must be mounted to make them available within the file-
systemnamespace.
Themountprocedureisstraightforward.Theoperatingsystemisgiventhe
nameofthedeviceandthe mount point —thelocationwithinthefilestructure
where the file system is to be attached. Some operating systems require that a
file-system type be provided,while others inspect the structures of the device"
2,15.3 Partitions and Mounting,734,15.2 File-System Mounting,"15.3 Partitions and Mounting 601
with its drive letter. The path to a specific file takes the form drive-
letter: ∖path ∖to∖file. The more recent versions of Windows allow a file
system to be mounted anywhere in the directory tree, just as UNIXdoes.
Windows operating systems automatically discover all devices and mount
all located file systems at boot time. In some systems, like UNIX,t h em o u n t
commands are explicit. A system configuration file contains a list of devices
andmountpointsforautomaticmountingatboottime,butothermountsmay
beexecutedmanually.
Issues concerning file system mounting are further discussed in Section
15.3and inSectionC.7.5.
15.3 Partitions and Mounting
The layout of a disk can have many variations, depending on the operating
system and volume management software. Adisk can be sliced into multiple
partitions, or a volume can span multiple partitions on multiple disks. The
former layout is discussed here, while th e latter, which is more appropriately
consideredaform of RAID,iscoveredinSection11.8.
Each partition can be either “raw, ”containing no file system, or “cooked, ”
containingafilesystem. Raw disk isusedwherenofilesystemisappropriate.
UNIXswap space can use a raw partition, for example, since it uses its own
format on disk and does not use a file system. Likewise, some databases use
rawdiskandformatthedatatosuittheirneeds.Rawdiskcanalsoholdinfor-
mationneededbydisk RAIDsystems,suchasbitmapsindicatingwhichblocks
aremirroredandwhichhavechangedandneedtobemirrored.Similarly,raw
diskcancontainaminiaturedatabaseholding RAIDconfigurationinformation,
such as which disks are members of each RAIDset. Raw disk use is discussed
inSection11.5.1.
If a partition contains a file system that is bootable—that has a properly
installedandconfiguredoperatingsystem—thenthepartitionalsoneedsboot
information,asdescribedinSection11.5.2.Thisinformationhasitsownformat,
becauseatboottimethesystemdoesnothavethefile-systemcodeloadedand
therefore cannot interpret the file-system format. Rather, boot information is
usuallyasequentialseriesofblocksloadedasanimageintomemory.Execution
of the image starts at a predefined location, such as the first byte. This image,
thebootstrap loader ,in turn knows enough about the file-system structure to
be able tofind and load the kerneland startitexecuting.
The boot loader can contain more than the instructions for booting a spe-
cificoperatingsystem.Forinstance,manysystemscanbe dual-booted ,allow-
ing us to install multiple operating systems on a single system. How does
the system know which one to boot? A b oot loader that understands multi-
ple file systems and multiple operating systems can occupy the boot space.
Once loaded, it can boot one of the operating systems available on the drive.
The drive can have multiple partitions, each containing a different type of file
system and a differentoperating system. Note that if the boot loader does not
understandaparticularfile-systemformat,anoperatingsystemstoredonthat
filesystemisnotbootable.Thisisoneofthereasonsonlysomefilesystemsare
supportedasroot filesystemsfor any givenoperating system."
2,15.4 File Sharing,735,15.3 Partitions and Mounting,"602 Chapter 15 File-System Internals
The root partition selected by the boot loader, which contains the
operating-system kernel and sometimes other system files, is mounted at
boot time. Other volumes can be automatically mounted at boot or manually
mounted later, depending on the operating system. As part of a successful
mount operation, the operating system verifies that the device contains a
valid file system. It does so by asking the device driver to read the device
directory and verifying that the directory has the expected format. If the
formatisinvalid,thepartitionmusthaveitsconsistencycheckedandpossibly
corrected, either with or without user intervention. Finally, the operating
system notes in its in-memory mount table that a file system is mounted,
along with the type of the file system. The details of this function depend on
theoperating system.
Microsoft Windows–based systems mount each volume in a separate
name space, denoted by a letter and a colon, as mentioned earlier. To record
that a file system is mounted at F:, for example, the operating system places
a pointer to the file system in a field of the device structure corresponding to
F:. When a process specifies the driver letter, the operating system finds the
appropriate file-system pointer and traverses the directory structures on that
device to find the specified file or directory. Later versions of Windows can
mount a filesystemat any pointwithin theexistingdirectorystructure.
OnUNIX,filesystemscanbemountedatanydirectory.Mountingisimple-
mentedbysettingaflaginthein-memorycopyoftheinodeforthatdirectory.
The flag indicates that the directory is a mount point. A field then points to
an entry in the mount table, indicating which device is mounted there. The
mount table entry contains a pointe r to the superblock of the file system on
thatdevice.Thisschemeenablestheoperatingsystemtotraverseitsdirectory
structure,switching seamlesslyamong filesystemsof varyingtypes.
15.4 File Sharing
The ability to share files is very desirab le for users who want to collaborate
andtoreducetheeffortrequiredtoachieveacomputinggoal.Therefore,user-
orientedoperating systemsmust accommodate the needto share files in spite
of the inherent difficulties.
In this section, we examine more aspects of file sharing. We begin by
discussing general issues that arise when multiple users share files. Once
multiple users are allowed to share files, the challenge is to extend sharing to
multiplefilesystems,includingremotefilesystems;wediscussthatchallenge
aswell.Finally,we considerwhat todoabout conflicting actions occurring on
shared files. For instance, if multiple users are writing to a file, should all the
writes be allowed to occur, or should the operating system protect the users’
actions from one another?
15.4.1 Multiple Users
When an operating system accommodates multiple users, the issues of file
sharing,filenaming,andfileprotectionbecomepreeminent.Givenadirectory
structure that allows files to be shared by users, the system must mediate the
filesharing.Thesystemcaneitherallowausertoaccessthefilesofotherusers"
3,15.4.1 Multiple Users,735,15.4 File Sharing,"602 Chapter 15 File-System Internals
The root partition selected by the boot loader, which contains the
operating-system kernel and sometimes other system files, is mounted at
boot time. Other volumes can be automatically mounted at boot or manually
mounted later, depending on the operating system. As part of a successful
mount operation, the operating system verifies that the device contains a
valid file system. It does so by asking the device driver to read the device
directory and verifying that the directory has the expected format. If the
formatisinvalid,thepartitionmusthaveitsconsistencycheckedandpossibly
corrected, either with or without user intervention. Finally, the operating
system notes in its in-memory mount table that a file system is mounted,
along with the type of the file system. The details of this function depend on
theoperating system.
Microsoft Windows–based systems mount each volume in a separate
name space, denoted by a letter and a colon, as mentioned earlier. To record
that a file system is mounted at F:, for example, the operating system places
a pointer to the file system in a field of the device structure corresponding to
F:. When a process specifies the driver letter, the operating system finds the
appropriate file-system pointer and traverses the directory structures on that
device to find the specified file or directory. Later versions of Windows can
mount a filesystemat any pointwithin theexistingdirectorystructure.
OnUNIX,filesystemscanbemountedatanydirectory.Mountingisimple-
mentedbysettingaflaginthein-memorycopyoftheinodeforthatdirectory.
The flag indicates that the directory is a mount point. A field then points to
an entry in the mount table, indicating which device is mounted there. The
mount table entry contains a pointe r to the superblock of the file system on
thatdevice.Thisschemeenablestheoperatingsystemtotraverseitsdirectory
structure,switching seamlesslyamong filesystemsof varyingtypes.
15.4 File Sharing
The ability to share files is very desirab le for users who want to collaborate
andtoreducetheeffortrequiredtoachieveacomputinggoal.Therefore,user-
orientedoperating systemsmust accommodate the needto share files in spite
of the inherent difficulties.
In this section, we examine more aspects of file sharing. We begin by
discussing general issues that arise when multiple users share files. Once
multiple users are allowed to share files, the challenge is to extend sharing to
multiplefilesystems,includingremotefilesystems;wediscussthatchallenge
aswell.Finally,we considerwhat todoabout conflicting actions occurring on
shared files. For instance, if multiple users are writing to a file, should all the
writes be allowed to occur, or should the operating system protect the users’
actions from one another?
15.4.1 Multiple Users
When an operating system accommodates multiple users, the issues of file
sharing,filenaming,andfileprotectionbecomepreeminent.Givenadirectory
structure that allows files to be shared by users, the system must mediate the
filesharing.Thesystemcaneitherallowausertoaccessthefilesofotherusers"
2,15.5 Virtual File Systems,736,15.4 File Sharing,"15.5 Virtual File Systems 603
by defaultor requirethat a userspecifically grant access to the files.These are
theissuesof accesscontrol andprotection,which arecoveredinSection13.4.
To implement sharing and protection, the system must maintain more file
and directory attributes than are need ed on a single-user system. Although
manyapproacheshavebeentakentomeet thisrequirement,mostsystemshave
evolvedtousetheconceptsoffile(ordirectory) owner(oruser)and group.The
owneristheuserwhocanchangeattributesandgrantaccessandwhohasthe
most control over the file. The group attribute defines a subset of users who
can share access to the file. For example, the owner of a file on a UNIXsystem
canissuealloperationsonafile,whilemembersofthefile’sgroupcanexecute
one subset of those operations, and all other users can execute another subset
of operations. Exactly which operations can be executed by group members
andother usersisdefinableby the file’sowner.
The owner and group IDs of a given file (or directory) are stored with the
otherfileattributes.Whenauserrequestsanoperationonafile,theuser IDcan
becomparedwiththeownerattributetodetermineiftherequestinguseristhe
ownerofthefile.Likewise,thegroup IDscanbecompared.Theresultindicates
which permissions are applicable. The system then applies those permissions
tothe requestedoperationand allowsor deniesit.
Many systems have multiple local file systems, including volumes of a
single disk or multiple volumes on multiple attached disks. In these cases,
theIDchecking and permission matching are straightforward, once the file
systemsaremounted.Butconsideranexternaldiskthatcanbemovedbetween
systems.Whatifthe IDsonthesystemsaredifferent?Caremustbetakentobe
surethat IDsmatchbetweensystemswhendevicesmovebetweenthemorthat
file ownership is reset when such a move occurs. (For example, we can create
anewuser IDandsetallfilesontheportabledisktothat ID,tobesur enofiles
areaccidentallyaccessibleto existingusers.)
15.5 Virtual File Systems
Aswe’veseen,modernoperatingsystemsmustconcurrentlysupportmultiple
types of file systems. But how does an operating system allow multiple types
of file systems to be integrated into a directory structure? And how can users
seamlessly move between file-system types as they navigate the file-system
space?We now discuss someof theseimplementationdetails.
Anobviousbutsuboptimalmethodofimplementingmultipletypesoffile
systemsis to write directoryand file routines for each type.Instead, however,
mostoperatingsystems,including UNIX,useobject-orientedtechniquestosim-
plify,organize,andmodularizetheimplementation.Theuseofthesemethods
allows very dissimilar file-system types to be implemented within the same
structure, including network file systems, such as NFS. Users can access files
containedwithinmultiplefilesystemsonthelocaldriveorevenonfilesystems
availableacross the network.
Data structures and procedures are used to isolate the basic system-call
functionality from the implementation details. Thus, the file-system imple-
mentation consists of three major layers, as depicted schematically in Figure
15.5. The first layer is the file-system interface, based on the open(),read(),
write() ,and close() callsand onfiledescriptors."
2,15.6 Remote File Systems,738,15.5 Virtual File Systems,"15.6 Remote File Systems 605
•The inode object ,which representsanindividualfile
•The fil object ,which representsanopenfile
•The superblock object , which representsanentirefilesystem
•The dentry object , which representsan individualdirectoryentry
For each of these four object types, the VFSdefines a set of operations that
may be implemented. Every object of one of these types contains a pointer to
a function table. The function table lists the addresses of the actual functions
that implement the defined operations for that particular object. For example,
anabbreviated APIfor some of the operationsforthe file object includes:
•int open(. . .) —Openafile.
•int close(. . .) —Closean already-openfile.
•ssize
 t read(. . .) —Read fromafile.
•ssize
 t write(. . .) —Write toa file.
•int mmap(. . .) —Memory-map a file.
Animplementationofthefileobjectfora specificfiletypeisrequiredtoimple-
ment each function specified in the definition of the file object. (The complete
definition of the file object is specified in the file struct file
 operations ,
which islocatedin thefile /usr/include/linux/fs.h .)
Thus, the VFSsoftware layer can perform an operation on one of these
objects by calling the appropriate function from the object’s function table,
without having to know in advance exactly what kind of object it is dealing
with. The VFSdoes not know, or care, whether an inode represents a disk file,
adirectoryfile,oraremotefile.Theappropriatefunctionforthatfile’s read()
operation will always be at the same place in its function table, and the VFS
software layer will call that function without caring how the data are actually
read.
15.6 Remote File Systems
Withtheadventofnetworks(Chapter19),communicationamongremotecom-
puters became possible. Networking allows the sharing of resources spread
across a campus or even around the world. One obvious resource to share is
dataintheform of files.
Through the evolutionofnetwork and file technology, remote file-sharing
methods have changed. The first implemented method involves manually
transferring files between machines via programs like ftp. The second major
method uses a distributed fil system (DFS), in which remote directories are
visiblefromalocalmachine.Insomeways,thethirdmethod,the World Wide
Web, is a reversion to the first. A browser is needed to gain access to the
remote files, and separate operations (essentially a wrapper for ftp)a r eu s e d
totransferfiles.Increasingly,cloudcom puting(Section1.10.5)isbeingusedfor
file sharing as well."
3,15.6.1 The Client–Server Model,739,15.6 Remote File Systems,"606 Chapter 15 File-System Internals
ftpis used for both anonymous and authenticated access. Anonymous
accessallows a user to transfer files without having an account on the remote
system. The World Wide Web uses anonymous file exchange almost exclu-
sively.DFSinvolves a much tighter integration between the machine that is
accessingtheremotefilesandthemachineprovidingthefiles.Thisintegration
addscomplexity,aswe describeinthis section.
15.6.1 The Client–Server Model
Remotefilesystemsallowacomputertomountoneormorefilesystemsfrom
one or more remote machines. In this case, the machine containing the files
is the server, and the machine seeking access to the files is the client.T h e
client–server relationship is common w ith networked machines. Generally,
the server declares that a resource is available to clients and specifies exactly
which resource (in this case, which files) and exactly which clients. A server
canservemultipleclients,andaclientcanusemultipleservers,dependingon
theimplementationdetailsof a givenclient–serverfacility.
The server usually specifies the available files on a volume or directory
level. Client identification is more difficult. Aclient can be specified by a net-
worknameorotheridentifier,suchasan IPaddress,butthesecanbe spoofed,
or imitated. As a result of spoofing, an unauthorized client could be allowed
accesstotheserver.Moresecuresolutionsincludesecureauthenticationofthe
clientviaencryptedkeys.Unfortunately,withsecuritycomemanychallenges,
including ensuring compatibility of the client and server (they must use the
same encryption algorithms) and security of key exchanges (intercepted keys
could again allow unauthorized access). Because of the difficulty of solving
theseproblems,unsecure authentica tionmethodsaremost commonly used.
I nt h ec a s eo f UNIXand its network file system ( NFS), authentication takes
place via the client networking information, by default. In this scheme, the
user’sIDs on the client and server must match. If they do not, the server will
be unable to determine access rights to files. Consider the example of a user
who has an IDof 1000 on the client and 2000 on the server. A request from
the client to the server for a specific file will not be handled appropriately, as
the server will determine if user 1000 ha s access to the file rather than basing
thedeterminationontherealuser IDof2000.Accessisthusgrantedordenied
basedonincorrectauthenticationinformation.Theservermusttrusttheclient
topresentthecorrectuser ID.Notethatthe NFSprotocolsallowmany-to-many
relationships. That is, many servers can provide files to many clients. In fact,
a given machine can be both a server to some NFSclients and a client of other
NFSservers.
Once the remote file system is mounted, file operation requests are sent
on behalf of the user across the network to the server via the DFSprotocol.
Typically, a file-open request is sent along with the IDof the requesting user.
The server then applies the standard access checks to determine if the user
has credentials to access the file in the mode requested. The request is either
allowed or denied. If it is allowed, a file handle is returned to the client appli-
cation,andtheapplicationthencanperformread,write,andotheroperations
on the file. The client closes the file when access is completed. The operating
system may apply semantics similar to those for a local file-system mount or
may usedifferentsemantics."
3,15.6.2 Distributed Information Systems,740,15.6.1 The Client–Server Model,"15.6 Remote File Systems 607
15.6.2 Distributed Information Systems
Tomakeclient–serversystemseasiertomanage, distributed information sys-
tems,alsoknownas distributed naming services ,provideunifiedaccesstothe
information needed for remote computing. The domain name system (DNS)
provides host-name-to-network-address translations for the entire Internet.
BeforeDNSbecame widespread, files containing the same information were
sentviae-mailor ftpbetweenallnetworkedhosts.Obviously,thismethodol-
ogywas not scalable! DNSis furtherdiscussedinSection19.3.1.
Other distributed information systems provide user name/password/user
ID/group IDspace for a distributed facility. UNIXsystems have employed a
wide variety of distributed information methods. Sun Microsystems (now
partofOracleCorporation)introduced yellow pages (sincerenamed network
information service ,o r NIS), and most of the industry adopted its use. It
centralizesstorageofusernames,hostnames,printerinformation,andthelike.
Unfortunately, it uses unsecure authen tication methods, including sending
userpasswordsunencrypted(incleartext)andidentifyinghostsby IPaddress.
Sun’sNIS+ was a much more secure replacement for NISbut was much more
complicatedand was not widelyadopted.
I nt h ec a s eo fM i c r o s o f t ’ s common Internet file system (CIFS), network
information is used in conjunction with user authentication (user name and
password) to create a network login that the server uses to decide whether
to allow or deny access to a requested file system. For this authentication
to be valid, the user names must match from machine to machine (as with
NFS). Microsoft uses active directory as a distributed naming structure to
provide a single name space for users. Once established, the distributed
naming facility is used by all clients and servers to authenticate users
via Microsoft’s version of the Kerberos network authentication protocol
(https://web.mit.edu/kerberos/ ).
The industry is moving toward use of the lightweight directory-access
protocol (LDAP) as a secure distributed naming mechanism. In fact, active
directory is based on LDAP. Oracle Solaris and most other major operating
systems include LDAPand allow it to be employed for user authentication as
well as system-wide retrieval of information, such as availability of printers.
Conceivably,onedistributed LDAPdirectorycouldbeusedbyanorganization
tostorealluserandresourceinformationforalltheorganization’scomputers.
The result would be secure single sign-on for users, who would enter their
authenticationinformation once fora ccess toallcomputerswithintheorgani-
zation. It would also ease system-administration efforts by combining, in one
location,informationthatiscurrentlyscatteredinvariousfilesoneachsystem
orindifferentdistributedinformationservices.
15.6.3 Failure Modes
Local file systems can fail for a variety of reasons, including failure of the
drive containing the file system, corruption of the directory structure or other
disk-management information (collectively called metadata ), disk-controller
failure, cable failure, and host-adapter failure. User or system-administrator
failure can also cause files to be lost or entire directories or volumes to be
deleted.Manyofthesefailureswillcauseahosttocrashandanerrorcondition
tobedisplayed,andhumaninterventionmayberequiredtorepairthedamage."
3,15.6.3 Failure Modes,740,15.6.2 Distributed Information Systems,"15.6 Remote File Systems 607
15.6.2 Distributed Information Systems
Tomakeclient–serversystemseasiertomanage, distributed information sys-
tems,alsoknownas distributed naming services ,provideunifiedaccesstothe
information needed for remote computing. The domain name system (DNS)
provides host-name-to-network-address translations for the entire Internet.
BeforeDNSbecame widespread, files containing the same information were
sentviae-mailor ftpbetweenallnetworkedhosts.Obviously,thismethodol-
ogywas not scalable! DNSis furtherdiscussedinSection19.3.1.
Other distributed information systems provide user name/password/user
ID/group IDspace for a distributed facility. UNIXsystems have employed a
wide variety of distributed information methods. Sun Microsystems (now
partofOracleCorporation)introduced yellow pages (sincerenamed network
information service ,o r NIS), and most of the industry adopted its use. It
centralizesstorageofusernames,hostnames,printerinformation,andthelike.
Unfortunately, it uses unsecure authen tication methods, including sending
userpasswordsunencrypted(incleartext)andidentifyinghostsby IPaddress.
Sun’sNIS+ was a much more secure replacement for NISbut was much more
complicatedand was not widelyadopted.
I nt h ec a s eo fM i c r o s o f t ’ s common Internet file system (CIFS), network
information is used in conjunction with user authentication (user name and
password) to create a network login that the server uses to decide whether
to allow or deny access to a requested file system. For this authentication
to be valid, the user names must match from machine to machine (as with
NFS). Microsoft uses active directory as a distributed naming structure to
provide a single name space for users. Once established, the distributed
naming facility is used by all clients and servers to authenticate users
via Microsoft’s version of the Kerberos network authentication protocol
(https://web.mit.edu/kerberos/ ).
The industry is moving toward use of the lightweight directory-access
protocol (LDAP) as a secure distributed naming mechanism. In fact, active
directory is based on LDAP. Oracle Solaris and most other major operating
systems include LDAPand allow it to be employed for user authentication as
well as system-wide retrieval of information, such as availability of printers.
Conceivably,onedistributed LDAPdirectorycouldbeusedbyanorganization
tostorealluserandresourceinformationforalltheorganization’scomputers.
The result would be secure single sign-on for users, who would enter their
authenticationinformation once fora ccess toallcomputerswithintheorgani-
zation. It would also ease system-administration efforts by combining, in one
location,informationthatiscurrentlyscatteredinvariousfilesoneachsystem
orindifferentdistributedinformationservices.
15.6.3 Failure Modes
Local file systems can fail for a variety of reasons, including failure of the
drive containing the file system, corruption of the directory structure or other
disk-management information (collectively called metadata ), disk-controller
failure, cable failure, and host-adapter failure. User or system-administrator
failure can also cause files to be lost or entire directories or volumes to be
deleted.Manyofthesefailureswillcauseahosttocrashandanerrorcondition
tobedisplayed,andhumaninterventionmayberequiredtorepairthedamage."
2,15.7 Consistency Semantics,741,15.6 Remote File Systems,"608 Chapter 15 File-System Internals
Remote file systems have even more failure modes. Because of the
complexity of network systems and the requiredinteractions between remote
machines, many more problems can interfere with the proper operation of
remote file systems. In the case of networks, the network can be interrupted
between two hosts. Such interruptions can result from hardware failure, poor
hardware configuration, or networking implementation issues. Although
some networks have built-in resiliency, including multiple paths between
hosts, many do not. Any single failure can thus interrupt the flow of DFS
commands.
Consideraclientinthemidstofusingaremotefilesystem.Ithasfilesopen
from the remote host; among other activities, it may be performing directory
lookups to open files, reading or writing data to files, and closing files. Now
considerapartitioningofthenetwork,acrashoftheserver,orevenascheduled
shutdownoftheserver.Suddenly,theremotefilesystemisnolongerreachable.
This scenario is rather common, so it would not be appropriate for the client
systemtoactasitwouldifalocalfilesystemwerelost.Rather,thesystemcan
either terminate all operations to the l ost server or delay operations until the
serverisagainreachable.Thesefailuresemanticsaredefinedandimplemented
as part of the remote-file-system protocol. Termination of all operations can
result in users’ losing data—and patience. Thus, most DFSprotocols either
enforce or allow delaying of file-system operations to remote hosts, with the
hope that theremotehost willbecome availableagain.
To implementthis kind of recoveryfrom failure, some kind of state infor-
mationmaybemaintainedonboththeclientandtheserver.Ifbothserverand
client maintain knowledge of their curr ent activities and open files, then they
canseamlesslyrecoverfromafailure.Inthesituationwheretheservercrashes
but must recognize that it has remotely mounted exported file systems and
openedfiles, NFSVersion3 takesasimpleapproach, implementinga stateless
DFS.Inessence,itassumesthataclientrequestforafilereadorwritewouldnot
have occurred unless the file system ha d been remotely mounted and the file
hadbeenpreviouslyopen.The NFSprotocolcarriesalltheinformationneeded
to locate the appropriate file and perform the requested operation. Similarly,
it does not track which clients have the exported volumes mounted, again
assuming that if a request comes in, it must be legitimate. While this stateless
approach makes NFSresilient and rather easy to implement, it also makes it
unsecure. For example, forged read or write requests could be allowed by an
NFSserver. These issues are addressed in the industry standard NFSVersion
4, in which NFSis made stateful to improve its security, performance, and
functionality.
15.7 Consistency Semantics
Consistencysemanticsrepresentanimportantcriterionforevaluatinganyfile
systemthat supportsfilesharing. Thesesemanticsspecifyhow multipleusers
ofasystemaretoaccessasharedfilesimultaneously.Inparticular,theyspecify
whenmodificationsofdatabyoneuserw illbeobservablebyotherusers.These
semantics aretypicallyimplementedascodewiththe filesystem.
Consistency semantics are directly related to the process synchronization
algorithmsofChapter6.However,thecomplexalgorithmsofthatchaptertend"
3,15.7.1 UNIX Semantics,742,15.7 Consistency Semantics,"15.7 Consistency Semantics 609
nottobeimplementedinthecaseoffile I/Obecauseofthegreatlatenciesand
slowtransferratesofdisksandnetworks.For example,performinganatomic
transaction to a remote disk could involve several network communications,
several disk reads and writes, or both. Systems that attempt such a full set of
functionalitiestendtoperformpoorly.Asuccessfulimplementationofcomplex
sharing semanticscan be found in the Andrewfile system.
For the following discussion, we assume that a series of file accesses (that
is, reads and writes) attempted by a user to the same file is always enclosed
between the open()andclose() operations. The series of accesses between
theopen()andclose() operations makes up a fil session . To illustrate the
concept,we sketchseveralprominent examplesof consistency semantics.
15.7.1 UNIX Semantics
TheUNIXfilesystem(Chapter19) usesthefollowing consistency semantics:
•Writestoanopenfilebyauserarevisibleimmediatelytootheruserswho
have thisfile open.
•One mode of sharing allows users to share the pointer of current location
into the file. Thus, the advancing of the pointer by one user affects all
sharing users. Here, a file has a single image that interleaves all accesses,
regardlessoftheir origin.
In theUNIXsemantics, a file is associated with a single physical image that
is accessed as an exclusive resource. Contention for this single image causes
delaysinuserprocesses.
15.7.2 Session Semantics
TheAndrewfilesystem(Open AFS) usesthe following consistency semantics:
•Writes to an open file by a user are not visible immediately to other users
that have thesamefileopen.
•Onceafileisclosed,thechangesmadetoi tarevisibleonlyinsessionsstart-
ing later.Alreadyopeninstances of thefiledo not reflectthesechanges.
Accordingtothesesemantics,afilemaybeassociatedtemporarilywithseveral
(possibly different)images at the same time.Consequently,multipleusers are
allowedtoperformbothreadandwriteaccessesconcurrentlyontheirimages
of the file, without delay. Almost no constraints are enforced on scheduling
accesses.
15.7.3 Immutable-Shared-Files Semantics
A unique approach is that of immutable shared files. Once a file is declared
as shared by its creator, it cannot be modified. An immutable file has two key
properties: its name may not be reused, and its contents may not be altered.
Thus, the name of an immutable file signifies that the contents of the file are
fixed.Theimplementationofthesesemanticsinadistributedsystem(Chapter
19) issimple,becausethe sharing isdisciplined(read-only)."
3,15.7.2 Session Semantics,742,15.7.1 UNIX Semantics,"15.7 Consistency Semantics 609
nottobeimplementedinthecaseoffile I/Obecauseofthegreatlatenciesand
slowtransferratesofdisksandnetworks.For example,performinganatomic
transaction to a remote disk could involve several network communications,
several disk reads and writes, or both. Systems that attempt such a full set of
functionalitiestendtoperformpoorly.Asuccessfulimplementationofcomplex
sharing semanticscan be found in the Andrewfile system.
For the following discussion, we assume that a series of file accesses (that
is, reads and writes) attempted by a user to the same file is always enclosed
between the open()andclose() operations. The series of accesses between
theopen()andclose() operations makes up a fil session . To illustrate the
concept,we sketchseveralprominent examplesof consistency semantics.
15.7.1 UNIX Semantics
TheUNIXfilesystem(Chapter19) usesthefollowing consistency semantics:
•Writestoanopenfilebyauserarevisibleimmediatelytootheruserswho
have thisfile open.
•One mode of sharing allows users to share the pointer of current location
into the file. Thus, the advancing of the pointer by one user affects all
sharing users. Here, a file has a single image that interleaves all accesses,
regardlessoftheir origin.
In theUNIXsemantics, a file is associated with a single physical image that
is accessed as an exclusive resource. Contention for this single image causes
delaysinuserprocesses.
15.7.2 Session Semantics
TheAndrewfilesystem(Open AFS) usesthe following consistency semantics:
•Writes to an open file by a user are not visible immediately to other users
that have thesamefileopen.
•Onceafileisclosed,thechangesmadetoi tarevisibleonlyinsessionsstart-
ing later.Alreadyopeninstances of thefiledo not reflectthesechanges.
Accordingtothesesemantics,afilemaybeassociatedtemporarilywithseveral
(possibly different)images at the same time.Consequently,multipleusers are
allowedtoperformbothreadandwriteaccessesconcurrentlyontheirimages
of the file, without delay. Almost no constraints are enforced on scheduling
accesses.
15.7.3 Immutable-Shared-Files Semantics
A unique approach is that of immutable shared files. Once a file is declared
as shared by its creator, it cannot be modified. An immutable file has two key
properties: its name may not be reused, and its contents may not be altered.
Thus, the name of an immutable file signifies that the contents of the file are
fixed.Theimplementationofthesesemanticsinadistributedsystem(Chapter
19) issimple,becausethe sharing isdisciplined(read-only)."
3,15.7.3 Immutable-Shared-Files Semantics,742,15.7.2 Session Semantics,"15.7 Consistency Semantics 609
nottobeimplementedinthecaseoffile I/Obecauseofthegreatlatenciesand
slowtransferratesofdisksandnetworks.For example,performinganatomic
transaction to a remote disk could involve several network communications,
several disk reads and writes, or both. Systems that attempt such a full set of
functionalitiestendtoperformpoorly.Asuccessfulimplementationofcomplex
sharing semanticscan be found in the Andrewfile system.
For the following discussion, we assume that a series of file accesses (that
is, reads and writes) attempted by a user to the same file is always enclosed
between the open()andclose() operations. The series of accesses between
theopen()andclose() operations makes up a fil session . To illustrate the
concept,we sketchseveralprominent examplesof consistency semantics.
15.7.1 UNIX Semantics
TheUNIXfilesystem(Chapter19) usesthefollowing consistency semantics:
•Writestoanopenfilebyauserarevisibleimmediatelytootheruserswho
have thisfile open.
•One mode of sharing allows users to share the pointer of current location
into the file. Thus, the advancing of the pointer by one user affects all
sharing users. Here, a file has a single image that interleaves all accesses,
regardlessoftheir origin.
In theUNIXsemantics, a file is associated with a single physical image that
is accessed as an exclusive resource. Contention for this single image causes
delaysinuserprocesses.
15.7.2 Session Semantics
TheAndrewfilesystem(Open AFS) usesthe following consistency semantics:
•Writes to an open file by a user are not visible immediately to other users
that have thesamefileopen.
•Onceafileisclosed,thechangesmadetoi tarevisibleonlyinsessionsstart-
ing later.Alreadyopeninstances of thefiledo not reflectthesechanges.
Accordingtothesesemantics,afilemaybeassociatedtemporarilywithseveral
(possibly different)images at the same time.Consequently,multipleusers are
allowedtoperformbothreadandwriteaccessesconcurrentlyontheirimages
of the file, without delay. Almost no constraints are enforced on scheduling
accesses.
15.7.3 Immutable-Shared-Files Semantics
A unique approach is that of immutable shared files. Once a file is declared
as shared by its creator, it cannot be modified. An immutable file has two key
properties: its name may not be reused, and its contents may not be altered.
Thus, the name of an immutable file signifies that the contents of the file are
fixed.Theimplementationofthesesemanticsinadistributedsystem(Chapter
19) issimple,becausethe sharing isdisciplined(read-only)."
2,15.8 NFS,743,15.7 Consistency Semantics,"610 Chapter 15 File-System Internals
15.8 NFS
Network file systems are commonplace. They are typically integrated with
the overall directory structure and interface of the client system. NFSis a
good example of a widely used, well implemented client–server network file
system.Here,weuseitasanexampletoexploretheimplementationdetailsof
network filesystems.
NFSisbothanimplementationandaspecificationofasoftwaresystemfor
accessingremotefilesacross LANs(oreven WANs).NFSispartof ONC+,which
mostUNIXvendorsandsome PCoperatingsystemssupport.Theimplementa-
tiondescribedhereispartoftheSolarisoperatingsystem,whichisamodified
version of UNIX SVR4 . It uses either the TCPorUDP/IPprotocol (depending
ontheinterconnectingnetwork).Thespecificationandtheimplementationare
intertwined in our description of NFS. Whenever detail is needed, we refer to
the Solaris implementation; whenever the description is general, it applies to
the specification also.
There are multiple versions of NFS, with the latest being Version 4. Here,
we describeVersion3,which is theversionmostcommonly deployed.
15.8.1 Overview
NFSviews a set of interconnected workstations as a set of independent
machines with independent file systems. The goal is to allow some degree of
sharingamongthesefilesystems(onexplicitrequest)inatransparentmanner.
Sharingisbasedonaclient–serverrelationship.Amachinemaybe,andoften
is,bothaclientandaserver.Sharingisallowedbetweenanypairofmachines.
To ensure machine independence, shar ing of a remote file system affects only
the client machine and no other machine.
So that a remote directorywill be accessible in a transparent manner from
aparticularmachine—say,from M1—aclientofthatmachinemustfirstcarry
out a mount operation. The semantics of the operation involve mounting a
remote directory over a directory of a local file system. Once the mount oper-
ationiscompleted,themounteddirectorylookslikeanintegralsubtreeof the
localfilesystem,replacingthesubtreede scendingfromthelocaldirectory.The
local directory becomes the name of the root of the newly mounted directory.
Specification of the remote directory as an argument for the mount operation
is not done transparently; the location (or host name) of the remote directory
has to be provided. However, from then on, users on machine M1can access
filesintheremotedirectoryina totallytransparentmanner.
Toillustratefilemounting,considerthefilesystemdepictedinFigure15.6,
where the triangles represent subtrees of directories that are of interest. The
figure shows three independent file systems of machines named U,S1,a n d
S2. At this point, on each machine, only the local files can be accessed. Figure
15.7(a) shows the effects of mounting S1:/usr/shared over U:/usr/local .
This figure depicts the view users on Uhave of their file system. After the
mountiscomplete,theycanaccessanyfilewithinthe dir1directoryusingthe
prefix/ usr/local/dir1 .Theoriginaldirectory /usr/local onthatmachine
isno longervisible.
Subject to access-rights accreditation, any file system, or any directory
within a file system, can be mounted remotely on top of any local directory."
3,15.8.1 Overview,743,15.8 NFS,"610 Chapter 15 File-System Internals
15.8 NFS
Network file systems are commonplace. They are typically integrated with
the overall directory structure and interface of the client system. NFSis a
good example of a widely used, well implemented client–server network file
system.Here,weuseitasanexampletoexploretheimplementationdetailsof
network filesystems.
NFSisbothanimplementationandaspecificationofasoftwaresystemfor
accessingremotefilesacross LANs(oreven WANs).NFSispartof ONC+,which
mostUNIXvendorsandsome PCoperatingsystemssupport.Theimplementa-
tiondescribedhereispartoftheSolarisoperatingsystem,whichisamodified
version of UNIX SVR4 . It uses either the TCPorUDP/IPprotocol (depending
ontheinterconnectingnetwork).Thespecificationandtheimplementationare
intertwined in our description of NFS. Whenever detail is needed, we refer to
the Solaris implementation; whenever the description is general, it applies to
the specification also.
There are multiple versions of NFS, with the latest being Version 4. Here,
we describeVersion3,which is theversionmostcommonly deployed.
15.8.1 Overview
NFSviews a set of interconnected workstations as a set of independent
machines with independent file systems. The goal is to allow some degree of
sharingamongthesefilesystems(onexplicitrequest)inatransparentmanner.
Sharingisbasedonaclient–serverrelationship.Amachinemaybe,andoften
is,bothaclientandaserver.Sharingisallowedbetweenanypairofmachines.
To ensure machine independence, shar ing of a remote file system affects only
the client machine and no other machine.
So that a remote directorywill be accessible in a transparent manner from
aparticularmachine—say,from M1—aclientofthatmachinemustfirstcarry
out a mount operation. The semantics of the operation involve mounting a
remote directory over a directory of a local file system. Once the mount oper-
ationiscompleted,themounteddirectorylookslikeanintegralsubtreeof the
localfilesystem,replacingthesubtreede scendingfromthelocaldirectory.The
local directory becomes the name of the root of the newly mounted directory.
Specification of the remote directory as an argument for the mount operation
is not done transparently; the location (or host name) of the remote directory
has to be provided. However, from then on, users on machine M1can access
filesintheremotedirectoryina totallytransparentmanner.
Toillustratefilemounting,considerthefilesystemdepictedinFigure15.6,
where the triangles represent subtrees of directories that are of interest. The
figure shows three independent file systems of machines named U,S1,a n d
S2. At this point, on each machine, only the local files can be accessed. Figure
15.7(a) shows the effects of mounting S1:/usr/shared over U:/usr/local .
This figure depicts the view users on Uhave of their file system. After the
mountiscomplete,theycanaccessanyfilewithinthe dir1directoryusingthe
prefix/ usr/local/dir1 .Theoriginaldirectory /usr/local onthatmachine
isno longervisible.
Subject to access-rights accreditation, any file system, or any directory
within a file system, can be mounted remotely on top of any local directory."
3,15.8.2 The Mount Protocol,745,15.8.1 Overview,"612 Chapter 15 File-System Internals
NFSspecificationisindependentofthesemedia.Thisindependenceisachieved
through the use of RPCprimitives built on top of an external data representa-
tion(XDR)protocolusedbetweentwoimplementation-independentinterfaces.
Hence, if the system’s heterogeneous m achines and file systems are properly
interfaced to NFS, file systems of different types can be mounted both locally
and remotely.
TheNFSspecification distinguishes between the services provided by a
mountmechanismandtheactualremote-fi le-accessservices.Accordingly,two
separateprotocolsarespecifiedfortheseservices:amountprotocolandapro-
tocol for remote file accesses, the NFS protocol . The protocols are specified as
setsofRPCs.These RPCsarethebuildingblocksusedtoimplementtransparent
remotefile access.
15.8.2 The Mount Protocol
The mount protocol establishestheinitiallogicalconnectionbetweenaserver
and a client. In Solaris, each machine has a server process, outside the kernel,
performingthe protocol functions.
A mount operation includes the name of the remote directory to be
mounted and the name of the server machine storing it. The mount request
is mapped to the corresponding RPCand is forwarded to the mount server
running on the specific server machine. The server maintains an export
listthat specifies local file systems that it exports for mounting, along with
namesofmachinesthatarepermittedtomountthem.(InSolaris,thislististhe
/etc/dfs/dfstab ,whichcanbeeditedonlybyasuperuser.)Thespecification
can also include access rights, such as read only. To simplify the maintenance
of export lists and mount tables, a distributed naming scheme can be used to
hold thisinformationand makeitavailableto appropriateclients.
Recall that any directory within an exported file system can be mounted
remotely by an accredited machine. A component unit is such a directory.
When the server receives a mount request that conforms to its export list, it
returns to the client a file handle that serves as the key for further accesses to
files within the mounted file system. The file handle contains all the informa-
tion that the server needs to distinguish an individual file it stores. In UNIX
terms, the file handle consists of a file -system identifier and an inode number
to identifytheexact mounteddirec torywithin theexportedfilesystem.
Theserveralsomaintainsalistofthec lientmachinesandthecorrespond-
ing currently mounted directories. This list is used mainly for administrative
purposes—forinstance,fornotifyingallclientsthattheserverisgoingdown.
Onlythroughadditionanddeletionofentriesinthislistcantheserverstatebe
affected by the mount protocol.
Usually,asystemhasastaticmountingpreconfigurationthatisestablished
atboottime( /etc/vfstab inSolaris);however,thislayoutcanbemodified.In
addition to the actual mount procedure, the mount protocol includes several
other procedures, such as unmount and return export list.
15.8.3 The NFS Protocol
TheNFSprotocol provides a set of RPCs for remote file operations. The proce-
duressupport thefollowing operations:"
3,15.8.3 The NFS Protocol,745,15.8.2 The Mount Protocol,"612 Chapter 15 File-System Internals
NFSspecificationisindependentofthesemedia.Thisindependenceisachieved
through the use of RPCprimitives built on top of an external data representa-
tion(XDR)protocolusedbetweentwoimplementation-independentinterfaces.
Hence, if the system’s heterogeneous m achines and file systems are properly
interfaced to NFS, file systems of different types can be mounted both locally
and remotely.
TheNFSspecification distinguishes between the services provided by a
mountmechanismandtheactualremote-fi le-accessservices.Accordingly,two
separateprotocolsarespecifiedfortheseservices:amountprotocolandapro-
tocol for remote file accesses, the NFS protocol . The protocols are specified as
setsofRPCs.These RPCsarethebuildingblocksusedtoimplementtransparent
remotefile access.
15.8.2 The Mount Protocol
The mount protocol establishestheinitiallogicalconnectionbetweenaserver
and a client. In Solaris, each machine has a server process, outside the kernel,
performingthe protocol functions.
A mount operation includes the name of the remote directory to be
mounted and the name of the server machine storing it. The mount request
is mapped to the corresponding RPCand is forwarded to the mount server
running on the specific server machine. The server maintains an export
listthat specifies local file systems that it exports for mounting, along with
namesofmachinesthatarepermittedtomountthem.(InSolaris,thislististhe
/etc/dfs/dfstab ,whichcanbeeditedonlybyasuperuser.)Thespecification
can also include access rights, such as read only. To simplify the maintenance
of export lists and mount tables, a distributed naming scheme can be used to
hold thisinformationand makeitavailableto appropriateclients.
Recall that any directory within an exported file system can be mounted
remotely by an accredited machine. A component unit is such a directory.
When the server receives a mount request that conforms to its export list, it
returns to the client a file handle that serves as the key for further accesses to
files within the mounted file system. The file handle contains all the informa-
tion that the server needs to distinguish an individual file it stores. In UNIX
terms, the file handle consists of a file -system identifier and an inode number
to identifytheexact mounteddirec torywithin theexportedfilesystem.
Theserveralsomaintainsalistofthec lientmachinesandthecorrespond-
ing currently mounted directories. This list is used mainly for administrative
purposes—forinstance,fornotifyingallclientsthattheserverisgoingdown.
Onlythroughadditionanddeletionofentriesinthislistcantheserverstatebe
affected by the mount protocol.
Usually,asystemhasastaticmountingpreconfigurationthatisestablished
atboottime( /etc/vfstab inSolaris);however,thislayoutcanbemodified.In
addition to the actual mount procedure, the mount protocol includes several
other procedures, such as unmount and return export list.
15.8.3 The NFS Protocol
TheNFSprotocol provides a set of RPCs for remote file operations. The proce-
duressupport thefollowing operations:"
3,15.8.4 Path-Name Translation,747,15.8.3 The NFS Protocol,"614 Chapter 15 File-System Internals
disk disksystem-calls interfaceclient server
other types of
file systemsUNIX file
systemUNIX file
systemNFS
client
RPC/XDR
networkRPC/XDRNFS
serverVFS interface VFS interface
Figure 15.8 Schematic view of the NFS architecture.
NFSis integrated into the operating system via a VFS. As an illustration of
thearchitecture,let’stracehow anoperationonanalready-openremotefileis
handled (follow the example in Figure 15. 8). The client initiates the operation
with a regular system call. The operating-system layer maps this call to a VFS
operationontheappropriatevnode.The VFSlayeridentifiesthefileasaremote
one and invokes the appropriate NFSprocedure. An RPCcall is made to the
NFSservicelayerattheremoteserver.Thiscallisreinjectedtothe VFSlayeron
theremotesystem,whichfindsthatitislocalandinvokestheappropriatefile-
systemoperation.Thispathisretracedtoreturntheresult.Anadvantageofthis
architectureisthattheclientand theserverareidentical;thus,amachine may
be a client, or a server,or both. The actual serviceon each serveris performed
by kernelthreads.
15.8.4 Path-Name Translation
Path-name translation inNFSinvolves the parsing of a path name such as
/usr/local/dir1/file.txt into separate directory entries, or components:
(1)usr,( 2 ) local,a n d( 3 ) dir1. Path-name translation is done by breaking
the path into component names and performing a separate NFSlookup call
for every pair of component name and directory vnode. Once a mount point
is crossed, every component lookup causes a separate RPCto the server. This
expensive path-name-traversal scheme is needed, since the layout of each
client’s logical name space is unique, dictated by the mounts the client has
p e r f o r m e d .I tw o u l db em u c hm o r ee f fi c i e n tt oh a n das e r v e rap a t hn a m e
and receive a target vnode once a mount point is encountered. At any point,
however,theremightbeanothermountpointfortheparticularclientofwhich
thestatelessserverisunaware."
3,15.8.5 Remote Operations,748,15.8.4 Path-Name Translation,"15.9 Summary 615
So that lookup is fast, a directory-name-lookup cache on the client side
holdsthevnodesforremotedirectorynames.Thiscachespeedsupreferences
tofileswiththesameinitialpathname.Thedirectorycacheisdiscardedwhen
attributes returned from the server do not match the attributes of the cached
vnode.
Recall that some implementations of NFSallow mounting a remote file
system on top of another already-mounted remote file system (a cascading
mount). When a client has a cascading mount, more than one server can be
involved in a path-name traversal. However, when a client does a lookup on
a directory on which the server has mounted a file system, the client sees the
underlyingdirectoryinsteadofthe mounteddirectory.
15.8.5 Remote Operations
With the exception of opening and closing files, there is an almost one-to-one
correspondence between the regular UNIXsystem calls for file operations and
theNFSprotocol RPCs. Thus, a remote file operation can be translated directly
to the corresponding RPC. Conceptually, NFSadheres to the remote-service
paradigm;but in practice, buffering and caching techniques are employed for
the sake of performance. No direct correspondence exists between a remote
operation and an RPC. Instead, file blocks and file attributes are fetched by
theRPCsandarecachedlocally.Futureremoteoperationsusethecacheddata,
subjectto consistency constraints.
There are two caches: the file-attribut e (inode-information) cache and the
file-blocks cache. When a file is opened, the kernel checks with the remote
server to determine whether to fetch o r revalidate the cached attributes. The
cached file blocks are used only if the corresponding cached attributes are up
to date. The attribute cache is updated whenever new attributes arrive from
the server. Cached attributes are, by default, discarded after 60 seconds. Both
read-aheadanddelayed-writetechniquesareusedbetweentheserverandthe
client. Clients do not free delayed-write blocks until the server confirms that
the data have been writtento disk. Delayed-writeis retainedevenwhen a file
is opened concurrently, in conflicting modes. Hence, UNIXsemantics (Section
15.7.1)arenot preserved.
Tuning the system for performance makes it difficult to characterize the
consistency semantics of NFS. New files created on a machine may not be
visible elsewhere for 30 seconds. Furthermore, writes to a file at one site may
or may not be visible at other sites that have this file open for reading. New
opens of a file observe only the changes that have already been flushed to the
server. Thus, NFSprovides neither strict emulation of UNIXsemantics nor the
session semantics of Andrew (Section 15.7.2). In spite of these drawbacks, the
utilityandgoodperformanceofthemechanismmakeitthemostwidelyused
multi-vendor-distributedsysteminoperation.
15.9 Summary
•General-purposeoperatingsystemsprovidemanyfile-systemtypes,from
special-purposethrough general."
2,15.9 Summary,748,15.8 NFS,"15.9 Summary 615
So that lookup is fast, a directory-name-lookup cache on the client side
holdsthevnodesforremotedirectorynames.Thiscachespeedsupreferences
tofileswiththesameinitialpathname.Thedirectorycacheisdiscardedwhen
attributes returned from the server do not match the attributes of the cached
vnode.
Recall that some implementations of NFSallow mounting a remote file
system on top of another already-mounted remote file system (a cascading
mount). When a client has a cascading mount, more than one server can be
involved in a path-name traversal. However, when a client does a lookup on
a directory on which the server has mounted a file system, the client sees the
underlyingdirectoryinsteadofthe mounteddirectory.
15.8.5 Remote Operations
With the exception of opening and closing files, there is an almost one-to-one
correspondence between the regular UNIXsystem calls for file operations and
theNFSprotocol RPCs. Thus, a remote file operation can be translated directly
to the corresponding RPC. Conceptually, NFSadheres to the remote-service
paradigm;but in practice, buffering and caching techniques are employed for
the sake of performance. No direct correspondence exists between a remote
operation and an RPC. Instead, file blocks and file attributes are fetched by
theRPCsandarecachedlocally.Futureremoteoperationsusethecacheddata,
subjectto consistency constraints.
There are two caches: the file-attribut e (inode-information) cache and the
file-blocks cache. When a file is opened, the kernel checks with the remote
server to determine whether to fetch o r revalidate the cached attributes. The
cached file blocks are used only if the corresponding cached attributes are up
to date. The attribute cache is updated whenever new attributes arrive from
the server. Cached attributes are, by default, discarded after 60 seconds. Both
read-aheadanddelayed-writetechniquesareusedbetweentheserverandthe
client. Clients do not free delayed-write blocks until the server confirms that
the data have been writtento disk. Delayed-writeis retainedevenwhen a file
is opened concurrently, in conflicting modes. Hence, UNIXsemantics (Section
15.7.1)arenot preserved.
Tuning the system for performance makes it difficult to characterize the
consistency semantics of NFS. New files created on a machine may not be
visible elsewhere for 30 seconds. Furthermore, writes to a file at one site may
or may not be visible at other sites that have this file open for reading. New
opens of a file observe only the changes that have already been flushed to the
server. Thus, NFSprovides neither strict emulation of UNIXsemantics nor the
session semantics of Andrew (Section 15.7.2). In spite of these drawbacks, the
utilityandgoodperformanceofthemechanismmakeitthemostwidelyused
multi-vendor-distributedsysteminoperation.
15.9 Summary
•General-purposeoperatingsystemsprovidemanyfile-systemtypes,from
special-purposethrough general."
2,Practice Exercises,749,15.9 Summary,"616 Chapter 15 File-System Internals
•Volumescontaining file systemscan be mountedinto the computer’s file-
systemspace.
•Depending on the operating system, the file-system space is seamless
(mounted file systems integrated into the directory structure) or distinct
(each mountedfile systemhaving itsown designation).
•At least one file system must be bootable for the systemto be able to start
—thatis,itmustcontainanoperatingsystem.Thebootloaderisrunfirst;
itisasimpleprogramthatisabletofindthekernelinthefilesystem,load
it,andstartitsexecution.Systemscancontainmultiplebootablepartitions,
lettingthe administratorchoose which to runat boot time.
•Mostsystemsaremulti-userandthusmustprovideamethodforfileshar-
ing and file protection. Frequently, files and directories include metadata,
such as owner, user,and group access permissions.
•Massstoragepartitionsareusedeitherforrawblock I/Oorforfilesystems.
Each file system resides in a volume, which can be composed of one
partitionor multiplepartitionsworking togetherviaavolumemanager.
•To simplify implementation of multiple file systems, an operating system
can use a layered approach, with a virtual file-system interface making
access topossibly dissimilarfilesystemsseamless.
•Remotefilesystemscanbeimplementedsimplybyusingaprogramsuch
asftporthewebserversandclientsintheWorldWideWeb,orwithmore
functionalityviaaclient–servermodel.Mountrequestsanduser IDsmust
beauthenticated topreventunapprovedaccess.
•Client–serverfacilitiesdonotnativelyshareinformation,butadistributed
information system such as DNSc a nb eu s e dt oa l l o ws u c hs h a r i n g ,p r o -
viding a unified user name space, password management, and system
identification. For example, Microsoft CIFSuses active directory, which
employsaversionoftheKerberosnetworkauthenticationprotocoltopro-
videafullsetofnamingandauthenticationservicesamongthecomputers
inanetwork.
•Once file sharing is possible, a consistency semantics model must be cho-
senandimplementedtomoderatemultipleconcurrent accesstothesame
file. Semantics models include UNIX, session, and immutable-shared-files
semantics.
•NFSis an example of a remote file system, providing clients with seam-
lessaccesstodirectories,files,andevenentirefilesystems.Afull-featured
remotefilesystemincludesacommunicationprotocolwithremoteopera-
tions and path-name translation.
Practice Exercises
15.1Explainhowthe VFSlayerallowsanoperatingsystemtosupportmul-
tipletypesof filesystemseasily.
15.2Why have morethanone filesystemtypeon agivensystem?"
2,Further Reading,750,Practice Exercises,"Bibliography 617
15.3On a Unix or Linux system that implements the procfs file system,
determine how to use the procfs interface to explore the process name
space.Whataspectsofprocessescanbeviewedviathisinterface?How
wouldthesameinformationbegatheredonasystemlackingtheprocfs
file system?
15.4Whydosomesystemsintegratemountedfilesystemsintotherootfile
system naming structure, while others use a separate naming method
for mountedfile systems?
15.5Given a remote file access facility such as ftp, why were remote file
systemslike NFScreated?
Further Reading
The internals of the BSD UNIX system are covered in full in [McKusick et al.
(2015)].DetailsconcerningfilesystemsforLinuxcanbefoundin[Love(2010)].
The network file system ( NFS) is discussed in [Callaghan (2000)]. NFSVer-
sion 4 is a standard described at http://www.ietf.org/rfc/rfc3530.txt .[ O u s t e r -
hout (1991)] discusses the role of distributed state in networked file systems.
NFSand the UNIXfile system ( UFS) are described in [Mauro and McDougall
(2007)].
The Kerberos network authentication protocol is explored in
https://web.mit.edu/kerberos/ .
Bibliography
[Callaghan (2000)] B. Callaghan, NFS Illustrated , Addison-Wesley (2000).
[Love (2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library(2010).
[Mauro and McDougall (2007)] J. Mauro and R. McDougall, Solaris Internals:
Core Kernel Architecture ,PrenticeHall (2007).
[McKusick et al. (2015)] M. K. McKusick, G. V. Neville-Neil, and R. N. M. Wat-
son, The Design and Implementation of the FreeBSD UNIX Operating System–Second
Edition, Pearson(2015).
[Ousterhout (1991)] J. Ousterhout. “The Role of Distributed State ”.In CMU
Computer Science: a 25th Anniversary Commemorative ,R.F.Rashid,Ed.,Addison-
Wesley(1991)."
2,Bibliography,750,Further Reading,"Bibliography 617
15.3On a Unix or Linux system that implements the procfs file system,
determine how to use the procfs interface to explore the process name
space.Whataspectsofprocessescanbeviewedviathisinterface?How
wouldthesameinformationbegatheredonasystemlackingtheprocfs
file system?
15.4Whydosomesystemsintegratemountedfilesystemsintotherootfile
system naming structure, while others use a separate naming method
for mountedfile systems?
15.5Given a remote file access facility such as ftp, why were remote file
systemslike NFScreated?
Further Reading
The internals of the BSD UNIX system are covered in full in [McKusick et al.
(2015)].DetailsconcerningfilesystemsforLinuxcanbefoundin[Love(2010)].
The network file system ( NFS) is discussed in [Callaghan (2000)]. NFSVer-
sion 4 is a standard described at http://www.ietf.org/rfc/rfc3530.txt .[ O u s t e r -
hout (1991)] discusses the role of distributed state in networked file systems.
NFSand the UNIXfile system ( UFS) are described in [Mauro and McDougall
(2007)].
The Kerberos network authentication protocol is explored in
https://web.mit.edu/kerberos/ .
Bibliography
[Callaghan (2000)] B. Callaghan, NFS Illustrated , Addison-Wesley (2000).
[Love (2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library(2010).
[Mauro and McDougall (2007)] J. Mauro and R. McDougall, Solaris Internals:
Core Kernel Architecture ,PrenticeHall (2007).
[McKusick et al. (2015)] M. K. McKusick, G. V. Neville-Neil, and R. N. M. Wat-
son, The Design and Implementation of the FreeBSD UNIX Operating System–Second
Edition, Pearson(2015).
[Ousterhout (1991)] J. Ousterhout. “The Role of Distributed State ”.In CMU
Computer Science: a 25th Anniversary Commemorative ,R.F.Rashid,Ed.,Addison-
Wesley(1991)."
2,Chapter 15 Exercises,751,Bibliography,"Chapter 15 Exercises
15.6Assume that in a particular augmentation of a remote-file-access pro-
tocol,eachclientmaintainsanamecache thatcachestranslationsfrom
file names to corresponding file handles. What issues should we take
into account in implementingthe name cache?
15.7Given a mounted file system with write operations underway, and a
system crash or power loss, what must be done before the file system
is remounted if: (a) The file system is not log-structured? (b) The file
systemislog-structured?
15.8Whydooperatingsystemsmounttherootfilesystemautomaticallyat
boot time?
15.9Why do operating systems require file systems other than root to be
mounted?EX-51"
0,PART SEVEN SECURITY AND PROTECTION,753,PART SIX FILE SYSTEM,"Part Seven
Security and
Protection
Security ensures the authenticati on of system users to protect the
integrity of the information stored in the system (both data and code),
as well as the physical resources o f the computer system. The security
system prevents unauthorized access, ma licious destruction or alteration
of data, and accidental introduction of inconsistency.
Protection mechanisms control access to a system by limiting the
types of ﬁle access permitted to users. In addition, protection must ensure
that only processes that have gained proper authorization from the oper-
ating system can operate on memory segments, the CPU , and other
resources.
Protection is provided by a mechanism that controls the access of
programs, processes, or users to the resources deﬁned by a computer
system. This mechanism must provid e a means for specifying the con-
trols to be imposed, together with a means of enforcing them."
1,Chapter 16 Security,755,PART SEVEN SECURITY AND PROTECTION,"16CHAPTER
Security
Both protection and security are vital to computer systems. We distinguish
betweenthesetwoconceptsinthefollowingway:Securityisameasureofcon-
fidencethattheintegrityofasystemanditsdatawillbepreserved.Protection
is the set of mechanisms that control the access of processes and users to the
resources defined by a computer system. We focus on security in this chapter
andaddressprotectioninChapter17.
Security involves guarding computer resources against unauthorized
access, malicious destruction or alter ation, and accidental introduction of
inconsistency. Computer resources include the information stored in the
system (both data and code), as well as the CPU, memory, secondary storage,
tertiary storage, and networking tha t compose the computer facility. In this
chapter, we start by examining ways in which resources may be accidentally
orpurposelymisused.Wethenexploreakeysecurityenabler—cryptography.
Finally,we lookat mechanisms to guardagainstor detectattacks.
CHAPTER OBJECTIVES
•Discuss security threats and attacks.
•Explain the fundamentals of encryption, authentication, and hashing.
•Examine the uses of cryptography in computing.
•Describe various countermeasures to security attacks.
16.1 The Security Problem
In many applications, ensuring the security of the computer system is worth
considerable effort. Large commercial systems containing payroll or other
financialdataareinvitingtargetstothieves.Systemsthatcontaindatapertain-
ing to corporate operations may be of interest to unscrupulous competitors.
Furthermore, loss of such data, whether by accident or fraud, can seriously
impairtheabilityofthecorporationtofunction.Evenrawcomputingresources
areattractivetoattackersforbitcoinmining,forsendingspam,andasasource
fromwhich to anonymously attack other systems.
621"
2,16.1 The Security Problem,755,Chapter 16 Security,"16CHAPTER
Security
Both protection and security are vital to computer systems. We distinguish
betweenthesetwoconceptsinthefollowingway:Securityisameasureofcon-
fidencethattheintegrityofasystemanditsdatawillbepreserved.Protection
is the set of mechanisms that control the access of processes and users to the
resources defined by a computer system. We focus on security in this chapter
andaddressprotectioninChapter17.
Security involves guarding computer resources against unauthorized
access, malicious destruction or alter ation, and accidental introduction of
inconsistency. Computer resources include the information stored in the
system (both data and code), as well as the CPU, memory, secondary storage,
tertiary storage, and networking tha t compose the computer facility. In this
chapter, we start by examining ways in which resources may be accidentally
orpurposelymisused.Wethenexploreakeysecurityenabler—cryptography.
Finally,we lookat mechanisms to guardagainstor detectattacks.
CHAPTER OBJECTIVES
•Discuss security threats and attacks.
•Explain the fundamentals of encryption, authentication, and hashing.
•Examine the uses of cryptography in computing.
•Describe various countermeasures to security attacks.
16.1 The Security Problem
In many applications, ensuring the security of the computer system is worth
considerable effort. Large commercial systems containing payroll or other
financialdataareinvitingtargetstothieves.Systemsthatcontaindatapertain-
ing to corporate operations may be of interest to unscrupulous competitors.
Furthermore, loss of such data, whether by accident or fraud, can seriously
impairtheabilityofthecorporationtofunction.Evenrawcomputingresources
areattractivetoattackersforbitcoinmining,forsendingspam,andasasource
fromwhich to anonymously attack other systems.
621"
2,16.2 Program Threats,759,16.1 The Security Problem,"16.2 Program Threats 625
protection cannot be secure. New hardware features are allowing systems to
bemademoresecure,as weshall discuss.
Unfortunately, little in security is straightforward. As intruders exploit
security vulnerabilities, security countermeasures are created and deployed.
Thiscausesintruderstobecomemoresophisticatedintheirattacks.Forexam-
ple, spyware can provide a conduit for spam through innocent systems (we
discussthispracticeinSection16.2),whichinturncandeliverphishingattacks
to other targets. This cat-and-mouse game is likely to continue, with more
securitytoolsneededtoblocktheescalati ngintrudertechniquesandactivities.
In the remainder of this chapter, we address security at the network and
operating-system levels. Security at th e application, physical and human lev-
els, although important, is for the most part beyond the scope of this text.
Securitywithintheoperatingsystemandbetweenoperatingsystemsisimple-
mented in several ways, ranging from passwords for authentication through
guarding against viruses to detecting intrusions. We start with an exploration
ofsecuritythreats.
16.2 Program Threats
Processes, along with the kernel, are the only means of accomplishing work
on a computer. Therefore, writing a program that creates a breach of security,
or causing a normal process to change its behavior and create a breach, is a
commongoalofattackers.Infact,evenmostnonprogramsecurityeventshave
astheirgoalcausingaprogramthreat.Forexample,whileitisusefultologin
toa systemwithout authorization, it isquitea lotmore usefulto leavebehind
a back-door daemon or Remote Access Tool (RAT) that provides information
or allows easyaccess evenif the originalexploitis blocked.Inthis section,we
describe common methods by which programs cause security breaches. Note
thatthereisconsiderablevariationinth enamingconventionsforsecurityholes
andthat we usethemost common ordescriptiveterms.
16.2.1 Malware
Malware issoftwaredesignedtoexploit,disableordamagecomputersystems.
There are many ways to perform such activities, and we explore the major
variationsin thissection.
Many systems have mechanisms for allowing programs written by a user
tobeexecutedbyotherusers.Iftheseprogramsareexecutedinadomainthat
provides the access rights of the executing user, the other users may misuse
these rights. Aprogram that acts in a clandestine or malicious manner, rather
thansimplyperformingitsstatedfunction,iscalleda Trojan horse .Ifthepr o-
gramisexecutedinanotherdomain,itcanescalateprivileges.Asanexample,
consider a mobile app that purports to provide some benign functionality—
say, a flashlight app—but that meanwhile surreptitiously accesses the user’s
contacts or messagesandsmugglesthemto someremoteserver.
A classic variation of the Trojan horse is a “Trojan mule ”program that
emulates a login program. An unsuspecting user starts to log in at a terminal,
computer, or web page and notices that she has apparently mistyped her"
3,16.2.1 Malware,759,16.2 Program Threats,"16.2 Program Threats 625
protection cannot be secure. New hardware features are allowing systems to
bemademoresecure,as weshall discuss.
Unfortunately, little in security is straightforward. As intruders exploit
security vulnerabilities, security countermeasures are created and deployed.
Thiscausesintruderstobecomemoresophisticatedintheirattacks.Forexam-
ple, spyware can provide a conduit for spam through innocent systems (we
discussthispracticeinSection16.2),whichinturncandeliverphishingattacks
to other targets. This cat-and-mouse game is likely to continue, with more
securitytoolsneededtoblocktheescalati ngintrudertechniquesandactivities.
In the remainder of this chapter, we address security at the network and
operating-system levels. Security at th e application, physical and human lev-
els, although important, is for the most part beyond the scope of this text.
Securitywithintheoperatingsystemandbetweenoperatingsystemsisimple-
mented in several ways, ranging from passwords for authentication through
guarding against viruses to detecting intrusions. We start with an exploration
ofsecuritythreats.
16.2 Program Threats
Processes, along with the kernel, are the only means of accomplishing work
on a computer. Therefore, writing a program that creates a breach of security,
or causing a normal process to change its behavior and create a breach, is a
commongoalofattackers.Infact,evenmostnonprogramsecurityeventshave
astheirgoalcausingaprogramthreat.Forexample,whileitisusefultologin
toa systemwithout authorization, it isquitea lotmore usefulto leavebehind
a back-door daemon or Remote Access Tool (RAT) that provides information
or allows easyaccess evenif the originalexploitis blocked.Inthis section,we
describe common methods by which programs cause security breaches. Note
thatthereisconsiderablevariationinth enamingconventionsforsecurityholes
andthat we usethemost common ordescriptiveterms.
16.2.1 Malware
Malware issoftwaredesignedtoexploit,disableordamagecomputersystems.
There are many ways to perform such activities, and we explore the major
variationsin thissection.
Many systems have mechanisms for allowing programs written by a user
tobeexecutedbyotherusers.Iftheseprogramsareexecutedinadomainthat
provides the access rights of the executing user, the other users may misuse
these rights. Aprogram that acts in a clandestine or malicious manner, rather
thansimplyperformingitsstatedfunction,iscalleda Trojan horse .Ifthepr o-
gramisexecutedinanotherdomain,itcanescalateprivileges.Asanexample,
consider a mobile app that purports to provide some benign functionality—
say, a flashlight app—but that meanwhile surreptitiously accesses the user’s
contacts or messagesandsmugglesthemto someremoteserver.
A classic variation of the Trojan horse is a “Trojan mule ”program that
emulates a login program. An unsuspecting user starts to log in at a terminal,
computer, or web page and notices that she has apparently mistyped her"
3,16.2.2 Code Injection,762,16.2.1 Malware,"628 Chapter 16 Security
#include <stdio.h >
#define BUFFER
 SIZE 0
int main(int argc, char *argv[])
{
int j = 0;
char buffer[BUFFER
 SIZE];
int k = 0;
if (argc < 2) {return -1; }
strcpy(buffer,argv[1]);
printf(""K is %d, J is %d, buffer is %s ∖n"", j,k,buffer);
return 0;
}
}
Figure 16.2 C program with buffer-overflow condition.
code-scanning tools designed to find flaws, including security flaws, but gen-
erallygoodprogrammersarethebestcodereviewers.
For those not involved in developing the code, code review is useful for
finding and reporting flaws (or for finding and exploiting them). For most
software, source code is not available, making code review much harder for
nondevelopers.
16.2.2 Code Injection
Most software is not malicious, but it can nonetheless pose serious threats to
security due to a code-injection attack , in which executable code is added
or modified. Even otherwise benign sof tware can harbor vulnerabilities that,
if exploited, allow an attacker to take over the program code, subverting its
existingcode flow or entirelyreprogrammingit by supplyingnewcode.
Code-injection attacks are nearly always the result of poor or insecure
programming paradigms, commonly in low-level languages such as C or
C++, which allow direct memory access through pointers. This direct mem-
ory access, coupled with the need to carefully decide on sizes of memory
buffersandtakecarenottoexceedthem,canleadtomemorycorruptionwhen
memorybuffersarenot properlyhandled.
Asanexample,considerthesimplestcode-injectionvector—abufferover-
flow.TheprograminFigure16.2illustratessuchanoverflow,whichoccursdue
to an unbounded copy operation, the call to strcpy() . The function copies
with no regard to the buffer size in question, halting only when a NULL(∖0)
byte is encountered. If such a byte occurs before the BUFFER
 SIZEis reached,
the program behaves as expected. But the copy could easily exceed the buffer
size—what then?
The answer is that the outcome of an overflow depends largely on the
lengthoftheoverflowandtheoverflowingcontents(Figure16.3).Italsovaries
greatly with the code generated by t he compiler, which may be optimized"
3,16.2.3 Viruses and Worms,765,16.2.2 Code Injection,"16.2 Program Threats 631
There are, in fact, shellcode compilers (the “MetaSploit ”project being a
notable example), which also take care of such specifics as ensuring that the
code is compact and contains no NULLbytes (in case of exploitationvia string
copy, which would terminate on NULLs). Such a compiler may even mask the
shellcodeas alphanumeric characters.
If the attacker has managed to overwrite the return address (or any func-
tion pointer, such as that of a VTable), then all it takes (in the simple case) is
to redirect the address to point to the supplied shellcode, which is commonly
loaded as part of the user input, through an environment variable, or over
somefileornetworkinput.Assumingnomitigationsexist(asdescribedlater),
this is enough for the shellcode to exe cute and the hacker to succeed in the
attack. Alignment considerations are often handled by adding a sequence of
NOPinstructions before the shellcode. The result is known as a NOP-sled, as
it causes execution to “slide ”down the NOPinstructions until the payload is
encounteredand executed.
This exampleof a buffer-overflow attack revealsthat considerable knowl-
edge and programming skill are needed to recognize exploitable code and
thentoexploitit.Unfortunately,itdoesnottakegreatprogrammerstolaunch
security attacks. Rather, one hacker can determine the bug and then write an
exploit.Anyonewithrudimentarycomputerskillsandaccesstotheexploit—
aso-called script kiddie —can then tryto launch the attack attargetsystems.
The buffer-overflow attack is especially pernicious because it can be run
between systems and can travel over allowed communication channels. Such
attackscanoccurwithinprotocolsthatareexpectedtobeusedtocommunicate
withthetargetmachine,andtheycanthereforebehardtodetectandprevent.
Theycan evenbypass thesecurityaddedby firewalls(Section16.6.6).
Note that buffer overflows are just one of several vectors which can be
manipulated for code injection. Overflows can also be exploited when they
occur in the heap. Using memory buffers after freeing them, as well as over-
freeingthem(calling free()twice),can also leadto codeinjection.
16.2.3 Viruses and Worms
Anotherformofprogramthreatisa virus.Avirusisafragmentofcodeembed-
ded in a legitimate program. Viruses are self-replicating and are designed to
“infect ”other programs. They can wreak havoc in a system by modifying or
destroying files and causing system crashes and program malfunctions. As
with most penetration attacks (direct attacks on a system), viruses are very
specifictoarchitectures,operatingsystems,andapplications.Virusesareapar-
ticular problem for users of PCs.UNIXand other multiuser operating systems
generally are not susceptible to viruses because the executable programs are
protected from writing by the operating system. Even if a virus does infect
such a program, its powers usually are limited because other aspects of the
systemareprotected.
Viruses are usually borne via spam e- mail and phishing attacks. They can
also spread when users download viral programs from Internet file-sharing
servicesorexchangeinfecteddisks.Adistinctioncanbemadebetweenviruses,
which require human activity, and worms, which use a network to replicate
without any helpfrom humans."
2,16.3 System and Network Threats,768,16.2 Program Threats,"634 Chapter 16 Security
•Multipartite .Avirusofthistypeisabletoinfectmultiplepartsofasystem,
including boot sectors, memory, and files. This makes it difficult to detect
and contain.
•Armored .Anarmoredvirusisobfuscated—thatis,writtensoastobehard
for antivirus researchers to unravel and understand. It can also be com-
pressed to avoid detection and disinfection. In addition, virus droppers
andotherfullfilesthatarepartofavirusinfestationarefrequentlyhidden
viafileattributesor unviewablefilenames.
This vast variety of viruses has continued to grow. For example, in 2004 a
widespread virus was detected. It exploited three separate bugs for its oper-
ation. This virus started by infecting h undreds of Windows servers (includ-
ing many trusted sites) running Microsoft Internet Information Server ( IIS).
Any vulnerable Microsoft Explorer web browser visiting those sites received
a browser virus with any download. The browser virus installed several
back-door programs, including a keystroke logger , which records everything
entered on the keyboard (including passwords and credit-card numbers). It
also installed a daemon to allow unlimited remote access by an intruder and
another that allowed an intruder to route spam through the infected desktop
computer.
An active security-related debate within the computing community con-
cerns the existence of a monoculture , in which many systems run the same
hardware,operatingsystem,andapplicationsoftware.Thismonoculturesup-
posedlyconsistsofMicrosoftproducts.Onequestioniswhethersuchamono-
culture even exists today. Another question is whether, if it does, it increases
thethreatofanddamagecausedbyvirusesandothersecurityintrusions.Vul-
nerability information is bought and sold in places like the dark web (World
Wide Web systems reachable via unusual client configurations or methods).
The moresystemsan attack can affect,the more valuable the attack.
16.3 System and Network Threats
Programthreats,bythemselves,poseserioussecurityrisks.Butthoserisksare
compoundedbyordersofmagnitudewhenasystemisconnectedtoanetwork.
Worldwideconnectivity makesthe systemvulnerabletoworldwideattacks.
The more openan operating system is—the more services it has enabled
and the more functions it allows—the more likely it is that a bug is available
to exploit it. Increasingly, operating systems strive to be secure by default .
For example, Solaris 10 moved from a model in which many services ( FTP,
telnet, and others) were enabled by default when the system was installed
to a model in which almost all services are disabled at installation time and
must specifically be enabled by system administrators. Such changes reduce
the system’s attacksurface.
All hackers leave tracks behind them—whether via network traffic pat-
terns,unusualpackettypes,orothermean s.Forthatreason,hackersfrequently
launch attacks from zombie systems —independent systems or devices that
have been compromised by hackers but that continue to serve their own-
ers while being used without the owner s’ knowledge for nefarious purposes,"
3,16.3.1 Attacking Network Traffic,769,16.3 System and Network Threats,"16.3 System and Network Threats 635
communication
communication
communicationcommunicationsender receiver
attacker
sender
attackerreceiver
attacker
Masquerading
Man-in-the-middleNormal
sender
receiver
Figure 16.6 Standard security attacks.1
includingdenial-of-serviceattacksandspamrelay.Zombiesmakehackerspar-
ticularly difficult to track because they mask the original source of the attack
andtheidentityoftheattacker.Thisisoneofmanyreasonsforsecuring “incon-
sequential ”systems, not just systems containing “valuable ”information or
services—lesttheybe turned intostrongholds for hackers.
The widespread use of broadband and WiFi has only exacerbated the
difficulty in tracking down attackers: even a simple desktop machine, which
canoftenbeeasilycompromisedbymalware,canbecome avaluablemachine
if used for its bandwidth or network access. Wireless ethernet makes it easy
for attackers to launch attacks by joining a public network anonymously or
“WarDriving ”—locating a privateunprotectednetworkto target.
16.3.1 Attacking Network Trafﬁc
Networksare common and attractivetargets,and hackers have many options
for mounting network attacks. As shown in Figure 16.6, an attacker can opt
to remain passive and intercept network traffic (an attack commonly referred
to as sniffin), often obtaining useful information about the types of sessions
1LorelynMedina/Shutterstock."
3,16.3.2 Denial of Service,770,16.3.1 Attacking Network Traffic,"636 Chapter 16 Security
conductedbetweensystemsorthesessions’content.Alternatively,anattacker
cantakeamoreactiverole,eithermasqueradingasoneoftheparties(referred
toas spoofin ),orbecomingafullyactiveman-in-the-middle,interceptingand
possiblymodifyingtransactions betweentwo peers.
Next, we describe a common type of network attack, the denial-of-service
(DoS) attack. Note that it is possible to guard against attacks through such
meansasencryptionandauthentication,whicharediscussedlaterinthechap-
ter. Internet protocols do not, however, support eitherencryption or authenti-
cation by default.
16.3.2 Denial of Service
As mentioned earlier, denial-of-service attacks are aimed not at gaining infor-
mation or stealing resources but rather at disrupting legitimate use of a sys-
tem or facility. Most such attacks involve target systems or facilities that the
attacker has not penetrated. Launching an attack that prevents legitimate use
isfrequentlyeasierthanbreaking into asystemor facility.
Denial-of-service attacks are generally network based. They fall into two
categories. Attacks in the first category use so many facility resources that,
in essence, no useful work can be done. For example, a website click could
download a Java applet that proceeds to use all available CPUtime or to pop
upwindowsinfinitely.Thesecondcategoryinvolvesdisruptingthenetworkof
thefacility.Therehavebeenseveralsuccessfuldenial-of-serviceattacksofthis
kind against major websites. Such attacks, which can last hours or days, have
caused partial or full failure of attempts to use the target facility. The attacks
are usually stopped at the network level until the operating systems can be
updatedto reducetheirvulnerability.
Generally,itisimpossibleto preventdenial-of-serviceattacks.Theattacks
usethesamemechanismsasnormaloperation.Evenmoredifficulttoprevent
and resolve are Distributed Denial-of-Service (DDoS) attacks. These attacks
arelaunchedfrommultiplesitesatonce,towardacommontarget,typicallyby
zombies. DDoSattacks have become more common and are sometimes asso-
ciated with blackmail attempts. A site comes under attack, and the attackers
offerto halt the attack in exchange formoney.
Sometimes a site does not even know it is under attack. It can be difficult
todeterminewhetherasystemslowdownisanattackorjustasurgeinsystem
use. Consider that a successful advertising campaign that greatly increases
traffic to a sitecould beconsidereda DDoS.
There are other interesting aspects of DoSattacks. For example, if an
authentication algorithm locks an account for a period of time after several
incorrect attempts to access the accoun t, then an attacker could cause all
authenticationtobeblockedbypurposelymakingincorrectattemptstoaccess
allaccounts.Similarly,afirewallthatautomaticallyblockscertainkindsoftraf-
fic could be induced to block that traffic when it should not. These examples
suggest that programmers and systems managers need to fully understand
thealgorithmsandtechnologiestheyaredeploying.Finally,computerscience
classes are notorious sources of accidental system DoSattacks. Consider the
first programming exercises in which students learn to create subprocesses
or threads. A common bug involves spawning subprocesses infinitely. The
system’sfreememoryand CPUresourcesdon’t stand achance."
3,16.3.3 Port Scanning,771,16.3.2 Denial of Service,"16.4 Cryptography as a Security Tool 637
16.3.3 Port Scanning
Port scanning is not itself an attack but is a means for a hacker to detect a
system’s vulnerabilities to attack. (Security personnel also use port scanning
—forexample,todetectservicesthatarenotneededorarenotsupposedtobe
running.) Port scanning typically is automated, involving a tool that attempts
tocreatea TCP/IPconnection or send a UDPpacketto a specific portor a range
ofports.
Port scanning is often part of a reconnaissance technique known as fin-
gerprinting, in which an attacker attempts to deduce the type of operating
systeminuseanditssetofservicesinordertoidentifyknownvulnerabilities.
Many servers and clients make this easier by disclosing their exact version
number as part of network protocol headers (for example, HTTP’s “Server: ”
and “User-Agent: ”headers). Detailed analyses of idiosyncratic behaviors by
protocol handlers can also help the attacker figure out what operating system
thetargetisusing—a necessarystepfor successfulexploitation.
Network vulnerability scanners are sold as commercial products. There
are also tools that perform subsets of the functionality of a full scanner. For
example, nmap(from http://www.insecure.org/nmap/ )isaveryversatileopen-
source utility for network exploration and security auditing. When pointed
at a target, it will determine what services are running, including application
names and versions. It can identify the host operating system. It can also
provide information about defenses, such as what firewalls are defending
the target. It does not exploit known bugs. Other tools, however (such as
Metasploit), pick up where the port scanners leave off and provide payload
construction facilities that can be used to test for vulnerabilities—or exploit
themby creatinga specific payload that triggersthe bug.
The seminal work on port-scanning techniques can be found in
http://phrack.org/issues/49/15.html . Techniques are constantly evolving,
as are measures to detect them (which form the basis for network intrusion
detectionsystems,discussedlater).
16.4 Cryptography as a Security Tool
There are many defenses against computer attacks, running the gamut from
methodology to technology. The broade st tool available to system designers
and users is cryptography. In this section, we discuss cryptography and its
usein computersecurity.Note that the cryptography discussedhere has been
simplified for educational purposes; readers are cautioned against using any
of the schemes described here in the real world. Good cryptography libraries
arewidelyavailableandwouldmakeagoodbasisforproductionapplications.
In an isolated computer, the operating system can reliably determine the
sender and recipient of all interprocess communication, since it controls all
communication channels in the computer. In a network of computers, the
situation is quite different. A networked computer receives bits “from the
wire ”with no immediate and reliable way of determining what machine or
applicationsentthosebits.Similarly,thecomputersendsbitsontothenetwork
with no way of knowing who might eventually receive them. Additionally,
when either sending or receiving, the system has no way of knowing if an
eavesdropperlistenedto the communication."
2,16.4 Cryptography as a Security Tool,771,16.3 System and Network Threats,"16.4 Cryptography as a Security Tool 637
16.3.3 Port Scanning
Port scanning is not itself an attack but is a means for a hacker to detect a
system’s vulnerabilities to attack. (Security personnel also use port scanning
—forexample,todetectservicesthatarenotneededorarenotsupposedtobe
running.) Port scanning typically is automated, involving a tool that attempts
tocreatea TCP/IPconnection or send a UDPpacketto a specific portor a range
ofports.
Port scanning is often part of a reconnaissance technique known as fin-
gerprinting, in which an attacker attempts to deduce the type of operating
systeminuseanditssetofservicesinordertoidentifyknownvulnerabilities.
Many servers and clients make this easier by disclosing their exact version
number as part of network protocol headers (for example, HTTP’s “Server: ”
and “User-Agent: ”headers). Detailed analyses of idiosyncratic behaviors by
protocol handlers can also help the attacker figure out what operating system
thetargetisusing—a necessarystepfor successfulexploitation.
Network vulnerability scanners are sold as commercial products. There
are also tools that perform subsets of the functionality of a full scanner. For
example, nmap(from http://www.insecure.org/nmap/ )isaveryversatileopen-
source utility for network exploration and security auditing. When pointed
at a target, it will determine what services are running, including application
names and versions. It can identify the host operating system. It can also
provide information about defenses, such as what firewalls are defending
the target. It does not exploit known bugs. Other tools, however (such as
Metasploit), pick up where the port scanners leave off and provide payload
construction facilities that can be used to test for vulnerabilities—or exploit
themby creatinga specific payload that triggersthe bug.
The seminal work on port-scanning techniques can be found in
http://phrack.org/issues/49/15.html . Techniques are constantly evolving,
as are measures to detect them (which form the basis for network intrusion
detectionsystems,discussedlater).
16.4 Cryptography as a Security Tool
There are many defenses against computer attacks, running the gamut from
methodology to technology. The broade st tool available to system designers
and users is cryptography. In this section, we discuss cryptography and its
usein computersecurity.Note that the cryptography discussedhere has been
simplified for educational purposes; readers are cautioned against using any
of the schemes described here in the real world. Good cryptography libraries
arewidelyavailableandwouldmakeagoodbasisforproductionapplications.
In an isolated computer, the operating system can reliably determine the
sender and recipient of all interprocess communication, since it controls all
communication channels in the computer. In a network of computers, the
situation is quite different. A networked computer receives bits “from the
wire ”with no immediate and reliable way of determining what machine or
applicationsentthosebits.Similarly,thecomputersendsbitsontothenetwork
with no way of knowing who might eventually receive them. Additionally,
when either sending or receiving, the system has no way of knowing if an
eavesdropperlistenedto the communication."
3,16.4.1 Encryption,772,16.4 Cryptography as a Security Tool,"638 Chapter 16 Security
Commonly, network addressesare used to infer the potentialsendersand
receiversofnetworkmessages.Networkpacketsarrivewithasourceaddress,
such as an IPaddress. And when a computer sends a message, it names the
intended receiver by specifying a destination address. However, for appli-
cations where security matters, we are asking for trouble if we assume that
the source or destination address of a packet reliably determines who sent or
received that packet. A rogue computer can send a message with a falsified
source address, and numerous computers other than the one specified by the
destinationaddresscan(andtypicallydo)receiveapacket.Forexample,allof
theroutersonthewaytothedestinationwillreceivethepacket,too.How,then,
isanoperatingsystemtodecidewhethertograntarequestwhenitcannottrust
thenamedsourceoftherequest?Andhowisitsupposedtoprovideprotection
for a request or data when it cannot determine who will receive the response
or messagecontents it sendsoverthe network?
It is generally considered infeasible to build a network of any scale in
which the source and destination addresses of packets can be trustedin this
sense. Therefore, the only alternative is somehow to eliminate the need to
trust the network. This is the job of cryptography. Abstractly, cryptography is
usedtoconstrainthepotentialsendersand/orreceiversofamessage.Modern
cryptographyisbasedonsecretscalled keysthatareselectivelydistributedto
computersinanetworkandusedtoprocessmessages.Cryptographyenablesa
recipientofamessagetoverifythatthemessagewascreatedbysomecomputer
possessing a certain key. Similarly, a sender can encode its message so that
only a computer with a certain key can decode the message. Unlike network
addresses,however,keysaredesignedsothatitisnotcomputationallyfeasible
toderivethemfromthemessagestheywereusedtogenerateorfromanyother
public information. Thus, they provide a much more trustworthy means of
constraining sendersand receiversof messages.
Cryptography is a powerful tool, and the use of cryptography can cause
contention. Some countries ban its use in certain forms or limit how long the
keys can be. Others have ongoing debates about whether technology vendors
(suchassmartphonevendors)mustprovidea back door totheincludedcryp-
tography, allowing law enforcement to bypass the privacy it provides. Many
observersargue,however,thatbackdoorsareanintentionalsecurityweakness
that could beexploitedby attackers orevenmisusedby governments.
Finally,notethatcryptographyisafieldofstudyuntoitself,withlargeand
smallcomplexitiesandsubtleties.Here,weexplorethemostimportantaspects
of thepartsof cryptography that pertainto operatingsystems.
16.4.1 Encryption
Becauseitsolvesawidevarietyofcommunicationsecurityproblems, encryp-
tionisusedfrequentlyinmanyaspectsofmoderncomputing.Itisusedtosend
messages securely across a network, as well as to protect database data, files,
andevenentiredisksfromhavingtheircontentsreadbyunauthorizedentities.
An encryption algorithm enables the s ender of a message to ensure that only
a computer possessing a certain key can read the message or to ensure that
the writer of data is the only reader of the data. Encryption of messages is an
ancient practice, of course, and there have been many encryption algorithms,"
3,16.4.2 Implementation of Cryptography,779,16.4.1 Encryption,"16.4 Cryptography as a Security Tool 645
message m  
encryption
algorithm
E
decryption
algorithm
Dwrite
3. E
kbad(m)
message m  readencryption
key kbad
decryption
key kddecryption
algorithm
Ddecryption
key kbad
2. Public
keykbad1. Public
key keattacker
Figure 16.9 A man-in-the-middle attack on asymmetric cryptography.4
X.509digitalcertificateformatthatcanbeparsedbycomputer.Thisschemeis
usedfor secureweb communication, aswe discussin Section16.4.3.
16.4.2 Implementation of Cryptography
Network protocols are typically organized in layers, with each layer acting as
a client of the one below it. That is, when one protocol generates a message
to send to its protocol peer on another machine, it hands its message to the
protocol below it in the network-protocol stack for deliveryto its peer on that
machine.Forexample,inan IPnetwork, TCP(atransport-layer protocol)actsas
aclientof IP(anetwork-layer protocol): TCPpacketsarepasseddownto IPfor
deliverytothe IPpeerattheotherendoftheconnection. IPencapsulatesthe TCP
packetinan IPpacket,whichitsimilarlypassesdowntothe data-link layer to
betransmittedacrossthenetworktoitspeeronthedestinationcomputer.This
IPpeerthendeliversthe TCPpacketuptothe TCPpeeronthatmachine.Seven
4LorelynMedina/Shutterstock."
3,16.4.3 An Example: TLS,780,16.4.2 Implementation of Cryptography,"646 Chapter 16 Security
such layers are included in the OSImodel, mentioned earlier and describedin
detailinSection19.3.2.
Cryptography can be inserted at almost any layer in network protocol
stacks. TLS(Section 16.4.3), for example, provides security at the transport
layer.Network-layersecurityg enerallyhasbeenstandardizedon IPSec,which
defines IPpacket formats that allow the insertion of authenticators and the
encryption of packet contents. IPSec uses symmetric encryption and uses the
Internet Key Exchange (IKE)protocolforkeyexchange. IKEisbasedonpublic-
keyencryption. IPSechaswidelyusedasthebasisfor virtual private networks
(VPNs),inwhichalltrafficbetweentwo IPSecendpointsisencryptedtomakea
private network out of one that would otherwise be public. Numerous proto-
colsalsohavebeendevelopedforusebyapplications,suchas PGPforencrypt-
ing e-mail; in this type of scheme, the applications themselves must be coded
to implementsecurity.
Where is cryptographic protection best placed in a protocol stack? In gen-
eral,thereisnodefinitiveanswer.Ontheonehand,moreprotocolsbenefitfrom
protections placed lower in the stack. For example, since IPpackets encapsu-
lateTCPpackets,encryptionof IPpackets(using IPSec,forexample)alsohides
the contents of the encapsulated TCPpackets. Similarly, authenticators on IP
packetsdetectthe modificationof contained TCPheaderinformation.
On the other hand, protection at lower layers in the protocol stack may
give insufficient protection to higher-layer protocols. For example, an appli-
cation server that accepts connections encrypted with IPSec might be able to
authenticatetheclientcomputersfromwhichrequestsarereceived.However,
to authenticate a user at a client computer, the server may need to use an
application-levelprotocol—theusermayberequiredtotypeapassword.Also
consider the problem of e-mail. E-mail delivered via the industry-standard
SMTPprotocol is stored and forwarded, frequently multiple times, before it is
delivered. Each of these transmissions could go over a secure or an insecure
network.For e-mailto besecure,thee-mailmessageneedsto beencryptedso
that itssecurityisindependentof the transports that carry it.
Unfortunately,likemanytools,encryptioncanbeusednotonlyfor “good ”
but also for “evil. ”The ransomware attacks describedearlier,for example,are
based on encryption. As mentioned, the attackers encrypt information on the
target system and render it inaccessible to the owner. The idea is to force the
ownertopayaransomtogetthekeyneededtodecryptthedata.Preventionof
such attacks takes the form of better system and network security and a well-
executed backup plan so that the contents of the files can be restored without
thekey.
16.4.3 An Example: TLS
Transport Layer Security (TLS) is a cryptographic protocol that enables two
computerstocommunicatesecurely—thatis,sothateachcanlimitthesender
and receiver of messages to the other. It is perhaps the most commonly
used cryptographic protocol on the Internet today, since it is the standard
protocol by which web browsers communicate securely with web servers.
For completeness, we should note that TLSevolved from SSL(Secure Sock-
ets Layer), which was designed by Netscape. It is described in detail in
https://tools.ietf.org/html/rfc5246 ."
2,16.5 User Authentication,782,16.4 Cryptography as a Security Tool,"648 Chapter 16 Security
•AMACgenerationkey k𝗆𝖺𝖼
scforgeneratingauthenticatorsonmessagesfrom
theserverto theclient
To sendamessage mto the server,the clientsends
c=Ek𝖼𝗋𝗒𝗉𝗍
cs(⟨m,Sk𝗆𝖺𝖼
cs(m)⟩).
Uponreceiving c,theserverrecovers
⟨m,a⟩=Dk𝖼𝗋𝗒𝗉𝗍
cs(c)
and accepts mifVk𝗆𝖺𝖼
cs(m,a) = true. Similarly,to send a message mto the client,
theserversends
c=Ek𝖼𝗋𝗒𝗉𝗍
sc(⟨m,Sk𝗆𝖺𝖼
sc(m)⟩)
and the client recovers
⟨m,a⟩=Dk𝖼𝗋𝗒𝗉𝗍
sc(c)
and accepts mifVk𝗆𝖺𝖼
sc(m,a)=tr ue.
Thisprotocolenablestheservertolimittherecipientsofitsmessagestothe
clientthatgenerated pmsandtolimitthesendersofthemessagesitacceptsto
that same client. Similarly, the client can limit the recipients of the messages
it sends and the senders of the messages it accepts to the party that knows kd
(that is, the party that can decrypt cpms). In many applications, such as web
transactions, the client needs to verif y the identity of the party that knows kd.
Thisisonepurposeofthecertificate certs.Inparticular,the attrsfieldcontains
informationthattheclientcanusetodeterminetheidentity—forexample,the
domainname—oftheserverwithwhichitiscommunicating.Forapplications
in which the server also needs information about the client, TLSsupports an
option by which a clientcan send acertificate tothe server.
InadditiontoitsuseontheInternet, TLSisbeingusedforawidevarietyof
tasks.Forexample,wementionedearlierthat IPSeciswidelyusedasthebasis
forvirtualprivatenetworks,or VPNs.IPSecVPNsnowhaveacompetitorin TLS
VPNs.IPSec is good for point-to-point encryption of traffic—say, between two
company offices. TLS VPNs are more flexible but not as efficient, so they might
beusedbetweenanindividualemployeeworkingremotelyandthecorporate
office.
16.5 User Authentication
Our earlier discussion of authentication involves messages and sessions. But
what about users? If a system cannot authe nticate a user, then authenticating
thatamessagecamefromthatuserispoin tless.Thus,amajorsecurityproblem
for operating systems is user authentication . The protection system depends
on the ability to identify the programs and processes currently executing,
whichinturndependsontheabilitytoidentifyeachuserofthesystem.Users
normally identify themselves, but how do we determine whether a user’s
identity is authentic? Generally, user authentication is based on one or more
of three things: the user’s possession of something (a key or card), the user’s
knowledgeofsomething(auseridentifierandpassword),oranattributeofthe
user(fingerprint,retinapattern,or signature)."
3,16.5.1 Passwords,783,16.5 User Authentication,"16.5 User Authentication 649
16.5.1 Passwords
The most common approach to authenticating a user identity is the use of
passwords . When the user identifies herself by user IDor account name, she
is asked for a password. If the user-su ppliedpassword matches the password
storedinthesystem,thesystemassumesthattheaccountisbeingaccessedby
the owner of that account.
Passwords are often used to protect objects in the computer system, in
the absence of more complete protection schemes. They can be considered a
special case of either keys or capabilities. For instance, a password may be
associated with each resource (such as a file). Whenever a request is made to
usetheresource,thepasswordmustbegiven.Ifthepasswordiscorrect,access
isgranted.Differentpasswordsmaybea ssociatedwithdifferentaccessrights.
For example, different passwords may be used for reading files, appending
files,and updatingfiles.
In practice, most systems require only one password for a user to gain
theirfullrights.Althoughmorepasswor dstheoreticallywouldbemoresecure,
such systems tend not to be implementeddue to the classic trade-off between
securityand convenience. If security makes something inconvenient, then the
securityisfrequentlybypassedorotherwisecircumvented.
16.5.2 Password Vulnerabilities
Passwords are extremely common because they are easy to understand and
use. Unfortunately, passwords can often be guessed, accidentally exposed,
sniffed (read by an eavesdropper), or illegally transferred from an authorized
usertoanunauthorized one, aswe show next.
There are three common ways to guess a password. One way is for the
intruder (either human or program) to know the user or to have information
abouttheuser.Alltoofrequently,peopleuseobviousinformation(suchasthe
namesoftheircatsorspouses)astheirpasswords.Anotherwayistousebrute
force, trying enumeration—or all possible combinations of valid password
characters (letters, numbers, and punctuation on some systems)—until the
password is found. Short passwords are e specially vulnerable to this method.
For example, a four-character password provides only 10,000 variations. On
average, guessing 5,000 times would produce a correct hit. A program that
could try a password every millisecond would take only about 5 seconds to
guessafour-characterpassword.Enumerationislesssuccessfulwheresystems
allow longer passwords that include both uppercase and lowercase letters,
alongwithnumbersandallpunctuationcharacters.Ofcourse,usersmusttake
advantage of the large password space and must not, for example, use only
lowercase letters. The third, common method is dictionary attacks where all
words,word variations,and common passwordsare tried.
Inadditiontobeingguessed,passwordscanbeexposedasaresultofvisual
or electronic monitoring. An intruder can look over the shoulder of a user
(shoulder surfin ) when the user is logging in and can learn the password
easily by watching the keyboard. Alternatively, anyone with access to the
network on which a computer resides can seamlessly add a network monitor,
allowing him to sniff, or watch, all data being transferred on the network,
including user IDs and passwords. Encrypting the data stream containing the
password solves this problem. Even such a system could have passwords"
3,16.5.2 Password Vulnerabilities,783,16.5.1 Passwords,"16.5 User Authentication 649
16.5.1 Passwords
The most common approach to authenticating a user identity is the use of
passwords . When the user identifies herself by user IDor account name, she
is asked for a password. If the user-su ppliedpassword matches the password
storedinthesystem,thesystemassumesthattheaccountisbeingaccessedby
the owner of that account.
Passwords are often used to protect objects in the computer system, in
the absence of more complete protection schemes. They can be considered a
special case of either keys or capabilities. For instance, a password may be
associated with each resource (such as a file). Whenever a request is made to
usetheresource,thepasswordmustbegiven.Ifthepasswordiscorrect,access
isgranted.Differentpasswordsmaybea ssociatedwithdifferentaccessrights.
For example, different passwords may be used for reading files, appending
files,and updatingfiles.
In practice, most systems require only one password for a user to gain
theirfullrights.Althoughmorepasswor dstheoreticallywouldbemoresecure,
such systems tend not to be implementeddue to the classic trade-off between
securityand convenience. If security makes something inconvenient, then the
securityisfrequentlybypassedorotherwisecircumvented.
16.5.2 Password Vulnerabilities
Passwords are extremely common because they are easy to understand and
use. Unfortunately, passwords can often be guessed, accidentally exposed,
sniffed (read by an eavesdropper), or illegally transferred from an authorized
usertoanunauthorized one, aswe show next.
There are three common ways to guess a password. One way is for the
intruder (either human or program) to know the user or to have information
abouttheuser.Alltoofrequently,peopleuseobviousinformation(suchasthe
namesoftheircatsorspouses)astheirpasswords.Anotherwayistousebrute
force, trying enumeration—or all possible combinations of valid password
characters (letters, numbers, and punctuation on some systems)—until the
password is found. Short passwords are e specially vulnerable to this method.
For example, a four-character password provides only 10,000 variations. On
average, guessing 5,000 times would produce a correct hit. A program that
could try a password every millisecond would take only about 5 seconds to
guessafour-characterpassword.Enumerationislesssuccessfulwheresystems
allow longer passwords that include both uppercase and lowercase letters,
alongwithnumbersandallpunctuationcharacters.Ofcourse,usersmusttake
advantage of the large password space and must not, for example, use only
lowercase letters. The third, common method is dictionary attacks where all
words,word variations,and common passwordsare tried.
Inadditiontobeingguessed,passwordscanbeexposedasaresultofvisual
or electronic monitoring. An intruder can look over the shoulder of a user
(shoulder surfin ) when the user is logging in and can learn the password
easily by watching the keyboard. Alternatively, anyone with access to the
network on which a computer resides can seamlessly add a network monitor,
allowing him to sniff, or watch, all data being transferred on the network,
including user IDs and passwords. Encrypting the data stream containing the
password solves this problem. Even such a system could have passwords"
3,16.5.3 Securing Passwords,784,16.5.2 Password Vulnerabilities,"650 Chapter 16 Security
stolen, however. For example, if a file is used to contain the passwords, it
could be copied for off-system analysis. Or consider a Trojan-horse program
installed on the system that captures every keystroke before sending it on to
the application. Another common method to grab passwords, specially debit
card passcodes, is installing physical devices where the codes are used and
recording what the user does,for examplea “skimmer ”at anATMmachine or
a deviceinstalledbetweenthekeyboardand the computer.
Exposureisaparticularlysevereproblemifthepasswordiswrittendown
where it can be read or lost. Some systems force users to select hard-to-
remember or long passwords, or to change their password frequently, which
may cause a user to record the password or to reuse it. As a result, such sys-
tems provide much less security than systems that allow users to select easy
passwords!
The final type of password compromise, illegal transfer, is the result of
human nature. Most computer installations have a rule that forbids users to
share accounts. This rule is sometimes implemented for accounting reasons
but is often aimed at improving security. For instance, suppose one user IDis
shared by several users, and a security breach occurs from that user ID.I ti s
impossible to know who was using the IDa tt h et i m et h eb r e a ko c c u r r e do r
even whether the user was an authorized one. With one user per user ID,a n y
user can be questioned directlyabout use of the account; in addition, the user
might notice something different about the account and detect the break-in.
Sometimes, users break account-sharing rules to help friends or to circum-
vent accounting, and this behavior can result in a system’s being accessed by
unauthorized users—possibly harmful ones.
Passwords can be either generated by the system or selected by a user.
System-generatedpasswordsmaybedifficulttoremember,andthususersmay
write them down. As mentioned, however, user-selected passwords are often
easytoguess(theuser’snameorfavoritecar,forexample).Somesystemswill
check a proposed password for ease of guessing or cracking before accepting
it. Some systems also agepasswords, forcing users to change their passwords
at regular intervals (every three months, for instance). This method is not
foolproof either, because users can easily toggle between two passwords. The
solution,asimplementedonsomesystems,istorecordapasswordhistoryfor
each user. For instance, the system could record the last Npasswords and not
allowtheirreuse.
Severalvariantsonthesesimplepasswordschemescanbeused.Forexam-
ple, the password can be changed more frequently. At the extreme, the pass-
word is changed from session to session. A new password is selected (either
by the system or by the user) at the end of each session, and that password
mustbeusedforthenextsession.Insuchacase,evenifapasswordisusedby
anunauthorizedperson,thatpersoncanuseitonlyonce.Whenthelegitimate
user tries to use a now-invalid password at the next session, he discovers the
securityviolation.Stepscan thenbe takento repairthe breachedsecurity.
16.5.3 Securing Passwords
One problem with all these approaches is the difficulty of keeping the pass-
word secret within the computer. How can the system store a password
securely yet allow its use for authentication when the user presents her pass-"
3,16.5.4 One-Time Passwords,786,16.5.3 Securing Passwords,"652 Chapter 16 Security
16.5.4 One-Time Passwords
Toavoidtheproblemsofpasswordsniffingandshouldersurfing,asystemcan
use a set of paired passwords . When a session begins, the system randomly
selectsandpresentsonepartofapasswordpair;theusermustsupplytheother
part. In this system, the user is challenged and must respond with the correct
answer to that challenge.
Thisapproachcanbegeneralizedto theuseofanalgorithmasapassword.
In this scheme, the system and the user share a symmetric password. The
password pwisnevertransmittedoveramediumthatallowsexposure.Rather,
thepasswordisusedasinputtoafunction,alongwitha challenge chpresented
by the system. The user then computes the function H(pw,ch). The result of
this function is transmitted as the auth enticator to the computer. Because the
computer also knows pwandch, it can perform the same computation. If the
results match, the user is authenticated. The next time the user needs to be
authenticated, another chis generated, and the same steps ensue. This time,
the authenticator is different. Such algorithmic passwords are not susceptible
toreuse.Thatis,ausercantypeinapassword,andnoentityinterceptingthat
passwordwillbeabletoreuseit.This one-time password systemisoneofonly
a fewways to preventimproperauthentication dueto passwordexposure.
One-time password systems are implemented in various ways. Commer-
cial implementations use hardware calculators with a display or a display
and numeric keypad. These calculators generally take the shape of a credit
card, a key-chain dongle, or a USBdevice. Software running on computers or
smartphones provides the user with H(pw,ch);pwcan be input by the user
or generated by the calculator in synchronization with the computer. Some-
times, pwis just a personal identificatio number (PIN). The output of any
of these systems shows the one-time password. A one-time password gener-
ator that requires input by the user involves two-factor authentication .T w o
different types of components are needed in this case—for example, a one-
time password generator that generates the correct response only if the PINis
valid.Two-factorauthenticationoffersfa rbetterauthenticationprotectionthan
single-factor authentication because it requires “something you have ”as well
as“something you know. ”
16.5.5 Biometrics
Yet another variation on the use of passwords for authentication involves the
useofbiometricmeasures.Palm-orhand-readersarecommonlyusedtosecure
physical access—for example, access to a data center. These readers match
stored parameters against what is being read from hand-reader pads. The
parameters can include a temperature map, as well as finger length, finger
width, and line patterns. These devices are currently too large and expensive
to be used for normal computerauthentication.
Fingerprintreadershavebecomeaccurateandcost-effective.Thesedevices
readfingerridgepatternsandconvertthemintoasequenceofnumbers.Over
time, they can store a set of sequences to adjust for the location of the finger
on the reading pad and other factors. Software can then scan a finger on the
padandcompareitsfeatureswiththesestoredsequencestodetermineifthey
match. Ofcourse, multipleuserscan have profilesstored,and the scanner can
differentiate among them. A very accura te two-factor authentication scheme"
3,16.5.5 Biometrics,786,16.5.4 One-Time Passwords,"652 Chapter 16 Security
16.5.4 One-Time Passwords
Toavoidtheproblemsofpasswordsniffingandshouldersurfing,asystemcan
use a set of paired passwords . When a session begins, the system randomly
selectsandpresentsonepartofapasswordpair;theusermustsupplytheother
part. In this system, the user is challenged and must respond with the correct
answer to that challenge.
Thisapproachcanbegeneralizedto theuseofanalgorithmasapassword.
In this scheme, the system and the user share a symmetric password. The
password pwisnevertransmittedoveramediumthatallowsexposure.Rather,
thepasswordisusedasinputtoafunction,alongwitha challenge chpresented
by the system. The user then computes the function H(pw,ch). The result of
this function is transmitted as the auth enticator to the computer. Because the
computer also knows pwandch, it can perform the same computation. If the
results match, the user is authenticated. The next time the user needs to be
authenticated, another chis generated, and the same steps ensue. This time,
the authenticator is different. Such algorithmic passwords are not susceptible
toreuse.Thatis,ausercantypeinapassword,andnoentityinterceptingthat
passwordwillbeabletoreuseit.This one-time password systemisoneofonly
a fewways to preventimproperauthentication dueto passwordexposure.
One-time password systems are implemented in various ways. Commer-
cial implementations use hardware calculators with a display or a display
and numeric keypad. These calculators generally take the shape of a credit
card, a key-chain dongle, or a USBdevice. Software running on computers or
smartphones provides the user with H(pw,ch);pwcan be input by the user
or generated by the calculator in synchronization with the computer. Some-
times, pwis just a personal identificatio number (PIN). The output of any
of these systems shows the one-time password. A one-time password gener-
ator that requires input by the user involves two-factor authentication .T w o
different types of components are needed in this case—for example, a one-
time password generator that generates the correct response only if the PINis
valid.Two-factorauthenticationoffersfa rbetterauthenticationprotectionthan
single-factor authentication because it requires “something you have ”as well
as“something you know. ”
16.5.5 Biometrics
Yet another variation on the use of passwords for authentication involves the
useofbiometricmeasures.Palm-orhand-readersarecommonlyusedtosecure
physical access—for example, access to a data center. These readers match
stored parameters against what is being read from hand-reader pads. The
parameters can include a temperature map, as well as finger length, finger
width, and line patterns. These devices are currently too large and expensive
to be used for normal computerauthentication.
Fingerprintreadershavebecomeaccurateandcost-effective.Thesedevices
readfingerridgepatternsandconvertthemintoasequenceofnumbers.Over
time, they can store a set of sequences to adjust for the location of the finger
on the reading pad and other factors. Software can then scan a finger on the
padandcompareitsfeatureswiththesestoredsequencestodetermineifthey
match. Ofcourse, multipleuserscan have profilesstored,and the scanner can
differentiate among them. A very accura te two-factor authentication scheme"
2,16.6 Implementing Security Defenses,787,16.5 User Authentication,"16.6 Implementing Security Defenses 653
can result from requiring a password as well as a user name and fingerprint
scan.Ifthisinformationisencryptedintransit,thesystemcanbeveryresistant
tospoofing orreplayattack.
Multifactor authentication isbetterstill.Considerhowstrongauthentica-
tioncanbewitha USBdevicethatmustbepluggedintothesystem,a PIN,anda
fingerprintscan. Exceptforhavingtoplaceone’sfingeronapadandplugthe
USBintothesystem,thisauthenticationmethodisnolessconvenientthanthat
usingnormalpasswords.Recall,though,t hatstrongauthenticationbyitselfis
notsufficienttoguaranteethe IDoftheuser.Anauthenticatedsessioncanstill
behijackedif itisnot encrypted.
16.6 Implementing Security Defenses
Justastherearemyriadthreatstosystemandnetworksecurity,therearemany
securitysolutions.Thesolutionsrangefromimprovedusereducation,through
technology,towritingbettersoftware.Mostsecurityprofessionalssubscribeto
the theory of defense in depth , which states that more layers of defense are
betterthan fewerlayers.Of course,this theory appliesto any kindof security.
Consider the security of a house without a door lock, with a door lock, and
with a lock and an alarm. In this sectio n, we look at the major methods, tools,
and techniques that can be used to improve resistance to threats. Note that
somesecurity-improvingtechniquesaremoreproperlypartofprotectionthan
securityandarecoveredinChapter17.
16.6.1 Security Policy
The first step toward improving the security of any aspect of computing is to
have a security policy . Policiesvary widelybut generallyinclude a statement
of what is being secured. For example, a policy might state that all outside-
accessibleapplicationsmusthaveacodereviewbeforebeingdeployed,orthat
usersshouldnotsharetheirpasswords,orthatallconnectionpointsbetweena
companyandtheoutsidemusthaveportscansruneverysixmonths.Without
a policy in place, it is impossible for users and administrators to know what
is permissible,what is required,and what is not allowed. The policy is a road
maptosecurity,andifasiteistryingtomovefromlesssecuretomoresecure,
itneedsa map toknow how to getthere.
Once the security policy is in place, the people it affects should know it
well. It should be their guide. The policy should also be a living document
thatisreviewedandupdatedperiodica llytoensurethatitisstillpertinentand
stillfollowed.
16.6.2 Vulnerability Assessment
How can we determine whether a security policy has been correctly imple-
mented? The best way is to execute a v ulnerability assessment. Such assess-
ments can cover broad ground, from social engineering through risk assess-
menttoportscans. Risk assessment ,forexample,attemptstovaluetheassets
of the entity in question (a program, a management team, a system, or a facil-
ity) and determine the odds that a security incident will affect the entity and"
3,16.6.1 Security Policy,787,16.6 Implementing Security Defenses,"16.6 Implementing Security Defenses 653
can result from requiring a password as well as a user name and fingerprint
scan.Ifthisinformationisencryptedintransit,thesystemcanbeveryresistant
tospoofing orreplayattack.
Multifactor authentication isbetterstill.Considerhowstrongauthentica-
tioncanbewitha USBdevicethatmustbepluggedintothesystem,a PIN,anda
fingerprintscan. Exceptforhavingtoplaceone’sfingeronapadandplugthe
USBintothesystem,thisauthenticationmethodisnolessconvenientthanthat
usingnormalpasswords.Recall,though,t hatstrongauthenticationbyitselfis
notsufficienttoguaranteethe IDoftheuser.Anauthenticatedsessioncanstill
behijackedif itisnot encrypted.
16.6 Implementing Security Defenses
Justastherearemyriadthreatstosystemandnetworksecurity,therearemany
securitysolutions.Thesolutionsrangefromimprovedusereducation,through
technology,towritingbettersoftware.Mostsecurityprofessionalssubscribeto
the theory of defense in depth , which states that more layers of defense are
betterthan fewerlayers.Of course,this theory appliesto any kindof security.
Consider the security of a house without a door lock, with a door lock, and
with a lock and an alarm. In this sectio n, we look at the major methods, tools,
and techniques that can be used to improve resistance to threats. Note that
somesecurity-improvingtechniquesaremoreproperlypartofprotectionthan
securityandarecoveredinChapter17.
16.6.1 Security Policy
The first step toward improving the security of any aspect of computing is to
have a security policy . Policiesvary widelybut generallyinclude a statement
of what is being secured. For example, a policy might state that all outside-
accessibleapplicationsmusthaveacodereviewbeforebeingdeployed,orthat
usersshouldnotsharetheirpasswords,orthatallconnectionpointsbetweena
companyandtheoutsidemusthaveportscansruneverysixmonths.Without
a policy in place, it is impossible for users and administrators to know what
is permissible,what is required,and what is not allowed. The policy is a road
maptosecurity,andifasiteistryingtomovefromlesssecuretomoresecure,
itneedsa map toknow how to getthere.
Once the security policy is in place, the people it affects should know it
well. It should be their guide. The policy should also be a living document
thatisreviewedandupdatedperiodica llytoensurethatitisstillpertinentand
stillfollowed.
16.6.2 Vulnerability Assessment
How can we determine whether a security policy has been correctly imple-
mented? The best way is to execute a v ulnerability assessment. Such assess-
ments can cover broad ground, from social engineering through risk assess-
menttoportscans. Risk assessment ,forexample,attemptstovaluetheassets
of the entity in question (a program, a management team, a system, or a facil-
ity) and determine the odds that a security incident will affect the entity and"
3,16.6.2 Vulnerability Assessment,787,16.6.1 Security Policy,"16.6 Implementing Security Defenses 653
can result from requiring a password as well as a user name and fingerprint
scan.Ifthisinformationisencryptedintransit,thesystemcanbeveryresistant
tospoofing orreplayattack.
Multifactor authentication isbetterstill.Considerhowstrongauthentica-
tioncanbewitha USBdevicethatmustbepluggedintothesystem,a PIN,anda
fingerprintscan. Exceptforhavingtoplaceone’sfingeronapadandplugthe
USBintothesystem,thisauthenticationmethodisnolessconvenientthanthat
usingnormalpasswords.Recall,though,t hatstrongauthenticationbyitselfis
notsufficienttoguaranteethe IDoftheuser.Anauthenticatedsessioncanstill
behijackedif itisnot encrypted.
16.6 Implementing Security Defenses
Justastherearemyriadthreatstosystemandnetworksecurity,therearemany
securitysolutions.Thesolutionsrangefromimprovedusereducation,through
technology,towritingbettersoftware.Mostsecurityprofessionalssubscribeto
the theory of defense in depth , which states that more layers of defense are
betterthan fewerlayers.Of course,this theory appliesto any kindof security.
Consider the security of a house without a door lock, with a door lock, and
with a lock and an alarm. In this sectio n, we look at the major methods, tools,
and techniques that can be used to improve resistance to threats. Note that
somesecurity-improvingtechniquesaremoreproperlypartofprotectionthan
securityandarecoveredinChapter17.
16.6.1 Security Policy
The first step toward improving the security of any aspect of computing is to
have a security policy . Policiesvary widelybut generallyinclude a statement
of what is being secured. For example, a policy might state that all outside-
accessibleapplicationsmusthaveacodereviewbeforebeingdeployed,orthat
usersshouldnotsharetheirpasswords,orthatallconnectionpointsbetweena
companyandtheoutsidemusthaveportscansruneverysixmonths.Without
a policy in place, it is impossible for users and administrators to know what
is permissible,what is required,and what is not allowed. The policy is a road
maptosecurity,andifasiteistryingtomovefromlesssecuretomoresecure,
itneedsa map toknow how to getthere.
Once the security policy is in place, the people it affects should know it
well. It should be their guide. The policy should also be a living document
thatisreviewedandupdatedperiodica llytoensurethatitisstillpertinentand
stillfollowed.
16.6.2 Vulnerability Assessment
How can we determine whether a security policy has been correctly imple-
mented? The best way is to execute a v ulnerability assessment. Such assess-
ments can cover broad ground, from social engineering through risk assess-
menttoportscans. Risk assessment ,forexample,attemptstovaluetheassets
of the entity in question (a program, a management team, a system, or a facil-
ity) and determine the odds that a security incident will affect the entity and"
3,16.6.3 Intrusion Prevention,789,16.6.2 Vulnerability Assessment,"16.6 Implementing Security Defenses 655
allremoteaccess.Forinstance,theInternetcurrentlyconnectsbillionsofcom-
puters and devices and has become a mission-critical, indispensable resource
formanycompaniesandindividuals.IfyouconsidertheInternetaclub,then,
as in any club with millions of members, there are many good members and
somebadmembers.Thebadmembershavemanytoolstheycanusetoattempt
togain access to the interconnected computers.
Vulnerability scans can be applied to networks to address some of the
problems with network security. The scans search a network for ports that
respondtoarequest.Ifservicesareenabledthatshouldnotbe,accesstothem
can be blocked, or they can be disabled. The scans then determine the details
of the application listening on that port and try to determine if it has any
knownvulnerabilities.Testingthosevu lnerabilitiescandetermineifthesystem
ismisconfiguredor lacks neededpatches.
Finally,though,considertheuseofportscannersinthehandsofanattacker
ratherthansomeonetryingtoimprovesecurity.Thesetoolscouldhelpattack-
ersfindvulnerabilitiestoattack.(Fortunately,itispossibletodetectportscans
through anomaly detection, as we discuss next.) It is a general challenge to
security that the same tools can be used for good and for harm. In fact, some
people advocate security through obscurity , stating that no tools should be
written to test security, because such tools can be used to find (and exploit)
security holes. Others believethat this approach to security is not a valid one,
pointing out, for example, that attackers could write their own tools. It seems
reasonable that security through obscurity be considered one of the layers of
securityonly so long as it isnot theonly layer.For example,a company could
publish its entire network configuration, but keeping that information secret
makes it harder for intruders to know what to attack. Even here, though, a
companyassumingthatsuchinformationwillremainasecrethasafalsesense
ofsecurity.
16.6.3 Intrusion Prevention
Securing systems and facilities is intimately linked to intrusion detection
and prevention. Intrusion prevention , as its name suggests, strives to detect
attemptedorsuccessfulintrusionsintocomputersystemsandtoinitiateappro-
priate responses to the intrusions. Intrusion prevention encompasses a wide
arrayof techniquesthat varyon a number of axes,includingthe following:
•Thetimeatwhichdetectionoccurs.Detectioncanoccurinrealtime(while
the intrusionis occurring) or afterthefact.
•The types of inputs examined to detect intrusive activity. These may
include user-shell commands, process system calls, and network packet
headers or contents. Some forms of intrusion might be detected only by
correlating informationfromseveralsuch sources.
•Therangeofresponsecapabilities.Simpleformsofresponseincludealert-
ing an administrator to the potential intrusion or somehow halting the
potentially intrusive activity—for example, killing a process engaged in
suchactivity.Inasophisticatedformofresponse,asystemmighttranspar-
entlydivertanintruder’sactivitytoa honeypot —afalseresourceexposed"
3,16.6.4 Virus Protection,791,16.6.3 Intrusion Prevention,"16.6 Implementing Security Defenses 657
security-relevant events are recorded for purposes of intrusion detection. A
smallinstallationsuchasthiscouldeasilygenerateamillionauditrecordsper
day.Onlyoneortwomightbeworthyofanadministrator’sinvestigation.Ifwe
suppose,optimistically,thateachactualattackisreflectedintenauditrecords,
wecanroughlycomputetherateofoccurrenceofauditrecordsreflectingtruly
intrusiveactivityas follows:
2intrusions
day⋅10records
intrusion
106records
day=0.00002 .
Interpreting this as a “probability of occurrence of intrusive records, ”we
denote it as P(I); that is, event Iis the occurrence of a record reflecting truly
intrusive behavior. Since P(I)=0.00002, we also know that P(¬I)=1−P(I)=
0.99998.Nowwelet Adenotetheraisingofanalarmbyan IDS.Anaccurate IDS
should maximize both P(I|A)a n d P(¬I|¬A)—that is, the probabilities that an
alarmindicatesanintrusionandthatno alarmindicatesnointrusion.Focusing
onP(I|A)for the moment,we can compute itusing Bayes’ theorem :
P(I|A)=P(I)⋅P(A|I)
P(I)⋅P(A|I)+P(¬I)⋅P(A|¬I)
=0.00002 ⋅P(A|I)
0.00002 ⋅P(A|I)+0.99998 ⋅P(A|¬I)
Now consider the impact of the false-alarm rate P(A|¬I)o n P(I|A). Even
with a very good true-alarm rate of P(A|I)=0.8, a seemingly good false-
alarm rate of P(A|¬I)=0.0001 yields P(I|A)≈0.14. That is, fewer than one
in every seven alarms indicates a real intrusion! In systems where a security
administrator investigates each alarm, a high rate of false alarms—called a
“Christmas tree effect ”—is exceedingly wasteful and will quickly teach the
administratorto ignorealarms.
Thisexampleillustratesageneralprinciplefor IPSs:forusability,theymust
offer an extremely low false-alarm rate . Achieving a sufficiently low false-
alarm rate is an especially serious challenge for anomaly-detection systems,
as mentioned, because of the difficulties of adequately benchmarking normal
system behavior. However, research continues to improve anomaly-detection
techniques. Intrusion-detection software is evolving to implement signatures,
anomalyalgorithms,andotheralgorithmsandtocombinetheresultstoarrive
ata moreaccurate anomaly-detectionrate.
16.6.4 Virus Protection
Aswehaveseen,virusescananddowreakhavoconsystems.Protectionfrom
viruses thus is an important security concern. Antivirus programs are often
used to provide this protection. Some of these programs are effective against
only particular known viruses. They work by searching all the programs on
a system for the specific pattern of instructions known to make up the virus."
3,"16.6.5 Auditing, Accounting, and Logging",793,16.6.4 Virus Protection,"16.6 Implementing Security Defenses 659
andcomparesitwiththesignatureontheoriginallist;anydifferencesserveasa
warningofpossibleinfection.Thistechniquecanbecombinedwithothers.For
example,a high-overhead antivirusscan, such as a sandbox, can be used;and
if a program passes the test, a signature can be created for it. If the signatures
match the next time the program is run, it does not need to be virus-scanned
again.
16.6.5 Auditing, Accounting, and Logging
Auditing,accounting,andloggingcandecreasesystemperformance,butthey
are useful in several areas, including security. Logging can be general or spe-
cific.Allsystem-callexecutionscanbe loggedforanalysisofprogrambehavior
(or misbehavior). More typically, suspicious events are logged. Authentica-
tion failures and authorization failures can tell us quite a lot about break-in
attempts.
Accounting is another potential tool in a security administrator’s kit. It
can be used to find performance changes, which in turn can reveal security
problems.Oneoftheearly UNIXcomputerbreak-inswasdetectedbyCliffStoll
when he was examiningaccounting logsand spottedan anomaly.
16.6.6 Firewalling to Protect Systems and Networks
Weturnnexttothequestionofhowatrustedcomputercanbeconnectedsafely
to an untrustworthy network. One solution is the use of a firewall to separate
trustedanduntrustedsystems.A firewalisacomputer,appliance,process,or
routerthatsitsbetweenthetrustedandtheuntrusted.Anetworkfirewalllimits
networkaccessbetweenthemultiple security domains andmonitorsandlogs
all connections. It can also limit connections based on source or destination
address,sourceordestinationport,ordirectionoftheconnection.Forinstance,
webserversuse HTTPtocommunicatewithwebbrowsers.Afirewalltherefore
may allow only HTTPto pass from all hosts outside the firewall to the web
serverwithinthe firewall.Thefirst worm,theMorrisInternetworm, usedthe
fingerprotocol to break into computers, so fingerwould not be allowed to
pass,forexample.
In fact, a network firewall can separate a network into multiple domains.
A common implementation has the Internet as the untrusted domain; a
semitrusted and semisecure network, called the demilitarized zone (DMZ),
as another domain; and a company’s computers as a third domain (Figure
16.10). Connections are allowed from the Internet to the DMZcomputers and
from the company computers to the Internet but are not allowed from the
Internet or DMZcomputers to the company computers. Optionally, controlled
communications may be allowed between the DMZand one company
computerormore.Forinstance,awebserveronthe DMZmayneedtoquerya
database server on the corporate network. With a firewall, however, access is
contained, and any DMZsystemsthat are broken into stillareunable to access
the company computers.
Of course, a firewall itself must be secure and attack-proof. Otherwise,
its ability to secure connections can be compromised. Furthermore, firewalls
do not prevent attacks that tunnel, or travel within protocols or connections"
3,16.6.6 Firewalling to Protect Systems and Networks,793,"16.6.5 Auditing, Accounting, and Logging","16.6 Implementing Security Defenses 659
andcomparesitwiththesignatureontheoriginallist;anydifferencesserveasa
warningofpossibleinfection.Thistechniquecanbecombinedwithothers.For
example,a high-overhead antivirusscan, such as a sandbox, can be used;and
if a program passes the test, a signature can be created for it. If the signatures
match the next time the program is run, it does not need to be virus-scanned
again.
16.6.5 Auditing, Accounting, and Logging
Auditing,accounting,andloggingcandecreasesystemperformance,butthey
are useful in several areas, including security. Logging can be general or spe-
cific.Allsystem-callexecutionscanbe loggedforanalysisofprogrambehavior
(or misbehavior). More typically, suspicious events are logged. Authentica-
tion failures and authorization failures can tell us quite a lot about break-in
attempts.
Accounting is another potential tool in a security administrator’s kit. It
can be used to find performance changes, which in turn can reveal security
problems.Oneoftheearly UNIXcomputerbreak-inswasdetectedbyCliffStoll
when he was examiningaccounting logsand spottedan anomaly.
16.6.6 Firewalling to Protect Systems and Networks
Weturnnexttothequestionofhowatrustedcomputercanbeconnectedsafely
to an untrustworthy network. One solution is the use of a firewall to separate
trustedanduntrustedsystems.A firewalisacomputer,appliance,process,or
routerthatsitsbetweenthetrustedandtheuntrusted.Anetworkfirewalllimits
networkaccessbetweenthemultiple security domains andmonitorsandlogs
all connections. It can also limit connections based on source or destination
address,sourceordestinationport,ordirectionoftheconnection.Forinstance,
webserversuse HTTPtocommunicatewithwebbrowsers.Afirewalltherefore
may allow only HTTPto pass from all hosts outside the firewall to the web
serverwithinthe firewall.Thefirst worm,theMorrisInternetworm, usedthe
fingerprotocol to break into computers, so fingerwould not be allowed to
pass,forexample.
In fact, a network firewall can separate a network into multiple domains.
A common implementation has the Internet as the untrusted domain; a
semitrusted and semisecure network, called the demilitarized zone (DMZ),
as another domain; and a company’s computers as a third domain (Figure
16.10). Connections are allowed from the Internet to the DMZcomputers and
from the company computers to the Internet but are not allowed from the
Internet or DMZcomputers to the company computers. Optionally, controlled
communications may be allowed between the DMZand one company
computerormore.Forinstance,awebserveronthe DMZmayneedtoquerya
database server on the corporate network. With a firewall, however, access is
contained, and any DMZsystemsthat are broken into stillareunable to access
the company computers.
Of course, a firewall itself must be secure and attack-proof. Otherwise,
its ability to secure connections can be compromised. Furthermore, firewalls
do not prevent attacks that tunnel, or travel within protocols or connections"
3,16.6.7 Other Solutions,795,16.6.6 Firewalling to Protect Systems and Networks,"16.6 Implementing Security Defenses 661
16.6.7 Other Solutions
Intheongoingbattlebetween CPUdesigners,operatingsystemimplementers,
andhackers,oneparticulartechniqueh asbeenhelpfultodefendagainstcode
injection.Tomountacode-injectiona ttack,hackersmustbeabletodeducethe
exact address in memory of their target. Normally, this may not be difficult,
since memory layout tends to be predictable. An operating system technique
called Address Space Layout Randomization (ASLR) attempts to solve this
problembyrandomizingaddressspaces—thatis,puttingaddressspaces,such
as the starting locations of the stack an d heap, in unpredictable locations.
Address randomization, although not foolproof, makes exploitation consid-
erably more difficult. ASLRis a standard feature in many operating systems,
includingWindows, Linux,and mac OS.
In mobile operating systems such as i OSand Android, an approach often
adopted is to place the user data and the system files into two separate parti-
tions.Thesystempartitionismountedread-only,whereasthedatapartitionis
read–write. This approach has numerous advantages, not the least of which
is greater security: the system partition files cannot easily be tampered with,
bolsteringsystem integrity.Androidtakes this a stepfurther by using Linux’s
dm-verity mechanism to cryptographically hash the system partition and
detectany modifications.
16.6.8 Security Defenses Summarized
By applying appropriate layers of defense, we can keep systems safe from all
but the most persistent attackers. In summary, these layers may include the
following:
•Educate users about safe computing—don’t attach devices of unknown
origin to the computer, don’t share passwords, use strong passwords,
avoid falling for social engineering appeals, realize that an e-mail is not
necessarilya privatecommunication, and so on
•Educate users about how to prevent phishing attacks—don’t click on e-
mailattachmentsorlinksfromunknown(orevenknown)senders;authen-
ticate(for example,viaa phone call)that a requestislegitimate.
•Usesecurecommunication when possible.
•Physically protectcomputerhardware.
•Configuretheoperatingsystemtominimizetheattacksurface;disableall
unused services.
•Configure system daemons, privileges applications, and services to be as
secureas possible.
•Use modern hardware and software, as they are likely to have up-to-date
securityfeatures.
•Keepsystemsand applicationsup todateand patched.
•Only run applications from trusted sources (such as those that are code
signed)."
3,16.6.8 Security Defenses Summarized,795,16.6.7 Other Solutions,"16.6 Implementing Security Defenses 661
16.6.7 Other Solutions
Intheongoingbattlebetween CPUdesigners,operatingsystemimplementers,
andhackers,oneparticulartechniqueh asbeenhelpfultodefendagainstcode
injection.Tomountacode-injectiona ttack,hackersmustbeabletodeducethe
exact address in memory of their target. Normally, this may not be difficult,
since memory layout tends to be predictable. An operating system technique
called Address Space Layout Randomization (ASLR) attempts to solve this
problembyrandomizingaddressspaces—thatis,puttingaddressspaces,such
as the starting locations of the stack an d heap, in unpredictable locations.
Address randomization, although not foolproof, makes exploitation consid-
erably more difficult. ASLRis a standard feature in many operating systems,
includingWindows, Linux,and mac OS.
In mobile operating systems such as i OSand Android, an approach often
adopted is to place the user data and the system files into two separate parti-
tions.Thesystempartitionismountedread-only,whereasthedatapartitionis
read–write. This approach has numerous advantages, not the least of which
is greater security: the system partition files cannot easily be tampered with,
bolsteringsystem integrity.Androidtakes this a stepfurther by using Linux’s
dm-verity mechanism to cryptographically hash the system partition and
detectany modifications.
16.6.8 Security Defenses Summarized
By applying appropriate layers of defense, we can keep systems safe from all
but the most persistent attackers. In summary, these layers may include the
following:
•Educate users about safe computing—don’t attach devices of unknown
origin to the computer, don’t share passwords, use strong passwords,
avoid falling for social engineering appeals, realize that an e-mail is not
necessarilya privatecommunication, and so on
•Educate users about how to prevent phishing attacks—don’t click on e-
mailattachmentsorlinksfromunknown(orevenknown)senders;authen-
ticate(for example,viaa phone call)that a requestislegitimate.
•Usesecurecommunication when possible.
•Physically protectcomputerhardware.
•Configuretheoperatingsystemtominimizetheattacksurface;disableall
unused services.
•Configure system daemons, privileges applications, and services to be as
secureas possible.
•Use modern hardware and software, as they are likely to have up-to-date
securityfeatures.
•Keepsystemsand applicationsup todateand patched.
•Only run applications from trusted sources (such as those that are code
signed)."
2,16.7 An Example: Windows 10,796,16.6 Implementing Security Defenses,"662 Chapter 16 Security
•Enable logging and auditing; review the logs periodically, or automate
alerts.
•Install and use antivirus software on systems susceptible to viruses, and
keepthe softwareupto date.
•Usestrongpasswordsandpassphrases,anddon’trecordthemwherethey
could be found.
•Use intrusion detection, firewalling, and other network-based protection
systemsas appropriate.
•For important facilities, use periodic vulnerability assessments and other
testingmethodstotestsecurityand responseto incidents.
•Encryptmass-storagedevices,andcon siderencryptingimportantindivid-
ualfiles aswell.
•Haveasecuritypolicyforimportantsystemsandfacilities,andkeepitup
todate
16.7 An Example: Windows 10
MicrosoftWindows10isageneral-purposeoperatingsystemdesignedtosup-
port a variety of security features and methods. In this section, we examine
features that Windows 10 uses to perform security functions. For more infor-
mation and background on Windows, seeAppendixB.
The Windows 10 security model is based on the notion of user accounts .
Windows 10 allows the creation of any number of user accounts, which can
be grouped in any manner. Access to syst em objects can then be permitted or
denied as desired. Users are identified to the system by a uniquesecurity ID.
Whenauserlogson,Windows10createsa security access token thatincludes
the security IDfor the user, security IDsf o ra n yg r o u p so fw h i c ht h eu s e ri s
a member, and a list of any special privileges that the user has. Examples
of special privileges include backing u p files and directories, shutting down
the computer, logging on interactively, and changing the system clock. Every
process that Windows 10 runs on behalf of a user will receive a copy of the
access token. The system uses the security IDs in the access token to permit or
deny access to system objects whenever the user, or a process on behalf of the
user,attemptstoaccesstheobject.Authenticationofauseraccountistypically
accomplishedviaausernameandpassword,although themodulardesignof
Windows 10 allows the development of custom authentication packages. For
example,aretinal(oreye)scannermightbeusedtoverifythattheuseriswho
she saysshe is.
Windows 10 uses the idea of a subject to ensure that programs run by a
userdonotgetgreateraccesstothesystemthantheuserisauthorizedtohave.
Asubjectis used to track and manage permissions for each program that a
user runs. It is composed of the user’s access token and the program acting
on behalf of the user. Since Windows 10 operates with a client–server model,
two classes of subjects are used to control access: simple subjects and server
subjects. An example of a simple subject is the typical application program
thatauserexecutesaftershelogson.Thesimplesubjectisassigneda security"
2,16.8 Summary,798,16.7 An Example: Windows 10,"664 Chapter 16 Security
An access-control list is composed of access-control entries that contain
the security IDof the individual or group being granted access and an
access mask that defines all possible actions on the object, with a value of
AccessAllowedorAccessDeniedforeachaction.FilesinWindows10mayhave
the following access types: ReadData ,WriteData ,AppendData ,Execute ,
ReadExtendedAttribute ,WriteExtendedAttribute ,ReadAttributes ,
andWriteAttributes . We can see how this allows a fine degree of control
overaccess toobjects.
Windows 10 classifies objects as either container objects or noncontainer
objects. Container objects , such as directories, can logically contain other
objects.Bydefault,whenanobjectiscreatedwithinacontainerobject,thenew
objectinheritspermissionsfromthepare ntobject.Similarly,iftheusercopiesa
filefromonedirectorytoanewdirectory,thefilewillinheritthepermissionsof
the destination directory. Noncontainer objects inherit no other permissions.
Furthermore, if a permission is changed on a directory, the new permissions
do not automatically apply to existing files and subdirectories; the user may
explicitlyapplythemif heso desires.
ThesystemadministratorcanusetheWindows10PerformanceMonitorto
help her spot approaching problems. In general, Windows 10 does a good job
ofprovidingfeaturestohelpensureasecurecomputingenvironment.Manyof
these features are not enabled by default, however, which may be one reason
forthemyriadsecuritybreachesonWindows10systems.Anotherreasonisthe
vastnumberofservicesWindows10startsatsystemboottimeandthenumber
of applications that typically are installed on a Windows 10 system. For a real
multiuser environment, the system administrator should formulate a security
planandimplementit,usingthefeaturesthatWindows10providesandother
securitytools.
OnefeaturedifferentiatingsecurityinWindows10fromearlierversionsis
codesigning.SomeversionsofWindows 10makeitmandatory—applications
that are not properly signed by their authors will not execute—while other
versionsmakeitoptionalorleaveittotheadministratortodeterminewhat to
dowithunsigned applications.
16.8 Summary
•Protection is an internal problem. Security, in contrast, must consider
boththecomputersystemandtheenvironment—people,buildings,busi-
nesses,valuableobjects, andthreats—within which the systemis used.
•Thedata storedin thecomputer systemmustbe protectedfromunautho-
rized access, malicious destruction or a lteration, and accidental introduc-
tion of inconsistency. It is easier to protect against accidental loss of data
consistency than to protect against malicious access to the data. Absolute
protectionoftheinformationstoredinacomputersystemfrommalicious
abuse is not possible; but the cost to the perpetrator can be made suffi-
ciently high to deter most, if not all, attempts to access that information
without properauthority.
•Several types of attacks can be launched against programs and against
individual computers or the masses. Stack- and buffer-overflow tech-"
2,Further Reading,799,16.8 Summary,"Further Reading 665
niques allow successful attackers to change their level of system access.
Viruses and malware require human interaction, while worms are self-
perpetuating, sometimes infecting thousands of computers. Denial-of-
serviceattacks preventlegitimateuseof targetsystems.
•Encryption limits the domain of receivers of data, while authentication
limits the domain of senders. Encryption is used to provide confidential-
ity of data being stored or transferred. Symmetric encryption requires a
sharedkey,whileasymmetricencryptionprovidesapublickeyandapri-
vate key. Authentication, when combined with hashing, can prove that
data havenot beenchanged.
•User authentication methods are used to identify legitimate users of a
system. In addition to standard user-name and password protection, sev-
eral authentication methods are used. One-time passwords, for example,
changefromsessiontosessiontoavoidreplayattacks.Two-factorauthen-
tication requirestwo forms of authentication, such as a hardware calcula-
tor with an activation PIN, or one that presents a different response based
on the time. Multifactor authentication uses three or more forms. These
methodsgreatlydecreasethe chance of authentication forgery.
•Methods of preventing or detecting security incidents include an up-to-
datesecuritypolicy,intrusion-detect ionsystems,antivirussoftware,audit-
ing and logging of system events, system -call monitoring, code signing,
sandboxing, and firewalls.
Further Reading
Information about viruses and worms can be found at http://www.securelist.
com,aswellasin[Ludwig(1998)]and[Ludwig(2002)].Anotherwebsitecon-
tainingup-to-datesecurityinformationis http://www.eeye.com/resources/se
curity-center/research .Apaperonthedangersofacomputermonoculturecan
be found at http://cryptome.org/cyberinsecurity.htm .
The first paper discussing least privilege is a Multics overview:
https://pdfs.semanticscholar.org/ 1c8d/06510ad449ad24fbdd164f8008cc730
cab47.pdf ).
For the original article that explored buffer overflow attacks, see
http://phrack.org/issues/49/14.html . For the development version control
system git,see https://github.com/git/ .
[C. Kaufman (2002)] and [Stallings and Brown (2011)] explore the use
of cryptography in computer systems. Discussions concerning protection of
digitalsignaturesareofferedby[Akl(1983)],[Davies(1983)],[Denning(1983)],
and [Denning (1984)]. Complete cryptography information is presented in
[Schneier(1996)] and [Katzand Lindell(2008)].
Asymmetrickeyencryptionisdiscussedat https://www-ee.stanford.edu/
hellman/publications/24.pdf ). TheTLScryptographic protocol is described in
detail at https://tools.ietf.org/html/rfc5246 .T h e nmapnetwork scanning tool
is from http://www.insecure.org/nmap/ . For more information on port scans"
2,Bibliography,800,Further Reading,"666 Chapter 16 Security
andhowtheyarehidden,see http://phrack.org/issues/49/15.html .Nessusisa
commercialvulnerabilityscannerbutcanbeusedforfreewithlimitedtargets:
https://www.tenable.com/products/nessus-home .
Bibliography
[Akl (1983)] S. G. Akl, “Digital Signatures: A Tutorial Survey ”,Computer ,V o l -
ume16,Number2 (1983), pages15–24.
[C. Kaufman (2002)] M. S. C. Kaufman, R. Perlman, Network Security: Private
Communication in a Public World, SecondEdition, PrenticeHall (2002).
[Davies (1983)] D.W.Davies, “ApplyingtheRSADigitalSignaturetoElectronic
Mail ”,Computer ,Volume16,Number2(1983), pages 55–62.
[Denning (1983)] D. E. Denning, “Protecting Public Keys and Signature Keys ”,
Computer ,Volume16,Number2 (1983), pages27–35.
[Denning (1984)] D. E. Denning, “Digital Signatures with RSAand Other Pub-
lic-Key Cryptosystems ”,Communications of the ACM , Volume 27, Number 4
(1984), pages 388–392.
[Katz and Lindell (2008)] J. Katzand Y.Lindell, Introduction to Modern Cryptog-
raphy, Chapman&Hall/CRC Press(2008).
[Ludwig (1998)] M. Ludwig, The Giant Black Book of Computer Viruses, Second
Edition, AmericanEagle Publications (1998).
[Ludwig (2002)] M. Ludwig, The Little Black Book of Email Viruses ,A m e r i c a n
Eagle Publications (2002).
[Schneier (1996)] B. Schneier, Applied Cryptography, Second Edition, John Wiley
and Sons(1996).
[Stallings and Brown (2011)] W. Stallings and L. Brown, Computer Security:
Principles and Practice, SecondEdition, PrenticeHall (2011)."
2,Chapter 16 Exercises,801,Bibliography,"Exercises
Chapter 16 Exercises
16.1 Buffer-overflowattacks can be avoidedby adopting a better program-
mingmethodologyorbyusingspecialhardwaresupport.Discussthese
solutions.
16.2Apasswordmay become known to other usersina varietyof ways. Is
there a simple method for detecting that such an event has occurred?
Explainyour answer.
16.3What isthepurposeof usinga “salt”alongwithauser-providedpass-
word? Where should the salt be stored, and how should it be used?
16.4Thelistofallpasswordsiskeptintheoperatingsystem.Thus,ifauser
manages to read this list, password protection is no longer provided.
Suggest a scheme that will avoid this problem. (Hint: Use different
internal and externalrepresentations.)
16.5An experimental addition to UNIXallows a user to connect a watch-
dogprogram to a file. The watchdog is invoked whenever a program
requests access to the file. The watchdog then either grants or denies
access to the file. Discuss two pros and two cons of using watchdogs
for security.
16.6DiscussameansbywhichmanagersofsystemsconnectedtotheInter-
net could design their systems to limit or eliminate the damage done
by worms. What are the drawbacks of making the change that you
suggest?
16.7Make a list of six security concerns for a bank’s computer system. For
each item on your list, state whether this concern relates to physical,
human, or operating-systemsecurity.
16.8What are two advantages of encrypting data stored in the computer
system?
16.9What commonly used computer programs are prone to man-in-the-
middleattacks?Discuss solutions forpreventingthis form ofattack.
16.10Comparesymmetricandasymmetricencryptionschemes,anddiscuss
the circumstances under which a distributedsystemwould useone or
the other.
16.11Why doesn’t Dkd,N(Eke,N(m)) provide authentication of the sender? To
w h a tu sesc a nsu c ha nen c ryptio nb epu t?
16.12Discuss how the asymmetric encryption algorithm can be used to
achieve the following goals.
a. Authentication: the receiver knows that only the sender could
have generatedthemessage.
b. Secrecy:onlythe receivercan decryptthe message.
c. Authentication and secrecy: only the receiver can decrypt the
message,andthereceiverknowsthatonlythesendercouldhave
generatedthe message.EX-52"
1,Chapter 17 Protection,803,Chapter 16 Security,"17CHAPTER
Protection
In Chapter 16, we addressed security, which involves guarding computer
resourcesagainstunauthorizedaccess,ma liciousdestructionoralteration,and
accidentalintroductionofinconsistenc y.Inthischapter,weturntoprotection,
which involves controlling the access of processes and users to the resources
definedby a computersystem.
Theprocessesinanoperatingsystemmustbeprotectedfromoneanother’s
activities.Toprovidethisprotection ,wecanusevariousmechanismstoensure
that only processes that have gained proper authorization from the operating
systemcanoperateonthefiles,memorysegments, CPU,networking,andother
resourcesofasystem.Thesemechanismsmustprovideameansforspecifying
thecontrols to beimposed,togetherwith a meansof enforcement.
CHAPTER OBJECTIVES
•Discuss the goals and principles of protection in a modern computer
system.
•Explain how protection domains, combined with an access matrix, are
used to specify the resources a process may access.
•Examine capability- and language-based protection systems.
•Describe how protection mechanisms can mitigate system attacks.
17.1 Goals of Protection
As computer systems have become more sophisticated and pervasive in their
applications,theneedtoprotecttheirintegrityhasalsogrown.Protectionwas
originally conceived as an adjunct to multiprogramming operating systems,
sothat untrustworthy usersmightsafelyshare acommon logicalname space,
suchasadirectoryoffiles,oracommonphysicalnamespace,suchasmemory.
Modernprotectionconceptshaveevolved toincreasethereliabilityofanycom-
plex system that makes use of shared resources and is connected to insecure
communications platformssuch as the Internet.
667"
2,17.1 Goals of Protection,803,Chapter 17 Protection,"17CHAPTER
Protection
In Chapter 16, we addressed security, which involves guarding computer
resourcesagainstunauthorizedaccess,ma liciousdestructionoralteration,and
accidentalintroductionofinconsistenc y.Inthischapter,weturntoprotection,
which involves controlling the access of processes and users to the resources
definedby a computersystem.
Theprocessesinanoperatingsystemmustbeprotectedfromoneanother’s
activities.Toprovidethisprotection ,wecanusevariousmechanismstoensure
that only processes that have gained proper authorization from the operating
systemcanoperateonthefiles,memorysegments, CPU,networking,andother
resourcesofasystem.Thesemechanismsmustprovideameansforspecifying
thecontrols to beimposed,togetherwith a meansof enforcement.
CHAPTER OBJECTIVES
•Discuss the goals and principles of protection in a modern computer
system.
•Explain how protection domains, combined with an access matrix, are
used to specify the resources a process may access.
•Examine capability- and language-based protection systems.
•Describe how protection mechanisms can mitigate system attacks.
17.1 Goals of Protection
As computer systems have become more sophisticated and pervasive in their
applications,theneedtoprotecttheirintegrityhasalsogrown.Protectionwas
originally conceived as an adjunct to multiprogramming operating systems,
sothat untrustworthy usersmightsafelyshare acommon logicalname space,
suchasadirectoryoffiles,oracommonphysicalnamespace,suchasmemory.
Modernprotectionconceptshaveevolved toincreasethereliabilityofanycom-
plex system that makes use of shared resources and is connected to insecure
communications platformssuch as the Internet.
667"
2,17.2 Principles of Protection,804,17.1 Goals of Protection,"668 Chapter 17 Protection
Weneedtoprovideprotectionforseveralreasons.Themostobviousisthe
need to prevent the mischievous, intentional violation of an access restriction
byauser.Ofmoregeneralimportance,however,istheneedtoensurethateach
process in a systemuses system resourcesonly in ways consistent with stated
policies.This requirementisan absoluteone for areliablesystem.
Protectioncanimprovereliabilitybydetectinglatenterrorsattheinterfaces
between component subsystems. Early det ection of interface errors can often
prevent contamination of a healthy subsystem by a malfunctioning subsys-
tem. Also, an unprotected resource cannot defend against use (or misuse) by
an unauthorized or incompetent user. Aprotection-oriented system provides
means todistinguishbetweenauthorizedandunauthorized usage.
Theroleofprotectioninacomputersystemistoprovideamechanism for
the enforcement of the policies governing resource use. These policies can be
established in a variety of ways. Some are fixed in the design of the system,
while others are formulated by the management of a system. Still others are
defined by individual users to protect resources they “own. ”Ap r o t e c t i o n
system,then, musthavethe flexibilityto enforcea varietyof policies.
Policies for resource use may vary by application, and they may change
over time. For these reasons, protection is no longer the concern solely of
the designer of an operating system. The application programmer needs to
use protectionmechanisms as well,to guard resourcescreatedand supported
by an application subsystem against misuse. In this chapter, we describe the
protection mechanisms the operating system should provide, but application
designerscan usethemas wellindesigningtheirown protectionsoftware.
Note that mechanisms are distinct from policies. Mechanisms determine
howsomethingwillbedone;policiesdecide whatwillbedone.Theseparation
of policy and mechanism is important for flexibility. Policies are likely to
change from place to place or time to time. In the worst case, every change
inpolicywouldrequireachangeintheu nderlyingmechanism.Usinggeneral
mechanisms enablesus to avoidsuch a situation.
17.2 Principles of Protection
Frequently, a guiding principle can be used throughout a project, such as
the design of an operating system. Following this principle simplifies design
decisionsandkeepsthesystemconsistentandeasytounderstand.Akey,time-
tested guiding principle for protection is the principle of least privilege .A s
discussedinChapter16,thisprincipledictatesthatprograms,users,andeven
systemsbegivenjustenoughprivilegesto performtheirtasks.
Consider one of the tenets of UNIX—that a user should not run as root.
(InUNIX, only the root user can execute privileged commands.) Most users
innately respect that, fearing an accide ntal delete operation for which there is
nocorrespondingundelete.Becauserootisvirtuallyomnipotent,thepotential
for human error when a user acts as root is grave, and its consequences far
reaching.
Now consider that rather than human error, damage may result from
malicious attack. Avirus launched by an accidental click on an attachment is
one example. Another is a buffer overflo w or other code-injection attack that
is successfully carried out against a root-privileged process (or, in Windows,"
2,17.3 Protection Rings,805,17.2 Principles of Protection,"17.3 Protection Rings 669
a process with administrator privileges) . Either case could prove catastrophic
forthe system.
Observing the principle of least privilege would give the system a chance
tomitigatetheattack—ifmaliciouscodecannotobtainrootprivileges,thereis
a chance that adequately defined permissions may block all, or at least some,
ofthedamagingoperations.Inthissense,permissionscanactlikeanimmune
systemat theoperating-systemlevel.
The principle of least privilege takes many forms, which we examine in
more detail later in the chapter. Another important principle, often seen as a
derivative of the principle of least privilege, is compartmentalization .C o m -
partmentalization is the process of protecting each individual system compo-
nent through the use of specific permissions and access restrictions. Then, if a
component is subverted, another line of defense will “kick in ”and keep the
attacker from compromising the system any further. Compartmentalization
is implemented in many forms—from network demilitarized zones ( DMZs)
through virtualization.
The careful use of access restrictions can help make a system more secure
andcanalsobebeneficialinproducingan audit trail ,whichtracksdivergences
from allowed accesses. An audit trail is a hard record in the system logs. If
monitored closely, it can reveal early warnings of an attack or (if its integrity
ismaintaineddespiteanattack) providecluesas to which attack vectorswere
used,as wellasaccurately assessthedamagecaused.
Perhaps most importantly, no single principle is a panacea for security
vulnerabilities. Defense in depth must be used: multiple layers of protection
should be applied one on top of the other (think of a castle with a garrison,
a wall, and a moat to protect it). At the same time, of course, attackers use
multiplemeanstobypassdefenseindepth,resultinginanever-escalatingarms
race.
17.3 Protection Rings
As we’ve seen, the main component of modern operating systems is the ker-
nel, which manages access to system resources and hardware. The kernel, by
definition,isatrustedandprivilegedcomponentandthereforemustrunwith
ahigher levelofprivilegesthan userprocesses.
To carry out this privilege separation, hardware support is required.
Indeed, all modern hardware supports the notion of separate execution
levels,thoughimplementationsvarysomewhat.Apopularmodelofprivilege
separation is that of protection rin gs. In this model, fashioned after Bell
–LaPadula ( https://www.acsac.org/2005/papers/Bell.pdf ), execution is
defined as a set of concentric rings, with ring iproviding a subset of the
functionality of ring jfor any j<i. The innermost ring, ring 0,t h u sp r o v i d e s
thefullsetof privileges.This patternisshown inFigure17.1.
When the system boots, it boots to the highest privilege level. Code at
thatlevelperformsnecessaryinitializationbeforedroppingtoalessprivileged
level.In orderto returnto a higher privilegelevel,code usually calls a special
instruction, sometimes referred to as a gate, which provides a portal between
rings.The syscall instruction(inIntel)isoneexample.Callingthisinstruction
shiftsexecutionfromusertokernelmode.Aswehaveseen,executingasystem"
2,17.4 Domain of Protection,807,17.3 Protection Rings,"17.4 Domain of Protection 671
Figure 17.2 Android uses of TrustZone.
also makesbrute-forceattacks lesslikelyto succeed.(AsdescribedinChapter
16, these attacks involve trying all possible combinations of valid password
characters until the password is found.) The various keys usedby the system,
from the user’s password to the system’s own, are stored in the on-chip key,
which is only accessible in a trusted c ontext. When a key—say, a password—
is entered,it is verified via a request to the TrustZone environment. If a key is
notknownandmustbeguessed,theTrustZoneverifiercanimposelimitations
—by capping the number ofverificationattempts,for example.
In the 64-bit ARMv8 architecture, ARMextended its model to support four
levels, called “exception levels, ”numbered EL0through EL3.U s e rm o d er u n s
inEL0,a n dk e r n e lm o d ei n EL1.EL2is reserved for hypervisors, and EL3(the
mostprivileged)isreservedforthesecuremonitor(theTrustZonelayer).Any
oneof theexceptionlevelsallows running separateoperatingsystemssideby
side,as shown inFigure17.3.
Notethatthesecuremonitorrunsatahigherexecutionlevelthangeneral-
purposekernels,whichmakesittheperfectplacetodeploycodethatwillcheck
the kernels’ integrity. This functionality is included in Samsung’s Realtime
KernelProtection ( RKP) for Android and Apple’sWatchTower (also known as
KPP, for KernelPatch Protection) fori OS.
17.4 Domain of Protection
Rings of protection separate functions into domains and order them hierar-
chically. A generalization of rings is using domains without a hierarchy. A
computer system can be treated as a collection of processes and objects. By"
3,17.4.1 Domain Structure,809,17.4 Domain of Protection,"17.4 Domain of Protection 673
17.4.1 Domain Structure
To facilitate the sort of scheme just described, a process may operate within a
protection domain ,which specifiesthe resourcesthat the processmay access.
Each domain defines a set of objects and the types of operations that may be
invoked on each object. The ability to execute an operation on an object is
anaccess right . Adomain is a collection of access rights, each of which is an
orderedpair <object-name, rights-set >.Forexample,ifdomain Dhasthe
access right <file F,{read,write }>, then a process executing in domain D
canbothreadandwritefile F.Itcannot,however,performanyotheroperation
on that object.
Domains may share access rights. For example, in Figure 17.4, we have
threedomains: D1,D2,a n d D3. The accessright <O4,{print }>issharedby D2
and D3, implying that a process executing in either of these two domains can
print object O4. Note that a process must be executing in domain D1to read
andwriteobject O1,whileonlyprocessesindomain D3mayexecuteobject O1.
The association between a process and a domain may be either static,i f
the set of resources available to the process is fixed throughout the process’s
lifetime, or dynamic . As might be expected, establishing dynamic protection
domainsismorecomplicatedthan esta blishingstatic protectiondomains.
Iftheassociationbetweenprocessesanddomainsisfixed,andwewantto
adhere to the need-to-know principle, then a mechanism must be available to
change the content of a domain. The reason stems from the fact that a process
may execute in two different phases and may, for example, need read access
in one phase and write access in another. If a domain is static, we must define
thedomaintoincludeboth readand writeaccess. However,thisarrangement
providesmorerightsthanareneededineachofthetwophases,sincewehave
readaccessinthephasewhereweneedonlywriteaccess,andviceversa.Thus,
theneed-to-knowprincipleisviolated.Wemustallowthecontentsofadomain
to be modified so that the domain always reflects the minimum necessary
access rights.
If the association is dynamic, a mechanism is available to allow domain
switching ,enablingtheprocesstoswitchfromonedomaintoanother.Wemay
alsowanttoallowthecontentofadomaintobechanged.Ifwecannotchange
the content of a domain, we can provide the same effect by creating a new
domainwiththechangedcontentandswitchingtothatnewdomainwhenwe
want to change the domaincontent.
D1
< O3, {read, write} >
< O1, {read, write} >
< O2, {execute} >< O1, {execute} >
< O3, {read} >< O2, {write} ><  O4, {print} >D2 D3
Figure 17.4 System with three protection domains."
3,17.4.2 Example: UNIX,810,17.4.1 Domain Structure,"674 Chapter 17 Protection
Adomaincan berealizedin a varietyof ways:
•Each usermay be a domain. In this case, the set of objects that can be
accessed depends on the identity of the user. Domain switching occurs
whentheuserischanged—generallywhenoneuserlogsoutandanother
userlogsin.
•Each processmay be a domain. In this case, the set of objects that can be
accesseddependsontheidentityoftheprocess.Domainswitchingoccurs
when one process sends a message to an other process and then waits for
a response.
•Each procedure maybeadomain.Inthiscase,thesetofobjectsthatcanbe
accessed corresponds to the local variables defined within the procedure.
Domain switching occurs when a procedurecall ismade.
Wediscuss domainswitching in greaterdetailinSection17.5.
Considerthestandarddual-mode(kernel–usermode)modelofoperating-
system execution. When a process is in kernel mode,it can execute privileged
instructions and thus gain complete control of the computer system. In con-
trast, when a process executesin user mode, it can invoke only nonprivileged
instructions. Consequently, it can execute only within its predefined memory
space. These two modes protect the operating system (executing in kernel
domain) from the user processes (executing in user domain). In a multipro-
grammed operating system, two protection domains are insufficient, since
users also want to be protected from one another. Therefore, a more elaborate
scheme is needed. We illustrate such a scheme by examining two influential
operating systems— UNIXand Android—to see how they implement these
concepts.
17.4.2 Example: UNIX
Asnotedearlier,in UNIX,therootusercanexecuteprivilegedcommands,while
other users cannot. Restricting certain operations to the root user can impair
other users in their everyday operations, however. Consider, for example, a
user who wants to change his password. In evitably,this requiresaccess to the
passworddatabase(commonly, /etc/shadow ),whichcanonlybeaccessedby
root. A similar challenge is encountered when setting a scheduled job (using
theatcommand)—doing so requires access to privileged directories that are
beyond the reach of a normal user.
The solution to this problem is the setuid bit. In UNIX, an owner identi-
fication and a domain bit, known as the setuid bit, are associated with each
file. The setuid bit may or may not be enabled. When the bit is enabled on
an executable file (through chmod +s ), whoever executes the file temporarily
assumestheidentityofthefileowner.Thatmeansifausermanagestocreatea
filewiththeuserID “root ”andthesetuidbitenabled,anyonewhogainsaccess
toexecutethefilebecomesuser “root ”forthedurationoftheprocess’slifetime.
If that strikes you as alarming, it is with good reason. Because of their
potential power, setuid executable binaries are expected to be both sterile
(affecting only necessary files under specific constraints) and hermetic (for
example, tamperproof and impossible to subvert). Setuid programs need to"
3,17.4.3 Example: Android Application IDs,811,17.4.2 Example: UNIX,"17.5 Access Matrix 675
be very carefully written to make these assurances. Returning to the example
of changing passwords, the passwdcommand is setuid-root and will indeed
modifythepassworddatabase,butonlyiffirstpresentedwiththeuser’svalid
password, and it will then restrict itself to editing the password of that user
and only that user.
Unfortunately,experiencehasrepeatedlyshownthatfewsetuidbinaries,if
any,fulfillbothcriteriasuccessfully.Timeandagain,setuidbinarieshavebeen
subverted—some through race conditions and others through code injection
—yieldinginstant root access to attack ers. Attackersarefrequentlysuccessful
inachievingprivilegeescalationinthisway.Methodsofdoingsoarediscussed
in Chapter 16. Limiting damage from bugs in setuid programs is discussed in
Section17.8.
17.4.3 Example: Android Application IDs
InAndroid,distinctuser IDsareprovidedonaper-applicationbasis.Whenan
applicationisinstalled,the installd daemonassignsitadistinctuser ID(UID)
and group ID(GID), along with a private data directory ( /data/data/<app-
name>)whoseownershipisgrantedtothis UID/GIDcombinationalone.Inthis
way, applications on the device enjoy the same level of protection provided
byUNIXsystems to separate users. This is a quick and simple way to provide
isolation, security, and privacy. The mechanism is extended by modifying the
kernel to allow certain operations (such as networking sockets) only to mem-
bers of a particular GID(for example, AID
INET, 3003). Afurther enhancement
by Android is to define certain UIDsa s “isolated, ”which prevents them from
initiating RPCrequeststo any but a bareminimum of services.
17.5 Access Matrix
The general model of protection can be viewed abstractly as a matrix, called
anaccess matrix . The rows of the access matrix represent domains, and the
columns represent objects. Each entry in the matrix consists of a set of access
rights. Because the column defines objects explicitly, we can omit the object
name from the access right. The entry access(i,j) defines the set of operations
thata processexecutingindomain Dican invoke on object Oj.
Toillustratetheseconcepts,weconsidertheaccessmatrixshowninFigure
17.5. There are four domains and four objects—three files ( F1,F2,F3)a n do n e
laser printer. A process executing in domain D1can read files F1and F3.A
process executing in domain D4has the same privileges as one executing in
domain D1; but in addition, it can also write onto files F1and F3.T h el a s e r
printercan beaccessedonly by a processexecutingin domain D2.
Theaccess-matrixschemeprovidesuswiththemechanismforspecifyinga
varietyofpolicies.Themechanismconsistsofimplementingtheaccessmatrix
andensuringthatthesemanticpropertieswehaveoutlinedhold.Morespecif-
ically, we must ensure that a process executing in domain Dican access only
thoseobjects specifiedinrow i, and then only as allowed by the access-matrix
entries.
The access matrix can implement policy decisions concerning protection.
Thepolicydecisionsinvolvewhich rightsshouldbeincludedinthe( i,j)thentry."
2,17.5 Access Matrix,811,17.4 Domain of Protection,"17.5 Access Matrix 675
be very carefully written to make these assurances. Returning to the example
of changing passwords, the passwdcommand is setuid-root and will indeed
modifythepassworddatabase,butonlyiffirstpresentedwiththeuser’svalid
password, and it will then restrict itself to editing the password of that user
and only that user.
Unfortunately,experiencehasrepeatedlyshownthatfewsetuidbinaries,if
any,fulfillbothcriteriasuccessfully.Timeandagain,setuidbinarieshavebeen
subverted—some through race conditions and others through code injection
—yieldinginstant root access to attack ers. Attackersarefrequentlysuccessful
inachievingprivilegeescalationinthisway.Methodsofdoingsoarediscussed
in Chapter 16. Limiting damage from bugs in setuid programs is discussed in
Section17.8.
17.4.3 Example: Android Application IDs
InAndroid,distinctuser IDsareprovidedonaper-applicationbasis.Whenan
applicationisinstalled,the installd daemonassignsitadistinctuser ID(UID)
and group ID(GID), along with a private data directory ( /data/data/<app-
name>)whoseownershipisgrantedtothis UID/GIDcombinationalone.Inthis
way, applications on the device enjoy the same level of protection provided
byUNIXsystems to separate users. This is a quick and simple way to provide
isolation, security, and privacy. The mechanism is extended by modifying the
kernel to allow certain operations (such as networking sockets) only to mem-
bers of a particular GID(for example, AID
INET, 3003). Afurther enhancement
by Android is to define certain UIDsa s “isolated, ”which prevents them from
initiating RPCrequeststo any but a bareminimum of services.
17.5 Access Matrix
The general model of protection can be viewed abstractly as a matrix, called
anaccess matrix . The rows of the access matrix represent domains, and the
columns represent objects. Each entry in the matrix consists of a set of access
rights. Because the column defines objects explicitly, we can omit the object
name from the access right. The entry access(i,j) defines the set of operations
thata processexecutingindomain Dican invoke on object Oj.
Toillustratetheseconcepts,weconsidertheaccessmatrixshowninFigure
17.5. There are four domains and four objects—three files ( F1,F2,F3)a n do n e
laser printer. A process executing in domain D1can read files F1and F3.A
process executing in domain D4has the same privileges as one executing in
domain D1; but in addition, it can also write onto files F1and F3.T h el a s e r
printercan beaccessedonly by a processexecutingin domain D2.
Theaccess-matrixschemeprovidesuswiththemechanismforspecifyinga
varietyofpolicies.Themechanismconsistsofimplementingtheaccessmatrix
andensuringthatthesemanticpropertieswehaveoutlinedhold.Morespecif-
ically, we must ensure that a process executing in domain Dican access only
thoseobjects specifiedinrow i, and then only as allowed by the access-matrix
entries.
The access matrix can implement policy decisions concerning protection.
Thepolicydecisionsinvolvewhich rightsshouldbeincludedinthe( i,j)thentry."
2,17.6 Implementation of the Access Matrix,815,17.5 Access Matrix,"17.6 Implementation of the Access Matrix 679
laser
printer
read
read execute
write writeread
print
switchswitch
switchswitch
controlF1
D1D1
D2D2
D3D3
D4D4 F2 F3object
domain
Figure 17.9 Modified access matrix of Figure 17.6.
These operations on the domains and the access matrix are not in them-
selvesimportant,buttheyillustrateth eabilityoftheaccess-matrixmodeltolet
us implementand control dynamic protectionrequirements.Newobjects and
new domains can be created dynamically and included in the access-matrix
model.However,wehaveshownonlythatthebasicmechanismexists.System
designersandusersmustmakethepolicydecisionsconcerningwhichdomains
are tohave access to which objects in which ways.
17.6 Implementation of the Access Matrix
How can the access matrix be implementedeffectively?In general, the matrix
will be sparse; that is, most of the entries will be empty. Although data-
structuretechniquesareavailableforrepresentingsparsematrices,theyarenot
particularlyusefulforthisapplication,becauseofthewayinwhichtheprotec-
tion facility is used. Here, we first describe several methods of implementing
theaccess matrixand then comparethemethods.
17.6.1 Global Table
The simplest implementation of the access matrix is a global table consisting
of a set of ordered triples <domain, object, rights-set >. Whenever an
operation Mis executed on an object Ojwithin domain Di,t h eg l o b a lt a b l e
is searched for a triple <Di,Oj,Rk>,w i t h M∈Rk. If this triple is found, the
operation is allowed to continue; otherwise, an exception (or error) condition
israised.
This implementation suffers from several drawbacks. The table is usually
large and thus cannot be kept in main memory, so additional I/Ois needed.
Virtualmemorytechniquesareoftenusedformanagingthistable.Inaddition,
it is difficult to take advantage of special groupings of objects or domains.
For example, if everyone can read a particular object, this object must have
aseparateentryineverydomain.
17.6.2 Access Lists for Objects
Each column in the access matrix can be implemented as an access list for
one object, as described in Section 13.4.2. Obviously, the empty entries can be"
3,17.6.1 Global Table,815,17.6 Implementation of the Access Matrix,"17.6 Implementation of the Access Matrix 679
laser
printer
read
read execute
write writeread
print
switchswitch
switchswitch
controlF1
D1D1
D2D2
D3D3
D4D4 F2 F3object
domain
Figure 17.9 Modified access matrix of Figure 17.6.
These operations on the domains and the access matrix are not in them-
selvesimportant,buttheyillustrateth eabilityoftheaccess-matrixmodeltolet
us implementand control dynamic protectionrequirements.Newobjects and
new domains can be created dynamically and included in the access-matrix
model.However,wehaveshownonlythatthebasicmechanismexists.System
designersandusersmustmakethepolicydecisionsconcerningwhichdomains
are tohave access to which objects in which ways.
17.6 Implementation of the Access Matrix
How can the access matrix be implementedeffectively?In general, the matrix
will be sparse; that is, most of the entries will be empty. Although data-
structuretechniquesareavailableforrepresentingsparsematrices,theyarenot
particularlyusefulforthisapplication,becauseofthewayinwhichtheprotec-
tion facility is used. Here, we first describe several methods of implementing
theaccess matrixand then comparethemethods.
17.6.1 Global Table
The simplest implementation of the access matrix is a global table consisting
of a set of ordered triples <domain, object, rights-set >. Whenever an
operation Mis executed on an object Ojwithin domain Di,t h eg l o b a lt a b l e
is searched for a triple <Di,Oj,Rk>,w i t h M∈Rk. If this triple is found, the
operation is allowed to continue; otherwise, an exception (or error) condition
israised.
This implementation suffers from several drawbacks. The table is usually
large and thus cannot be kept in main memory, so additional I/Ois needed.
Virtualmemorytechniquesareoftenusedformanagingthistable.Inaddition,
it is difficult to take advantage of special groupings of objects or domains.
For example, if everyone can read a particular object, this object must have
aseparateentryineverydomain.
17.6.2 Access Lists for Objects
Each column in the access matrix can be implemented as an access list for
one object, as described in Section 13.4.2. Obviously, the empty entries can be"
3,17.6.2 Access Lists for Objects,815,17.6.1 Global Table,"17.6 Implementation of the Access Matrix 679
laser
printer
read
read execute
write writeread
print
switchswitch
switchswitch
controlF1
D1D1
D2D2
D3D3
D4D4 F2 F3object
domain
Figure 17.9 Modified access matrix of Figure 17.6.
These operations on the domains and the access matrix are not in them-
selvesimportant,buttheyillustrateth eabilityoftheaccess-matrixmodeltolet
us implementand control dynamic protectionrequirements.Newobjects and
new domains can be created dynamically and included in the access-matrix
model.However,wehaveshownonlythatthebasicmechanismexists.System
designersandusersmustmakethepolicydecisionsconcerningwhichdomains
are tohave access to which objects in which ways.
17.6 Implementation of the Access Matrix
How can the access matrix be implementedeffectively?In general, the matrix
will be sparse; that is, most of the entries will be empty. Although data-
structuretechniquesareavailableforrepresentingsparsematrices,theyarenot
particularlyusefulforthisapplication,becauseofthewayinwhichtheprotec-
tion facility is used. Here, we first describe several methods of implementing
theaccess matrixand then comparethemethods.
17.6.1 Global Table
The simplest implementation of the access matrix is a global table consisting
of a set of ordered triples <domain, object, rights-set >. Whenever an
operation Mis executed on an object Ojwithin domain Di,t h eg l o b a lt a b l e
is searched for a triple <Di,Oj,Rk>,w i t h M∈Rk. If this triple is found, the
operation is allowed to continue; otherwise, an exception (or error) condition
israised.
This implementation suffers from several drawbacks. The table is usually
large and thus cannot be kept in main memory, so additional I/Ois needed.
Virtualmemorytechniquesareoftenusedformanagingthistable.Inaddition,
it is difficult to take advantage of special groupings of objects or domains.
For example, if everyone can read a particular object, this object must have
aseparateentryineverydomain.
17.6.2 Access Lists for Objects
Each column in the access matrix can be implemented as an access list for
one object, as described in Section 13.4.2. Obviously, the empty entries can be"
3,17.6.3 Capability Lists for Domains,816,17.6.2 Access Lists for Objects,"680 Chapter 17 Protection
discarded.Theresultinglistforeachobjectconsistsoforderedpairs <domain,
rights-set >, which define all domains with a nonempty set of access rights
for that object.
This approach can be extended easily to define a list plus a defaultset of
accessrights.Whenanoperation Monanobject Ojisattemptedindomain Di,
we search the access list for object Oj, looking for an entry <Di,Rk>with M∈
Rk.Iftheentryisfound,weallowtheoperation;ifitisnot,wecheckthedefault
set. If Mis in the default set, we allow the access. Otherwise, access is denied,
andanexceptionconditionoccurs.Forefficiency,wemaycheckthedefaultset
first and thensearch the access list.
17.6.3 Capability Lists for Domains
Rather than associating the columns of the access matrix with the objects as
access lists, we can associate each row with its domain. A capability list for
a domain is a list of objects together with the operations allowed on those
objects. An object is often represented by its physical name or address, called
acapability .T oe x e c u t eo p e r a t i o n Mon object Oj,t h ep r o c e s se x e c u t e st h e
operation M,specifyingthecapability(orpointer)forobject Ojasaparameter.
Simple possession of the capabilitymeans that access isallowed.
The capability list is associated with a domain, but it is never directly
accessible to a process executing in that domain. Rather, the capability list
is itself a protected object, maintai ned by the operating system and accessed
by the user only indirectly. Capability- based protection relies on the fact that
the capabilities are never allowed to mig rate into any address space directly
accessible by a user process (where they could be modified). If all capabilities
aresecure,the object theyprotectisal so secureagainst unauthorized access.
Capabilities were originally proposed as a kind of secure pointer, to meet
the need for resource protection that was foreseen as multiprogrammed com-
putersystemscameofage.Theideaofaninherentlyprotectedpointerprovides
a foundationfor protectionthat can beextendedupto theapplicationlevel.
Toprovideinherentprotection,wemustdistinguishcapabilitiesfromother
kindsofobjects,andtheymustbeinterpretedbyanabstractmachineonwhich
higher-level programs run. Capabilitie s are usually distinguished from other
datain one of two ways:
•Each object has a tagto denote whether it is a capability or accessible
data.Thetagsthemselvesmustnotbedirectlyaccessiblebyanapplication
program. Hardware or firmware support may be used to enforce this
restriction. Although only one bit is necessary to distinguish between
capabilities and other objects, more bits are often used. This extension
allows all objects to be tagged with their types by the hardware. Thus,
the hardware can distinguish integers, floating-point numbers, pointers,
Booleans,characters,instructions,capabilities,anduninitializedvaluesby
theirtags.
•Alternatively,theaddressspaceassociatedwithaprogramcanbesplitinto
twoparts.Onepartisaccessibletotheprogramandcontainstheprogram’s
normaldataandinstructions.Theotherpart,containingthecapabilitylist,
is accessible only by the operating system. Asegmentedmemory space is
usefulto supportthisapproach."
3,17.6.4 A Lock–Key Mechanism,817,17.6.3 Capability Lists for Domains,"17.6 Implementation of the Access Matrix 681
Severalcapability-basedprotectionsystemshavebeendeveloped;wedescribe
them briefly in Section 17.10. The Mach operating system also uses a version
ofcapability-based protection;it isdescribedinAppendixD.
17.6.4 A Lock–Key Mechanism
Thelock–key scheme isacompromisebetweenaccesslistsandcapabilitylists.
Eachobjecthasalistofuniquebitpatternscalled locks.Similarly,eachdomain
has a list of unique bit patterns called keys. Aprocess executing in a domain
canaccessanobjectonlyifthatdomainhasakeythatmatchesoneofthelocks
ofthe object.
As with capability lists, the list of keys for a domain must be managed by
theoperatingsystemonbehalfofthedomain.Usersarenotallowedtoexamine
ormodifythe listof keys(or locks) directly.
17.6.5 Comparison
Asyoumightexpect,choosingatechniqueforimplementinganaccessmatrix
involves various trade-offs. Using a global table is simple; however, the table
can be quite large and often cannot take advantage of special groupings of
objects or domains. Access lists correspond directly to the needs of users.
When a user creates an object, he can specify which domains can access the
object, as well as what operations are allowed. However, because access-right
information for a particular domain is not localized, determining the set of
accessrightsforeachdomainisdifficult.Inaddition,everyaccesstotheobject
must be checked, requiring a search of the access list. In a large system with
long accesslists,thissearch can be time consuming.
Capability lists do not correspond directly to the needs of users, but they
are useful for localizing information for a givenprocess.The process attempt-
ingaccessmustpresentacapabilityfor thataccess.Then,theprotectionsystem
needs only to verify that the capability is valid. Revocation of capabilities,
however,may beinefficient (Section17.7).
The lock–key mechanism, as mentioned, is a compromise between access
lists and capability lists. The mechanism can be both effective and flexible,
depending on the length of the keys. The keys can be passed freely from
domaintodomain.Inaddition,accessprivilegescanbeeffectivelyrevokedby
the simple technique of changing some of the locks associated with the object
(Section17.7).
Most systems use a combination of access lists and capabilities. When a
process first tries to access an object, the access list is searched. If access is
denied, an exception condition occurs. Otherwise, a capability is created and
attachedtotheprocess.Additionalrefe rencesusethecapabilitytodemonstrate
swiftlythataccessisallowed.Afterthelastaccess,thecapabilityisdestroyed.
Thisstrategywas usedinthe MULTICS systemand in the CALsystem.
As an example of how such a strategy works, consider a file system in
which each file has an associated access list. When a process opens a file, the
directorystructureissearchedtofindthefile,accesspermissionischecked,and
buffers are allocated. All this information is recorded in a new entry in a file
tableassociatedwiththeprocess.Theoperationreturnsanindexintothistable
for the newly opened file. All operations on the file are made by specification
of the index into the file table. The entry in the file table then points to the file"
3,17.6.5 Comparison,817,17.6.4 A Lock–Key Mechanism,"17.6 Implementation of the Access Matrix 681
Severalcapability-basedprotectionsystemshavebeendeveloped;wedescribe
them briefly in Section 17.10. The Mach operating system also uses a version
ofcapability-based protection;it isdescribedinAppendixD.
17.6.4 A Lock–Key Mechanism
Thelock–key scheme isacompromisebetweenaccesslistsandcapabilitylists.
Eachobjecthasalistofuniquebitpatternscalled locks.Similarly,eachdomain
has a list of unique bit patterns called keys. Aprocess executing in a domain
canaccessanobjectonlyifthatdomainhasakeythatmatchesoneofthelocks
ofthe object.
As with capability lists, the list of keys for a domain must be managed by
theoperatingsystemonbehalfofthedomain.Usersarenotallowedtoexamine
ormodifythe listof keys(or locks) directly.
17.6.5 Comparison
Asyoumightexpect,choosingatechniqueforimplementinganaccessmatrix
involves various trade-offs. Using a global table is simple; however, the table
can be quite large and often cannot take advantage of special groupings of
objects or domains. Access lists correspond directly to the needs of users.
When a user creates an object, he can specify which domains can access the
object, as well as what operations are allowed. However, because access-right
information for a particular domain is not localized, determining the set of
accessrightsforeachdomainisdifficult.Inaddition,everyaccesstotheobject
must be checked, requiring a search of the access list. In a large system with
long accesslists,thissearch can be time consuming.
Capability lists do not correspond directly to the needs of users, but they
are useful for localizing information for a givenprocess.The process attempt-
ingaccessmustpresentacapabilityfor thataccess.Then,theprotectionsystem
needs only to verify that the capability is valid. Revocation of capabilities,
however,may beinefficient (Section17.7).
The lock–key mechanism, as mentioned, is a compromise between access
lists and capability lists. The mechanism can be both effective and flexible,
depending on the length of the keys. The keys can be passed freely from
domaintodomain.Inaddition,accessprivilegescanbeeffectivelyrevokedby
the simple technique of changing some of the locks associated with the object
(Section17.7).
Most systems use a combination of access lists and capabilities. When a
process first tries to access an object, the access list is searched. If access is
denied, an exception condition occurs. Otherwise, a capability is created and
attachedtotheprocess.Additionalrefe rencesusethecapabilitytodemonstrate
swiftlythataccessisallowed.Afterthelastaccess,thecapabilityisdestroyed.
Thisstrategywas usedinthe MULTICS systemand in the CALsystem.
As an example of how such a strategy works, consider a file system in
which each file has an associated access list. When a process opens a file, the
directorystructureissearchedtofindthefile,accesspermissionischecked,and
buffers are allocated. All this information is recorded in a new entry in a file
tableassociatedwiththeprocess.Theoperationreturnsanindexintothistable
for the newly opened file. All operations on the file are made by specification
of the index into the file table. The entry in the file table then points to the file"
2,17.7 Revocation of Access Rights,818,17.6 Implementation of the Access Matrix,"682 Chapter 17 Protection
and itsbuffers.When the file is closed,the file-table entryisdeleted.Since the
file table is maintained by the operating system, the user cannot accidentally
corrupt it. Thus, the user can access only those files that have been opened.
Since access is checked when the file is opened, protection is ensured. This
strategyisusedinthe UNIXsystem.
The right to access must still be checked on each access, and the file-table
entry has a capability only for the allowed operations. If a file is opened for
reading, then a capability for read acce ss is placed in the file-table entry. If
an attempt is made to write onto the file, the system identifies this protection
violationbycomparingtherequestedoperationwiththecapabilityinthefile-
table entry.
17.7 Revocation of Access Rights
In a dynamic protection system, we may sometimes need to revoke access
rights to objects shared by differentusers. Various questions about revocation
may arise:
•Immediate versus delayed . Does revocation occur immediately, or is it
delayed?Ifrevocationisdelayed,canwefindoutwhenitwilltakeplace?
•Selective versus general . When an access right to an object is revoked,
does it affect all the users who have an access right to that object, or can
wespecifyaselectgroupofuserswhoseaccessrightsshouldberevoked?
•Partial versus total .Canasubsetoftherightsassociatedwithanobjectbe
revoked,or mustwe revokeall access rightsfor thisobject?
•Temporary versus permanent . Can access be revoked permanently (that
is,therevokedaccessrightwillneveragainbeavailable),orcanaccessbe
revokedand laterbe obtained again?
Withanaccess-listscheme,revocationiseasy.Theaccesslistissearchedfor
any access rightsto be revoked,and they aredeletedfrom the list.Revocation
isimmediateandcanbegeneralorselective,totalorpartial,andpermanentor
temporary.
Capabilities, however, present a much more difficult revocation problem,
asmentionedearlier.Sincethecapabilit iesaredistributedthroughoutthesys-
tem, we must find them before we can revoke them. Schemes that implement
revocationfor capabilitiesincludethefollowing:
•Reacquisition .Periodically,capabilitiesaredeletedfromeachdomain.Ifa
process wants to use a capability, it may find that that capability has been
deleted.The processmaythentryto reacquirethecapability.Ifaccess has
beenrevoked,the processwillnot be ableto reacquirethecapability.
•Back-pointers . Alist of pointers is maintained with each object, pointing
toallcapabilitiesassociatedwiththatobject.Whenrevocationisrequired,
we can follow these pointers, changing the capabilities as necessary. This
scheme was adopted in the MULTICS system. It is quite general, but its
implementationis costly."
2,17.8 Role-Based Access Control,819,17.7 Revocation of Access Rights,"17.8 Role-Based Access Control 683
•Indirection . The capabilities point indirectly, not directly, to the objects.
Each capability points to a unique entry in a global table, which in turn
pointstotheobject.Weimplementrevo cationbysearchingtheglobaltable
for the desired entry and deleting it. Then, when an access is attempted,
the capability is found to point to an illegal table entry. Table entries can
bereusedforothercapabilitieswithoutdifficulty,sinceboththecapability
and the table entry contain the unique name of the object. The object for a
capabilityanditstableentrymustmatch.Thisschemewasadoptedinthe
CALsystem.Itdoesnot allowselectiverevocation.
•Keys.Akeyisauniquebitpatternthatcanbeassociatedwithacapability.
This key is defined when the capability is created, and it can be neither
modified nor inspected by the process that owns the capability. A master
keyis associated with each object; it can be defined or replaced with
theset-key operation. When a capability is created, the current value
of the master key is associated with the capability. When the capability
is exercised, its key is compared with the master key. If the keys match,
the operation is allowed to continue; otherwise, an exception condition
is raised. Revocation replaces the master key with a new value via the
set-key operation,invalidatingallpreviouscapabilitiesfor thisobject.
Thisscheme doesnot allowselectiverevocation,since only one master
key is associated with each object. If we associate a list of keys with each
object,thenselectiverevocationcanbeimplemented.Finally,wecangroup
all keys into one global table of keys. A capability is valid only if its
key matches some key in the global table. We implement revocation by
removing the matching key from the table. With this scheme, a key can
beassociatedwithseveralobjects,andseveralkeyscanbeassociatedwith
each object,providingmaximumflexibility.
In key-based schemes, the operatio ns of defining keys, inserting them
intolists,anddeletingthemfromlistsshouldnotbeavailabletoallusers.
Inparticular,itwouldbereasonabletoallowonlytheownerofanobjectto
set the keys for that object. This choice, however, is a policy decision that
the protectionsystemcanimplementbut should not define.
17.8 Role-Based Access Control
InSection13.4.2,wedescribedhowaccesscontrolscanbeusedonfileswithin
afilesystem.Eachfileanddirectoryisassignedanowner,agroup,orpossibly
a list of users, and for each of those entities, access-control information is
assigned. A similar function can be added to other aspects of a computer
system.Agood exampleof this isfound inSolaris10 and laterversions.
The idea is to advance the protection available in the operating system by
explicitly adding the principle of least privilege via role-based access control
(RBAC). This facility revolves around privileges. A privilege is the right to
execute a system call or to use an option within that system call (such as
opening a file with write access). Privileges can be assigned to processes,
limitingthemtoexactlytheaccesstheyneedtoperformtheirwork.Privileges
andprogramscanalsobeassignedto roles.Usersareassignedrolesorcantake
roles based on passwords assigned to the roles. In this way, a user can take a"
2,17.9 Mandatory Access Control (MAC),820,17.8 Role-Based Access Control,"684 Chapter 17 Protection
user 1
role 1
privileges 1
executes with role 1 privilegesprivileges 2
process
Figure 17.10 Role-based access control in Solaris 10.
rolethatenablesaprivilege,allowingtheusertorunaprogramtoaccomplish
a specific task, as depicted in Figure 17.10. This implementation of privileges
decreasesthesecurityriskassociatedwithsuperusersand setuidprograms.
Notice that this facility is similar to the access matrix described in Section
17.5. This relationship is further explored in the exercises at the end of the
chapter.
17.9 Mandatory Access Control (MAC)
Operatingsystemshavetraditionallyused discretionary access control (DAC)
as a means of restricting access to files and other system objects. With DAC,
access is controlled based on the identities of individual users or groups. In
UNIX-basedsystem, DACtakestheformoffilepermissions(settableby chmod,
chown,a n d chgrp), whereas Windows (and some UNIXvariants) allow finer
granularity bymeans of access-control lists( ACLs).
DACs, however, have proved insufficient over the years. A key weakness
lies in their discretionary nature, which allows the owner of a resource to set
or modify its permissions. Another weakness is the unlimited access allowed
for the administrator or root user. As we have seen, this design can leave the
system vulnerable to both accidental and malicious attacks and provides no
defensewhen hackersobtain rootprivileges.
The need arose, therefore, for a stronger form of protection, which was
introducedintheformof mandatory access control (MAC).MACisenforcedas
asystempolicythateventherootusercannotmodify(unlessthepolicyexplic-
itly allows modifications or the system is rebooted, usually into an alternate
configuration). The restrictions imposed by MACp o l i c yr u l e sa r em o r ep o w -
erful than the capabilities of the root user and can be used to make resources
inaccessible toanyone but theirintendedowners."
2,17.10 Capability-Based Systems,821,17.9 Mandatory Access Control (MAC),"17.10 Capability-Based Systems 685
Modern operating systems all provide MACalong with DAC,a l t h o u g h
implementations differ. Solaris was among the first to introduce MAC,w h i c h
was part of Trusted Solaris (2.5). Free BSDmadeDACpart of its Trusted BSD
implementation (Free BSD5.0). The Free BSDimplementation was adopted by
Apple in mac OS10.5 and has served as the substrate over which most of the
security features of MACand iOSare implemented. Linux’s MACimplemen-
tation is part of the SELinux project, which was devised by the NSA, and has
been integrated into most distribution s. Microsoft Windows joined the trend
with Windows Vista’s Mandatory IntegrityControl.
Attheheartof MACistheconceptof labels.Alabelisanidentifier(usually
a string) assigned to an object (files, devices, and the like). Labels may also
be applied to subjects (actors, such as processes). When a subject request to
performoperationsontheobjects.Whensuchrequestsaretobeservedbythe
operating system, it first performs checks defined in a policy, which dictates
whetherornotagivenlabelholdingsubjectisallowedtoperformtheoperation
onthelabeledobject.
As a brief example, consider a simple set of labels, ordered according to
levelofprivilege: “unclassified, ”“secret, ”and “topsecret. ”Auserwith “secret ”
clearancewillbeabletocreatesimilarl ylabeledprocesses,whichwillthenhave
access to “unclassified ”and “secret ”files, but not to “top secret ”files. Neither
theusernor itsprocesseswouldevenbeawareof theexistenceof “top secret ”
files, since the operating system would filter them out of all file operations
(for example, they would not be displayed when listing directory contents).
User processes would similarly be protected themselves in this way, so that
an""unclassified""processwouldnotbeabletoseeorperform IPCrequeststoa
“secret ”(or“topsecret ”)process.Inthisway, MAClabelsareanimplementation
ofthe access matrixdescribedearlier.
17.10 Capability-Based Systems
Theconceptof capability-based protection wasintroducedintheearly1970s.
Two early research systems were Hydra and CAP. Neither system was widely
used, but both provided interesting proving grounds for protection theories.
Formoredetailsonthesesystems,seeSectionA.14.1andSectionA.14.2.Here,
weconsidertwo morecontemporary approaches tocapabilities.
17.10.1 Linux Capabilities
Linuxusescapabilitiestoaddressthelimitationsofthe UNIXmodel,whichwe
described earlier. The POSIXstandards group introduced capabilities in POSIX
1003.1e. Although POSIX.1e was eventually withdrawn, Linux was quick to
adoptcapabilitiesinVersion2.2andhascontinuedtoaddnewdevelopments.
In essence, Linux’s capabilities “slice up ”the powers of root into distinct
areas, each represented by a bit in a bitmask, as shown in Figure 17.11. Fine-
grainedcontrol overprivilegedoperationscanbe achievedby togglingbitsin
thebitmask.
In practice, three bitmasks are used—denoting the capabilities permitted,
effective, and inheritable. Bitmaskscanapplyonaper-processoraper-thread
basis.Furthermore,oncerevoked,capabilitiescannotbereacquired.Theusual"
3,17.10.1 Linux Capabilities,821,17.10 Capability-Based Systems,"17.10 Capability-Based Systems 685
Modern operating systems all provide MACalong with DAC,a l t h o u g h
implementations differ. Solaris was among the first to introduce MAC,w h i c h
was part of Trusted Solaris (2.5). Free BSDmadeDACpart of its Trusted BSD
implementation (Free BSD5.0). The Free BSDimplementation was adopted by
Apple in mac OS10.5 and has served as the substrate over which most of the
security features of MACand iOSare implemented. Linux’s MACimplemen-
tation is part of the SELinux project, which was devised by the NSA, and has
been integrated into most distribution s. Microsoft Windows joined the trend
with Windows Vista’s Mandatory IntegrityControl.
Attheheartof MACistheconceptof labels.Alabelisanidentifier(usually
a string) assigned to an object (files, devices, and the like). Labels may also
be applied to subjects (actors, such as processes). When a subject request to
performoperationsontheobjects.Whensuchrequestsaretobeservedbythe
operating system, it first performs checks defined in a policy, which dictates
whetherornotagivenlabelholdingsubjectisallowedtoperformtheoperation
onthelabeledobject.
As a brief example, consider a simple set of labels, ordered according to
levelofprivilege: “unclassified, ”“secret, ”and “topsecret. ”Auserwith “secret ”
clearancewillbeabletocreatesimilarl ylabeledprocesses,whichwillthenhave
access to “unclassified ”and “secret ”files, but not to “top secret ”files. Neither
theusernor itsprocesseswouldevenbeawareof theexistenceof “top secret ”
files, since the operating system would filter them out of all file operations
(for example, they would not be displayed when listing directory contents).
User processes would similarly be protected themselves in this way, so that
an""unclassified""processwouldnotbeabletoseeorperform IPCrequeststoa
“secret ”(or“topsecret ”)process.Inthisway, MAClabelsareanimplementation
ofthe access matrixdescribedearlier.
17.10 Capability-Based Systems
Theconceptof capability-based protection wasintroducedintheearly1970s.
Two early research systems were Hydra and CAP. Neither system was widely
used, but both provided interesting proving grounds for protection theories.
Formoredetailsonthesesystems,seeSectionA.14.1andSectionA.14.2.Here,
weconsidertwo morecontemporary approaches tocapabilities.
17.10.1 Linux Capabilities
Linuxusescapabilitiestoaddressthelimitationsofthe UNIXmodel,whichwe
described earlier. The POSIXstandards group introduced capabilities in POSIX
1003.1e. Although POSIX.1e was eventually withdrawn, Linux was quick to
adoptcapabilitiesinVersion2.2andhascontinuedtoaddnewdevelopments.
In essence, Linux’s capabilities “slice up ”the powers of root into distinct
areas, each represented by a bit in a bitmask, as shown in Figure 17.11. Fine-
grainedcontrol overprivilegedoperationscanbe achievedby togglingbitsin
thebitmask.
In practice, three bitmasks are used—denoting the capabilities permitted,
effective, and inheritable. Bitmaskscanapplyonaper-processoraper-thread
basis.Furthermore,oncerevoked,capabilitiescannotbereacquired.Theusual"
3,17.10.2 Darwin Entitlements,822,17.10.1 Linux Capabilities,"686 Chapter 17 Protection
WI C
Figure 17.11 Capabilities in POSIX.1e.
sequenceofeventsisthataprocessorthreadstartswiththefullsetofpermitted
capabilities and voluntarily decreases that set during execution. For example,
afteropeninganetworkport,athreadmightremovethatcapabilitysothatno
furtherports can be opened.
You can probably see that capabilities are a direct implementation of the
principle of least privilege. As explained earlier, this tenet of security dictates
that an application or user must be given only those rights than are required
for itsnormal operation.
Android(which is based on Linux) also utilizescapabilities,which enable
system processes (notably, “system server ”), to avoid root ownership, instead
selectivelyenabling only thoseoperations required.
The Linux capabilities model is a gre at improvement over the traditional
UNIXmodel, but it still is inflexible. For one thing, using a bitmap with a bit
representing each capability makes it impossible to add capabilities dynami-
callyandrequiresrecompilingthekerneltoaddmore.Inaddition,thefeature
appliesonly to kernel-enforcedcapabilities.
17.10.2 Darwin Entitlements
Apple’s system protection takes the form of entitlements. Entitlements are
declaratory permissions— XMLproperty list stating which permissions are
claimed as necessary by the program (see Figure 17.12). When the process
attempts a privileged operation (in the figure, loading a kernel extension), its"
2,17.11 Other Protection Improvement Methods,823,17.10 Capability-Based Systems,"17.11 Other Protection Improvement Methods 687
<!DOCTYPEplistPUBLIC""-//Apple//DTDPLIST1.0//EN""
""http://www.apple.com/DTDs/PropertyList-1.0.dtd"">
<plist version=""1.0"">
<dict>
<key>com.apple.private.kernel.get-kext-info
<true/>
<key>com.apple.rootless.kext-management
<true/>
</dict>
</plist>
Figure 17.12 Apple Darwin entitlements
entitlementsarechecked,andonlyiftheneededentitlementsarepresentisthe
operationallowed.
To prevent programs from arbitrarily claiming an entitlement, Apple
embeds the entitlements in the code signature (explained in Section 17.11.4).
Once loaded, a process has no way of accessing its code signature. Other
processes(andthekernel)caneasilyquerythesignature,andinparticularthe
entitlements. Verifying an entitlement is therefore a simple string-matching
operation. In this way, only verifiab le, authenticated apps may claim
entitlements. All system entitlements ( com.apple.* ) are further restricted to
Apple’sown binaries.
17.11 Other Protection Improvement Methods
As the battle to protect systems from accidental and malicious damage esca-
lates, operating-system designers are implementing more types of protection
mechanisms at more levels. This section surveys some important real-world
protectionimprovements.
17.11.1 System Integrity Protection
Apple introduced in mac OS10.11 a new protection mechanism called System
Integrity Protection (SIP). Darwin-based operating systems use SIPto restrict
access to system files and resources in such a way that even the root user
cannottamperwiththem. SIPusesextendedattributesonfilestomarkthemas
restrictedandfurtherprotectssystembi nariessothattheycannotbedebugged
or scrutinized, much less tampered with. Most importantly, only code-signed
kernelextensionsarepermitted,and SIPcanfurtherbeconfiguredtoallowonly
code-signedbinariesas well.
UnderSIP,althoughrootisstillthemostpowerfuluserinthesystem,itcan
dofarlessthanbefore.Therootusercanstillmanageotherusers’files,aswell
asinstallandremoveprograms,butnotinanywaythatwouldreplaceormod-
ify operating-system components. SIPis implementedas a global, inescapable"
3,17.11.1 System Integrity Protection,823,17.11 Other Protection Improvement Methods,"17.11 Other Protection Improvement Methods 687
<!DOCTYPEplistPUBLIC""-//Apple//DTDPLIST1.0//EN""
""http://www.apple.com/DTDs/PropertyList-1.0.dtd"">
<plist version=""1.0"">
<dict>
<key>com.apple.private.kernel.get-kext-info
<true/>
<key>com.apple.rootless.kext-management
<true/>
</dict>
</plist>
Figure 17.12 Apple Darwin entitlements
entitlementsarechecked,andonlyiftheneededentitlementsarepresentisthe
operationallowed.
To prevent programs from arbitrarily claiming an entitlement, Apple
embeds the entitlements in the code signature (explained in Section 17.11.4).
Once loaded, a process has no way of accessing its code signature. Other
processes(andthekernel)caneasilyquerythesignature,andinparticularthe
entitlements. Verifying an entitlement is therefore a simple string-matching
operation. In this way, only verifiab le, authenticated apps may claim
entitlements. All system entitlements ( com.apple.* ) are further restricted to
Apple’sown binaries.
17.11 Other Protection Improvement Methods
As the battle to protect systems from accidental and malicious damage esca-
lates, operating-system designers are implementing more types of protection
mechanisms at more levels. This section surveys some important real-world
protectionimprovements.
17.11.1 System Integrity Protection
Apple introduced in mac OS10.11 a new protection mechanism called System
Integrity Protection (SIP). Darwin-based operating systems use SIPto restrict
access to system files and resources in such a way that even the root user
cannottamperwiththem. SIPusesextendedattributesonfilestomarkthemas
restrictedandfurtherprotectssystembi nariessothattheycannotbedebugged
or scrutinized, much less tampered with. Most importantly, only code-signed
kernelextensionsarepermitted,and SIPcanfurtherbeconfiguredtoallowonly
code-signedbinariesas well.
UnderSIP,althoughrootisstillthemostpowerfuluserinthesystem,itcan
dofarlessthanbefore.Therootusercanstillmanageotherusers’files,aswell
asinstallandremoveprograms,butnotinanywaythatwouldreplaceormod-
ify operating-system components. SIPis implementedas a global, inescapable"
3,17.11.2 System-Call Filtering,824,17.11.1 System Integrity Protection,"688 Chapter 17 Protection
screen on all processes, with the only exceptions allowed for system bina-
ries (for example, fsck,o rkextload , as shown in Figure 17.12), which are
specificallyentitledfor operationsfor theirdesignatedpurpose.
17.11.2 System-Call Filtering
Recall from Chapter 2 that monolithic systems place all of the functionality
of the kernel into a single file that runs in a single address space. Commonly,
general-purpose operating-system kernels are monolithic, and they are there-
fore implicitly trusted as secure. The t rust boundary, therefore, rests between
kernel mode and user mode—at the system layer. We can reasonably assume
thatanyattempttocompromisethesystem’sintegritywillbemadefromuser
modebymeansofasystemcall.Forexample,anattackercantrytogainaccess
by exploitingan unprotectedsystemcall.
Itisthereforeimperativetoimplementsomeformof system-call filtering.
To accomplish this, we can add code to the kernel to perform an inspection
at the system-call gate, restricting a caller to a subset of system calls deemed
safe or required for that caller’s function. Specific system-call profiles can be
constructedforindividualprocesses.TheLinuxmechanism SECCOMP-BPF does
justthat,harnessing theBerkeleyPacketFilterlanguagetoloadacustompro-
file through Linux’s proprietary prctlsystem call. This filtering is voluntary
but can be effectively enforced if called from within a run-time library when
it initializes or from within the loader itself before it transfers control to the
program’s entrypoint.
A second form of system-call filtering goes deeper still and inspects the
arguments of each system call. This form of protection is considered much
stronger, as even apparently benign system calls can harbor serious vulner-
abilities.ThiswasthecasewithLinux’sfastmutex( futex)systemcall.Arace
condition in its implementation led to an attacker-controlled kernel memory
overwrite and total system compromise. Mutexes are a fundamental compo-
nent of multitasking, and thus the system call itself could not be filtered out
entirely.
Achallengeencounteredwithbothapproachesiskeepingthemasflexible
as possible while at the same time avoiding the need to rebuild the kernel
when changes or new filters are required—a common occurrence due to the
differingneeds of differentprocesses. Flexibilityis especiallyimportant given
theunpredictablenatureofvulnerabilit ies.Newvulnerabilitiesarediscovered
everydayand may beimmediatelyexploitableby attackers.
Oneapproachtomeetingthischallengeistodecouplethefilterimplemen-
tation from the kernel itself. The kernel need only contain a set of callouts,
which can then be implemented in a specialized driver (Windows), kernel
module (Linux), or extension (Darwin). Because an external, modular com-
ponent provides the filtering logic, it can be updated independently of the
kernel. This component commonly makes use of a specialized profiling lan-
guage by including a built-in interpreter or parser. Thus, the profile itself can
bedecoupledfromthecode,providingahuman-readable,editableprofileand
further simplifying updates. It is also possible for the filtering component to
call atrusteduser-modedaemonprocesstoassist withvalidationlogic."
3,17.11.3 Sandboxing,825,17.11.2 System-Call Filtering,"17.11 Other Protection Improvement Methods 689
17.11.3 Sandboxing
Sandboxing involves running processes in environments that limit what they
can do. In a basic system, a process runs with the credentials of the user that
started it and has access to all things that the user can access. If run with
system privileges such as root, the process can literally do anything on the
system. It is almost always the case that a process does not need full user or
systemprivileges.Forexample,doesawordprocessorneedtoacceptnetwork
connections? Does a network service that provides the time of day need to
access filesbeyond a specific set?
Theterm sandboxing referstothepracticeofenforcingstrictlimitationson
aprocess.Ratherthangivethatprocessthefullsetofsystemcallsitsprivileges
wouldallow,weimposeanirremovablesetofrestrictionsontheprocessinthe
early stages of its startup—well before the execution of its main()function
andoftenasearlyasitscreationwiththe forksystemcall.Theprocessisthen
renderedunabletoperformanyoperationsoutsideitsallowedset.Inthisway,
itispossibletopreventtheprocessfromcommunicatingwithanyothersystem
component,resultingintightcompartmentalizationthatmitigatesanydamage
tothe systemevenifthe processiscompromised.
Therearenumerousapproachestosandboxing.Javaand.net,forexample,
imposesandbox restrictionsat the levelof the virtualmachine. Other systems
enforcesandboxingaspartoftheirmandatoryaccesscontrol( MAC)policy.An
exampleisAndroid,whichdrawsonanSELinuxpolicyenhancedwithspecific
labelsforsystempropertiesand serviceendpoints.
Sandboxingmayalsobeimplementedasacombinationofmultiplemech-
anisms.AndroidhasfoundSELinuxusefulbutlacking,becauseitcannoteffec-
tively restrict individual system calls. The latest Android versions ( “Nougat ”
and “O”)useanunderlyingLinuxmechanismcalled SECCOMP-BPF ,mentioned
earlier, to apply system-call restrictions through the use of a specialized sys-
tem call. The C run-time library in Android ( “Bionic ”) calls this system call to
imposerestrictionsonallAndroidprocessesand third-partyapplications.
Among the major vendors, Apple was the first to implement sandboxing,
which appeared in mac OS10.5 ( “Tiger ”)a s “Seatbelt ”. Seatbelt was “opt-in ”
rather than mandatory, allowing but not requiring applications to use it. The
ApplesandboxwasbasedondynamicprofileswrittenintheSchemelanguage,
which provided the ability to control not just which operations were to be
allowed or blocked but also their arguments. This capability enabled Apple
to create different custom-fit profiles for each binary on the system, a practice
thatcontinues tothis day.Figure17.13 depictsa profileexample.
Apple’ssandboxinghasevolvedconsid erablysinceitsinception.Itisnow
used in the i OSvariants, where it serves (along with code signing) as the
chief protection against untrusted third-party code. In i OS, and starting with
macOS10.8, the mac OSsandbox is mandatory and is automatically enforced
forallMac-storedownloadedapps.Morerecently,asmentionedearlier,Apple
adopted the System Integrity Protection ( SIP), used in mac OS10.11 and later.
SIPis, in effect, a system-wide “platform profile. ”Apple enforces it starting at
systemboot on all processes in the system. Only those processes that are enti-
tled can perform privileged operations, and those are code-signed by Apple
and therefore trusted."
3,17.11.4 Code Signing,826,17.11.3 Sandboxing,"690 Chapter 17 Protection
(version 1)
(deny default)
(allow file-chroot)
(allow file-read-metadata (literal ""/var""))
(allow sysctl-read)
(allow mach-per-user-lookup)
(allow mach-lookup)
(global-name ""com.apple.system.logger"")
Figure 17.13 A sandbox profile of a MacOS daemon denying most operations.
17.11.4 Code Signing
At a fundamental level, how can a system “trust ”a program or script? Gen-
erally, if the item came as part of the operating system, it should be trusted.
Butwhatiftheitemischanged?Ifit’schangedbyasystemupdate,thenagain
it’s trustworthy, but otherwise it should not be executable or should require
specialpermission(fromtheuseroradministrator)beforeitisrun.Toolsfrom
thirdparties,commercialorotherwise,aremoredifficulttojudge.Howcanwe
be sure the tool wasn’t modified on its way from where it was created to our
systems?
Currently,codesigningisthebesttoolintheprotectionarsenalforsolving
these problems. Code signing is the digital signing of programs and executa-
blestoconfirmthattheyhavenotbeenchangedsincetheauthorcreatedthem.
It uses a cryptographic hash (Section 16.4.1.3) to test for integrity and authen-
ticity. Code signing is used for operating-system distributions, patches, and
third-party tools alike.Some operating systems, including i OS,W i n d o w s ,a n d
macOS, refuse to run programs that fail their code-signing check. It can also
enhance system functionality in other ways. For example, Apple can disable
all programs writtenfor a now-obsolete versionof i OSby stopping itssigning
of thoseprograms when theyaredownloadedfrom theAppStore.
17.12 Language-Based Protection
To the degree that protection is provided in computer systems, it is usually
achieved through an operating-system kernel, which acts as a security agent
to inspect and validate each attempt to access a protected resource. Since
comprehensive access validation may be a source of considerable overhead,
eitherwe must giveit hardware supportto reducethe cost of each validation,
or we must allow the system designer to compromise the goals of protection.
Satisfying all these goals is difficult i f the flexibility to implement protection
policies is restricted by the support mechanisms provided or if protection
environments are made larger than necessary to secure greater operational
efficiency.
Asoperatingsystemshavebecomemorecomplex,andparticularlyasthey
haveattemptedtoprovidehigher-leveluserinterfaces,thegoals ofprotection"
2,17.12 Language-Based Protection,826,17.11 Other Protection Improvement Methods,"690 Chapter 17 Protection
(version 1)
(deny default)
(allow file-chroot)
(allow file-read-metadata (literal ""/var""))
(allow sysctl-read)
(allow mach-per-user-lookup)
(allow mach-lookup)
(global-name ""com.apple.system.logger"")
Figure 17.13 A sandbox profile of a MacOS daemon denying most operations.
17.11.4 Code Signing
At a fundamental level, how can a system “trust ”a program or script? Gen-
erally, if the item came as part of the operating system, it should be trusted.
Butwhatiftheitemischanged?Ifit’schangedbyasystemupdate,thenagain
it’s trustworthy, but otherwise it should not be executable or should require
specialpermission(fromtheuseroradministrator)beforeitisrun.Toolsfrom
thirdparties,commercialorotherwise,aremoredifficulttojudge.Howcanwe
be sure the tool wasn’t modified on its way from where it was created to our
systems?
Currently,codesigningisthebesttoolintheprotectionarsenalforsolving
these problems. Code signing is the digital signing of programs and executa-
blestoconfirmthattheyhavenotbeenchangedsincetheauthorcreatedthem.
It uses a cryptographic hash (Section 16.4.1.3) to test for integrity and authen-
ticity. Code signing is used for operating-system distributions, patches, and
third-party tools alike.Some operating systems, including i OS,W i n d o w s ,a n d
macOS, refuse to run programs that fail their code-signing check. It can also
enhance system functionality in other ways. For example, Apple can disable
all programs writtenfor a now-obsolete versionof i OSby stopping itssigning
of thoseprograms when theyaredownloadedfrom theAppStore.
17.12 Language-Based Protection
To the degree that protection is provided in computer systems, it is usually
achieved through an operating-system kernel, which acts as a security agent
to inspect and validate each attempt to access a protected resource. Since
comprehensive access validation may be a source of considerable overhead,
eitherwe must giveit hardware supportto reducethe cost of each validation,
or we must allow the system designer to compromise the goals of protection.
Satisfying all these goals is difficult i f the flexibility to implement protection
policies is restricted by the support mechanisms provided or if protection
environments are made larger than necessary to secure greater operational
efficiency.
Asoperatingsystemshavebecomemorecomplex,andparticularlyasthey
haveattemptedtoprovidehigher-leveluserinterfaces,thegoals ofprotection"
3,17.12.1 Compiler-Based Enforcement,827,17.12 Language-Based Protection,"17.12 Language-Based Protection 691
have become much more refined. The designers of protection systems have
drawn heavily on ideas that originated in programming languages and espe-
cially on the concepts of abstract data types and objects. Protection systems
are now concerned not only with the identity of a resource to which access
is attempted but also with the functional nature of that access. In the newest
protectionsystems,concernforthefunctiontobeinvokedextendsbeyondaset
of system-defined functions, such as sta ndard file-access methods, to include
functions that may be user-definedas well.
Policies for resource use may also vary, depending on the application,
and they may be subject to change over time. For these reasons, protection
can no longer be considered a matter of concern only to the designer of an
operatingsystem.Itshouldalsobeavailableasatoolforusebytheapplication
designer,sothatresourcesofanapplicationsubsystemcanbeguardedagainst
tamperingor theinfluence of anerror.
17.12.1 Compiler-Based Enforcement
Atthispoint,programminglanguagesenterthepicture.Specifyingthedesired
control of access to a shared resource in a system is making a declarative
statement about the resource. This kind of statement can be integrated into
a language by an extension of its typing facility. When protection is declared
alongwithdatatyping,thedesignerofeachsubsystemcanspecifyitsrequire-
mentsfor protection,as wellasits needfor useof other resourcesina system.
Suchaspecificationshouldbegivendirectlyasaprogramiscomposed,andin
the language in which the program itself is stated. This approach has several
significant advantages:
1.Protection needs are simply declared, rather than programmed as a
sequenceof calls onproceduresof anoperatingsystem.
2.Protectionrequirementscanbestatedindependentlyofthefacilitiespro-
videdby a particularoperatingsystem.
3.The means for enforcement need not be provided by the designer of a
subsystem.
4.A declarative notation is natural because access privileges are closely
relatedto thelinguistic concept of datatype.
A variety of techniques can be provided by a programming-language
implementation to enforce protection, but any of these must depend on some
degree of support from an underlying machine and its operating system. For
example,supposealanguageisusedtogeneratecodetorunontheCambridge
CAPsystem (Section A.14.2). On this system, every storage reference made on
theunderlyinghardwareoccursindirectly throughacapability.Thisrestriction
prevents any process from accessing a resource outside of its protection envi-
ronment at any time. However, a program may impose arbitrary restrictions
onhow aresourcecan beusedduringexecutionofaparticularcodesegment.
We can implement such restrictions most readily by using the software capa-
bilitiesprovidedby CAP. Alanguageimplementationmight providestandard
protected procedures to interpret software capabilities that would realize the
protection policies that could be specified in the language. This scheme puts"
3,17.12.2 Run-Time-Based Enforcement—Protection in Java,830,17.12.1 Compiler-Based Enforcement,"694 Chapter 17 Protection
17.12.2 Run-Time-Based Enforcement—Protection in Java
BecauseJavawasdesignedtoruninadistributedenvironment,theJavavirtual
machine—or JVM—has many built-inprotectionmechanisms.Javaprograms
are composed of classes, each of which is a collection of data fields and func-
tions (called methods ) that operate on those fields. The JVMloads a class in
response to a request to create instances (or objects) of that class. One of the
most novel and useful features of Java is its support for dynamically load-
ing untrusted classes over a network and for executing mutually distrusting
classeswithin the same JVM.
Because of these capabilities, protection is a paramount concern. Classes
runninginthesame JVMmaybefromdifferentsourcesandmaynotbeequally
trusted. As a result, enforcing protection at the granularity of the JVMprocess
is insufficient. Intuitively, whether a request to open a file should be allowed
will generally depend on which class ha s requested the open. The operating
systemlacksthis knowledge.
Thus,suchprotectiondecisionsarehandledwithinthe JVM.Whenthe JVM
loads a class, it assigns the class to a protection domain that gives the per-
missions of that class. The protection domain to which the class is assigned
dependsonthe URLfromwhichtheclasswasloadedandanydigitalsignatures
on the class file. (Digital signatures are covered in Section 16.4.1.3.) Aconfig-
urable policy file determines the permi ssions granted to the domain (and its
classes). For example, classes loaded from a trusted server might be placed in
a protection domain that allows them to access files in the user’s home direc-
tory,whereasclassesloadedfromanuntrustedservermighthavenofileaccess
permissionsatall.
It can be complicated for the JVMto determine what class is responsible
for a request to access a protected resource. Accesses are often performed
indirectly, through system libraries or other classes. For example, consider a
class that is not allowed to open network connections. It could call a system
library to request the load of the contents of a URL.T h eJVMmust decide
whether or not to open a network connection for this request. But which
class should be used to determine if the connection should be allowed, the
applicationorthe systemlibrary?
The philosophy adopted in Java is to re quire the library class to explicitly
permit a network connection. More generally, in order to access a protected
resource,somemethodinthecallingsequencethatresultedintherequestmust
explicitly assert the privilege to acce ss the resource. By doing so, this method
takes responsibility fortherequest.Presumably,itwillalsoperformwhatever
checks are necessary to ensure the safety of the request. Of course, not every
methodisallowedtoassertaprivilege ;amethodcanassertaprivilegeonlyif
itsclassisinaprotectiondomainthatisitselfallowedtoexercisetheprivilege.
This implementation approach is called stack inspection . Every thread
in theJVMhas an associated stack of its ongoing method invocations. When
a caller may not be trusted, a method executes an access request within a
doPrivileged block to perform the access to a protected resource directly or
indirectly. doPrivileged() isastaticmethodinthe AccessController class
thatispassedaclasswitha run()methodtoinvoke.Whenthe doPrivileged
block is entered, the stack frame for this method is annotated to indicate this
fact.Then,thecontentsoftheblockareexecuted.Whenanaccesstoaprotected"
2,17.13 Summary,832,17.12 Language-Based Protection,"696 Chapter 17 Protection
Moregenerally,Java’sload-timeandrun-timechecksenforce type safety of
Java classes. Type safety ensures that classes cannot treat integers as pointers,
write past the end of an array, or otherwise access memory in arbitrary ways.
Rather, a program can access an object only via the methods defined on that
object by its class. This is the foundation of Java protection, since it enables a
class to effectively encapsulate and protect its data and methods from other
classes loaded in the same JVM. For example, a variable can be defined as
private so that only the class that contains it can access it or protected so
thatitcanbeaccessedonlybytheclassthatcontainsit,subclassesofthatclass,
or classes in the same package. Type safety ensures that these restrictions can
be enforced.
17.13 Summary
•System protection features are guided by the principle of need-to-know
and implementmechanisms toenforce theprincipleof leastprivilege.
•Computer systems contain objects that must be protected from misuse.
Objects may be hardware (such as memory, CPUtime, and I/Odevices)
orsoftware (such as files,programs,andsemaphores).
•An access right is permission to perform an operation on an object. A
domainisasetofaccessrights.Processesexecuteindomainsandmayuse
any of the access rights in the domain to access and manipulate objects.
During its lifetime,a process may be eitherbound to a protectiondomain
orallowed to switch from one domainto another.
•Acommon method of securing objects is to provide a series of protection
rings,eachwithmoreprivilegesthanthelast. ARM,forexample,provides
four protection levels. The most privileged, TrustZone, is callable only
fromkernelmode.
•The access matrix is a general model of protection that provides a mech-
anism for protection without imposin g a particular protection policy on
the system or its users. The separation of policy and mechanism is an
importantdesignproperty.
•The access matrix is sparse. It is normally implemented either as access
lists associated with each object or as capability lists associated with each
domain. We can include dynamic protection in the access-matrix model
by considering domains and the access matrix itself as objects. Revoca-
tion of access rights in a dynamic protection model is typically easier to
implementwithanaccess-listscheme thanwitha capability list.
•Real systems are much more limited than the general model. Older UNIX
distributionsarerepresentative,providingdiscretionaryaccesscontrolsof
read,write,andexecutionprotectionseparatelyfortheowner,group,and
generalpublicforeachfile.Moremodernsystemsareclosertothegeneral
model, or at least provide a variety of protection features to protect the
systemanditsusers.
•Solaris 10 and beyond, among other systems, implement the principle
of least privilege via role-based access control, a form of access matrix."
2,Further Reading,833,17.13 Summary,"Bibliography 697
Anotherprotectionextensionismandatoryaccesscontrol,aformofsystem
policy enforcement.
•Capability-basedsystemsofferfiner-grainedprotectionthanoldermodels,
providingspecific abilitiesto processesby “slicing up ”the powers of root
intodistinctareas.OthermethodsofimprovingprotectionincludeSystem
IntegrityProtection,system-callfiltering,sandboxing, andcode signing.
•Language-based protection provides finer-grained arbitration of requests
andprivilegesthantheoperatingsystemisabletoprovide.Forexample,a
singleJava JVMcanrunseveralthreads,eachinadifferentprotectionclass.
It enforces the resource requests through sophisticated stack inspection
and viathe typesafetyof the language.
Further Reading
TheconceptofacapabilityevolvedfromIliffe’sandJodeit’s codewords ,which
wereimplementedinthe Rice Universitycomputer([Iliffeand Jodeit(1962)]).
Theterm capability was introduced by [Dennis and Horn (1966)].
Theprincipleofseparationofpolicyandmechanismwasadvocatedbythe
designerofHydra ([Levinetal.(1975)]).
The use of minimal operating-system support to enforce protection was
advocated by the Exokernel Project ([Ganger et al. (2002)], [Kaashoek et al.
(1997)]).
The access-matrix model of protection between domains and objects was
developed by [Lampson (1969)] and [Lampson (1971)]. [Popek (1974)] and
[Saltzer and Schroeder (1975)] provided excellent surveys on the subject of
protection.
ThePosixcapabilitystandardandthewayitwasimplementedinLinuxis
described in https://www.usenix.org/legacy/event/usenix03/tech/freenix03/
full
papers/gruenbacher/gruenbacher
 html/main.html
Details on POSIX.1e and its Linux implementation are provided in
https://www.usenix.org/legacy/even t/usenix03/tech/freenix03/full
 papers/gr
uenbacher/gruenbacher
 html/main.html .
Bibliography
[Dennis and Horn (1966)] J.B.DennisandE.C.V.Horn, “ProgrammingSeman-
ticsforMultiprogrammedComputations ”,Communications of the ACM ,V olume
9,Number3 (1966),pages 143–155.
[Ganger et al. (2002)] G.R.Ganger ,D.R.Engler ,M.F .Kaashoek,H.M.Briceno,
R. Hunt, and T. Pinckney, “Fast and Flexible Applicat ion-Level Networking on
ExokernelSystems ”,ACM Transactions on Computer Systems ,Volume20,Number
1(2002), pages 49–83.
[Iliffe and Jodeit (1962)] J.K.IliffeandJ.G.Jodeit, “ADynamicStorageAlloca-
tionSystem ”,Computer Journal , Volume5, Number3(1962), pages200–209."
2,Bibliography,833,Further Reading,"Bibliography 697
Anotherprotectionextensionismandatoryaccesscontrol,aformofsystem
policy enforcement.
•Capability-basedsystemsofferfiner-grainedprotectionthanoldermodels,
providingspecific abilitiesto processesby “slicing up ”the powers of root
intodistinctareas.OthermethodsofimprovingprotectionincludeSystem
IntegrityProtection,system-callfiltering,sandboxing, andcode signing.
•Language-based protection provides finer-grained arbitration of requests
andprivilegesthantheoperatingsystemisabletoprovide.Forexample,a
singleJava JVMcanrunseveralthreads,eachinadifferentprotectionclass.
It enforces the resource requests through sophisticated stack inspection
and viathe typesafetyof the language.
Further Reading
TheconceptofacapabilityevolvedfromIliffe’sandJodeit’s codewords ,which
wereimplementedinthe Rice Universitycomputer([Iliffeand Jodeit(1962)]).
Theterm capability was introduced by [Dennis and Horn (1966)].
Theprincipleofseparationofpolicyandmechanismwasadvocatedbythe
designerofHydra ([Levinetal.(1975)]).
The use of minimal operating-system support to enforce protection was
advocated by the Exokernel Project ([Ganger et al. (2002)], [Kaashoek et al.
(1997)]).
The access-matrix model of protection between domains and objects was
developed by [Lampson (1969)] and [Lampson (1971)]. [Popek (1974)] and
[Saltzer and Schroeder (1975)] provided excellent surveys on the subject of
protection.
ThePosixcapabilitystandardandthewayitwasimplementedinLinuxis
described in https://www.usenix.org/legacy/event/usenix03/tech/freenix03/
full
papers/gruenbacher/gruenbacher
 html/main.html
Details on POSIX.1e and its Linux implementation are provided in
https://www.usenix.org/legacy/even t/usenix03/tech/freenix03/full
 papers/gr
uenbacher/gruenbacher
 html/main.html .
Bibliography
[Dennis and Horn (1966)] J.B.DennisandE.C.V.Horn, “ProgrammingSeman-
ticsforMultiprogrammedComputations ”,Communications of the ACM ,V olume
9,Number3 (1966),pages 143–155.
[Ganger et al. (2002)] G.R.Ganger ,D.R.Engler ,M.F .Kaashoek,H.M.Briceno,
R. Hunt, and T. Pinckney, “Fast and Flexible Applicat ion-Level Networking on
ExokernelSystems ”,ACM Transactions on Computer Systems ,Volume20,Number
1(2002), pages 49–83.
[Iliffe and Jodeit (1962)] J.K.IliffeandJ.G.Jodeit, “ADynamicStorageAlloca-
tionSystem ”,Computer Journal , Volume5, Number3(1962), pages200–209."
2,Chapter 17 Exercises,835,Bibliography,"Exercises
Chapter 17 Exercises
17.11The access-control matrix can be used to determine whether a process
can switch from, say, domain A to domain B and enjoy the access
privileges of domain B. Is this approach equivalent to including the
access privilegesof domainBinthoseof domainA?
17.12Consider a computer system in which computer games can be played
by students only between 10 P.M.and 6A.M., by faculty members
between5 P.M.and8A.M.,andbythecomputercenterstaffatalltimes.
Suggesta schemefor implementingthispolicy efficiently.
17.13What hardware features does a computer system need for efficient
capability manipulation? Can these features be used for memory pro-
tection?
17.14Discuss the strengths and weaknesses of implementing an access
matrix usingaccess liststhat areassociatedwith objects.
17.15Discuss the strengths and weaknesses of implementing an access
matrix usingcapabilitiesthat areassociatedwithdomains.
17.16Explainwhyacapability-basedsystemprovidesgreaterflexibilitythan
a ring-protectionschemeinenforcing protectionpolicies.
17.17What is the need-to-know principle? Why is it important for a protec-
tionsystemto adhereto thisprinciple?
17.18Discuss which of the following systems allow module designers to
enforce theneed-to-knowprinciple.
a. Ring-protection scheme
b.JVM’s stack-inspection scheme
17.19Describe how the Java protection model would be compromised if a
Javaprogramwereallowedtodirectlyaltertheannotationsofitsstack
frame.
17.20How are the access-matrix facility and the role-based access-control
facility similar?How dothey differ?
17.21How does the principle of least privilege aid in the creation of protec-
tionsystems?
17.22How can systems that implement the principle of least privilege still
have protectionfailuresthat leadto securityviolations?EX-54"
0,PART EIGHT ADVANCED TOPICS,836,PART SEVEN SECURITY AND PROTECTION,"Part Eight
Advanced Topics
Virtualization permeates all aspects of computing. Virtual machines are
one instance of this trend. Generally, with a virtual machine, guest operat-
ing systems and applications run in an environment that appears to them
to be native hardware. This environment behaves toward them as native
hardware would but also protects, manages, and limits them.
Adistributed system is a collection of processors that do not share
memory or a clock. Instead, each processor has its own local memory,
and the processors communicate with one another through a local-area
or wide-area computer network. C omputer networks allow disparate
computing devices to communicate by adopting standard communica-
tion protocols. Distributed systems o ffer several beneﬁts: they give users
access to more of the resources maintained by the system, boost com-
putation speed, and improve data availability and reliability."
1,Chapter 18 Virtual Machines,838,PART EIGHT ADVANCED TOPICS,"18CHAPTER
Virtual Machines
The term virtualization has many meanings, and aspects of virtualization
permeate all aspects of computing. Virtual machines are one instance of this
trend.Generally,withavirtualmachine,guestoperatingsystemsandapplica-
tions run in an environment that appears to them to be native hardware and
that behaves toward them as native hardware would but that also protects,
manages,and limitsthem.
This chapter delves into the uses, features, and implementation of virtual
machines. Virtual machines can be implemented in several ways, and this
chapterdescribestheseoptions.One optionistoaddvirtualmachine support
tothekernel.Becausethatimplementationmethodisthemostpertinenttothis
book,weexploreitmostfully.Additionally,hardwarefeaturesprovidedbythe
CPUand evenby I/Odevicescan support virtualmachine implementation,so
wediscusshow thosefeaturesareusedbythe appropriatekernelmodules.
CHAPTER OBJECTIVES
•Explore the history and benefits of virtual machines.
•Discuss the various virtual machine technologies.
•Describe the methods used to implement virtualization.
•Identifythemostcommonhardwarefeaturesthatsupportvirtualizationand
explain how they are used by operating-system modules.
•Discuss current virtualization research areas.
18.1 Overview
The fundamental idea behind a virtual machine is to abstract the hardware
of a single computer (the CPU, memory, disk drives, network interface cards,
and so forth) into several different execution environments, thereby creating
the illusion that each separate environment is running on its own private
computer.Thisconceptmayseemsimilartothelayeredapproachofoperating
systemimplementation(seeSection2.8.2),andinsomewaysitis.Inthecaseof
701"
2,18.1 Overview,838,Chapter 18 Virtual Machines,"18CHAPTER
Virtual Machines
The term virtualization has many meanings, and aspects of virtualization
permeate all aspects of computing. Virtual machines are one instance of this
trend.Generally,withavirtualmachine,guestoperatingsystemsandapplica-
tions run in an environment that appears to them to be native hardware and
that behaves toward them as native hardware would but that also protects,
manages,and limitsthem.
This chapter delves into the uses, features, and implementation of virtual
machines. Virtual machines can be implemented in several ways, and this
chapterdescribestheseoptions.One optionistoaddvirtualmachine support
tothekernel.Becausethatimplementationmethodisthemostpertinenttothis
book,weexploreitmostfully.Additionally,hardwarefeaturesprovidedbythe
CPUand evenby I/Odevicescan support virtualmachine implementation,so
wediscusshow thosefeaturesareusedbythe appropriatekernelmodules.
CHAPTER OBJECTIVES
•Explore the history and benefits of virtual machines.
•Discuss the various virtual machine technologies.
•Describe the methods used to implement virtualization.
•Identifythemostcommonhardwarefeaturesthatsupportvirtualizationand
explain how they are used by operating-system modules.
•Discuss current virtualization research areas.
18.1 Overview
The fundamental idea behind a virtual machine is to abstract the hardware
of a single computer (the CPU, memory, disk drives, network interface cards,
and so forth) into several different execution environments, thereby creating
the illusion that each separate environment is running on its own private
computer.Thisconceptmayseemsimilartothelayeredapproachofoperating
systemimplementation(seeSection2.8.2),andinsomewaysitis.Inthecaseof
701"
2,18.2 History,840,18.1 Overview,"18.2 History 703
INDIRECTION
“Allproblemsincomputersciencecanbesolvedbyanotherlevelofindirec-
tion ”—DavidWheeler
“...e x c e p tf o rt h ep r o b l e mo ft o om a n yl a y e r so fi n d i r e c t i o n . ”—Kevlin
Henney
•Operating-system-like software built to provide virtualization, including
VMwareESX(mentioned above), Joyent Smart OS, and Citrix XenServer.
Th eseVMMsa r ekn o w na s type 1 hypervisors .
•General-purpose operating systems that provide standard functions as
wellas VMMfunctions,includingMicrosoftWindowsServerwithHyperV
and Red Hat Linux with the KVMfeature. Because such systems have a
featuresetsimilarto type1hypervisors,they arealsoknown as type1.
•Applications that run on standard operating systems but provide VMM
features to guest operating systems. These applications, which include
VMware Workstation and Fusion, Parallels Desktop, and Oracle Virtual-
Box,are type 2 hypervisors .
•Paravirtualization , a technique in which the guest operating system is
mo difi edtow o rkinc o o pera tio nw ithth e VMMtooptimizeperformance.
•Programming-environment virtualization ,i nw h i c h VMMsd on o tv i r t u -
alize real hardware but instead create an optimized virtual system. This
technique isusedby OracleJavaand Microsoft.Net.
•Emulators that allow applications written for one hardware environment
to run on a very different hardware environment, such as a different type
ofCPU.
•Application containment , which is not virtualization at all but rather
provides virtualization-like features by segregating applications from the
operating system. Oracle Solaris Zones, BSDJails, and IBM AIX WPARs
“contain ”applications,making themmore secure and manageable.
The variety of virtualization techniques in use today is a testament to
the breadth, depth, and importance of virtualization in modern computing.
Virtualization is invaluable for data-cen ter operations, efficient application
development,and softwaretesting,among many other uses.
18.2 History
Virtual machines first appeared commercially on IBMmainframes in 1972.
Virtualizationwasprovidedbythe IBM VMoperatingsystem.Thissystemhas
evolved and is still available. In additi on, many of its original concepts are
found inother systems,making itworth exploring."
2,18.3 Benefits and Features,841,18.2 History,"704 Chapter 18 Virtual Machines
IBM VM/370 divided a mainframe into multiple virtual machines, each
running its own operating system. A major difficulty with the VMapproach
involved disk systems. Suppose that the physical machine had three disk
drives but wanted to support seven virtual machines. Clearly, it could not
allocate a disk drive to each virtual machine. The solution was to provide
virtualdisks—termed minidisks inIBM’sVMoperatingsystem.Theminidisks
wereidenticaltothesystem’sharddisksinallrespectsexceptsize.Thesystem
implementedeachminidiskbyallocatingasmanytracksonthephysicaldisks
as theminidiskneeded.
Once the virtual machines were created, users could run any of the oper-
ating systems or software packages that were available on the underlying
machine. For the IBM VM system, a user normally ran CMS—a single-user
interactiveoperatingsystem.
For many years after IBM introduced this technology, virtualization
remained in its domain. Most systems could not support virtualization.
However, a formal definition of virtualization helped to establish system
requirements and a target for functiona lity. The virtualization requirements
calledfor:
•Fidelity.AVMMprovidesanenvironmentforprogramsthatisessentially
identicaltothe originalmachine.
•Performance . Programs running within that environment show only
minor performance decreases.
•Safety.Th eVMMis incompletecontrol of systemresources.
Theserequirementsstillguidevirtualizationeffortstoday.
By the late 1990s, Intel 80x86 CPUs had become common, fast, and rich
in features. Accordingly, developers launched multiple efforts to implement
virtualization on that platform. Both Xenand VMwarecreated technologies,
still used today, to allow guest operating systems to run on the 80x86. Since
that time, virtualization has expanded to include all common CPUs, many
commercial and open-source tools, and many operating systems. For exam-
ple, the open-source VirtualBox project ( http://www.virtualbox.org )p r o v i d e s
a program that runs on Intel x86 and AMD64CPUs and on Windows, Linux,
macOS, and Solaris host operating systems. Possible guest operating systems
include many versions of Windows, Linux, Solaris, and BSD, including even
MS-DOSandIBM OS/2 .
18.3 Beneﬁts and Features
Severaladvantagesmakevirtualizationattractive.Mostofthemarefundamen-
tallyrelatedtotheabilitytosharethesamehardwareyetrunseveraldifferent
executionenvironments(that is,differentoperatingsystems)concurrently.
One important advantage of virtualization is that the host system is pro-
tected from the virtual machines, just as the virtual machines are protected
from each other. A virus inside a guest operating system might damage that
operating systembut is unlikelyto affec t the host or the other guests.Because"
2,18.4 Building Blocks,844,18.3 Benefits and Features,"18.4 Building Blocks 707
remote data centers and access their applications as if they were local. This
practice can increase security, because no data are stored on local disks at the
user’s site. The cost of the user’s computing resource may also decrease. The
usermusthave networking, CPU,and somememory,but allthat thesesystem
componentsneedtodoisdisplayanimageoftheguestasitsrunsremotely(via
ap r o t o c o ls u c ha s RDP). Thus, they need not be expensive, high-performance
components.Otherusesofvirtualizationaresuretofollowasitbecomesmore
prevalentand hardwaresupport continues toimprove.
18.4 Building Blocks
Although the virtual machine concept is useful, it is difficult to implement.
Much work is required to provide an exactduplicate of the underlying
machine. This is especially a challenge on dual-mode systems, where the
underlying machine has only user mode and kernel mode. In this section, we
examine the building blocks that are needed for efficient virtualization. Note
thatthesebuildingblocksarenotrequiredbytype0hypervisors,asdiscussed
inSection18.5.2.
The ability to virtualize depends on the features provided by the CPU.I f
the features are sufficient, then it is possible to write a VMMthat provides
a guest environment. Otherwise, virtualization is impossible. VMMs use sev-
eral techniques to implement virtuali zation, including trap-and-emulate and
binary translation. We discuss each of these techniques in this section, along
withthehardwaresupportneededto supportvirtualization.
As you read the section, keep in mind that an important concept found
in most virtualization options is the implementation of a virtual CPU(VCPU).
TheVCPUdoes not execute code. Rather, it represents the state of the CPUas
theguestmachinebelievesittobe.Foreachguest,the VMMmaintainsa VCPU
representingthatguest’scurrent CPUstate.Whentheguestiscontext-switched
onto aCPUby theVMM, information from the VCPUis used to load the right
context,much asa general-purposeoperatingsystemwouldusethe PCB.
18.4.1 Trap-and-Emulate
On a typicaldual-modesystem,the virtualmachine guestcan executeonly in
usermode(unlessextrahardwaresupportisprovided).Thekernel,ofcourse,
runs in kernel mode, and it is not safe to allow user-level code to run in
kernelmode.Just as the physical machine has two modes,so must the virtual
machine.Consequently,wemusthaveavirtualusermodeandavirtualkernel
mode, both of which run in physical user mode. Those actions that cause a
transfer from user mode to kernel mode on a real machine (such as a system
call, an interrupt, or an attempt to execute a privileged instruction) must also
cause a transfer from virtual user mode to virtual kernel mode in the virtual
machine.
How can such a transfer be accomplished? The procedure is as follows:
When the kernel in the guest attempts to execute a privileged instruction,
that is an error (because the system is in user mode) and causes a trap to the
VMMintherealmachine.The VMMgainscontrolandexecutes(or “emulates ”)
the action that was attempted by the guest kernel on the part of the guest. It"
3,18.4.1 Trap-and-Emulate,844,18.4 Building Blocks,"18.4 Building Blocks 707
remote data centers and access their applications as if they were local. This
practice can increase security, because no data are stored on local disks at the
user’s site. The cost of the user’s computing resource may also decrease. The
usermusthave networking, CPU,and somememory,but allthat thesesystem
componentsneedtodoisdisplayanimageoftheguestasitsrunsremotely(via
ap r o t o c o ls u c ha s RDP). Thus, they need not be expensive, high-performance
components.Otherusesofvirtualizationaresuretofollowasitbecomesmore
prevalentand hardwaresupport continues toimprove.
18.4 Building Blocks
Although the virtual machine concept is useful, it is difficult to implement.
Much work is required to provide an exactduplicate of the underlying
machine. This is especially a challenge on dual-mode systems, where the
underlying machine has only user mode and kernel mode. In this section, we
examine the building blocks that are needed for efficient virtualization. Note
thatthesebuildingblocksarenotrequiredbytype0hypervisors,asdiscussed
inSection18.5.2.
The ability to virtualize depends on the features provided by the CPU.I f
the features are sufficient, then it is possible to write a VMMthat provides
a guest environment. Otherwise, virtualization is impossible. VMMs use sev-
eral techniques to implement virtuali zation, including trap-and-emulate and
binary translation. We discuss each of these techniques in this section, along
withthehardwaresupportneededto supportvirtualization.
As you read the section, keep in mind that an important concept found
in most virtualization options is the implementation of a virtual CPU(VCPU).
TheVCPUdoes not execute code. Rather, it represents the state of the CPUas
theguestmachinebelievesittobe.Foreachguest,the VMMmaintainsa VCPU
representingthatguest’scurrent CPUstate.Whentheguestiscontext-switched
onto aCPUby theVMM, information from the VCPUis used to load the right
context,much asa general-purposeoperatingsystemwouldusethe PCB.
18.4.1 Trap-and-Emulate
On a typicaldual-modesystem,the virtualmachine guestcan executeonly in
usermode(unlessextrahardwaresupportisprovided).Thekernel,ofcourse,
runs in kernel mode, and it is not safe to allow user-level code to run in
kernelmode.Just as the physical machine has two modes,so must the virtual
machine.Consequently,wemusthaveavirtualusermodeandavirtualkernel
mode, both of which run in physical user mode. Those actions that cause a
transfer from user mode to kernel mode on a real machine (such as a system
call, an interrupt, or an attempt to execute a privileged instruction) must also
cause a transfer from virtual user mode to virtual kernel mode in the virtual
machine.
How can such a transfer be accomplished? The procedure is as follows:
When the kernel in the guest attempts to execute a privileged instruction,
that is an error (because the system is in user mode) and causes a trap to the
VMMintherealmachine.The VMMgainscontrolandexecutes(or “emulates ”)
the action that was attempted by the guest kernel on the part of the guest. It"
3,18.4.2 Binary Translation,845,18.4.1 Trap-and-Emulate,"708 Chapter 18 Virtual Machines
privileged instruction
operating
system
VCPU
VMMVMMguest
kernel modeuser mode
emulate actionreturn
trap
updateuser processes
Figure 18.2 Trap-and-emulate virtualization implementation.
thenreturnscontroltothevir tualmachine.Thisiscalledthe trap-and-emulate
method and isshown in Figure 18.2.
With privileged instructions, time becomes an issue. All nonprivileged
instructions run natively on the hardware, providing the same performance
forguestsasnativeapplications.Privile gedinstructionscreateextraoverhead,
however, causing the guest to run more slowly than it would natively. In
addition, the CPUis being multiprogrammed among many virtual machines,
which can furtherslow down the virtualmachines in unpredictable ways.
This problem has been approached in various ways. IBM VM,f o re x a m -
ple, allows normal instructions for the virtual machines to execute directly
on the hardware. Only the privilege d instructions (needed mainly for I/O)
must be emulated and hence execute more slowly. In general, with the evolu-
tion ofhardware, the performance of trap-and-emulatefunctionality has been
improved, and cases in which it is needed have been reduced. For example,
manyCPUs now have extra modes added to their standard dual-mode opera-
tion.The VCPUneednotkeeptrackofwhatmodetheguestoperatingsystemis
in,becausethephysical CPUperformsthatfunction.Infact,some CPUsprovide
guestCPUstate management in hardware, so the VMMneed not supply that
functionality, removingthe extraoverhead.
18.4.2 Binary Translation
SomeCPUs do not have a clean separation of privileged and nonprivileged
instructions. Unfortunately for virtualization implementers, the Intel x86 CPU
line is one of them. No thought was given to running virtualization on the
x86 when it was designed. (In fact, the first CPUin the family—the Intel
4004, released in 1971—was designed to be the core of a calculator.) The chip
has maintained backward compatibility throughout its lifetime, preventing
changes that would have made virtualization easier through many genera-
tions."
3,18.4.3 Hardware Assistance,847,18.4.2 Binary Translation,"710 Chapter 18 Virtual Machines
The basic method of binary translation just described would execute
correctly but perform poorly. Fortunately, the vast majority of instructions
wouldexecutenatively.Buthowcouldperformancebeimprovedfortheother
instructions? We can turn to a specific implementation of binary translation,
theVMwaremethod,toseeonewayofimprov ingperformance.Here,caching
provides the solution. The replacement code for each instruction that needs
to be translated is cached. All later executions of that instruction run from the
translationcacheandneednotbetranslatedagain.Ifthecacheislargeenough,
this methodcangreatlyimproveperformance.
Let’s consider another issue in virtualization: memory management,
specifically the page tables. How can the VMMkeep page-table state both for
guests that believe they are managing the page tables and for the VMMitself?
Acommon method, used with both trap-and-emulate and binary translation,
is to use nested page tables (NPTs). Each guest operating system maintains
one or more page tables to translate from virtual to physical memory. The
VMMmaintains NPTstorepresenttheguest’spage-tablestate,justasitcreates
aVCPUto represent the guest’s CPUstate. The VMMknows when the guest
tries to change its page table, and it makes the equivalent change in the NPT.
When the guest is on the CPU,t h eVMMputs the pointer to the appropriate
NPTinto the appropriate CPUregisterto make that table the active page table.
If the guest needs to modify the page table (for example, fulfilling a page
fault), then that operation must be intercepted by the VMMand appropriate
changes made to the nested and system page tables. Unfortunately, the use of
NPTsc a nc a u s e TLBmisses to increase, and many other complexities need to
be addressedtoachievereasonableperformance.
Although it might seem that the binary translation method creates large
amounts of overhead, it performed well enough to launch a new industry
aimedatvirtualizingIntelx86-basedsystems. VMwaretestedtheperformance
impact of binary translation by booting one such system, Windows XP,a n d
immediately shutting it down while monitoring the elapsed time and the
numberof translationsproducedbythe binarytranslation method.The result
was 950,000 translations, taking 3 microseconds each, for a total increase of
3 seconds (about 5 percent) over native execution of Windows XP. To achieve
that result,developersused many performance improvementsthat we do not
discusshere.Formoreinformation,consultthebibliographicalnotesattheend
of thischapter.
18.4.3 Hardware Assistance
Without some level of hardware support, virtualization would be impossible.
The more hardware support available within a system, the more feature-rich
and stable the virtual machines can be and the better they can perform. In the
Intelx86 CPUfamily,Inteladdednewvirtualizationsupport(the VT-xinstruc-
tions) in successive generations begi nning in 2005. Now, binary translation is
nolonger needed.
In fact, all major general-purpose CPUs now provide extended hardware
supportforvirtualization.Forexample, AMDvirtualizationtechnology( AMD-
V)hasappearedinseveral AMDprocessorsstartingin2006.Itdefinestwonew
modes of operation—host and guest—thus moving from a dual-mode to a"
2,18.5 Types of VMs and Their Implementations,850,18.4 Building Blocks,"18.5 Types of VMs and Their Implementations 713
code. The actual work is done via system calls, which have the kernel call the
privilegedvirtualization CPUinstructionsonbehalfofthehypervisorprocess,
allowing management of virtual machines without the hypervisor needing to
loada kernelmoduleof itsownto executethose calls.
18.5 Types of VMs and Their Implementations
We’venowlookedatsomeofthetechniquesusedtoimplementvirtualization.
Next, we consider the major types of virtual machines, their implementation,
their functionality, and how they use the building blocks just described to
create a virtual environment. Of course, the hardware on which the virtual
machines are running can cause great variation in implementation methods.
Here,wediscusstheimplementationsin general,withtheunderstandingthat
VMMs takeadvantageof hardwareassistancewhere itisavailable.
18.5.1 The Virtual Machine Life Cycle
Let’s begin with the virtual machine life cycle. Whatever the hypervisor type,
at the time a virtual machine is created, its creator gives the VMMcertain
parameters. These parameters usually include the number of CPUs, amount
ofmemory,networkingdetails,andstoragedetailsthatthe VMMwilltakeinto
account when creating the guest. For example, a user might want to create a
new guest with two virtual CPUs, 4GBof memory, 10 GBof disk space, one
networkinterfacethatgetsits IPaddressvia DHCP,andaccesstothe DVDdrive.
TheVMMthen creates the virtual machine with those parameters. In the
case of a type 0 hypervisor, the resources are usually dedicated. In this situa-
tion, if there are not two virtual CPUs available and unallocated, the creation
request in our example will fail. For other hypervisor types, the resources are
dedicated or virtualized, depending on the type. Certainly, an IPaddress can-
not be shared, but the virtual CPUs are usually multiplexed on the physical
CPUs as discussed in Section 18.6.1. Similarly, memory management usually
involves allocating more memory to guests than actually exists in physical
memory.Thisis morecomplicatedand isdescribedinSection18.6.2.
Finally, when the virtual machine is no longer needed, it can be deleted.
When this happens, the VMMfirst frees up any used disk space and then
removes the configuration associated wi th the virtual machine, essentially
forgettingthe virtualmachine.
These steps are quite simple compared with building, configuring, run-
ning, and removing physical machines. Creating a virtual machine from an
existingonecanbeaseasyasclickingthe “clone ”buttonandprovidinganew
nameand IPaddress.Thiseaseofcreationcanleadto virtual machine sprawl ,
which occurs when there are so many virtual machines on a system that their
use,history,and state become confusing and difficultto track.
18.5.2 Type 0 Hypervisor
Type0hypervisorshaveexistedformanyyearsundermanynames,including
“partitions ”and “domains. ”They are a hardware feature, and that brings its
own positives and negatives. Operating systems need do nothing special to
takeadvantageoftheirfeatures.The VMMitselfisencodedinthefirmwareand"
3,18.5.1 The Virtual Machine Life Cycle,850,18.5 Types of VMs and Their Implementations,"18.5 Types of VMs and Their Implementations 713
code. The actual work is done via system calls, which have the kernel call the
privilegedvirtualization CPUinstructionsonbehalfofthehypervisorprocess,
allowing management of virtual machines without the hypervisor needing to
loada kernelmoduleof itsownto executethose calls.
18.5 Types of VMs and Their Implementations
We’venowlookedatsomeofthetechniquesusedtoimplementvirtualization.
Next, we consider the major types of virtual machines, their implementation,
their functionality, and how they use the building blocks just described to
create a virtual environment. Of course, the hardware on which the virtual
machines are running can cause great variation in implementation methods.
Here,wediscusstheimplementationsin general,withtheunderstandingthat
VMMs takeadvantageof hardwareassistancewhere itisavailable.
18.5.1 The Virtual Machine Life Cycle
Let’s begin with the virtual machine life cycle. Whatever the hypervisor type,
at the time a virtual machine is created, its creator gives the VMMcertain
parameters. These parameters usually include the number of CPUs, amount
ofmemory,networkingdetails,andstoragedetailsthatthe VMMwilltakeinto
account when creating the guest. For example, a user might want to create a
new guest with two virtual CPUs, 4GBof memory, 10 GBof disk space, one
networkinterfacethatgetsits IPaddressvia DHCP,andaccesstothe DVDdrive.
TheVMMthen creates the virtual machine with those parameters. In the
case of a type 0 hypervisor, the resources are usually dedicated. In this situa-
tion, if there are not two virtual CPUs available and unallocated, the creation
request in our example will fail. For other hypervisor types, the resources are
dedicated or virtualized, depending on the type. Certainly, an IPaddress can-
not be shared, but the virtual CPUs are usually multiplexed on the physical
CPUs as discussed in Section 18.6.1. Similarly, memory management usually
involves allocating more memory to guests than actually exists in physical
memory.Thisis morecomplicatedand isdescribedinSection18.6.2.
Finally, when the virtual machine is no longer needed, it can be deleted.
When this happens, the VMMfirst frees up any used disk space and then
removes the configuration associated wi th the virtual machine, essentially
forgettingthe virtualmachine.
These steps are quite simple compared with building, configuring, run-
ning, and removing physical machines. Creating a virtual machine from an
existingonecanbeaseasyasclickingthe “clone ”buttonandprovidinganew
nameand IPaddress.Thiseaseofcreationcanleadto virtual machine sprawl ,
which occurs when there are so many virtual machines on a system that their
use,history,and state become confusing and difficultto track.
18.5.2 Type 0 Hypervisor
Type0hypervisorshaveexistedformanyyearsundermanynames,including
“partitions ”and “domains. ”They are a hardware feature, and that brings its
own positives and negatives. Operating systems need do nothing special to
takeadvantageoftheirfeatures.The VMMitselfisencodedinthefirmwareand"
3,18.5.2 Type 0 Hypervisor,850,18.5.1 The Virtual Machine Life Cycle,"18.5 Types of VMs and Their Implementations 713
code. The actual work is done via system calls, which have the kernel call the
privilegedvirtualization CPUinstructionsonbehalfofthehypervisorprocess,
allowing management of virtual machines without the hypervisor needing to
loada kernelmoduleof itsownto executethose calls.
18.5 Types of VMs and Their Implementations
We’venowlookedatsomeofthetechniquesusedtoimplementvirtualization.
Next, we consider the major types of virtual machines, their implementation,
their functionality, and how they use the building blocks just described to
create a virtual environment. Of course, the hardware on which the virtual
machines are running can cause great variation in implementation methods.
Here,wediscusstheimplementationsin general,withtheunderstandingthat
VMMs takeadvantageof hardwareassistancewhere itisavailable.
18.5.1 The Virtual Machine Life Cycle
Let’s begin with the virtual machine life cycle. Whatever the hypervisor type,
at the time a virtual machine is created, its creator gives the VMMcertain
parameters. These parameters usually include the number of CPUs, amount
ofmemory,networkingdetails,andstoragedetailsthatthe VMMwilltakeinto
account when creating the guest. For example, a user might want to create a
new guest with two virtual CPUs, 4GBof memory, 10 GBof disk space, one
networkinterfacethatgetsits IPaddressvia DHCP,andaccesstothe DVDdrive.
TheVMMthen creates the virtual machine with those parameters. In the
case of a type 0 hypervisor, the resources are usually dedicated. In this situa-
tion, if there are not two virtual CPUs available and unallocated, the creation
request in our example will fail. For other hypervisor types, the resources are
dedicated or virtualized, depending on the type. Certainly, an IPaddress can-
not be shared, but the virtual CPUs are usually multiplexed on the physical
CPUs as discussed in Section 18.6.1. Similarly, memory management usually
involves allocating more memory to guests than actually exists in physical
memory.Thisis morecomplicatedand isdescribedinSection18.6.2.
Finally, when the virtual machine is no longer needed, it can be deleted.
When this happens, the VMMfirst frees up any used disk space and then
removes the configuration associated wi th the virtual machine, essentially
forgettingthe virtualmachine.
These steps are quite simple compared with building, configuring, run-
ning, and removing physical machines. Creating a virtual machine from an
existingonecanbeaseasyasclickingthe “clone ”buttonandprovidinganew
nameand IPaddress.Thiseaseofcreationcanleadto virtual machine sprawl ,
which occurs when there are so many virtual machines on a system that their
use,history,and state become confusing and difficultto track.
18.5.2 Type 0 Hypervisor
Type0hypervisorshaveexistedformanyyearsundermanynames,including
“partitions ”and “domains. ”They are a hardware feature, and that brings its
own positives and negatives. Operating systems need do nothing special to
takeadvantageoftheirfeatures.The VMMitselfisencodedinthefirmwareand"
3,18.5.3 Type 1 Hypervisor,851,18.5.2 Type 0 Hypervisor,"714 Chapter 18 Virtual Machines
guest 1 guest 2
CPUs
memoryCPUs
memory
hypervisor (in firmware) I/OCPUs
memoryCPUs
memoryguest 3 guest 4guest guest guest guest guest
Figure 18.5 Type 0 hypervisor.
loadedat boot time.In turn, it loads the guestimages to run in each partition.
Thefeaturesetofatype0hypervisorten dstobesmallerthanthoseoftheother
typesbecause it is implementedinhardware. For example,a system might be
split into four virtual systems, each with dedicated CPUs, memory, and I/O
devices. Each guest believes that it has dedicated hardware because it does,
simplifyingmany implementationdetails.
I/Opresents some difficulty, because it is not easy to dedicate I/Odevices
toguestsiftherearenot enough. What ifasystemhas twoEthernetportsand
more than two guests, for example? Either all guests must get their own I/O
devices, or the system must provided I/Odevice sharing. In these cases, the
hypervisor manages shared access or grants all devices to a control partition .
Inthecontrolpartition,aguestoperatingsystemprovidesservices(suchasnet-
working) viadaemonsto otherguests,and the hypervisorroutes I/Orequests
appropriately. Some type 0 hypervisors are even more sophisticated and can
move physical CPUs and memory between running guests. In these cases, the
guests are paravirtualized,aware of the virtualizationand assisting in its exe-
cution.Forexample,aguestmustwatchforsignalsfromthehardwareor VMM
thatahardware change hasoccurred,probeitshardwaredevicestodetectthe
change, and add orsubtract CPUs ormemoryfrom itsavailableresources.
Because type 0 virtualization is very close to raw hardware execution, it
shouldbeconsideredseparatelyfromtheothermethodsdiscussedhere.Atype
0 hypervisor can run multipleguest operating systems (one in each hardware
partition).Allofthose guests,because theyarerunningon rawhardware,can
inturnbe VMMs.Essentially,eachguestoperatingsysteminatype0hypervisor
is a native operating system with a subset of hardware made available to it.
Because of that, each can have its own guest operating systems (Figure 18.5).
Other types of hypervisors usually cannot provide this virtualization-within-
virtualizationfunctionality.
18.5.3 Type 1 Hypervisor
Type1hypervisorsarecommonlyfoundincompanydatacentersandare,ina
sense,becoming “thedata-centeroperatingsystem. ”Theyarespecial-purpose
operatingsystemsthatrunnativelyonthehardware,butratherthanproviding"
3,18.5.4 Type 2 Hypervisor,852,18.5.3 Type 1 Hypervisor,"18.5 Types of VMs and Their Implementations 715
system calls and other interfaces for running programs, they create, run, and
manage guest operating systems. In addition to running on standard hard-
ware,theycanrunontype0hypervisor s,butnotonothertype1hypervisors.
Whatever the platform, guests generally do not know they are running on
anything but the nativehardware.
Type1hypervisorsruninkernelmode,takingadvantageofhardwarepro-
tection.Wherethehost CPUallows,theyusemultiplemodestogiveguestoper-
ating systems their own control and imp roved performance. They implement
device drivers for the hardware they run on, since no other component could
doso.Becausetheyareoperatingsystems,theymustalsoprovide CPUschedul-
ing, memory management, I/Omanagement, protection, and even security.
Frequently,theyprovide APIs,butthose APIssupportapplicationsinguestsor
externalapplicationsthatsupplyfeatu reslikebackups,monitoring,and secu-
rity. Many type 1 hypervisors are closed-source commercial offerings, such as
VMwareESX,whilesomeareopensourceorhybridsofopenandclosedsource,
suchas CitrixXenServerand itsopenXencounterpart.
By using type 1 hypervisors, data-center managers can control and man-
age the operating systems and applications in new and sophisticated ways.
An important benefit is the ability to consolidate more operating systems and
applicationsonto fewersystems.Forexample,ratherthanhavingtensystems
runningat10percentutilizationeach,adatacentermighthaveoneserverman-
agetheentireload.Ifutilizationincreases,guestsandtheirapplicationscanbe
movedtoless-loadedsystemslive,withoutinterruptionofservice.Usingsnap-
shotsandcloning,thesystemcansavethestatesofguestsandduplicatethose
states—amucheasiertaskthanrestor ingfrombackupsorinstallingmanually
or via scripts and tools. The price of this increased manageability is the cost
oftheVMM(ifitisacommercialproduct),theneedtolearnnewmanagement
toolsand methods,and the increasedcomplexity.
Anothertypeoftype1hypervisorincludesvariousgeneral-purposeoper-
atingsystemswith VMMfunctionality.Here,anoperatingsystemsuchasRed-
Hat Enterprise Linux, Windows, or Oracle Solaris performs its normal duties
aswellasprovidinga VMMallowingotheroperatingsystemstorunasguests.
Becauseoftheirextraduties,thesehypervisorstypicallyprovidefewervirtual-
izationfeaturesthanothertype1hypervisors.Inmanyways,theytreataguest
operating system as just another process, but they provide special handling
whentheguesttriestoexecutespecialinstructions.
18.5.4 Type 2 Hypervisor
Type 2 hypervisors are less interesting to us as operating-system explorers,
becausethereisverylittleoperating-systeminvolvementintheseapplication-
level virtual machine managers. This type of VMMis simply another process
run and managed by the host, and even the host does not know that virtual-
izationis happening within the VMM.
Type2hypervisorshavelimitsnotassociatedwithsomeoftheothertypes.
For example, a user needs administrative privileges to access many of the
hardware assistance features of modern CPUs. If the VMMis being run by a
standard user without additional privileges, the VMMcannot take advantage
ofthesefeatures.Duetothislimitation,aswellastheextraoverheadofrunning"
3,18.5.5 Paravirtualization,853,18.5.4 Type 2 Hypervisor,"716 Chapter 18 Virtual Machines
request producer
shared pointer
updated by guest OSrequest consumer
private pointer
in Xen
response producer
shared pointer
updated by
Xenresponse consumer
private pointer
in guest OS
request queue - descriptors queued by the VM but not yet accepted by Xen
outstanding descriptors - descriptor slots awaiting a response from Xen
response queue - descriptors returned by Xen in response to serviced requests
unused descriptors
Figure 18.6 Xen I/O via shared circular buffer.1
ageneral-purposeoperatingsystemaswellasguestoperatingsystems,type2
hypervisorstendto havepooreroverallperformance thantype0 ortype1.
As is often the case, the limitations of type 2 hypervisors also provide
some benefits. They run on a variety of general-purpose operating systems,
andrunningthemrequiresnochangestothehostoperatingsystem.Astudent
canuseatype2hypervisor,forexample,totestanon-nativeoperatingsystem
without replacing the native operating system. In fact, on an Apple laptop,
as t u d e n tc o u l dh a v ev e r s i o n so fW i n d o w s ,L i n u x ,U n i x ,a n dl e s sc o m m o n
operatingsystemsallavailableforlearning and experimentation.
18.5.5 Paravirtualization
As we’ve seen, paravirtualization works differently than the other types of
virtualization. Rather than try to trick a guest operating system into believing
it has a system to itself, paravirtualization presents the guest with a system
thatissimilarbutnotidenticaltotheguest’spreferredsystem.Theguestmust
be modified to run on the paravirtualized virtual hardware. The gain for this
extraworkismoreefficientuseofresourcesandasmallervirtualizationlayer.
The Xen VMMbecame the leader in paravirtulization by implementing
severaltechniquestooptimizetheperformanceofguestsaswellasofthehost
system.Forexample,asmentionedearlier,some VMMspresentvirtualdevices
togueststhatappeartoberealdevices.Insteadoftakingthatapproach,theXen
VMMpresentedcleanandsimpledeviceabstractionsthatallowefficient I/Oas
well as good I/O-relatedcommunication between the guest and the VMM.F o r
1Barham, Paul. “Xen and the Art of Virtualization ”. SOSP ’03 Proceedings of the Nineteenth ACM
SymposiumonOperatingSystemsPrinciples,p164-177. c/circlecopyrt2003AssociationforComputingMachinery,
Inc"
3,18.5.6 Programming-Environment Virtualization,854,18.5.5 Paravirtualization,"18.5 Types of VMs and Their Implementations 717
eachdeviceusedbyeachguest,therewasacircularbuffersharedbytheguest
andthe VMMviasharedmemory.Readandwritedataareplacedinthisbuffer,
asshown in Figure 18.6.
For memory management, Xen did not implement nested page tables.
Rather,eachguesthaditsownsetofpagetables,settoread-only.Xenrequired
theguesttouseaspecificmechanism,a hypercall fromtheguesttothehyper-
visorVMM, when a page-table change was needed. This meant that the guest
operatingsystem’skernelcodemusthavebeenchangedfromthedefaultcode
totheseXen-specificmethods.Tooptimi zeperformance,Xenallowedtheguest
to queue up multiple page-table changes asynchronously via hypercalls and
then checked to ensure that the changes were complete before continuing
operation.
Xen allowed virtualization of x86 CPUs without the use of binary trans-
lation, instead requiring modifications in the guest operating systems like the
onedescribedabove.Overtime,Xenhastakenadvantageofhardwarefeatures
supportingvirtualization.Asaresult,itnolongerrequiresmodifiedguestsand
essentially does not need the paravirtua lization method. Paravirtualization is
stillusedinothersolutions,however,such astype0 hypervisors.
18.5.6 Programming-Environment Virtualization
Another kind of virtualization, based on a different execution model, is the
virtualizationof programming environments. Here,a programming language
is designed to run within a custom-built virtualized environment. For exam-
ple, Oracle’s Java has many features that depend on its running in the Java
virtual machine (JVM), including specific methods for security and memory
management.
Ifwedefinevirtualizationasincludingonlyduplicationofhardware,thisis
notreallyvirtualizationatall.Butweneednotlimitourselvestothatdefinition.
Instead,wecandefineavirtualenvironment,basedon APIs,thatprovidesaset
of features we want to have available for a particular language and programs
writteninthatlanguage.Javapr ogramsrunwithinthe JVMenvironment,and
theJVM iscompiledto be anativeprogramon systemson which itruns.This
arrangement means that Java programs are written once and then can run on
any system (including all of the major operating systems) on which a JVMis
available. The same can be said of interpreted languages , which run inside
programsthat readeach instruction and interpretitinto nativeoperations.
18.5.7 Emulation
Virtualization is probably the most common method for running applications
designedforoneoperatingsystemonadifferentoperatingsystem,but onthe
sameCPU. This method works relatively efficiently because the applications
werecompiledforthe instructionsetthatthe targetsystemuses.
But what if an application or operating system needs to run on a different
CPU? Here, it is necessary to translate all of the source CPU’s instructions so
thattheyareturnedintotheequivalentinstructionsofthetarget CPU.Suchan
environmentisno longervirtualizedbut ratherisfully emulated.
Emulation is useful when the host system has one system architecture
and the guest system was compiled for a different architecture. For example,"
3,18.5.7 Emulation,854,18.5.6 Programming-Environment Virtualization,"18.5 Types of VMs and Their Implementations 717
eachdeviceusedbyeachguest,therewasacircularbuffersharedbytheguest
andthe VMMviasharedmemory.Readandwritedataareplacedinthisbuffer,
asshown in Figure 18.6.
For memory management, Xen did not implement nested page tables.
Rather,eachguesthaditsownsetofpagetables,settoread-only.Xenrequired
theguesttouseaspecificmechanism,a hypercall fromtheguesttothehyper-
visorVMM, when a page-table change was needed. This meant that the guest
operatingsystem’skernelcodemusthavebeenchangedfromthedefaultcode
totheseXen-specificmethods.Tooptimi zeperformance,Xenallowedtheguest
to queue up multiple page-table changes asynchronously via hypercalls and
then checked to ensure that the changes were complete before continuing
operation.
Xen allowed virtualization of x86 CPUs without the use of binary trans-
lation, instead requiring modifications in the guest operating systems like the
onedescribedabove.Overtime,Xenhastakenadvantageofhardwarefeatures
supportingvirtualization.Asaresult,itnolongerrequiresmodifiedguestsand
essentially does not need the paravirtua lization method. Paravirtualization is
stillusedinothersolutions,however,such astype0 hypervisors.
18.5.6 Programming-Environment Virtualization
Another kind of virtualization, based on a different execution model, is the
virtualizationof programming environments. Here,a programming language
is designed to run within a custom-built virtualized environment. For exam-
ple, Oracle’s Java has many features that depend on its running in the Java
virtual machine (JVM), including specific methods for security and memory
management.
Ifwedefinevirtualizationasincludingonlyduplicationofhardware,thisis
notreallyvirtualizationatall.Butweneednotlimitourselvestothatdefinition.
Instead,wecandefineavirtualenvironment,basedon APIs,thatprovidesaset
of features we want to have available for a particular language and programs
writteninthatlanguage.Javapr ogramsrunwithinthe JVMenvironment,and
theJVM iscompiledto be anativeprogramon systemson which itruns.This
arrangement means that Java programs are written once and then can run on
any system (including all of the major operating systems) on which a JVMis
available. The same can be said of interpreted languages , which run inside
programsthat readeach instruction and interpretitinto nativeoperations.
18.5.7 Emulation
Virtualization is probably the most common method for running applications
designedforoneoperatingsystemonadifferentoperatingsystem,but onthe
sameCPU. This method works relatively efficiently because the applications
werecompiledforthe instructionsetthatthe targetsystemuses.
But what if an application or operating system needs to run on a different
CPU? Here, it is necessary to translate all of the source CPU’s instructions so
thattheyareturnedintotheequivalentinstructionsofthetarget CPU.Suchan
environmentisno longervirtualizedbut ratherisfully emulated.
Emulation is useful when the host system has one system architecture
and the guest system was compiled for a different architecture. For example,"
3,18.5.8 Application Containment,855,18.5.7 Emulation,"718 Chapter 18 Virtual Machines
suppose a company has replaced its outdated computer system with a new
systembutwouldliketocontinuetoruncertainimportantprogramsthatwere
compiled for the old system. The programs could be run in an emulator that
translateseachoftheoutdatedsystem’sinstructionsintothenativeinstruction
set of the new system. Emulation can increase the life of programs and allow
us toexploreold architectureswithout havingan actual old machine.
As may be expected, the major challenge of emulation is performance.
Instruction-set emulation may run an order of magnitude slower than native
instructions, because it may take ten instructions on the new system to read,
parse, and simulate an instruction from the old system. Thus, unless the new
machine is ten times faster than the old, the program running on the new
machine will run more slowly than it did on its native hardware. Another
challenge for emulator writers is that it is difficult to create a correct emulator
because,inessence,thistask involveswritingan entire CPUin software.
In spite of these challenges, emulation is very popular, particularly in
gamingcircles.Manypopularvideogameswerewrittenforplatformsthatare
no longer in production. Users who want to run those games frequently can
findanemulatorofsuchaplatformandthenrunthegameunmodifiedwithin
the emulator.Modernsystemsareso much fasterthan oldgameconsoles that
eventheAppleiPhonehasgameemulatorsandgamesavailabletorunwithin
them.
18.5.8 Application Containment
Thegoalofvirtualizationinsomeinstancesistoprovideamethodtosegregate
applications, manage their performance and resource use, and create an easy
waytostart,stop,move,andmanagethem.Insuchcases,perhapsfull-fledged
virtualization is not needed. If the applications are all compiled for the same
operatingsystem,thenwedonotneedcompletevirtualizationtoprovidethese
features.We can insteaduseapplication containment.
Consider one example of application c ontainment. Starting with version
10,OracleSolarishas included containers ,orzones,thatcreateavirtuallayer
between the operating system and the applications. In this system, only one
kernel is installed, and the hardware is not virtualized. Rather, the operating
systemanditsdevicesarevirtualized,providingprocesseswithinazonewith
the impression that they are the only processes on the system. One or more
containers can be created, and each can have its own applications, network
stacks,networkaddressandports,useraccounts,andsoon. CPUandmemory
resources can be divided among the zones and the system-wide processes.
Each zone, in fact, can run its own scheduler to optimize the performance of
itsapplicationsontheallottedresources.Figure18.7showsaSolaris10system
with two containers and the standard “global ”userspace.
Containers are much lighter weight than other virtualization methods.
That is, they use fewer system resources and are faster to instantiate and
destroy,moresimilar to processesthan virtualmachines. For this reason, they
are becoming more commonly used, especially in cloud computing. FreeBSD
was perhaps the first operating system to include a container-like feature
(called “jails ”), andAIXhas a similar feature. Linux added the LXCcontainer
feature in 2014. It is now included in the common Linux distributions via"
2,18.6 Virtualization and Operating-System Components,856,18.5 Types of VMs and Their Implementations,"18.6 Virtualization and Operating-System Components 719
virtual platform
device managementzone 1
global zone
Solaris kernel
network addresseszone 2
zone managementuser programs
system programs
CPU resources
memory resourcesuser programs
system programs
network addresses
device access
CPU resources
memory resourcesuser programs
system programs
network addresses
device access
CPU resources
memory resources
device device…
Figure 18.7 Solaris 10 with two zones.
afl a gi nt h e clone() system call. (The source code for LXCis available at
https://linuxcontainers.org/lxc/downloads .)
Containersarealsoeasytoautomateandmanage,leadingtoorchestration
tools like dockerand Kubernetes . Orchestration tools are means of automat-
ing and coordinating systems and services. Their aim is to make it simple to
run entire suites of distributed applications, just as operating systems make
it simple to run a single program. These tools offer rapid deployment of
full applications, consisting of many p rocesses within containers, and also
offer monitoring and other administration features. For more on docker, see
https://www.docker.com/what-docker .Information about Kubernetescan be
foundat https://kubernetes.io/docs/concep ts/overview/what-is-kubernetes .
18.6 Virtualization and Operating-System Components
Thus far, we have explored the building blocks of virtualization and the var-
ious types of virtualization. In this section, we take a deeper dive into the
operating-system aspects of virtualization, including how the VMMprovides
core operating-system functions like scheduling, I/O, and memory manage-
ment. Here, we answer questions such as these: How do VMMss c h e d u l e CPU
use when guest operating systems believe they have dedicated CPUs? How
can memory management work when many guests require large amounts of
memory?"
3,18.6.1 CPU Scheduling,857,18.6 Virtualization and Operating-System Components,"720 Chapter 18 Virtual Machines
18.6.1 CPU Scheduling
A system with virtualization, even a single- CPUsystem, frequently acts like
a multiprocessor system. The virtualization software presents one or more
virtual CPUs to each of the virtual machines running on the system and then
schedulesthe use of the physical CPUs among the virtualmachines.
The significant variations among virt ualization technologies make it diffi-
culttosummarizetheeffectofvirtualizat iononscheduling.First,let’sconsider
the general case of VMMscheduling. The VMMhas a number of physical CPUs
available and a number of threads to run on those CPUs. The threads can be
VMMthreadsorguestthreads.Guestsareconfiguredwithacertainnumberof
virtualCPUsatcreationtime,andthatnumbercanbeadjustedthroughoutthe
lifeofthe VM.Whenthereareenough CPUstoallocatetherequestednumberto
eachguest,the VMMcantreatthe CPUsasdedicatedandscheduleonlyagiven
guest’sthreadsonthat guest’s CPUs.Inthissituation,theguestsactmuch like
nativeoperatingsystemsrunning on native CPUs.
Ofcourse,inothersituations,theremaynotbeenough CPUstogoaround.
TheVMMitself needs some CPUcycles for guest management and I/Oman-
agement and can steal cycles from the guests by scheduling its threads across
all of the system CPUs, but the impact of this action is relatively minor. More
difficultisthecaseof overcommitment ,inwhichtheguestsareconfiguredfor
moreCPUsthanexistinthesystem.Here,a VMMcan usestandardscheduling
algorithmstomakeprogressoneachthreadbutcanalsoaddafairnessaspectto
thosealgorithms.Forexample,iftherearesixhardware CPUsandtwelveguest-
allocated CPUs,theVMMcanallocate CPUresourcesproportionally,givingeach
g u e s th a l fo ft h e CPUresources it believes it has. The VMMcan still present all
twelvevirtual CPUstotheguests,butinmappingthemontophysical CPUs,the
VMMcan useitsschedulertodistributethemappropriately.
Evengivenaschedulerthatprovidesfairness,anyguestoperating-system
scheduling algorithm that assumes a certain amount of progress in a given
amount of time will most likely be negatively affected by virtualization. Con-
sideratime-sharingoperatingsystemthattriestoallot100millisecondstoeach
t i m es l i c et og i v eu s e r sar e a s o n a b l er e s ponse time. Within a virtual machine,
thisoperatingsystemreceivesonly what CPUresourcesthevirtualizationsys-
tem gives it. A100-millisecond time slice may take much more than 100 mil-
liseconds of virtual CPUtime.Depending on how busy the system is, the time
slicemaytakeasecondormore,resultinginverypoorresponsetimesforusers
loggedintothatvirtualmachine.Theeffectonareal-timeoperatingsystemcan
be evenmoreserious.
Thenetoutcomeofsuchschedulingistha tindividualvirtualizedoperating
systems receive only a portion of the available CPUcycles, even though they
believe they are receiving all of the cycles and indeed are scheduling all of
thecycles.Commonly,thetime-of-daycl ocksinvirtualmachinesareincorrect
because timers take longer to trigger than they would on dedicated CPUs.
Virtualizationcanthusundotheschedu ling-algorithmeffortsoftheoperating
systemswithin virtualmachines.
To correct for this, the VMMmakesanapplicationavailableforeachtypeof
operatingsystemthatthesystemadministratorcaninstallintotheguests.This
application corrects clock drift and can have other functions, such as virtual
devicemanagement."
3,18.6.2 Memory Management,858,18.6.1 CPU Scheduling,"18.6 Virtualization and Operating-System Components 721
18.6.2 Memory Management
Efficient memory use in general-purpose operating systems is a major key to
performance.Invirtualizedenvironments,therearemoreusersofmemory(the
guestsandtheirapplications,aswellasthe VMM),leadingtomorepressureon
memory use. Further adding to this pressure is the fact that VMMs typically
overcommit memory, so that the total memory allocated to guests exceeds
the amount that physically exists in the system. The extra need for efficient
memory use is not lost on the implementers of VMMs, who take extensive
measuresto ensuretheoptimaluseof memory.
For example, VMwareESXuses several methods of memory management.
Before memory optimization can occur, the VMMmust establish how much
real memory each guest should use. To do that, the VMMfirst evaluates each
guest’s maximum memory size. General-purpose operating systems do not
expecttheamountofmemoryinthesystemtochange,so VMMsmustmaintain
theillusionthattheguesthasthatamountofmemory.Next,the VMMcomputes
atargetreal-memoryallocationforeachguestbasedontheconfiguredmemory
for that guest and other factors, such as overcommitment and system load. It
thenusesthethreelow-levelmechanismslistedbelowtoreclaimmemoryfrom
theguests
1.Recall that a guest believes it controls memory allocation via its page-
table management, whereas in reality the VMMmaintains a nested page
table that translates the guest page table to the real page table. The VMM
canusethisextralevelofindirectiontooptimizetheguest’suseofmem-
ory without the guest’s knowledge or help. One approach is to provide
doublepaging.Here,the VMMhas itsownpage-replacementalgorithms
and loads pages into a backing store that the guest believes is physical
memory.Ofcourse,the VMMknowslessabouttheguest’smemoryaccess
patterns than the guest does, so its paging is less efficient, creating per-
formance problems. VMMs do use this method when other methods are
notavailableorarenotprovidingenoughfreememory.However,itisnot
thepreferredapproach.
2.A common solution is for the VMMto install in each guest a pseudo–
devicedriverorkernelmodulethatthe VMMcontrols.(A pseudo–device
driverusesdevice-driverinterfaces,appearingtothekerneltobeadevice
driver, but does not actually control a device. Rather, it is an easy way
to add kernel-mode code without directly modifying the kernel.) This
balloon memory manager communicates with the VMMand is told to
allocate or deallocate memory. If told to allocate, it allocates memory
and tells the operating system to pin the allocated pages into physical
memory.Recallthatpinninglocksapageintophysicalmemorysothatit
cannot be moved or paged out. To the guest, these pinned pages appear
to decrease the amount of physical memory it has available, creating
memory pressure. The guest then may free up other physical memory
to be sure it has enough free memory. Meanwhile, the VMM, knowing
thatthepagespinnedbytheballoonprocesswillneverbeused,removes
thosephysicalpagesfromtheguestandallocatesthemtoanotherguest.
A tt h es a m et i m e ,t h eg u e s ti su s i n gi t so w nm e m o r y - m a n a g e m e n ta n d
paging algorithms to manage the available memory, which is the most"
3,18.6.3 I/O,859,18.6.2 Memory Management,"722 Chapter 18 Virtual Machines
efficient option. If memory pressure within the entire system decreases,
theVMMwill tell the balloon process within the guest to unpin and free
someor allof the memory,allowing theguestmorepagesfor itsuse.
3.Another common method for reducing memory pressure is for the VMM
to determine if the same page has been loaded more than once. If this
is the case, the VMMreduces the number of copies of the page to one
and maps the other users of the page to that one copy. VMware, for
example, randomly samples guest memory and creates a hash for each
page sampled. That hash value is a “thumbprint ”o ft h ep a g e .T h eh a s h
of every page examined is compared with other hashes stored in a hash
table.Ifthereisamatch,thepagesarecomparedbytebybytetoseeifthey
really are identical. If they are, one page is freed, and its logical address
is mapped to the other’s physical address. This technique might seem
at first to be ineffective, but consider that guests run operating systems.
If multiple guests run the same operating system, then only one copy of
theactiveoperating-systempagesneedbeinmemory.Similarly,multiple
guestscouldberunningthesamesetofapplications,againalikelysource
of memorysharing.
The overall effect of these mechanisms is to enable guests to behave and
performasiftheyhadthefullamountofmemoryrequested,althoughinreality
theyhave less.
18.6.3 I/O
In the area of I/O, hypervisors have some leeway and can be less concerned
with how they represent the underlying hardware to their guests. Because
of the wide variation in I/Odevices, operating systems are used to dealing
withvaryingandflexible I/Omechanisms.Forexample,anoperatingsystem’s
device-driver mechanism provides a uniform interface to the operating sys-
tem whatever the I/Odevice. Device-driver interfaces are designed to allow
third-partyhardwaremanufacturerstoprovidedevicedriversconnectingtheir
devices to the operating system. Usually, device drivers can be dynamically
loadedandunloaded.Virtualizationtakesadvantageofthisbuilt-inflexibility
by providingspecificvirtualizeddevicesto guestoperatingsystems.
As described in Section 18.5, VMMs vary greatly in how they provide I/O
to their guests. I/Odevices may be dedicated to guests, for example, or the
VMMmay have device drivers onto which it maps guest I/O.T h eVMMmay
also provide idealized device drivers to guests. In this case, the guest sees an
easy-to-controldevice,butinrealitythatsimpledevicedrivercommunicatesto
theVMM,which sendstherequeststoamorecomplicatedrealdevicethrough
a morecomplexrealdevicedriver. I/Oinvirtualenvironmentsiscomplicated
and requirescareful VMMdesignandimplementation.
Consider the case of a hypervisor and hardware combination that allows
devicestobededicatedtoaguestandallowstheguesttoaccessthosedevices
directly. Of course, a device dedicated to one guest is not available to any
other guests, but this direct access can still be useful in some circumstances.
The reason to allow direct access is to improve I/Operformance. The less the
hypervisor has to do to enable I/Ofor its guests, the faster the I/Ocan occur.
With type 0 hypervisors that provide direct device access, guests can often"
3,18.6.4 Storage Management,860,18.6.3 I/O,"18.6 Virtualization and Operating-System Components 723
run at the same speed as native operating systems. When type 0 hypervisors
insteadprovideshareddevices,performance maysuffer.
With direct device access in type 1 and 2 hypervisors, performance can
be similar to that of native operating systems if certain hardware support
is present. The hardware needs to provide DMApass-through with facilities
likeVT-d, as well as direct interrupt delivery (interrupts going directly to the
guests). Given how frequently interrupts occur, it should be no surprise that
t h eg u e s t so nh a r d w a r ew i t h o u tt h e s ef e a t u r e sh a v ew o r s ep e r f o r m a n c et h a n
iftheywere running natively.
In addition to direct access, VMMs provide shared access to devices. Con-
sideradiskdrivetowhichmultipleguestshaveaccess.The VMMmustprovide
protection while the device is being shared, assuring that a guest can access
only the blocks specified in the guest’s configuration. In such instances, the
VMMmust be part of every I/O, checking it for correctness as well as routing
thedatato and fromthe appropriatedevicesand guests.
In the area of networking, VMMs also have work to do. General-purpose
operating systems typically have one Internet protocol ( IP) address, although
they sometimes have more than one—for example, to connect to a manage-
mentnetwork,backupnetwork,andproductionnetwork.Withvirtualization,
eachguestneedsatleastone IPaddress,becausethatistheguest’smainmode
of communication. Therefore, a server running a VMMm a yh a v ed o z e n so f
addresses, and the VMMacts as a virtual switch to route the network packets
tothe addressedguests.
The guests can be “directly ”connected to the network by an IPaddress
thatisseenbythebroadernetwork(thisisknownas bridging ).Alternatively,
theVMMcan provide a network address translation (NAT) address. The NAT
address is local to the server on which the guest is running, and the VMM
provides routing between the broader network and the guest. The VMMalso
provides firewalling to guard connections between guests within the system
andbetweenguestsand externalsystems.
18.6.4 Storage Management
An important question in determining how virtualization works is this: If
multiple operating systems have been installed, what and where is the boot
disk?Clearly,virtualizedenvironmentsneedtoapproachstoragemanagement
differently than do native operating systems. Even the standard multiboot
methodofslicingthebootdiskintopartitions,installingabootmanagerinone
partition,andinstallingeachotheroper atingsysteminanotherpartitionisnot
sufficient, because partitioning has limits that would prevent it from working
fortens orhundredsof virtualmachines.
Onceagain,thesolutiontothisproblemdependsonthetypeofhypervisor.
Type 0 hypervisors often allow root disk partitioning, partly because these
systems tend to run fewer guests than other systems. Alternatively, a disk
manager may be part of the control partition, and that disk manager may
providediskspace(including boot disks)to theotherpartitions.
Type 1 hypervisors store the guest root disk (and configuration informa-
tion) in one or more files in the file systems provided by the VMM.T y p e2
hypervisorsstorethesameinformationinthehostoperatingsystem’sfilesys-
tems. In essence, a disk image , containing all of the contents of the root disk"
3,18.6.5 Live Migration,861,18.6.4 Storage Management,"724 Chapter 18 Virtual Machines
of the guest, is contained in one file in the VMM. Asidefrom the potential per-
formance problems that causes, this is a clever solution, because it simplifies
copyingandmovingguests.Iftheadministratorwantsaduplicateoftheguest
(for testing, for example), she simply copies the associated disk image of the
guestandtellsthe VMMabout the newcopy.Bootingthe newvirtualmachine
brings up an identical guest. Moving a virtual machine from one system to
another that runs the same VMMis as simple as halting the guest, copying the
imageto theothersystem,andstarting theguestthere.
Guests sometimes need more disk space than is available in their root
disk image. For example, a nonvirtualized database server might use several
file systems spread across many disks to store various parts of the database.
Virtualizingsuchadatabaseusuallyinvolvescreatingseveralfilesandhaving
theVMMpresentthose to the guestas disks.The guestthenexecutesas usual,
withthe VMMtranslatingthedisk I/Orequestscomingfromtheguestintofile
I/Ocommands to the correct files.
Frequently, VMMs provide a mechanism to capture a physical system as
it is currently configured and convert it to a guest that the VMMcan manage
and run. This physical-to-virtual (P-to-V) conversion reads the disk blocks of
the physical system’s disks and stores them in files on the VMM’s system or
on shared storage that the VMMcan access. VMMsa l s op r o v i d ea virtual-to-
physical (V-to-P) procedure for converting a guest to a physical system. This
procedure is sometimes neededfor debugging: a problem could be caused by
theVMMor associated components, and the administrator could attempt to
solvetheproblembyremovingvirtualizationfromtheproblemvariables.V-to-
Pconversioncantakethefilescontainingalloftheguestdataandgeneratedisk
blocksonaphysicaldisk,recreatingtheguestasanativeoperatingsystemand
applications. Once the testing is concluded, the original system can be reused
for other purposes when the virtual mach ine returns to service, or the virtual
machine can be deletedand the original systemcan continue to run.
18.6.5 Live Migration
One feature not found in general-purpose operating systems but found in
type 0 and type 1 hypervisors is the live migration of a running guest from
one system to another. We mentioned this capability earlier. Here, we explore
the details of how live migration works and why VMMs can implement it
relatively easily while general-purpose operating systems, in spite of some
researchattempts,cannot.
First, let’s consider how live migration works. A running guest on one
system is copied to another system running the same VMM. The copy occurs
with so little interruption of service that users logged in to the guest, as well
asnetworkconnections tothe guest,continue withoutnoticeable impact.This
ratherastonishing abilityisverypower fulinresourcemanagementand hard-
ware administration. After all, compare it with the steps necessary without
virtualization: we must warn users, shut down the processes, possibly move
thebinaries,and restartthe processeson thenew system.Only then can users
access the services again. With live migration, we can decrease the load on an
overloaded system or make hardware or system changes with no discernable
disruptionfor users."
2,18.7 Examples,863,18.6 Virtualization and Operating-System Components,"726 Chapter 18 Virtual Machines
Alimitationoflivemigrationisthatnodiskstateistransferred.Onereason
livemigrationispossibleis that mostof the guest’sstateis maintainedwithin
the guest—for example, open file tables, system-call state, kernel state, and
so on. Because disk I/Ois much slower than memory access, however, and
used disk space is usually much larger than used memory, disks associated
with the guest cannot be moved as part of a live migration. Rather, the disk
must be remote to the guest, accessed over the network. In that case, disk
access state is maintained within the guest, and network connections are all
that matter to the VMM. The network connections are maintained during the
migration,soremotediskaccesscontinues.Typically, NFS,CIFS,oriSCSIisused
to store virtual machine images and any other storage a guest needs access
to. These network-based storage accesses simply continue when the network
connections are continued once the guesthas beenmigrated.
Live migration makes it possible to manage data centers in entirely new
ways.Forexample,virtualizationmanagementtoolscanmonitorallthe VMMs
in an environment and automatically balance resource use by moving guests
between the VMMs. These tools can also optimize the use of electricity and
cooling by migrating all guests off selectedserversif other serverscan handle
theloadandpoweringdowntheselectedserversentirely.Iftheloadincreases,
thetools can powerupthe serversandmigrateguestsback to them.
18.7 Examples
Despite the advantages of virtual machines, they received little attention for
a number of years after they were first developed. Today, however, virtual
machines are coming into greater use as a means of solving system compat-
ibilityproblems.Inthissection,weexploretwopopularcontemporaryvirtual
machines:the VMwareWorkstationandtheJavavirtualmachine.Thesevirtual
machines can typically run on top of operating systems of any of the design
typesdiscussedinearlierchapters.
18.7.1 VMware
VMware Workstation is a popular commercial application that abstracts Intel
x86 and compatible hardware into isolated virtual machines. VMware Work-
stationisaprimeexampleofaType2hypervisor.Itrunsasanapplicationona
host operating system such as Windows or Linux and allows this host system
to run several different guest operating systems concurrently as independent
virtualmachines.
The architectureof such a systemis shown in Figure18.9. In this scenario,
Linuxisrunningasthehostoperatingsystem,and FreeBSD,W indows NT,and
Windows XPare running as guest operating systems. At the heart of VMware
is the virtualization layer, which abstracts the physical hardware into isolated
virtualmachinesrunningasguestopera tingsystems.Eachvirtualmachinehas
itsown virtual CPU, memory,diskdrives,network interfaces,andso forth.
The physical disk that the guest owns and manages is really just a file
withinthefilesystemofthehostoperatingsystem.Tocreateanidenticalguest,
we can simply copy the file. Copying the file to another location protects the
guestagainst a disasterat the original site.Moving the fileto another location"
3,18.7.1 VMware,863,18.7 Examples,"726 Chapter 18 Virtual Machines
Alimitationoflivemigrationisthatnodiskstateistransferred.Onereason
livemigrationispossibleis that mostof the guest’sstateis maintainedwithin
the guest—for example, open file tables, system-call state, kernel state, and
so on. Because disk I/Ois much slower than memory access, however, and
used disk space is usually much larger than used memory, disks associated
with the guest cannot be moved as part of a live migration. Rather, the disk
must be remote to the guest, accessed over the network. In that case, disk
access state is maintained within the guest, and network connections are all
that matter to the VMM. The network connections are maintained during the
migration,soremotediskaccesscontinues.Typically, NFS,CIFS,oriSCSIisused
to store virtual machine images and any other storage a guest needs access
to. These network-based storage accesses simply continue when the network
connections are continued once the guesthas beenmigrated.
Live migration makes it possible to manage data centers in entirely new
ways.Forexample,virtualizationmanagementtoolscanmonitorallthe VMMs
in an environment and automatically balance resource use by moving guests
between the VMMs. These tools can also optimize the use of electricity and
cooling by migrating all guests off selectedserversif other serverscan handle
theloadandpoweringdowntheselectedserversentirely.Iftheloadincreases,
thetools can powerupthe serversandmigrateguestsback to them.
18.7 Examples
Despite the advantages of virtual machines, they received little attention for
a number of years after they were first developed. Today, however, virtual
machines are coming into greater use as a means of solving system compat-
ibilityproblems.Inthissection,weexploretwopopularcontemporaryvirtual
machines:the VMwareWorkstationandtheJavavirtualmachine.Thesevirtual
machines can typically run on top of operating systems of any of the design
typesdiscussedinearlierchapters.
18.7.1 VMware
VMware Workstation is a popular commercial application that abstracts Intel
x86 and compatible hardware into isolated virtual machines. VMware Work-
stationisaprimeexampleofaType2hypervisor.Itrunsasanapplicationona
host operating system such as Windows or Linux and allows this host system
to run several different guest operating systems concurrently as independent
virtualmachines.
The architectureof such a systemis shown in Figure18.9. In this scenario,
Linuxisrunningasthehostoperatingsystem,and FreeBSD,W indows NT,and
Windows XPare running as guest operating systems. At the heart of VMware
is the virtualization layer, which abstracts the physical hardware into isolated
virtualmachinesrunningasguestopera tingsystems.Eachvirtualmachinehas
itsown virtual CPU, memory,diskdrives,network interfaces,andso forth.
The physical disk that the guest owns and manages is really just a file
withinthefilesystemofthehostoperatingsystem.Tocreateanidenticalguest,
we can simply copy the file. Copying the file to another location protects the
guestagainst a disasterat the original site.Moving the fileto another location"
3,18.7.2 The Java Virtual Machine,864,18.7.1 VMware,"18.7 Examples 727
virtualization layer
host operating system
(Linux)
CPU memoryhardware
I/O devicesapplication application application application
guest operating
system
(free BSD)
virtual CPU
virtual memory
virtual devicesguest operating
system
(Windows NT)
virtual CPU
virtual memory
virtual devicesguest operating
system
(Windows XP)
virtual CPU
virtual memory
virtual devices
Figure 18.9 VMware Workstation architecture.
moves the guest system. Such capabilities, as explained earlier, can improve
theefficiency of systemadministration aswellas systemresourceuse.
18.7.2 The Java Virtual Machine
Java is a popular object-oriented programming language introduced by Sun
Microsystems in 1995. In addition to a language specification and a large
APIlibrary, Java provides a specification for a Java virtual machine, or JVM.
Java therefore is an example of programming-environment virtualization, as
discussedinSection18.5.6.
Java objects are specified with the classconstruct; a Java program con-
sists of one or more classes. For each Java class, the compiler produces an
architecture-neutral bytecode output( .class)filethatwillrunonanyimple-
mentationof the JVM.
TheJVMis a specification for an abstract computer. It consists of a class
loaderand a Java interpreterthat executesthe architecture-neutralbytecodes,
as diagrammed in Figure 18.10. The class loader loads the compiled .class
files from both the Java program and the Java APIfor execution by the Java
interpreter. After a class is loa ded, the verifier checks that the .classfile is
validJavabytecodeandthatitdoesnotoverfloworunderflowthestack.Italso
ensures that the bytecode does not per form pointer arithmetic, which could
provide illegal memory access. If the class passes verification, it is run by the
Java interpreter. The JVMalso automatically manages memory by performing
garbage collection —thepracticeofreclaimingmemoryfromobjectsnolonger
inuseandreturningittothesystem.Muchresearchfocusesongarbagecollec-
tionalgorithmsforincreasingtheperformanceofJavaprogramsinthevirtual
machine."
2,18.8 Virtualization Research,865,18.7 Examples,"728 Chapter 18 Virtual Machines
host system
(Windows, Linux, etc.)class loader
Java
interpreterJava program
.class filesJava API
.class files
Figure 18.10 The Java virtual machine.
TheJVMmay be implemented in software on top of a host operating
system, such as Windows, Linux, or mac OS, or as part of a web browser.
Alternatively,the JVMmaybeimplementedinhardwareon achipspecifically
designed to run Java programs. If the JVMis implemented in software, the
Java interpreter interprets the bytecode operations one at a time. A faster
software technique is to use a just-in-time (JIT) compiler. Here, the first time
aJavamethodisinvoked,thebytecodesforthemethodareturnedintonative
machinelanguageforthehostsystem.Theseoperationsarethencachedsothat
subsequent invocations of a method are performed using the native machine
instructions, and the bytecode operations need not be interpreted all over
again. Running the JVMin hardware is potentially even faster. Here, a special
JavachipexecutestheJavabytecodeoperationsasnativecode,thusbypassing
theneedfor eithera softwareinterpreterora just-in-timecompiler.
18.8 Virtualization Research
As mentioned earlier,machine virtualization has enjoyed growing popularity
inrecentyearsasameansofsolvingsyst emcompatibilityproblems.Research
has expanded to cover many other uses of machine virtualization, including
support for microservices running on library operating systems and secure
partitioning of resources in embedded systems. Consequently, quite a lot of
interesting,activeresearchisunderway.
Frequently, in the context of cloud computing, the same application
is run on thousands of systems. To better manage those deployments,
they can be virtualized. But consider the execution stack in that case—the
application on top of a service-rich general-purpose operating system within
a virtual machine managed by a hypervisor. Projects like unikernels , built
onlibrary operating systems , aim to improve efficiency and security in these
environments. Unikernels are specialized machine images, using one address
space, that shrink the attack surface and resource footprint of deployed
applications. In essence, they compile the application, the system libraries it
calls, and the kernel services it uses into a single binary that runs within a
virtual environment (or even on bare metal). While research into changing
how operatingsystemkernels,hardware,andapplications interactisnot new
(see https://pdos.csail.mit.edu/6.828/20 05/readings/engler95exokernel.pdf ,"
2,18.9 Summary,866,18.8 Virtualization Research,"18.9 Summary 729
for example), cloud computing and virtualization have created renewed
interestinthearea.See http://unikernel.org for moredetails.
The virtualization instructions in modern CPUs have given rise to a new
branchofvirtualizationresearchfocusingnotonmoreefficientuseofhardware
butratheronbettercontrolofprocesses. Partitioninghypervisorspartitionthe
existingmachinephysicalresourcesamongstguests,therebyfullycommitting
rather than overcommitting machine resources. Partitioning hypervisors can
securely extend the features of an existing operating system via functionality
in another operating system (run in a separate guest VMdomain), running on
a subset of machine physical resources. This avoids the tedium of writing an
entire operating system from scratch. For example, a Linux system that lacks
real-timecapabilitiesforsafety-andsecurity-criticaltaskscanbeextendedwith
a lightweight real-time operating syst em running in its own virtual machine.
Traditional hypervisors have higher overhead than running native tasks, so a
newtypeof hypervisoris needed.
Eachtaskrunswithinavirtualmachine,butthehypervisoronlyinitializes
thesystemand startsthetasksandisnot involvedwithcontinuing operation.
Eachvirtualmachinehasitsownallocatedhardwareandisfreetomanagethat
hardware without interference from the hypervisor. Because the hypervisor
does not interrupt task operations and is not called by the tasks, the tasks can
have real-timeaspectsand can be much more secure.
Within the class of partitioning hypervisors are the Quest-V ,eVM,
Xtratum and Siemens Jailhouse projects. These are separation hypervisors
(see http://www.csl.sri.com/use rs/rushby/papers/sosp81.pdf )t h a tu s e
virtualization to partition separate system components into a chip-level
distributed system. Secure shared memory channels are then implemented
using hardware extended page tables so that separate sandboxed guests
can communicate with one another. The targets of these projects are
areas such as robotics, self-driving cars, and the Internet of Things. See
https://www.cs.bu.edu/richw est/papers/west-tocs16.pdf for moredetails.
18.9 Summary
•Virtualization is a method for providing a guest with a duplicate of a
system’sunderlyinghardware.Multipleguestscanrunonagivensystem,
each believingthat itisthenativeoperatingsystemand isinfullcontrol.
•Virtualization started as a method to allow IBMto segregate users and
providethemwiththeirownexecutionenvironmentson IBMmainframes.
Since then, thanks to improvements in system and CPUperformance and
innovativesoftwaretechniques,virtualizationhasbecomeacommonfea-
ture in data centers and even on personal computers. Because of its pop-
ularity, CPUdesignershave addedfeaturesto support virtualization.This
snowball effect is likely to continue, with virtualization and its hardware
supportincreasing overtime.
•The virtual machine manager, or hypervisor, creates and runs the virtual
machine.Type0hypervisorsareimplementedinthehardwareandrequire
modifications to the operating system to ensure proper operation. Some"
2,Further Reading,867,18.9 Summary,"730 Chapter 18 Virtual Machines
type 0 hypervisors offer an example of paravirtualization, in which the
operatingsystemisawareof virtualizationand assistsinitsexecution.
•Type 1 hypervisors provide the environment and features needed to cre-
ate, run, and manage guest virtual machines. Each guest includes all of
the software typically associated with a full native system, including the
operatingsystem,devicedrivers,applications,useraccounts, and soon.
•Type 2 hypervisors are simply applications that run on other operating
systems, which do not know that virtualization is taking place. These
hypervisors do not have hardware or host support so must perform all
virtualizationactivitiesinthecontext of aprocess.
•Programming-environment virtualization is part of the design of a pro-
gramming language. The language specifies a containing application in
which programs run, and this application provides services to the pro-
grams.
•Emulation is used when a host system has one architecture and the guest
was compiled for a different architecture. Every instruction the guest
wants to execute must be translated from its instruction set to that of
the native hardware. Although this method involves some performance
penalty,itisbalancedbytheusefulnessofbeingabletorunoldprograms
onnewer,incompatiblehardwareorrungamesdesignedforoldconsoles
on modern hardware.
•Implementing virtualization is challenging, especially when hardware
support is minimal. The more features providedby the system, the easier
virtualizationistoimplementandthebettertheperformanceoftheguests.
•VMMs take advantage of whatever hardware support is available when
optimizing CPUscheduling, memory management, and I/Omodules to
provideguestswithoptimumresourceusewhileprotectingthe VMMfrom
the guestsand the guestsfrom one another.
•Currentresearchisextendingtheusesofvirtualization.Unikernelsaimto
increase efficiency and decrease security attack surface by compiling an
application, its libraries, and the k ernel resources the application needs
intoonebinarywithoneaddressspace thatrunswithinavirtualmachine.
Partitioning hypervisors provide secure execution, real-time operation,
and other features traditionally only available to applications running on
dedicatedhardware.
Further Reading
Theoriginal IBMvirtualmachineisdescribedi n[MeyerandSeawright(1970)].
[Popek and Goldberg (1974)] established the characteristics that help define
VMMs. Methods of implementing virtual machines are discussed in [Agesen
etal.(2010)].
Intel x86 hardware virtualization support is described in [Neiger et al.
(2006)]. AMDhardware virtualization support is described in a white paper
availableat http://developer.amd.com/asse ts/NPT-WP-1%201-ﬁnal-TM.pdf ."
2,Bibliography,868,Further Reading,"Bibliography 731
Memory management in VMware is described in [Waldspurger (2002)].
[Gordon et al. (2012)] propose a solution to the problem of I/Ooverhead in
virtualized environments. Some protection challenges and attacks in virtual
environmentsare discussed in[Wojtczuk and Ruthkowska (2011)].
Forearlyworkonalternativekerneldesigns,see https://pdos.csail.mit.edu
/6.828/2005/readings/engler95exokernel.pdf . For more on unikernels, see
[West et al. (2016)] and http://unikernel.org . Partitioning hypervisors are dis-
cussed in http://ethdocs.org/en/latest/introduction/what-is-ethereum.html ,
and https://lwn.net/Articles/578295 and[Madhavapeddyetal.(2013)].Quest-
V,aseparationhypervisor,isdetailedin http://www.csl.sri.com/users/rushby/
papers/sosp81.pdf andhttps://www.cs.bu.edu/ ric hwest/papers/west-tocs16
.pdf.
Theopen-source VirtualBox projectisavailablefrom http://www.virtualbox
.org.Thesourcecodefor LXCisavailableat https://linuxcontainers.org/lxc/dow
nloads.
For more on docker, see https://www.docker.com/what-docker .I n f o r m a -
tionaboutKubernetescanbefoundat https://kubernetes.io/docs/concepts/ov
erview/what-is-kubernetes .
Bibliography
[Agesen et al. (2010)] O. Agesen, A. Garthwaite, J. Sheldon, and P. Subrah-
manyam, “TheEvolutionofanx86VirtualMachineMonitor ”,Proceedings of the
ACM Symposium on Operating Systems Principles (2010), pages3–18.
[Gordon et al. (2012)] A .G o r d o n ,N .A .N .H a r’ E l ,M .B e n - Y e h u d a ,A .L a n d a u ,
A.Schuster,andD.Tsafrir, “ELI:Bare-metalPerformancefor I/OVirtualization ”,
Proceedings of the International Conference on Architectural Support for Programming
Languages and Operating Systems (2012), pages411–422.
[Madhavapeddy et al. (2013)] A.Madhavapeddy ,R.Mirtier ,C.Rotsos,D.Scott,
B.Singh,T.Gazagnaire,S.Smith,S.Hand,andJ.Crowcroft, “Unikernels:Library
OperatingSystems fortheCloud ”(2013).
[Meyer and Seawright (1970)] R. A. Meyer and L. H. Seawright, “AV i r t u a l
Machine Time-Sharing System ”,IBM Systems Journal , Volume 9, Number 3
(1970), pages199–218.
[Neiger et al. (2006)] G. Neiger,A. Santoni, F. Leun g, D.Rodgers, and R. Uhlig,
“IntelVirtualizationTechnology:Hardwa re Support for Efficient Processor Vir-
tualization ”,Intel Technology Journal , Volume 10, (2006).
[Popek and Goldberg (1974)] G.J.PopekandR.P.Goldberg, “FormalRequire-
ments for Virtualizable Third Generation Architectures ”,Communications of the
ACM,Volume17, Number7(1974), pages 412–421.
[Waldspurger (2002)] C. Waldspurger, “Memory Resource Management in
VMware ESX Server ”,Operating Systems Review , Volume 36, Number 4 (2002),
pages181–194.
[West et al. (2016)] R. West, Y. Li, E. Missimer, and M. Danish, “A Virtualized
SeparationKernelforMixedCriticality Systems ”, Volume34, (2016)."
2,Chapter 18 Exercises,870,Bibliography,"Chapter 18 Exercises
18.1Describethethreetypesoftraditionalhypervisors.
18.2Describe four virtualization-like execution environments, and explain
how theydifferfrom “true ”virtualization.
18.3Describe four benefitsof virtualization.
18.4Why are VMMs unable to implement trap-and-emulate-based virtual-
i z a t i o no ns o m e CPUs? Lacking the ability to trap and emulate, what
method can a VMMusetoimplementvirtualization?
18.5What hardware assistance for virtualization can be provided by mod-
ernCPUs?
18.6Why is live migration possible in virtual environments but much less
possiblefora nativeoperatingsystem?EX-55"
1,Chapter 19 Networks and Distributed Systems,871,Chapter 18 Virtual Machines,"19CHAPTER Networks and
Distributed
Systems
Updated by Sarah Diesburg
A distributed system is a collection of processors that do not share memory
ora clock.Instead,each nodehas itsown local memory.Thenodescommuni-
cate with one another through various networks, such as high-speed buses.
Distributed systems are more relevant than ever, and you have almost cer-
tainly used some sort of distributed service. Applications of distributed sys-
temsrangefromprovidingtransparentaccesstofilesinsideanorganization,to
large-scalecloudfileandphotostorageservices,tobusinessanalysisoftrends
onlargedatasets,toparallelprocessingofscientificdata,andmore.Infact,the
mostbasicexampleofadistributedsystemisonewearealllikelyveryfamiliar
with—the Internet.
In this chapter, we discuss the general structure of distributed systems
and the networks that interconnect them. We also contrast the main differ-
ences in the types and roles of current distributed system designs. Finally, we
investigatesome of the basic designs and designchallenges of distributedfile
systems.
CHAPTER OBJECTIVES
•Explain the advantages of networked and distributed systems.
•Provideahigh-leveloverviewofthenetworksthatinterconnectdistributed
systems.
•Define the roles and types of distributed systems in use today.
•Discuss issues concerning the design of distributed file systems.
19.1 Advantages of Distributed Systems
Adistributed system is a collection of loosely coupled nodes interconnected
by a communication network. From the point of view of a specific node in
a distributed system, the rest of the nodes and their respective resources are
remote, whereas its own resources are local.
733"
2,19.1 Advantages of Distributed Systems,871,Chapter 19 Networks and Distributed Systems,"19CHAPTER Networks and
Distributed
Systems
Updated by Sarah Diesburg
A distributed system is a collection of processors that do not share memory
ora clock.Instead,each nodehas itsown local memory.Thenodescommuni-
cate with one another through various networks, such as high-speed buses.
Distributed systems are more relevant than ever, and you have almost cer-
tainly used some sort of distributed service. Applications of distributed sys-
temsrangefromprovidingtransparentaccesstofilesinsideanorganization,to
large-scalecloudfileandphotostorageservices,tobusinessanalysisoftrends
onlargedatasets,toparallelprocessingofscientificdata,andmore.Infact,the
mostbasicexampleofadistributedsystemisonewearealllikelyveryfamiliar
with—the Internet.
In this chapter, we discuss the general structure of distributed systems
and the networks that interconnect them. We also contrast the main differ-
ences in the types and roles of current distributed system designs. Finally, we
investigatesome of the basic designs and designchallenges of distributedfile
systems.
CHAPTER OBJECTIVES
•Explain the advantages of networked and distributed systems.
•Provideahigh-leveloverviewofthenetworksthatinterconnectdistributed
systems.
•Define the roles and types of distributed systems in use today.
•Discuss issues concerning the design of distributed file systems.
19.1 Advantages of Distributed Systems
Adistributed system is a collection of loosely coupled nodes interconnected
by a communication network. From the point of view of a specific node in
a distributed system, the rest of the nodes and their respective resources are
remote, whereas its own resources are local.
733"
3,19.1.1 Resource Sharing,872,19.1 Advantages of Distributed Systems,"734 Chapter 19 Networks and Distributed Systems
site C
resources
site Bclientcommunicationsite A    
server
network
Figure 19.1 A client-server distributed system.
The nodes in a distributed system may vary in size and function. They
may include small microprocessors, personal computers, and large general-
purpose computer systems. These processors are referred to by a number of
names, such as processors, sites, machines, andhosts,depending on the context
in which they are mentioned. We mainly use siteto indicate the location of a
machine and nodeto refer to a specific system at a site. Nodes can exist in a
client–server configuration, a peer-to-peer configuration, orahybridofthese.In
the common client-server configuration, one node at one site, the server,has a
resource that another node, the client(or user), would like to use. A general
structure of a client–server distributed system is shown in Figure 19.1. In a
peer-to-peer configuration, there are no servers or clients. Instead, the nodes
shareequalresponsibilitiesandcan act as both clientsand servers.
When several sites are connected to one another by a communication net-
work,usersatthevarioussiteshavetheopportunitytoexchangeinformation.
At a low level, messages are passed between systems, much as messages are
passed between processes in the single-computer message system discussed
in Section3.4. Givenmessage passing, all the higher-levelfunctionality found
in standalone systems can be expanded to encompass the distributed system.
Suchfunctionsincludefilestorage,executionofapplications,andremotepro-
cedurecalls ( RPCs).
There are three major reasons for building distributed systems: resource
sharing, computational speedup, and reliability. In this section, we briefly
discusseach of them.
19.1.1 Resource Sharing
If a number of different sites (with different capabilities) are connected to one
another, then a user at one site may be able to use the resources available
at another. For example, a user at site A may query a database located at
site B. Meanwhile, a user at site B may access a file that resides at site A. In
general, resource sharing in a distributed system provides mechanisms for"
3,19.1.2 Computation Speedup,873,19.1.1 Resource Sharing,"19.2 Network Structure 735
sharing files at remote sites, processing information in a distributed database,
printing files at remote sites, using remote specialized hardware devices such
asasupercomputerora graphics processing unit (GPU),andperformingother
operations.
19.1.2 Computation Speedup
If a particular computation can be partitioned into subcomputations that can
run concurrently, then a distributed system allows us to distribute the sub-
computations among the various sites. The subcomputations can be run con-
currently and thus provide computation speedup . This is especially relevant
when doing large-scale processing of big data sets (such as analyzing large
amounts of customer data for trends). In addition, if a particular site is cur-
rently overloaded with requests, some of them can be moved or rerouted to
other,morelightlyloadedsites.Thismovementofjobsiscalled load balancing
and is common among distributed system nodes and other services provided
on the Internet.
19.1.3 Reliability
If one site fails in a distributed system, the remaining sites can continue oper-
ating, giving the system better reliability. If the system is composed of multi-
ple large autonomous installations (that is, general-purpose computers), the
failure of one of them should not affect the rest. If, however, the system is
composed of diversified machines, each of which is responsible for some cru-
cial system function (such as the web server or the file system), then a single
failure may halt the operation of the whole system. In general, with enough
redundancy (in both hardware and data), the system can continue operation
evenif someof itsnodeshavefailed.
The failure of a node or site must be detected by the system, and appro-
priate action may be needed to recover from the failure. The system must no
longerusethe servicesof thatsite.In addition,ifthefunction ofthefailedsite
can be taken over by another site, the system must ensure that the transfer of
function occurs correctly. Finally, when the failed site recovers or is repaired,
mechanisms mustbe availableto integrateit back into thesystemsmoothly.
19.2 Network Structure
To completely understand the roles and types of distributed systems in use
today,weneedtounderstandthenetworksthatinterconnectthem.Thissection
serves as a network primer to introduce basic networking concepts and chal-
lengesastheyrelatetodistributedsystems.Therestofthechapterspecifically
discussesdistributedsystems.
There are basically two typesof networks: local-area networks (LAN)a n d
wide-area networks (WAN).Themaindifferencebetweenthetwoisthewayin
whichtheyaregeographicallydistribu ted.Local-areanetworksarecomposed
of hosts distributed over small areas (such as a single building or a number
of adjacent buildings), whereas wide-area networks are composed of systems
distributed over a large area (such as the United States). These differences"
3,19.1.3 Reliability,873,19.1.2 Computation Speedup,"19.2 Network Structure 735
sharing files at remote sites, processing information in a distributed database,
printing files at remote sites, using remote specialized hardware devices such
asasupercomputerora graphics processing unit (GPU),andperformingother
operations.
19.1.2 Computation Speedup
If a particular computation can be partitioned into subcomputations that can
run concurrently, then a distributed system allows us to distribute the sub-
computations among the various sites. The subcomputations can be run con-
currently and thus provide computation speedup . This is especially relevant
when doing large-scale processing of big data sets (such as analyzing large
amounts of customer data for trends). In addition, if a particular site is cur-
rently overloaded with requests, some of them can be moved or rerouted to
other,morelightlyloadedsites.Thismovementofjobsiscalled load balancing
and is common among distributed system nodes and other services provided
on the Internet.
19.1.3 Reliability
If one site fails in a distributed system, the remaining sites can continue oper-
ating, giving the system better reliability. If the system is composed of multi-
ple large autonomous installations (that is, general-purpose computers), the
failure of one of them should not affect the rest. If, however, the system is
composed of diversified machines, each of which is responsible for some cru-
cial system function (such as the web server or the file system), then a single
failure may halt the operation of the whole system. In general, with enough
redundancy (in both hardware and data), the system can continue operation
evenif someof itsnodeshavefailed.
The failure of a node or site must be detected by the system, and appro-
priate action may be needed to recover from the failure. The system must no
longerusethe servicesof thatsite.In addition,ifthefunction ofthefailedsite
can be taken over by another site, the system must ensure that the transfer of
function occurs correctly. Finally, when the failed site recovers or is repaired,
mechanisms mustbe availableto integrateit back into thesystemsmoothly.
19.2 Network Structure
To completely understand the roles and types of distributed systems in use
today,weneedtounderstandthenetworksthatinterconnectthem.Thissection
serves as a network primer to introduce basic networking concepts and chal-
lengesastheyrelatetodistributedsystems.Therestofthechapterspecifically
discussesdistributedsystems.
There are basically two typesof networks: local-area networks (LAN)a n d
wide-area networks (WAN).Themaindifferencebetweenthetwoisthewayin
whichtheyaregeographicallydistribu ted.Local-areanetworksarecomposed
of hosts distributed over small areas (such as a single building or a number
of adjacent buildings), whereas wide-area networks are composed of systems
distributed over a large area (such as the United States). These differences"
2,19.2 Network Structure,873,19.1 Advantages of Distributed Systems,"19.2 Network Structure 735
sharing files at remote sites, processing information in a distributed database,
printing files at remote sites, using remote specialized hardware devices such
asasupercomputerora graphics processing unit (GPU),andperformingother
operations.
19.1.2 Computation Speedup
If a particular computation can be partitioned into subcomputations that can
run concurrently, then a distributed system allows us to distribute the sub-
computations among the various sites. The subcomputations can be run con-
currently and thus provide computation speedup . This is especially relevant
when doing large-scale processing of big data sets (such as analyzing large
amounts of customer data for trends). In addition, if a particular site is cur-
rently overloaded with requests, some of them can be moved or rerouted to
other,morelightlyloadedsites.Thismovementofjobsiscalled load balancing
and is common among distributed system nodes and other services provided
on the Internet.
19.1.3 Reliability
If one site fails in a distributed system, the remaining sites can continue oper-
ating, giving the system better reliability. If the system is composed of multi-
ple large autonomous installations (that is, general-purpose computers), the
failure of one of them should not affect the rest. If, however, the system is
composed of diversified machines, each of which is responsible for some cru-
cial system function (such as the web server or the file system), then a single
failure may halt the operation of the whole system. In general, with enough
redundancy (in both hardware and data), the system can continue operation
evenif someof itsnodeshavefailed.
The failure of a node or site must be detected by the system, and appro-
priate action may be needed to recover from the failure. The system must no
longerusethe servicesof thatsite.In addition,ifthefunction ofthefailedsite
can be taken over by another site, the system must ensure that the transfer of
function occurs correctly. Finally, when the failed site recovers or is repaired,
mechanisms mustbe availableto integrateit back into thesystemsmoothly.
19.2 Network Structure
To completely understand the roles and types of distributed systems in use
today,weneedtounderstandthenetworksthatinterconnectthem.Thissection
serves as a network primer to introduce basic networking concepts and chal-
lengesastheyrelatetodistributedsystems.Therestofthechapterspecifically
discussesdistributedsystems.
There are basically two typesof networks: local-area networks (LAN)a n d
wide-area networks (WAN).Themaindifferencebetweenthetwoisthewayin
whichtheyaregeographicallydistribu ted.Local-areanetworksarecomposed
of hosts distributed over small areas (such as a single building or a number
of adjacent buildings), whereas wide-area networks are composed of systems
distributed over a large area (such as the United States). These differences"
3,19.2.1 Local-Area Networks,874,19.2 Network Structure,"736 Chapter 19 Networks and Distributed Systems
Router WAN Link
Wireless Access
         Point
WAN LAN
Figure 19.2 Local-area network.
imply major variations in the speed and reliability of the communications
networks,and theyarereflectedinthedistributedsystemdesign.
19.2.1 Local-Area Networks
Local-area networks emerged in the early 1970s as a substitute for large
mainframe computer systems. For many enterprises, it is more economi-
cal to have a number of small computers, each with its own self-contained
applications, than to have a single large system. Because each small com-
puter is likely to need a full complement of peripheral devices (such as disks
and printers), and because some form of data sharing is likely to occur in a
single enterprise, it was a natural step to connect these small systems into a
network.
LANs, as mentioned, are usually designed to cover a small geographical
area, and they are generally used in an office or home environment. All the
sitesinsuchsystemsareclosetooneanother,sothecommunicationlinkstend
tohaveahigherspeedandlowererrorratethantheircounterpartsinwide-area
networks.
At y p i c a l LANmay consist of a number of different computers (includ-
ing workstations, servers, laptops, tablets, and smartphones), various shared
peripheral devices (such as printers and storage arrays), and one or more
routers(specialized network communication processors) that provide access
toothernetworks(Figure19.2). Ethernetand WiFiarecommonly usedto con-
structLANs.Wireless access points connect devices to the LANwirelessly, and
theymay or maynot be routersthemselves.
Ethernet networks are generally found in businesses and organizations
in which computers and peripherals tend to be nonmobile. These networks
usecoaxial, twisted pair, and/orfiber optic cables to send signals. An Ethernet
networkhasnocentralcontroller,becauseitisamultiaccessbus,sonewhosts
canbeaddedeasilytothenetwork.TheEthernetprotocolisdefinedbythe IEEE
802.3 standard. Typical Ethernet speed s using common twisted-pair cabling"
3,19.2.2 Wide-Area Networks,875,19.2.1 Local-Area Networks,"19.2 Network Structure 737
can vary from 10 Mbps to over 10 Gbps, with other types of cabling reaching
speedsof 100 Gbps.
WiFi is now ubiquitous and either supplements traditional Ethernet net-
works or exists by itself. Specifically, WiFi allows us to construct a network
withoutusingphysicalcables.Eachhost hasawirelesstransmitterandreceiver
that it uses to participate in the network. WiFi is defined by the IEEE802.11
standard. Wireless networks are popular in homes and businesses, as well as
publicareassuchaslibraries,Internetcafes,sportsarenas,andevenbusesand
airplanes. WiFi speedscan varyfrom 11 Mbps toover400 Mbps.
Both the IEEE802.3 and 802.11 standards are constantly evolving. For the
latestinformationaboutvariousstandardsandspeeds,seethereferencesatthe
endof thechapter.
19.2.2 Wide-Area Networks
Wide-areanetworksemergedinthelate1960s,mainlyasanacademicresearch
project to provide efficient communication among sites, allowing hardware
and software to be shared conveniently and economically by a wide commu-
nity of users. The first WANto be designed and developed was the ARPANET .
Begunin1968,the ARPANET hasgrownfromafour-siteexperimentalnetwork
to a worldwide network of networks, the Internet (also known as the World
Wide Web ),comprising millionsof computersystems.
Sites in a WANare physically distributed over a large geographical area.
Typical links are telephone lines, leased (dedicated data) lines, optical cable,
microwave links, radio waves, and satellite channels. These communication
links are controlled by routers (Figure 19.3) that are responsible for directing
traffic to other routers and networks and transferring information among the
varioussites.
For example, the Internet WANenables hosts at geographically separate
sites to communicate with one another. The host computers typically differ
from one another in speed, CPUtype, operating system, and so on. Hosts are
routercommunication
subsystem
(network)
HH
Huser processes
network hostnetwork host
host operating system
RR
R R
H
Figure 19.3 Communication processors in a wide-area network."
2,19.3 Communication Structure,876,19.2 Network Structure,"738 Chapter 19 Networks and Distributed Systems
generally on LANs, which are, in turn, connected to the Internet via regional
networks. The regional networks are in terlinked with routers to form the
worldwide network. Residences can connect to the Internet by either tele-
phone, cable, or specialized Internet service providers that install routers to
connect the residences to central services. Of course, there are other WANs
besidestheInternet.Acompany,fore xample,mightcreateitsownprivate WAN
for increasedsecurity,performance,or reliability.
WANs are generally slower than LANs, although backbone WANconnec-
tionsthatlinkmajorcitiesmayhaveveryfasttransferratesthroughfiberoptic
cables. In fact, many backbone providers have fiber optic speeds of 40 Gbps
or 100 Gbps. (It is generally the links from local Internet Service Providers
(ISPs)tohomesorbusinessesthatslowthingsdown.)However, WANlinksare
beingconstantlyupdatedtofastertechnologiesasthedemandformorespeed
continues to grow.
Frequently, WANsa n dLANs interconnect, and it is difficult to tell where
one ends and the other starts. Consider the cellular phone data network. Cell
phones are used for both voice and data communications. Cell phones in a
given area connect via radio waves to a cell tower that contains receivers
and transmitters. This part of the network is similar to a LANexcept that the
cell phones do not communicate with each other (unless two people talking
or exchanging data happen to be connected to the same tower). Rather, the
towers are connected to other towers and to hubs that connect the tower
communications to land lines or other communication media and route the
packets toward their destinations. This part of the network is more WAN-like.
Oncetheappropriatetowerreceivesthepackets,itusesitstransmitterstosend
themto thecorrect recipient.
19.3 Communication Structure
Nowthatwehavediscussedthephysicalaspectsofnetworking,weturntothe
internalworkings.
19.3.1 Naming and Name Resolution
The first issuein network communication involvesthe naming of the systems
in the network. For a process at site Ato exchange information with a process
at site B, each must be able to specify the other. Within a computer system,
eachprocesshasaprocessidentifier, andmessagesmaybeaddressedwiththe
process identifier. Because networked systems share no memory, however, a
hostwithinthesysteminitiallyhasnok nowledgeabouttheprocessesonother
hosts.
Tosolvethisproblem,processesonremotesystemsaregenerallyidentified
bythepair <hostname,identifier >,where host name isanameuniquewithin
the network and identifie is a process identifier or other unique number
withinthathost.Ahostnameisusuallyan alphanumericidentifier,ratherthan
anumber,tomakeiteasierforuserstospecify.Forinstance,siteAmighthave
hostsnamed program,student,faculty, andcs.Thehostname programiscertainly
easierto rememberthan thenumerichost address 128.148.31.100."
3,19.3.1 Naming and Name Resolution,876,19.3 Communication Structure,"738 Chapter 19 Networks and Distributed Systems
generally on LANs, which are, in turn, connected to the Internet via regional
networks. The regional networks are in terlinked with routers to form the
worldwide network. Residences can connect to the Internet by either tele-
phone, cable, or specialized Internet service providers that install routers to
connect the residences to central services. Of course, there are other WANs
besidestheInternet.Acompany,fore xample,mightcreateitsownprivate WAN
for increasedsecurity,performance,or reliability.
WANs are generally slower than LANs, although backbone WANconnec-
tionsthatlinkmajorcitiesmayhaveveryfasttransferratesthroughfiberoptic
cables. In fact, many backbone providers have fiber optic speeds of 40 Gbps
or 100 Gbps. (It is generally the links from local Internet Service Providers
(ISPs)tohomesorbusinessesthatslowthingsdown.)However, WANlinksare
beingconstantlyupdatedtofastertechnologiesasthedemandformorespeed
continues to grow.
Frequently, WANsa n dLANs interconnect, and it is difficult to tell where
one ends and the other starts. Consider the cellular phone data network. Cell
phones are used for both voice and data communications. Cell phones in a
given area connect via radio waves to a cell tower that contains receivers
and transmitters. This part of the network is similar to a LANexcept that the
cell phones do not communicate with each other (unless two people talking
or exchanging data happen to be connected to the same tower). Rather, the
towers are connected to other towers and to hubs that connect the tower
communications to land lines or other communication media and route the
packets toward their destinations. This part of the network is more WAN-like.
Oncetheappropriatetowerreceivesthepackets,itusesitstransmitterstosend
themto thecorrect recipient.
19.3 Communication Structure
Nowthatwehavediscussedthephysicalaspectsofnetworking,weturntothe
internalworkings.
19.3.1 Naming and Name Resolution
The first issuein network communication involvesthe naming of the systems
in the network. For a process at site Ato exchange information with a process
at site B, each must be able to specify the other. Within a computer system,
eachprocesshasaprocessidentifier, andmessagesmaybeaddressedwiththe
process identifier. Because networked systems share no memory, however, a
hostwithinthesysteminitiallyhasnok nowledgeabouttheprocessesonother
hosts.
Tosolvethisproblem,processesonremotesystemsaregenerallyidentified
bythepair <hostname,identifier >,where host name isanameuniquewithin
the network and identifie is a process identifier or other unique number
withinthathost.Ahostnameisusuallyan alphanumericidentifier,ratherthan
anumber,tomakeiteasierforuserstospecify.Forinstance,siteAmighthave
hostsnamed program,student,faculty, andcs.Thehostname programiscertainly
easierto rememberthan thenumerichost address 128.148.31.100."
3,19.3.2 Communication Protocols,879,19.3.1 Naming and Name Resolution,"19.3 Communication Structure 741
Generally, the operating system is responsible for accepting from its pro-
cessesamessagedestinedfor <hostname,identifier >andfortransferringthat
message to the appropriate host. The kernel on the destination host is then
responsiblefortransferringthemessa getotheprocessnamedbytheidentifier.
ThisprocessisdescribedinSection19.3.4.
19.3.2 Communication Protocols
When we are designing a communication network, we must deal with the
inherentcomplexityofcoordinatingasynchronousoperationscommunicating
in a potentially slow and error-prone environment. In addition, the systems
on the network must agree on a protocol or a set of protocols for determin-
ing host names, locating hosts on the network, establishing connections, and
so on. We can simplify the design problem (and related implementation) by
partitioning the problem into multiple layers. Each layer on one system com-
municates with the equivalent layer on other systems. Typically, each layer
has its own protocols, and communication takes place between peer layers
using a specific protocol. The protocols may be implemented in hardware or
software.Forinstance,Figure19.5showsthelogicalcommunicationsbetween
two computers,withthe threelowest-levellayersimplementedinhardware.
TheInternationalStandardsOrgani zationcreatedtheOpenSystemsInter-
connection( OSI)modelfordescribingthevariouslayersofnetworking.While
theselayersarenotimplementedinpractice,theyareusefulforunderstanding
how networking logicallyworks, and wedescribethembelow:
•Layer 1: Physical layer .Thephysicallayerisresponsibleforhandlingboth
the mechanical and the electrical details of the physical transmission of a
bit stream. At the physical layer, the communicating systems must agree
on the electrical representation of a binary 0 and 1, so that when data are
sentasastreamofelectricalsignals,thereceiverisabletointerpretthedata
real systems environmentOSI environmentnetwork environmentdata networkcomputer A
application layer
presentation layer
session layer
transport layer
network layer
link layer
physical layercomputer B
A-L (7) 
P-L (6) 
S-L (5) 
T-L (4) 
N-L (3) 
L-L (2) 
P-L (1)AP AP
Figure 19.5 Two computers communicating via the OSI network model."
3,19.3.3 TCP/IP Example,883,19.3.2 Communication Protocols,"19.3 Communication Structure 745
the endpoints and encrypting the stream of packets in a virtual private net-
work,asdiscussedinSection16.4.2. LANcommunicationremainsunencrypted
atmostsites,butprotocolssuchas NFSVersion4,whichincludesstrongnative
authenticationand encryption,should helpimproveeven LANsecurity.
19.3.3 TCP/IP Example
Next,weaddressnameresolutionandexamineitsoperationwithrespecttothe
TCP/IPprotocolstackontheInternet.Thenweconsidertheprocessingneeded
totransferapacketbetweenhostsondifferentEthernetnetworks.Webaseour
description on the IPV4 protocols, which are the type most commonly used
today.
InaTCP/IPnetwork,everyhosthasanameandanassociated IPaddress(or
host-id). Both of these stringsmust be unique; and so that the name space can
bemanaged,theyaresegmented.Asdescribedearlier,thenameishierarchical,
describing the host name and then the organization with which the host is
associated.The host-idissplitintoanetworknumberand ahostnumber.The
proportion of the split varies, depending on the size of the network. Once the
Internetadministratorsassigna netwo rknumber, thesitewith that number is
freeto assignhost-ids.
The sending system checks its routing tables to locate a router to send the
frameonitsway.Thisroutingtableiseitherconfiguredmanuallybythesystem
administrator or is populated by one of several routing protocols, such as the
Border Gateway Protocol (BGP).Theroutersusethenetworkpartofthehost-
id to transfer the packet from its source network to the destination network.
Thedestinationsystemthenreceivesthepacket.Thepacketmaybeacomplete
message,oritmayjustbeacomponentofamessage,withmorepacketsneeded
beforethemessagecanbereassembledandpassedtothe TCP/UDP (transport)
layerfor transmissiontothe destinationprocess.
Withinanetwork,howdoesapacketmovefromsender(hostorrouter)to
receiver?EveryEthernetdevicehasauniquebytenumber,calledthe medium
access control (MAC)address, assigned to it for addressing. Two devices on a
LANcommunicate with each other only with this number. If a system needs
tosenddatatoanothersystem,thene tworkingsoftwaregeneratesan address
resolution protocol (ARP) packet containing the IPaddress of the destination
system.Thispacketis broadcast toallothersystemsonthatEthernetnetwork.
A broadcast uses a special network address (usually, the maximum
address) to signal that all hosts should receive and process the packet. The
broadcast is not re-sent by routers in between different networks, so only
systems on the local network receive it. Only the system whose IPaddress
matches the IPaddress of the ARPrequest responds and sends back its MAC
address to the system that initiated the query. For efficiency, the host caches
theIP–MACaddress pair in an internal table. The cache entries are aged, so
that an entry is eventually removed fr om the cache if an access to that system
is not required within a given time. In this way, hosts that are removed from
a network are eventually forgotten. For added performance, ARPentries for
heavilyused hosts maybe pinned in the ARPcache.
Once an Ethernet device has announced its host-id and address, commu-
nication can begin. A process may specify the name of a host with which to
communicate. Networking software takes that name and determines the IP
address of the target, using a DNSlookup or an entry in a local hostsfile"
3,19.3.4 Transport Protocols UDP and TCP,884,19.3.3 TCP/IP Example,"746 Chapter 19 Networks and Distributed Systems
preamble—start of packet
start of frame delimiter
destination address
source address
length of data section
pad (optional)
frame checksumbytes
7 
1 
2 or 6 
2 or 6 
2 each byte pattern 10101010
pattern 10101011
Ethernet address or broadcast
Ethernet address
length in bytes
message data
message must be > 63 bytes long
for error detection0–1500
0–46
4data
Figure 19.9 An Ethernet packet.
where translations can be manually stored. The message is passed from the
application layer, through the software layers, and to the hardware layer. At
the hardware layer, the packet has the Ethernet address at its start; a trailer
indicatestheendofthepacketandcontainsa checksum fordetectionofpacket
damage (Figure 19.9). The packet is placed on the network by the Ethernet
device. The data section of the packet may contain some or all of the data of
the original message, but it may also contain some of the upper-level headers
that compose the message. In other words, all parts of the original message
must be sent from source to destination, and all headers above the 802.3 layer
(data-linklayer)areincludedas dataintheEthernetpackets.
If the destination is on the same local network as the source, the system
can look in its ARPcache, find the Ethernet address of the host, and place the
packetonthewire.ThedestinationEthernetdevicethenseesitsaddressinthe
packetand readsinthe packet,passingitup theprotocol stack.
If the destination system is on a network differentfrom that of the source,
the source system finds an appropriate router on its network and sends the
packet there. Routers then pass the packet along the WANuntil it reaches its
destination network. The router that connects the destination network checks
itsARPcache, finds the Ethernet number of the destination, and sends the
packet to that host. Through all of these transfers, the data-link-layer header
maychangeastheEthernetaddressofthenextrouterinthechainisused,but
the other headers of the packet remain the same until the packet is received
andprocessedbytheprotocolstackandfinallypassedtothereceivingprocess
by the kernel.
19.3.4 Transport Protocols UDP and TCP
Onceahostwithaspecific IPaddressreceivesapacket,itmustsomehowpass
ittothecorrectwaiting process.Thetransportprotocols TCPandUDPidentify
thereceiving(andsending)processesthroughtheuseofa port number .Thus,"
2,19.4 Network and Distributed Operating Systems,887,19.3 Communication Structure,"19.4 Network and Distributed Operating Systems 749
inital request
for data
time
client serverserver starts sending
data to client
X
XV
VVData, seq = 904
Data, seq = 126
Data, seq = 128Data, seq = 128Data, seq = 127Data, seq = 127ACK for 904
ACK for 126
ACK for 127
ACK for 128ACK for 128timeout waiting
for ACK
retransmit
timeout waiting
for ACK
retransmit
Figure 19.11 Example of a TCP data transfer with dropped packets.
have a slower connection or may have slower hardware components (like a
slower network card or processor). Flow-control state can be returned in the
ACKpackets of the receiver to alert the sender to slow down or speed up.
Congestion control attempts to approximate the state of the networks (and
generallytherouters)betweenthesenderandthereceiver.Ifarouterbecomes
overwhelmedwithpackets,itwilltendtodropthem.Droppingpacketsresults
inACKtimeouts, which results in more packets saturating the network. To
preventthiscondition,thesendermonitorstheconnectionfordroppedpackets
by noticing how many packets are not acknowledged. If there are too many
dropped packets, the sender will slow down the rate at which it sends them.
This helps ensure that the TCPconnection is being fair to other connections
happening atthe same time.
Byutilizingareliabletransportprotocollike TCP,adistributedsystemdoes
not need extra logic to deal with lost or out-of-order packets. However, TCPis
slowerthan UDP.
19.4 Network and Distributed Operating Systems
In this section, we describe the two general categories of network-oriented
operating systems: network operating systems and distributed operating sys-"
3,19.4.1 Network Operating Systems,888,19.4 Network and Distributed Operating Systems,"750 Chapter 19 Networks and Distributed Systems
tems.Networkoperatingsystemsaresimplertoimplementbutgenerallymore
difficult for users to access and use than are distributed operating systems,
which provide more features.
19.4.1 Network Operating Systems
Anetwork operating system provides an environment in which users can
access remote resources (implementing resource sharing) by either logging
in to the appropriate remote machine or transferring data from the remote
machine to their own machines. Currentl y, all general-purpose operating sys-
tems, and even embedded operating systems such as Android and i OS,a r e
network operatingsystems.
19.4.1.1 Remote Login
An important function of a network operating system is to allow users to
log in remotely. The Internet provides the sshfacility for this purpose. To
illustrate, suppose that a user at Westminster College wishes to compute on
kristen.cs.yale.edu, a computer located at Yale University. To do so, the
user must have a valid account on that machine. To log in remotely, the user
issuesthecommand
ssh kristen.cs.yale.edu
This command results in the formation of an encrypted socket connection
between the local machine at Westminster College and the kris-
ten.cs.yale.edu computer. After this connection has been established,
the networking software creates a transparent, bidirectional link so that all
charactersenteredbytheuseraresenttoaprocesson kristen.cs.yale.edu
and all the output from that process is sent back to the user. The process on
the remote machine asks the user for a login name and a password. Once the
correct information has beenreceived,the process acts as a proxyfor the user,
who can compute on the remote machine justas any local usercan.
19.4.1.2 Remote File Transfer
Another major function of a network operating system is to provide a mech-
anism for remote fil transfer from one machine to another. In such an envi-
ronment, each computer maintains its own local file system. If a user at one
site(say,Kurtat albion.edu )wantstoaccessafileownedbyBeccalocatedon
another computer (say, at colby.edu ), then the file must be copied explicitly
from the computer at Colby in Maine to the computer at Albion in Michigan.
The communication is one-directional and individual, such that other users
at those sites wishing to transfer a file, say Sean at colby.edu to Karen at
albion.edu ,must likewiseissuea setof commands.
TheInternetprovidesamechanismforsuchatransferwiththefiletransfer
protocol( FTP)andthemoreprivatesecurefiletransferprotocol( SFTP).Suppose
that user Carla at wesleyan.edu wants to copy a file that is owned by Owen
atkzoo.edu. The usermustfirst invoke the sftpprogram byexecuting
sftp owen@kzoo.edu"
3,19.4.2 Distributed Operating Systems,889,19.4.1 Network Operating Systems,"19.4 Network and Distributed Operating Systems 751
The program then asks the user for a login name and a password. Once the
correct information has been received, the user can use a series of commands
to upload files, download files, and navigate the remote file system structure.
Someof thesecommands are:
•get—Transfer a file fromthe remotemachine tothe localmachine.
•put—Transfer a file fromthe local machine to the remotemachine.
•lsordir—List filesin thecurrent directoryon the remotemachine.
•cd—Change the currentdirectoryon the remotemachine.
Therearealsovariouscommandstochangetransfermodes(forbinaryor ASCII
files)and todetermineconnection status.
19.4.1.3 Cloud Storage
Basic cloud-based storage applications allow users to transfer files much as
withFTP. Users can upload files to a cloud server, download files to the local
computer,andsharefileswithothercloud-serviceusersviaaweblinkorother
sharingmechanismthroughagraphicalinterface.Commonexamplesinclude
Dropboxand GoogleDrive.
An important point about SSH,FTP, and cloud-based storage applications
is that they require the user to change paradigms. FTP, for example, requires
theusertoknow acommand setentirelydifferentfromthe normaloperating-
system commands. With SSH, the user must know appropriate commands on
the remote system. For instance, a user on a Windows machine who connects
remotelytoa UNIXmachinemustswitchto UNIXcommandsforthedurationof
theSSHsession.(In networking, a sessionisa complete round of communica-
tion,frequentlybeginningwithalogin toauthenticateandendingwithalogoff
toterminatethecommunication.)Withcloud-basedstorageapplications,users
may have to log into the cloud service (usually through a web browser) or
native application and then use a series of graphical commands to upload,
download,orsharefiles.Obviously,userswouldfinditmoreconvenientnotto
berequiredtousea differentsetofcommands.Distributedoperatingsystems
aredesignedto addressthisproblem.
19.4.2 Distributed Operating Systems
In a distributed operating system, users access remote resources in the same
way they access local resources. Data and process migration from one site to
another is under the control of the distributed operating system. Depending
on the goals of the system, it can implement data migration, computation
migration,processmigration,orany combination thereof.
19.4.2.1 Data Migration
Supposea useron siteAwants to access data(such as a file) that resideat site
B.Thesystemcantransferthedatabyoneoftwobasicmethods.Oneapproach
todata migration is to transfer the entire file to site A. From that point on, all
access to the file is local. When the user no longer needs access to the file, a
copy of the file (if it has been modified) is sent back to site B. Even if only a"
2,19.5 Design Issues in Distributed Systems,891,19.4 Network and Distributed Operating Systems,"19.5 Design Issues in Distributed Systems 753
•Load balancing .Theprocesses(orsubprocesses)maybedistributedacross
the sitesto eventhe workload.
•Computation speedup . If a single process can be divided into a number
ofsubprocessesthatcanrunconcurren tlyondifferentsitesornodes,then
the totalprocessturnaround time can be reduced.
•Hardware preference . The process may have characteristics that make it
moresuitableforexecutiononsomespecializedprocessor(suchasmatrix
inversionon a GPU)th a no nam ic r o pr o c es s o r .
•Software preference .Theprocessmayrequiresoftwarethatisavailableat
onlyaparticularsite,andeitherthesoftwarecannotbemoved,oritisless
expensivetomove the process.
•Data access .Justasincomputationmigration,ifthedatabeingusedinthe
computationarenumerous,itmaybemoreefficienttohaveaprocessrun
remotely (say, on a server that hosts a large database) than to transfer all
the dataand runthe processlocally.
We use two complementary techniques to move processes in a computer
network.Inthefirst,thesystemcanattempttohidethefactthattheprocesshas
migratedfromtheclient.Theclientthenneednotcodeherprogramexplicitly
to accomplish the migration. This method is usually employed for achieving
load balancing and computation speedup among homogeneous systems, as
theydonot needuserinputto helpthem executeprogramsremotely.
The other approach is to allow (or require) the user to specify explicitly
how the process should migrate. This method is usually employed when the
processmustbe movedtosatisfy ahardware orsoftware preference.
You have probably realized that the World Wide Web has many aspects
of a distributed computing environment. Certainly it provides data migra-
tion (between a web server and a web client). It also provides computation
migration. For instance, a web client could trigger a database operation on a
web server. Finally, with Java, Javascript, and similar languages, it provides
a form of process migration: Java applets and Javascript scripts are sent from
the server to the client, where they are executed. Anetwork operating system
providesmostofthesefeatures,butadistributedoperatingsystemmakesthem
seamlessandeasilyaccessible.Theresultisapowerfulandeasy-to-usefacility
—one of the reasons for the huge growth of the World Wide Web.
19.5 Design Issues in Distributed Systems
Thedesignersofadistributedsystemmusttakeanumberofdesignchallenges
intoaccount.Thesystemshouldberobustsothatitcanwithstandfailures.The
system should also be transparent to users in terms of both file location and
user mobility. Finally, the system should be scalable to allow the addition of
more computation power, more storage, or more users. We briefly introduce
theseissueshere.Inthenextsection,weputthemincontextwhenwedescribe
thedesignsofspecific distributedfilesystems."
3,19.5.1 Robustness,892,19.5 Design Issues in Distributed Systems,"754 Chapter 19 Networks and Distributed Systems
19.5.1 Robustness
Adistributed system may suffer from various types of hardware failure. The
failureofalink,ahost,orasiteandthelossofamessagearethemostcommon
types.Toensurethatthesystemisrobust,wemustdetectanyofthesefailures,
reconfigure the system so that computation can continue, and recover when
thefailureisrepaired.
Asystemcanbe fault tolerant inthatitcantolerateacertainleveloffailure
and continue to function normally. The degree of fault tolerance depends on
the design of the distributed system and the specific fault. Obviously, more
fault toleranceisbetter.
We use the term fault tolerance in a broad sense. Communication faults,
certain machine failures, storage-devi ce crashes, and decays of storage media
shouldallbetoleratedtosomeextent.A fault-tolerant system shouldcontinue
to function, perhaps in a degraded for m, when faced with such failures. The
degradation can affect performance, functionality, or both. It should be pro-
portional,however,tothefailuresthatcausedit.Asystemthatgrindstoahalt
when onlyone of itscomponents fails iscertainlynot fault tolerant.
Unfortunately,faulttolerancecanbedifficultandexpensivetoimplement.
At the network layer, multiple redundant communication paths and network
devices such as switches and routers are needed to avoid a communication
failure. Astorage failure can cause loss of the operating system, applications,
ordata.Storageunitscanincluderedundanthardwarecomponentsthatauto-
maticallytakeoverfromeachotherincaseoffailure.Inaddition, RAIDsystems
canensurecontinuedaccesstothedataevenintheeventofoneormorestorage
devicefailures(Section11.8).
19.5.1.1 Failure Detection
In an environment with no shared memory, we generally cannot differentiate
among link failure, site failure, host failure, and message loss. We can usu-
ally detect only that one of these failures has occurred. Once a failure has
been detected, appropriate action must be taken. What action is appropriate
dependson the particularapplication.
Todetectlinkandsitefailure,weusea heartbeat procedure.Supposethat
sites Aand B have a direct physical link between them. At fixed intervals, the
sitessendeachotheran I-am-upmessage.IfsiteAdoesnotreceivethismessage
within a predetermined time period, it can assume that site B has failed, that
thelinkbetweenAandBhasfailed,orthatthemessagefromBhasbeenlost.At
thispoint,siteAhastwochoices.Itcan waitforanothertimeperiodtoreceive
anI-am-upmessagefromB,or itcansendan Are-you-up? messageto B.
IftimegoesbyandsiteAstillhasnotreceivedan I-am-upmessage,orifsite
Ahassentan Are-you-up? messageandhasnotreceivedareply,theprocedure
can be repeated. Again, the only conclusion that site Acan draw safely is that
sometypeof failurehas occurred.
SiteAcantrytodifferentiatebetweenlinkfailureandsitefailurebysend-
inganAre-you-up? messagetoBbyanotherroute(ifoneexists).IfandwhenB
receivesthismessage,itimmediatelyrepliespositively.Thispositivereplytells
Athat B is up and that the failure is in th e direct link between them. Since we
donotknowinadvancehowlongitwilltakethemessagetotravelfromAtoB
andback,wemustuseatime-outscheme.AtthetimeAsendsthe Are-you-up?"
3,19.5.2 Transparency,894,19.5.1 Robustness,"756 Chapter 19 Networks and Distributed Systems
transaction log of unexecuted transactions, and mail. If the site has not
failedbut simplycannot be reached,then itstillneedsthis information.
19.5.2 Transparency
Making the multiple processors and storage devices in a distributed system
transparent to the users has been a key challenge to many designers. Ide-
ally, a distributed system should look to its users like a conventional, cen-
tralized system. The user interface of a tr ansparent distributed system should
not distinguish between local and remote resources. That is, users should be
able to access remote resources as though these resources were local, and the
distributed system should be responsible for locating the resources and for
arranging for theappropriateinteraction.
Anotheraspectoftransparencyisusermobility.Itwouldbeconvenientto
allow users to log into any machine in the system rather than forcing them to
useaspecificmachine.Atransparentdis tributedsystemfacilitatesusermobil-
ity by bringing over a user’s environment (for example, home directory) to
whereverhelogsin.Protocolslike LDAPprovideanauthenticationsystemfor
local, remote,and mobile users. Once the a uthentication is complete, facilities
like desktop virtualization allow users to see their desktop sessions at remote
facilities.
19.5.3 Scalability
Still another issue is scalability —the capability of a system to adapt to
increased service load. Systems have bounded resources and can become
completelysaturatedunder increasedload.For example,with respectto a file
system,saturationoccurseitherwhenaserver’s CPUrunsatahighutilization
rate or when disks’ I/Orequests overwhelm the I/Osubsystem. Scalability
is a relative property, but it can be measured accurately. A scalable system
reacts more gracefully to increased load than does a nonscalable one. First,
its performance degrades more moderately; and second, its resources reach
a saturated state later. Even perfect design however cannot accommodate
an ever-growing load. Adding new resources might solve the problem, but
it might generate additional indirect load on other resources (for example,
adding machines to a distributed system can clog the network and increase
service loads). Even worse, expanding the system can call for expensive
design modifications. A scalable syst em should have the potential to grow
without these problems. In a distributed system, the ability to scale up
gracefully is of special importance, since expanding a network by adding
new machines or interconnecting two networks is commonplace. In short, a
scalable design should withstand hig h service load, accommodate growth of
theusercommunity, and allowsimpleintegrationof addedresources.
Scalability is related to fault tolerance, discussed earlier. Aheavily loaded
componentcanbecomeparalyzedandbehavelikeafaultycomponent.Inaddi-
tion, shifting the load from a faulty component to that component’s backup
cansaturatethelatter.Generally,havingspareresourcesisessentialforensur-
ing reliability as well as for handling pea k loads gracefully. Thus, the multi-
ple resources in a distributed system represent an inherent advantage, giving
the system a greater potential for faul t tolerance and scalability. However,"
3,19.5.3 Scalability,894,19.5.2 Transparency,"756 Chapter 19 Networks and Distributed Systems
transaction log of unexecuted transactions, and mail. If the site has not
failedbut simplycannot be reached,then itstillneedsthis information.
19.5.2 Transparency
Making the multiple processors and storage devices in a distributed system
transparent to the users has been a key challenge to many designers. Ide-
ally, a distributed system should look to its users like a conventional, cen-
tralized system. The user interface of a tr ansparent distributed system should
not distinguish between local and remote resources. That is, users should be
able to access remote resources as though these resources were local, and the
distributed system should be responsible for locating the resources and for
arranging for theappropriateinteraction.
Anotheraspectoftransparencyisusermobility.Itwouldbeconvenientto
allow users to log into any machine in the system rather than forcing them to
useaspecificmachine.Atransparentdis tributedsystemfacilitatesusermobil-
ity by bringing over a user’s environment (for example, home directory) to
whereverhelogsin.Protocolslike LDAPprovideanauthenticationsystemfor
local, remote,and mobile users. Once the a uthentication is complete, facilities
like desktop virtualization allow users to see their desktop sessions at remote
facilities.
19.5.3 Scalability
Still another issue is scalability —the capability of a system to adapt to
increased service load. Systems have bounded resources and can become
completelysaturatedunder increasedload.For example,with respectto a file
system,saturationoccurseitherwhenaserver’s CPUrunsatahighutilization
rate or when disks’ I/Orequests overwhelm the I/Osubsystem. Scalability
is a relative property, but it can be measured accurately. A scalable system
reacts more gracefully to increased load than does a nonscalable one. First,
its performance degrades more moderately; and second, its resources reach
a saturated state later. Even perfect design however cannot accommodate
an ever-growing load. Adding new resources might solve the problem, but
it might generate additional indirect load on other resources (for example,
adding machines to a distributed system can clog the network and increase
service loads). Even worse, expanding the system can call for expensive
design modifications. A scalable syst em should have the potential to grow
without these problems. In a distributed system, the ability to scale up
gracefully is of special importance, since expanding a network by adding
new machines or interconnecting two networks is commonplace. In short, a
scalable design should withstand hig h service load, accommodate growth of
theusercommunity, and allowsimpleintegrationof addedresources.
Scalability is related to fault tolerance, discussed earlier. Aheavily loaded
componentcanbecomeparalyzedandbehavelikeafaultycomponent.Inaddi-
tion, shifting the load from a faulty component to that component’s backup
cansaturatethelatter.Generally,havingspareresourcesisessentialforensur-
ing reliability as well as for handling pea k loads gracefully. Thus, the multi-
ple resources in a distributed system represent an inherent advantage, giving
the system a greater potential for faul t tolerance and scalability. However,"
2,19.6 Distributed File Systems,895,19.5 Design Issues in Distributed Systems,"19.6 Distributed File Systems 757
inappropriatedesigncanobscurethispotential.Fault-toleranceandscalability
considerationscallforadesigndemonstratingdistributionofcontrolanddata.
Scalability can also be related to efficient storage schemes. For example,
manycloudstorageprovidersuse compression ordeduplication tocutdown
ontheamountofstorageused. Compression reducesthesizeofafile.Forexam-
ple,aziparchivefilecanbegeneratedoutofafile(orfiles)byexecutinga zip
command, which runs a lossless compression algorithm over the data speci-
fied. (Lossless compression allows original data to be perfectly reconstructed
from compressed data.) The result is a file archive that is smaller than the
uncompressedfile.Torestorethefiletoitsoriginalstate,auserrunssomesort
ofunzipcommand over the zip archive file. Deduplication seeks to lower data
storagerequirementsbyremovingredundantdata.Withthistechnology,only
oneinstanceofdataisstoredacross anentiresystem(evenacross dataowned
by multiple users). Both compression and deduplication can be performed at
thefilelevelortheblocklevel,andtheycanbeusedtogether.Thesetechniques
can be automatically built into a distributed system to compress information
without users explicitly issuing comma nds, thereby saving storage space and
possibly cutting down on network communication costs without adding user
complexity.
19.6 Distributed File Systems
Although the World Wide Web is the predominant distributed system in use
today,itisnottheonlyone.Anotherimportantandpopularuseofdistributed
computing isthe distributed fil system ,o r DFS.
To explain the structure of a DFS, we need to define the terms service,
server,andclientin theDFScontext. A serviceis a software entity running on
one or more machines and providing a particular type of function to clients.
Aserveris the service software running on a single machine. A clientis a
process that can invoke a service using a set of operations that form its client
interface . Sometimes a lower-level interface is defined for the actual cross-
machine interaction; itis the intermachine interface .
Using this terminology, we say that a file system provides file services to
clients. A client interface for a file service is formed by a set of primitive file
operations,suchascreateafile,deleteafile,readfromafile,andwritetoafile.
The primary hardware component that a file server controls is a set of local
secondary-storage devices(usually, hard disks or solid-state drives)on which
files are stored and from which they are retrieved according to the clients’
requests.
ADFSis a file system whose clients, servers, and storage devices are dis-
persedamongthemachinesofadistributedsystem.Accordingly,serviceactiv-
ity has to be carried out across the network. Instead of a single centralized
data repository, the system frequently has multiple and independent storage
devices. As you will see, the concrete configuration and implementation of a
DFSmay vary from system to system. In some configurations, servers run on
dedicatedmachines. In others, amachine can be both a serverand aclient.
The distinctive features of a DFSare the multiplicity and autonomy of
clients and servers in the system. Ideally, though, a DFSshould appear to its
clientstobeaconventional,centralized filesystem.Thatis,theclientinterface"
3,19.6.1 The Client–Server DFS Model,896,19.6 Distributed File Systems,"758 Chapter 19 Networks and Distributed Systems
of aDFSshould not distinguish between local and remote files. It is up to the
DFStolocatethefilesandtoarrangeforthetransportofthedata.A transparent
DFS—like the transparent distributed syst ems mentioned earlier—facilitates
usermobilitybybringingauser’senvironment(forexample,theuser’shome
directory)to whereverthe userlogsin.
The most important performance measure of a DFSis the amount of time
needed to satisfy service requests. In c onventional systems, this time consists
of storage-access time and a small amount of CPU-processing time. In a DFS,
however, a remote access has the additional overhead associated with the
distributed structure. This overhead includes the time to deliver the request
to a server, as well as the time to get the response across the network back
to the client. For each direction, in addition to the transfer of the information,
there is the CPUoverhead of running the communication protocol software.
The performance of a DFScan be viewed as another dimension of the DFS’s
transparency.Thatis,theperformanceofanideal DFSwouldbecomparableto
that of a conventional file system.
The basic architecture of a DFSdepends on its ultimate goals. Two widely
usedarchitecturalmodelswediscussherearethe client–server model andthe
cluster-based model . The maingoal of a client–serverarchitecture isto allow
transparent file sharing among one or more clients as if the files were stored
locallyontheindividualclientmachines.Thedistributedfilesystems NFSand
OpenAFSareprimeexamples. NFSisthemostcommon UNIX-basedDFS.Ithas
severalversions,and herewereferto NFSVersion3 unlessotherwisenoted.
Ifmanyapplicationsneedtoberuninparallelonlargedatasetswithhigh
availability and scalability, the cluster-based model is more appropriate than
theclient–servermodel.Twowell-knownexamplesaretheGooglefilesystem
and the open-source HDFS, which runsas partof the Hadoop framework.
19.6.1 The Client–Server DFS Model
Figure 19.12 illustrates a simple DFS client–server model . The server stores
both files and metadata on attached storage. In some systems, more than one
server can be used to store different files. Clients are connected to the server
through a network and can request access to files in the DFSby contacting
the server through a well-known protocol such as NFSVersion 3. The server
client
networkclient
clientserver
Figure 19.12 Client–server DFS model."
3,19.6.2 The Cluster-Based DFS Model,897,19.6.1 The Client–Server DFS Model,"19.6 Distributed File Systems 759
is responsible for carrying out authentication, checking the requestedfile per-
missions,and,ifwarranted,deliveringthefiletotherequestingclient.Whena
clientmakeschangestothefile,theclientmustsomehowdeliverthosechanges
to the server (which holds the master copy of the file). The client’s and the
server’sversions of the file should be kept consistent in a way that minimizes
networktraffic andthe server’sworkload tothe extentpossible.
The network file system (NFS) protocol was originally developed by Sun
Microsystems as an open protocol, which encouraged early adoption across
different architectures and systems. From the beginning, the focus of NFSwas
simple and fast crash recovery in the face of server failure. To implement this
goal, the NFSserver was designed to be stateless; it does not keep track of
which client is accessing which file or of things such as open file descriptors
and file pointers. This means that, whenever a client issues a file operation
(say, to read a file), that operation has to be idempotent in the face of server
crashes. Idempotent describesanoperationthatcanbeissuedmorethanonce
yetreturnthesameresult.Inthecaseofareadoperation,theclientkeepstrack
of the state (such as the file pointer) and can simply reissue the operation if
theserverhascrashedandcomebackonline.Youcanreadmoreaboutthe NFS
implementationinSection15.8.
The Andrew fil system (Open AFS) was created at Carnegie Mellon Uni-
versitywithafocusonscalability.Specifically,theresearcherswantedtodesign
a protocol that would allow the server to support as many clients as possible.
Thismeantminimizingrequestsandtraffictotheserver.Whenaclientrequests
a file, the file’s contents are downloaded from the server and stored on the
client’s local storage. Updates to the fi le are sent to the server when the file is
closed,andnewversionsofthefilearesenttotheclientwhenthefileisopened.
Incomparison,NFSisquitechattyandwillsendblockreadandwriterequests
tothe serveras thefile isbeing usedby a client.
Both Open AFSandNFSare meant to be used in addition to local file sys-
tems.Inotherwords,youwouldnotformataharddrivepartitionwiththe NFS
filesystem.Instead,ontheserver,you wouldformatthepartitionwithalocal
filesystemofyourchoosing,suchasext4,andexporttheshareddirectoriesvia
theDFS.Intheclient,youwouldsimplyattachtheexporteddirectoriestoyour
file-system tree. In this way, the DFScan be separated from responsibility for
thelocal filesystemand can concentrate on distributedtasks.
TheDFSclient–server model, by design, may suffer from a single point of
failureiftheservercrashes.Computerclusteringcanhelpresolvethisproblem
byusingredundantcomponentsandclu steringmethodssuchthatfailuresare
detectedandfailingovertoworkingcompo nentscontinuesserveroperations.
In addition, the server presents a bottleneck for all requests for both data and
metadata,which resultsin problemsof scalabilityand bandwidth.
19.6.2 The Cluster-Based DFS Model
Astheamountofdata, I/Oworkload,andprocessingexpands,sodoestheneed
foraDFStobefault-tolerantandscalable.Largebottleneckscannotbetolerated,
and system component failures must be expected. Cluster-based architecture
was developedinpartto meettheseneeds.
Figure19.13 illustratesasamplecluster-based DFSmodel.Thisisthebasic
modelpresentedbythe Googlefile system (GFS)andthe Hadoop distributed"
2,19.7 DFS Naming and Transparency,899,19.6 Distributed File Systems,"19.7 DFS Naming and Transparency 761
Shortly after developing GFS, Google developed a modularized software
layer called MapReduce to sit on top of GFS. MapReduce allows developers
to carry out large-scale parallel computations more easily and utilizes the
benefitsofthelower-layerfilesystem.Later, HDFSandtheHadoopframework
(which includes stackable modules like MapReduce on top of HDFS)w e r e
createdbased on Google’s work. Like GFSand MapReduce, Hadoop supports
the processing of large data sets in distributed computing environments. As
suggestedearlier,thedriveforsuchaframeworkoccurredbecausetraditional
systemscouldnotscaletothecapacityandperformanceneededby “bigdata ”
projects(atleastnotatreasonableprices).Examplesofbigdataprojectsinclude
crawling and analyzing social media, customer data, and large amounts of
scientific datapoints fortrends.
19.7 DFS Naming and Transparency
Naming isamappingbetweenlogicalandphysicalobjects.Forinstance,users
deal with logical data objects represented by file names, whereas the system
manipulatesphysicalblocksofdatastoredondisktracks.Usually,auserrefers
to a file by a textual name. The latter is mapped to a lower-level numerical
identifier that in turn is mapped to disk blocks. This multilevel mapping
provides users with an abstraction of a file that hides the details of how and
whereonthediskthe fileisstored.
In a transparent DFS, a new dimension is added to the abstraction: that of
hidingwhereinthenetworkthefileisloc ated.Inaconventionalfilesystem,the
range of the naming mapping is an address within a disk. In a DFS,t h i sr a n g e
is expanded to include the specific machine on whose disk the file is stored.
Going one step further with the concept of treating files as abstractions leads
to the possibility of fil replication . Given a file name, the mapping returns a
set of the locations of this file’s replicas. In this abstraction, both the existence
ofmultiplecopies andtheirlocations arehidden.
19.7.1 Naming Structures
We need to differentiate two related notions regarding name mappings in a
DFS:
1. Location transparency .Thenameofafiledoesnotrevealanyhintofthe
file’s physicalstorage location.
2. Location independence . The name of a file need not be changed when
the file’s physical storage location changes.
Both definitions relate to the level of naming discussed previously, since files
have different names at different levels (that is, user-level textual names and
system-levelnumericalidentifiers).Alo cation-independentnamingschemeis
adynamicmapping,sinceitcan mapthesamefilenametodifferentlocations
attwodifferenttimes.Therefore,locationindependenceisastrongerproperty
than location transparency.
In practice, most of the current DFSs provide a static, location-transparent
mappingforuser-levelnames.Somesupport fil migration —thatis,changing
thelocationofafileautomatically,pro vidinglocationindependence.Open AFS"
3,19.7.1 Naming Structures,899,19.7 DFS Naming and Transparency,"19.7 DFS Naming and Transparency 761
Shortly after developing GFS, Google developed a modularized software
layer called MapReduce to sit on top of GFS. MapReduce allows developers
to carry out large-scale parallel computations more easily and utilizes the
benefitsofthelower-layerfilesystem.Later, HDFSandtheHadoopframework
(which includes stackable modules like MapReduce on top of HDFS)w e r e
createdbased on Google’s work. Like GFSand MapReduce, Hadoop supports
the processing of large data sets in distributed computing environments. As
suggestedearlier,thedriveforsuchaframeworkoccurredbecausetraditional
systemscouldnotscaletothecapacityandperformanceneededby “bigdata ”
projects(atleastnotatreasonableprices).Examplesofbigdataprojectsinclude
crawling and analyzing social media, customer data, and large amounts of
scientific datapoints fortrends.
19.7 DFS Naming and Transparency
Naming isamappingbetweenlogicalandphysicalobjects.Forinstance,users
deal with logical data objects represented by file names, whereas the system
manipulatesphysicalblocksofdatastoredondisktracks.Usually,auserrefers
to a file by a textual name. The latter is mapped to a lower-level numerical
identifier that in turn is mapped to disk blocks. This multilevel mapping
provides users with an abstraction of a file that hides the details of how and
whereonthediskthe fileisstored.
In a transparent DFS, a new dimension is added to the abstraction: that of
hidingwhereinthenetworkthefileisloc ated.Inaconventionalfilesystem,the
range of the naming mapping is an address within a disk. In a DFS,t h i sr a n g e
is expanded to include the specific machine on whose disk the file is stored.
Going one step further with the concept of treating files as abstractions leads
to the possibility of fil replication . Given a file name, the mapping returns a
set of the locations of this file’s replicas. In this abstraction, both the existence
ofmultiplecopies andtheirlocations arehidden.
19.7.1 Naming Structures
We need to differentiate two related notions regarding name mappings in a
DFS:
1. Location transparency .Thenameofafiledoesnotrevealanyhintofthe
file’s physicalstorage location.
2. Location independence . The name of a file need not be changed when
the file’s physical storage location changes.
Both definitions relate to the level of naming discussed previously, since files
have different names at different levels (that is, user-level textual names and
system-levelnumericalidentifiers).Alo cation-independentnamingschemeis
adynamicmapping,sinceitcan mapthesamefilenametodifferentlocations
attwodifferenttimes.Therefore,locationindependenceisastrongerproperty
than location transparency.
In practice, most of the current DFSs provide a static, location-transparent
mappingforuser-levelnames.Somesupport fil migration —thatis,changing
thelocationofafileautomatically,pro vidinglocationindependence.Open AFS"
3,19.7.2 Naming Schemes,901,19.7.1 Naming Structures,"19.7 DFS Naming and Transparency 763
The disadvantages are the added complexity of the boot protocols and the
performancelossresultingfromthe useof a networkrather than a local disk.
19.7.2 Naming Schemes
There are three main approaches to naming schemes in a DFS.I nt h es i m p l e s t
approach, a file is identified by some combination of its host name and local
name, which guarantees a unique system-wide name. In Ibis, for instance, a
file is identified uniquely by the name host:local-name, wherelocal-name is a
UNIX-like path. The Internet URLsystem also uses this approach. This naming
scheme is neither location transparent nor location independent. The DFSis
structuredasacollectionofisolatedcomponentunits,eachofwhichisanentire
conventional file system. Component un its remain isolated, although means
areprovidedtorefertoremotefiles.Wedonotconsiderthisschemeanyfurther
here.
The second approach was popularized by NFS.NFSprovides a means to
attach remote directories to local directories, thus giving the appearance of a
coherent directory tree. Early NFSversions allowed only previously mounted
remote directories to be accessed transparently. The advent of the automount
feature allowed mounts to be done on demand based on a table of mount
points and file-structure names. Compon ents are integrated to support trans-
parent sharing, but this integration is limited and is not uniform, because
each machine may attach different remote directories to its tree. The resulting
structureisversatile.
We can achieve total integration of the component file systems by using
a third approach. Here, a single global name structure spans all the files in
the system. Open AFSprovides a single global namespace for the files and
directoriesitexports,allowingasimilaru serexperienceacrossdifferentclient
machines.Ideally,the composedfile-systemstructureisthe sameasthestruc-
ture of a conventional file system. In practice, however, the many special files
(for example, UNIXdevice files and machine-specific binary directories) make
thisgoal difficultto attain.
Toevaluatenamingstructures,welookattheiradministrativecomplexity.
Themostcomplexandmostdifficult-to-maintainstructureisthe NFSstructure.
Because any remote directory can be attached anywhere on the local directory
tree, the resulting hierarchy can be highly unstructured. If a server becomes
unavailable, some arbitrary set of directories on different machines becomes
unavailable. In addition, a separate a ccreditation mechanism controls which
machine is allowed to attach which direc tory to its tree. Thus, a user might
be able to access a remote directory tree on one client but be denied access on
another client.
19.7.3 Implementation Techniques
Implementation of transparent naming requires a provision for the mapping
of a file name to the associated location. To keep this mapping manageable,
wemustaggregatesetsoffilesintocomponentunitsandprovidethemapping
on a component-unit basis rather than on a single-file basis. This aggregation
servesadministrativepurposesaswell. UNIX-likesystemsusethehierarchical
directory tree to provide name-to-location mapping and to aggregate files
recursivelyinto directories."
3,19.7.3 Implementation Techniques,901,19.7.2 Naming Schemes,"19.7 DFS Naming and Transparency 763
The disadvantages are the added complexity of the boot protocols and the
performancelossresultingfromthe useof a networkrather than a local disk.
19.7.2 Naming Schemes
There are three main approaches to naming schemes in a DFS.I nt h es i m p l e s t
approach, a file is identified by some combination of its host name and local
name, which guarantees a unique system-wide name. In Ibis, for instance, a
file is identified uniquely by the name host:local-name, wherelocal-name is a
UNIX-like path. The Internet URLsystem also uses this approach. This naming
scheme is neither location transparent nor location independent. The DFSis
structuredasacollectionofisolatedcomponentunits,eachofwhichisanentire
conventional file system. Component un its remain isolated, although means
areprovidedtorefertoremotefiles.Wedonotconsiderthisschemeanyfurther
here.
The second approach was popularized by NFS.NFSprovides a means to
attach remote directories to local directories, thus giving the appearance of a
coherent directory tree. Early NFSversions allowed only previously mounted
remote directories to be accessed transparently. The advent of the automount
feature allowed mounts to be done on demand based on a table of mount
points and file-structure names. Compon ents are integrated to support trans-
parent sharing, but this integration is limited and is not uniform, because
each machine may attach different remote directories to its tree. The resulting
structureisversatile.
We can achieve total integration of the component file systems by using
a third approach. Here, a single global name structure spans all the files in
the system. Open AFSprovides a single global namespace for the files and
directoriesitexports,allowingasimilaru serexperienceacrossdifferentclient
machines.Ideally,the composedfile-systemstructureisthe sameasthestruc-
ture of a conventional file system. In practice, however, the many special files
(for example, UNIXdevice files and machine-specific binary directories) make
thisgoal difficultto attain.
Toevaluatenamingstructures,welookattheiradministrativecomplexity.
Themostcomplexandmostdifficult-to-maintainstructureisthe NFSstructure.
Because any remote directory can be attached anywhere on the local directory
tree, the resulting hierarchy can be highly unstructured. If a server becomes
unavailable, some arbitrary set of directories on different machines becomes
unavailable. In addition, a separate a ccreditation mechanism controls which
machine is allowed to attach which direc tory to its tree. Thus, a user might
be able to access a remote directory tree on one client but be denied access on
another client.
19.7.3 Implementation Techniques
Implementation of transparent naming requires a provision for the mapping
of a file name to the associated location. To keep this mapping manageable,
wemustaggregatesetsoffilesintocomponentunitsandprovidethemapping
on a component-unit basis rather than on a single-file basis. This aggregation
servesadministrativepurposesaswell. UNIX-likesystemsusethehierarchical
directory tree to provide name-to-location mapping and to aggregate files
recursivelyinto directories."
2,19.8 Remote File Access,902,19.7 DFS Naming and Transparency,"764 Chapter 19 Networks and Distributed Systems
Toenhancetheavailabilityofthecrucialmappinginformation,wecanuse
replication,localcaching, orboth. Aswe noted,location independencemeans
that the mapping changes over time. H ence, replicating the mapping makes
a simple yet consistent update of this information impossible. To overcome
thisobstacle,wecanintroducelow-level, location-independentfileidentifiers .
(OpenAFSusesthisapproach.)Textualfilenamesaremappedtolower-levelfile
identifiers that indicate to which compo nent unit the file belongs. These iden-
tifiers are still location independent. They can be replicated and cached freely
without being invalidated by migration of component units. The inevitable
priceistheneedforasecondlevelofmapping,whichmapscomponentunitsto
locationsandneedsasimpleyetconsist entupdatemechanism.Implementing
UNIX-like directory trees using these low-level, location-independent identi-
fiers makes the whole hierarchy invariant under component-unit migration.
The onlyaspect that doeschange isthe component-unit location mapping.
A common way to implement low-level identifiers is to use structured
names. These names are bit strings that usually have two parts. The first part
identifiesthecomponentunittowhichthefilebelongs;thesecondpartidenti-
fiestheparticularfilewithintheunit.Variantswithmorepartsarepossible.The
invariant of structured names, however, is that individual parts of the name
are unique at all times only within the context of the rest of the parts. We can
obtainuniquenessatalltimesbytakingcarenottoreuseanamethatisstillin
use, by adding sufficiently more bits (this method is used in Open AFS), or by
using a timestamp as one part of the name (as was done in Apollo Domain).
Another way to view this process is that we are taking a location-transparent
system, such as Ibis, and adding another level of abstraction to produce a
location-independentnaming scheme.
19.8 Remote File Access
Next, let’s consider a user who requests access to a remote file. The server
storing the file has been located by the naming scheme, and now the actual
datatransfer musttakeplace.
One way to achieve this transfer is through a remote-service mechanism ,
whereby requests for accesses are delivered to the server, the server machine
performstheaccesses,andtheirresultsareforwardedbacktotheuser.Oneof
the most common ways of implementing remote serviceis the RPCparadigm,
which we discussedinChapter 3. Adirectanalogy existsbetweendisk-access
methodsinconventional filesystemsand theremote-servicemethodin a DFS:
using the remote-service method is analogous to performing a disk access for
each access request.
Toensurereasonableperformanceofaremote-servicemechanism,wecan
useaformofcaching. Inconventionalfil esystems,therationaleforcachingis
toreducedisk I/O(therebyincreasingperformance),whereasin DFSs,thegoal
is to reduceboth network traffic and disk I/O. In the following discussion, we
describe the implementation of caching in a DFSand contrast it with the basic
remote-serviceparadigm.
19.8.1 Basic Caching Scheme
Theconceptofcachingissimple.Ifthedataneededtosatisfytheaccessrequest
are not already cached, then a copy of the data is brought from the server to"
3,19.8.1 Basic Caching Scheme,902,19.8 Remote File Access,"764 Chapter 19 Networks and Distributed Systems
Toenhancetheavailabilityofthecrucialmappinginformation,wecanuse
replication,localcaching, orboth. Aswe noted,location independencemeans
that the mapping changes over time. H ence, replicating the mapping makes
a simple yet consistent update of this information impossible. To overcome
thisobstacle,wecanintroducelow-level, location-independentfileidentifiers .
(OpenAFSusesthisapproach.)Textualfilenamesaremappedtolower-levelfile
identifiers that indicate to which compo nent unit the file belongs. These iden-
tifiers are still location independent. They can be replicated and cached freely
without being invalidated by migration of component units. The inevitable
priceistheneedforasecondlevelofmapping,whichmapscomponentunitsto
locationsandneedsasimpleyetconsist entupdatemechanism.Implementing
UNIX-like directory trees using these low-level, location-independent identi-
fiers makes the whole hierarchy invariant under component-unit migration.
The onlyaspect that doeschange isthe component-unit location mapping.
A common way to implement low-level identifiers is to use structured
names. These names are bit strings that usually have two parts. The first part
identifiesthecomponentunittowhichthefilebelongs;thesecondpartidenti-
fiestheparticularfilewithintheunit.Variantswithmorepartsarepossible.The
invariant of structured names, however, is that individual parts of the name
are unique at all times only within the context of the rest of the parts. We can
obtainuniquenessatalltimesbytakingcarenottoreuseanamethatisstillin
use, by adding sufficiently more bits (this method is used in Open AFS), or by
using a timestamp as one part of the name (as was done in Apollo Domain).
Another way to view this process is that we are taking a location-transparent
system, such as Ibis, and adding another level of abstraction to produce a
location-independentnaming scheme.
19.8 Remote File Access
Next, let’s consider a user who requests access to a remote file. The server
storing the file has been located by the naming scheme, and now the actual
datatransfer musttakeplace.
One way to achieve this transfer is through a remote-service mechanism ,
whereby requests for accesses are delivered to the server, the server machine
performstheaccesses,andtheirresultsareforwardedbacktotheuser.Oneof
the most common ways of implementing remote serviceis the RPCparadigm,
which we discussedinChapter 3. Adirectanalogy existsbetweendisk-access
methodsinconventional filesystemsand theremote-servicemethodin a DFS:
using the remote-service method is analogous to performing a disk access for
each access request.
Toensurereasonableperformanceofaremote-servicemechanism,wecan
useaformofcaching. Inconventionalfil esystems,therationaleforcachingis
toreducedisk I/O(therebyincreasingperformance),whereasin DFSs,thegoal
is to reduceboth network traffic and disk I/O. In the following discussion, we
describe the implementation of caching in a DFSand contrast it with the basic
remote-serviceparadigm.
19.8.1 Basic Caching Scheme
Theconceptofcachingissimple.Ifthedataneededtosatisfytheaccessrequest
are not already cached, then a copy of the data is brought from the server to"
3,19.8.2 Cache Location,903,19.8.1 Basic Caching Scheme,"19.8 Remote File Access 765
the client system. Accesses are performed on the cached copy. The idea is to
retainrecentlyaccesseddiskblocksinthecache,sothatrepeatedaccessestothe
same information can be handled locally, without additional network traffic.
A replacement policy (for example, the least-recently-used algorithm) keeps
thecachesizebounded.Nodirectcorrespondenceexistsbetweenaccessesand
traffic to the server. Files are still identified with one master copy residing at
the server machine, but copies (or parts) of the file are scattered in different
caches. When a cached copy is modified, the changes need to be reflected on
the master copy to preserve the relevant consistency semantics. The problem
of keeping the cached copies consistent with the master file is the cache-
consistency problem , which we discuss in Section 19.8.4. DFScaching could
just as easily be called network virtual memory . It acts similarly to demand-
pagedvirtualmemory,exceptthatthebackingstoreusuallyisaremoteserver
rather than a local disk. NFSallows the swap space to be mounted remotely,
so it actually can implement virtual memory over a network, though with a
resultingperformance penalty.
The granularity of the cached data in a DFScan vary from blocks of a file
to an entire file. Usually, more data are cached than are needed to satisfy a
single access, so that many accesses can be served by the cached data. This
procedure is much like disk read-ahead (Section 14.6.2). Open AFScaches files
in large chunks (64 KB). The other systems discussed here support caching
of individual blocks driven by client demand. Increasing the caching unit
increasesthehitratio,butitalsoincreasesthemisspenalty,becauseeachmiss
requires more data to be transferred. It increases the potential for consistency
problemsaswell.Selectingtheunitofca chinginvolvesconsideringparameters
such as the network transfer unit and the RPCprotocol service unit (if an RPC
protocol is used). The network transfer unit (for Ethernet, a packet) is about
1.5KB,solargerunitsofcacheddataneedtobedisassembledfordeliveryand
reassembledonreception.
Block size and total cache size are obviously of importance for block-
caching schemes. In UNIX-like systems, common block sizes are 4 KBand 8
KB.Forlargecaches(over1 MB),largeblocksizes(over8 KB)arebeneficial.For
smallercaches,largeblocksizesarelessbeneficialbecausetheyresultinfewer
blocks in the cache and a lowerhit ratio.
19.8.2 Cache Location
Where should the cached data be stored—on disk or in main memory? Disk
caches have one clear advantage over main-memory caches: they are reliable.
Modifications to cached data are lost in a crash if the cache is kept in volatile
memory. Moreover, if the cached data are kept on disk, they are still there
duringrecovery,andthereisnoneedtofetchthemagain.Main-memorycaches
haveseveraladvantagesof theirown, however:
•Main-memory caches permitworkstations tobe diskless.
•Datacanbeaccessedmorequicklyfromacacheinmainmemorythanfrom
one ona disk.
•Technology is moving toward larger and less expensive memory. The
resulting performance speedup is predicted to outweigh the advantages
of diskcaches."
3,19.8.3 Cache-Update Policy,904,19.8.2 Cache Location,"766 Chapter 19 Networks and Distributed Systems
•The server caches (used to speed up disk I/O) will be in main memory
regardlessofwhereusercachesarelocated;ifweusemain-memorycaches
ontheusermachine,too,wecanbuildasinglecachingmechanismforuse
by bothserversand users.
Many remote-access implementations can be thought of as hybrids of
caching and remote service. In NFS, for instance, the implementation is based
on remote service but is augmented with client- and server-side memory
cachingforperformance.Thus,toevaluatethetwomethods,wemustevaluate
the degreeto which either method is emphasized. The NFSprotocol and most
implementationsdo not providediskcaching (but Open AFSdoes).
19.8.3 Cache-Update Policy
Thepolicyusedtowritemodifieddatablocksbacktotheserver’smastercopy
has a critical effect on the system’s performance and reliability. The simplest
policyis towritedata through to diskas soon as theyareplacedin any cache.
The advantage of a write-through policy is reliability: little information is
lost when a client system crashes. However, this policy requires each write
accesstowaituntiltheinformationissenttotheserver,soitcausespoorwrite
performance.Cachingwithwrite-throughisequivalenttousingremoteservice
for writeaccessesand exploiting caching onlyfor read accesses.
An alternative is the delayed-write policy ,a l s ok n o w na s write-back
caching,wherewedelayupdatestothemastercopy.Modificationsarewritten
to the cache and then are written through to the server at a later time. This
policy has two advantages overwrite-through. First,because writes aremade
tothecache,writeaccessescompletemuchmorequickly.Second,datamaybe
overwritten before they are written back, in which case only the last update
needs to be written at all. Unfortunately, delayed-write schemes introduce
reliability problems, since unwritten data are lost whenever a user machine
crashes.
Variationsofthedelayed-writepolicydifferinwhenmodifieddatablocks
are flushedto the server.One alternativeistoflush ablock when itisabout to
be ejectedfromthe client’s cache. This optioncan resultingoodperformance,
but some blocks can reside in the client’s cache a long time before they are
written back to the server. A compromise between this alternative and the
write-throughpolicyistoscanthecacheatregularintervalsandtoflushblocks
that have been modified since the most recent scan, just as UNIXscans its
local cache. NFSuses the policy for file data, but once a write is issued to the
server during a cache flush, the write must reach the server’s disk before it
is considered complete. NFStreats metadata (directory data and file-attribute
data)differently.Anymetadatachange sareissuedsynchronouslytotheserver.
Thus, file-structure loss and directory -structure corruption are avoided when
a clientor theservercrashes.
Yet another variation on delayed write is to write data back to the server
when the file is closed. This write-on-close policy is used in Open AFS.I nt h e
case of files that are open for short periods or are modified rarely, this policy
does not significantly reduce network traffic. In addition, the write-on-close
policy requires the closing process to delay while the file is written through,"
3,19.8.4 Consistency,905,19.8.3 Cache-Update Policy,"19.9 Final Thoughts on Distributed File Systems 767
whichreducestheperformanceadvantagesofdelayedwrites.Forfilesthatare
open for long periods and are modified frequently,however, the performance
advantages of this policy over delayed write with more frequent flushing are
apparent.
19.8.4 Consistency
Aclient machine is sometimes faced with the problem of deciding whether a
locally cached copy of data is consistent with the master copy (and hence can
be used). If the client machine determines that its cached data are out of date,
it must cache an up-to-date copy of the data before allowing further accesses.
Therearetwo approaches to verifyingthevalidityof cached data:
1.Client-initiated approach . The client initiates a validity check in which
it contacts the server and checks whe ther the local data are consistent
withthemastercopy.Thefrequencyofthevaliditycheckingisthecruxof
this approach and determinesthe resultingconsistency semantics.It can
range from a check before every access to a check only on first access to
afile(onfileopen,basically).Everyaccesscoupledwithavaliditycheck
is delayed, compared with an access served immediately by the cache.
Alternatively, checks can be initiated at fixed time intervals. Depending
on its frequency, the validity check can load both the network and the
server.
2.Server-initiated approach .Theserverrecords,foreachclient,thefiles(or
partsoffiles)thatitcaches.When theserverdetectsapotentialinconsis-
tency, it must react. A potential for i nconsistency occurs when two dif-
ferentclientsinconflictingmodescache afile.If UNIXsemantics(Section
15.7) is implemented,we can resolvethe potentialinconsistency by hav-
ing the server play an active role. The server must be notified whenever
afileisopened,andtheintendedmode(readorwrite)mustbeindicated
for every open. The server can then act when it detects that a file has
been opened simultaneously in confl icting modes by disabling caching
forthat particularfile.Actually,disablingcaching resultsin switching to
a remote-servicemodeof operation.
In a cluster-based DFS, the cache-consistency issue is made more compli-
cated by the presence of a metadata server and several replicated file data
chunksacrossseveraldataservers.Usingourearlierexamplesof HDFSandGFS,
we can compare some differences. HDFSallows append-only write operations
(norandomwrites)andasinglefilewriter,while GFSdoesallowrandomwrites
withconcurrentwriters.Thisgreatlycomplicateswriteconsistencyguarantees
forGFSwhile simplifyingthem for HDFS.
19.9 Final Thoughts on Distributed File Systems
Thelinebetween DFSclient–serverandcluster-basedarchitecturesisblurring.
TheNFSVersion 4.1 specification includes a protocol for a parallel version of
NFScalledp NFS,but as of thiswriting,adoption isslow."
2,19.9 Final Thoughts on Distributed File Systems,905,19.8 Remote File Access,"19.9 Final Thoughts on Distributed File Systems 767
whichreducestheperformanceadvantagesofdelayedwrites.Forfilesthatare
open for long periods and are modified frequently,however, the performance
advantages of this policy over delayed write with more frequent flushing are
apparent.
19.8.4 Consistency
Aclient machine is sometimes faced with the problem of deciding whether a
locally cached copy of data is consistent with the master copy (and hence can
be used). If the client machine determines that its cached data are out of date,
it must cache an up-to-date copy of the data before allowing further accesses.
Therearetwo approaches to verifyingthevalidityof cached data:
1.Client-initiated approach . The client initiates a validity check in which
it contacts the server and checks whe ther the local data are consistent
withthemastercopy.Thefrequencyofthevaliditycheckingisthecruxof
this approach and determinesthe resultingconsistency semantics.It can
range from a check before every access to a check only on first access to
afile(onfileopen,basically).Everyaccesscoupledwithavaliditycheck
is delayed, compared with an access served immediately by the cache.
Alternatively, checks can be initiated at fixed time intervals. Depending
on its frequency, the validity check can load both the network and the
server.
2.Server-initiated approach .Theserverrecords,foreachclient,thefiles(or
partsoffiles)thatitcaches.When theserverdetectsapotentialinconsis-
tency, it must react. A potential for i nconsistency occurs when two dif-
ferentclientsinconflictingmodescache afile.If UNIXsemantics(Section
15.7) is implemented,we can resolvethe potentialinconsistency by hav-
ing the server play an active role. The server must be notified whenever
afileisopened,andtheintendedmode(readorwrite)mustbeindicated
for every open. The server can then act when it detects that a file has
been opened simultaneously in confl icting modes by disabling caching
forthat particularfile.Actually,disablingcaching resultsin switching to
a remote-servicemodeof operation.
In a cluster-based DFS, the cache-consistency issue is made more compli-
cated by the presence of a metadata server and several replicated file data
chunksacrossseveraldataservers.Usingourearlierexamplesof HDFSandGFS,
we can compare some differences. HDFSallows append-only write operations
(norandomwrites)andasinglefilewriter,while GFSdoesallowrandomwrites
withconcurrentwriters.Thisgreatlycomplicateswriteconsistencyguarantees
forGFSwhile simplifyingthem for HDFS.
19.9 Final Thoughts on Distributed File Systems
Thelinebetween DFSclient–serverandcluster-basedarchitecturesisblurring.
TheNFSVersion 4.1 specification includes a protocol for a parallel version of
NFScalledp NFS,but as of thiswriting,adoption isslow."
2,19.10 Summary,906,19.9 Final Thoughts on Distributed File Systems,"768 Chapter 19 Networks and Distributed Systems
GFS,HDFS, and other large-scale DFSs export a non- POSIXAPI, so they
cannot transparently map directories to regular user machines as NFSand
OpenAFSdo. Rather, for systems to access these DFSs, they need client code
installed.However,othersoftwarelayersarerapidlybeingdevelopedtoallow
NFSto be mounted on top of such DFSs. This is attractive, as it would take
advantage of the scalability and other advantages of cluster-based DFSs while
stillallowingnativeoperating-systemutilitiesanduserstoaccessfilesdirectly
on theDFS.
As of this writing, the open-source HDFS NFS Gateway supports NFSVer-
sion 3 and works as a proxy between HDFSand the NFSserver software.
SinceHDFScurrently doesnot support random writes, the HDFS NFS Gateway
also does not support this capability. That means a file must be deleted and
recreated from scratch even if only one byte is changed. Commercial organi-
zations and researchers are addressing this problem and building stackable
frameworksthatallowstackingofa DFS,parallelcomputingmodules(suchas
MapReduce),distributeddatabases,and exportedfilevolumesthrough NFS.
One other type of file system, less complex than a cluster-based DFSbut
more complex than a client–server DFS,i sa clustered file system (CFS)o r
parallel file system (PFS). ACFStypically runs over a LAN. These systems are
important and widely used and thus deserve mention here, though we do
not cover them in detail. Common CFSsi n c l u d e Lustreand GPFS,a l t h o u g h
there are many others. A CFSessentially treats Nsystems storing data and Y
systems accessing that data as a single client–server instance. Whereas NFS,
for example, has per-server naming, and two separate NFSservers generally
provide two different naming schemes, a CFSknits various storage contents
on various storage devices on various servers into a uniform, transparent
name space. GPFShas its own file-system structure, but Lustre uses existing
file systems such as ZFSfor file storage and management. To learn more, see
http://lustre.org .
Distributed file systems are in common use today, providing file sharing
withinLANs, within cluster environments, and across WANs. The complexity
of implementingsucha systemshould not beunderestimated,especiallycon-
sidering that the DFSmust be operating-system independent for widespread
adoptionandmustprovideavailabilityandgoodperformanceinthepresence
of long distances, commodity hardware failures, sometimes frail networking,
and ever-increasingusersand workloads.
19.10 Summary
•Adistributed system is a collection of processors that do not share mem-
ory or a clock. Instead, each processor has its own local memory, and the
processors communicate with one another through various communica-
tion lines, such as high-speed buses and the Internet. The processors in a
distributedsystemvaryinsizeand function.
•Adistributedsystemprovidestheuserwithaccesstoallsystemresources.
Access to a shared resource can be provided by data migration, compu-
tation migration, or process migrati on. The access can be specified by the
useror implicitlysuppliedby the operatingsystemand applications."
2,Practice Exercises,908,19.10 Summary,"770 Chapter 19 Networks and Distributed Systems
Practice Exercises
19.1Why would it be a bad idea for routers to pass broadcast packets
betweennetworks?What wouldbe theadvantagesof doingso?
19.2Discuss the advantages and disadvantages of caching name transla-
tions forcomputers locatedinremotedomains.
19.3Whataretwoformidableproblemsthatdesignersmustsolvetoimple-
menta network systemthathas the qualityof transparency?
19.4To build a robust distributed system, you must know what kinds of
failurescan occur.
a. Listthreepossibletypesof failureina distributedsystem.
b. Specify which of the entries in your list also are applicable to a
centralizedsystem.
19.5Isitalwayscrucialtoknowthatthemessageyouhavesenthasarrived
at its destination safely? If your answer is “yes, ”explain why. If your
answer is “no,”giveappropriateexamples.
19.6Adistributed system has two sites, Aand B. Consider whether site A
can distinguishamong the following:
a. B goesdown.
b. Thelink betweenAandBgoes down.
c. B is extremely overloaded, and its response time is 100 times
longerthan normal.
What implications does your answer have for recovery in distributed
systems?
Further Reading
[Peterson and Davie (2012)] and [Kurose and Ross (2017)] provide general
overviewsof computernetworks.The Internetandits protocolsaredescribed
in[Comer(2000)].Coverageof TCP/IPcanbefoundin[FallandStevens(2011)]
and [Stevens (1995)]. UNIXnetwork programming is described thoroughly in
[Stevenetal.(2003)].
Ethernetand WiFistandardsandspeedsareevolvingquickly.Current IEEE
802.3Ethernetstandardscanbefoundat http://standards.ieee.org/about/get/
802/802.3.html .C u r r e n t IEEE802.11 Wireless LANstandards can be found at
http://standards.ieee.org/ about/get/802/802.11.html .
Sun’s network file system ( NFS) is described by [Callaghan (2000)]. Infor-
mation about Open AFSisavailablefrom http://www.openafs.org .
Information on the Google file system can be found in [Ghe-
mawat et al. (2003)]. The Google MapReduce method is described in
http://research.google.com/archive/mapreduce.html . The Hadoop dis-
tributedfilesystemisdiscussedin[K.ShvachkoandChansler(2010)],andthe
Hadoop frameworkisdiscussedin http://hadoop.apache.org/ .
To learn more about Lustre, see http://lustre.org ."
2,Further Reading,908,Practice Exercises,"770 Chapter 19 Networks and Distributed Systems
Practice Exercises
19.1Why would it be a bad idea for routers to pass broadcast packets
betweennetworks?What wouldbe theadvantagesof doingso?
19.2Discuss the advantages and disadvantages of caching name transla-
tions forcomputers locatedinremotedomains.
19.3Whataretwoformidableproblemsthatdesignersmustsolvetoimple-
menta network systemthathas the qualityof transparency?
19.4To build a robust distributed system, you must know what kinds of
failurescan occur.
a. Listthreepossibletypesof failureina distributedsystem.
b. Specify which of the entries in your list also are applicable to a
centralizedsystem.
19.5Isitalwayscrucialtoknowthatthemessageyouhavesenthasarrived
at its destination safely? If your answer is “yes, ”explain why. If your
answer is “no,”giveappropriateexamples.
19.6Adistributed system has two sites, Aand B. Consider whether site A
can distinguishamong the following:
a. B goesdown.
b. Thelink betweenAandBgoes down.
c. B is extremely overloaded, and its response time is 100 times
longerthan normal.
What implications does your answer have for recovery in distributed
systems?
Further Reading
[Peterson and Davie (2012)] and [Kurose and Ross (2017)] provide general
overviewsof computernetworks.The Internetandits protocolsaredescribed
in[Comer(2000)].Coverageof TCP/IPcanbefoundin[FallandStevens(2011)]
and [Stevens (1995)]. UNIXnetwork programming is described thoroughly in
[Stevenetal.(2003)].
Ethernetand WiFistandardsandspeedsareevolvingquickly.Current IEEE
802.3Ethernetstandardscanbefoundat http://standards.ieee.org/about/get/
802/802.3.html .C u r r e n t IEEE802.11 Wireless LANstandards can be found at
http://standards.ieee.org/ about/get/802/802.11.html .
Sun’s network file system ( NFS) is described by [Callaghan (2000)]. Infor-
mation about Open AFSisavailablefrom http://www.openafs.org .
Information on the Google file system can be found in [Ghe-
mawat et al. (2003)]. The Google MapReduce method is described in
http://research.google.com/archive/mapreduce.html . The Hadoop dis-
tributedfilesystemisdiscussedin[K.ShvachkoandChansler(2010)],andthe
Hadoop frameworkisdiscussedin http://hadoop.apache.org/ .
To learn more about Lustre, see http://lustre.org ."
2,Bibliography,909,Further Reading,"Bibliography 771
Bibliography
[Callaghan (2000)] B. Callaghan, NFSIllustrated , Addison-Wesley (2000).
[Comer (2000)] D.Comer, InternetworkingwithTCP/IP,VolumeI, FourthEdition,
PrenticeHall (2000).
[Fall and Stevens (2011)] K.FallandR.Stevens, TCP/IPIllustrated,Volume1:The
Protocols, SecondEdition, JohnWiley and Sons(2011).
[Ghemawat et al. (2003)] S .G h e m a w a t ,H .G o b i o f f ,a n dS . - T .L e u n g , “The
Google File System ”,Proceedings of the ACM Symposium on Operating Systems
Principles (2003).
[K. Shvachko and Chansler (2010)] S. R. K. Shvachko, H. Kuang and
R.Chansler, “The HadoopDistributed File System ”(2010).
[Kurose and Ross (2017)] J. Kurose and K. Ross, ComputerNetworking—ATop–
DownApproach, SeventhEdition, Addison-Wesley (2017).
[Peterson and Davie (2012)] L. L. Peterson and B. S. Davie, ComputerNetworks:
ASystemsApproacm, Fifth Edition, MorganKaufmann(2012).
[Steven et al. (2003)] R.Steven,B.Fenner,andA.Rudoff, UnixNetworkProgram-
ming,Volume1:TheSocketsNetworkingAPI, Third Edition, JohnWiley and Sons
(2003).
[Stevens (1995)] R. Stevens, TCP/IP Illustrated, Volume 2: The Implementation ,
Addison-Wesley (1995)."
2,Chapter 19 Exercises,910,Bibliography,"Exercises
Chapter 19 Exercises
19.7What is the difference between computation migration and process
migration? Which is easierto implement,and why?
19.8Even though the OSImodel of networking specifies seven layers of
functionality, most computer systems use fewer layers to implement
a network. Why do they use fewer layers? What problems could the
use offewerlayerscause?
19.9ExplainwhydoublingthespeedofthesystemsonanEthernetsegment
mayresultindecreasednetworkperformancewhenthe UDPtransport
protocol isused.What changes couldhelpsolvethisproblem?
19.10What are the advantages of using dedicated hardware devices for
routers? What are the disadvantages of using these devices compared
with usinggeneral-purposecomputers?
19.11Inwhatwaysisusinganameserverbetterthanusingstatichosttables?
What problems or complications are associated with name servers?
What methods could you use to decrease the amount of traffic name
serversgeneratetosatisfytranslationrequests?
19.12Name serversare organized ina hierarchicalmanner. What isthe pur-
pose of using a hierarchical organization?
19.13The lower layers of the OSInetwork model provide datagram service,
with no delivery guarantees for messages. A transport-layer protocol
such as TCPis used to provide reliability. Discuss the advantages and
disadvantages of supporting reliable message delivery at the lowest
possiblelayer.
19.14Run theprogramshown inFigure19.4and determinethe IPaddresses
of the following host names:
•www.wiley.com
•www.cs.yale.edu
•www.apple.com
•www.westminstercollege.edu
•www.ietf.org
19.15ADNSname can map to multiple servers, such as www.google.com.
However,ifweruntheprogramshowninFigure19.4,wegetonlyone
IPaddress. Modify the program to display all the server IPaddresses
insteadof justone.
19.16The original HTTPprotocol used TCP/IPas the underlying network
protocol. For eachpage,graphic, or applet,a separate TCPsessionwas
constructed,used,andtorndown.Becauseoftheoverheadofbuilding
and destroying TCP/IPconnections, performance problems resulted
from this implementation method. Would using UDPrather than TCP
beagoodalternative?Whatotherchangescouldyoumaketoimprove
HTTPperformance?EX-56"
0,PART NINE CASE STUDIES,913,PART EIGHT ADVANCED TOPICS,"Part Nine
Case Studies
We now integrate the concepts described earlier in this book by examin-
ing real operating systems. We cove r two such systems in detail—Linux
and Windows 10.
We chose Linux for several reasons: it is popular, it is freely available,
and it represents a full-featured UNIX system. This gives a student of
operating systems an opportunity to read—and modify— realoperating-
system source code.
With Windows 10, the student can examine a modern operating sys-
tem whose design and implementation are drastically different from those
ofUNIX . This operating system from Microsoft is very popular as a desk-
top operating system, but it can also be used as an operating system for
mobile devices. Windows 10 has a modern design and features a look and
feel very different from earlier oper ating systems produced by Microsoft."
1,Chapter 20 The Linux System,915,PART NINE CASE STUDIES,"20CHAPTER
The Linux System
Updated by Robert Love
Thischapterpresentsan in-depthexamination ofthe Linux operatingsystem.
By examining a complete, real system, we can see how the concepts we have
discussedrelateboth to one another and topractice.
Linux is a variant of UNIXthat has gained popularity over the last several
decades, powering devices as small as mobile phones and as large as room-
fillingsupercomputers.Inthischapter,welookatthehistoryanddevelopment
ofLinuxand covertheuserand programmerinterfacesthatLinuxpresents—
interfacesthatoweagreatdealtothe UNIXtradition.Wealsodiscussthedesign
and implementation of these interfaces . Linux is a rapidly evolving operating
system. This chapter describes developments through the Linux 4.12 kernel,
which was releasedin 2017.
CHAPTER OBJECTIVES
•Explore the history of the UNIXoperating system from which Linux is
derived and the principles upon which Linux’s design is based.
•Examine the Linux process and thread models and illustrate how Linux
schedules threads and provides interprocess communication.
•Look at memory management in Linux.
•Explore how Linux implements file systems and manages I/Odevices.
20.1 Linux History
Linuxlooksandfeelsmuchlikeanyother UNIXsystem;indeed, UNIXcompat-
ibility has been a major design goal of the Linux project. However, Linux is
muchyoungerthanmost UNIXsystems.Itsdevelopmentbeganin1991,when
a Finnish university student, Linus Torvalds, began creating a small but self-
containedkernelforthe80386processor, thefirsttrue32-bitprocessorinIntel’s
range of PC-compatible CPUs.
775"
2,20.1 Linux History,915,Chapter 20 The Linux System,"20CHAPTER
The Linux System
Updated by Robert Love
Thischapterpresentsan in-depthexamination ofthe Linux operatingsystem.
By examining a complete, real system, we can see how the concepts we have
discussedrelateboth to one another and topractice.
Linux is a variant of UNIXthat has gained popularity over the last several
decades, powering devices as small as mobile phones and as large as room-
fillingsupercomputers.Inthischapter,welookatthehistoryanddevelopment
ofLinuxand covertheuserand programmerinterfacesthatLinuxpresents—
interfacesthatoweagreatdealtothe UNIXtradition.Wealsodiscussthedesign
and implementation of these interfaces . Linux is a rapidly evolving operating
system. This chapter describes developments through the Linux 4.12 kernel,
which was releasedin 2017.
CHAPTER OBJECTIVES
•Explore the history of the UNIXoperating system from which Linux is
derived and the principles upon which Linux’s design is based.
•Examine the Linux process and thread models and illustrate how Linux
schedules threads and provides interprocess communication.
•Look at memory management in Linux.
•Explore how Linux implements file systems and manages I/Odevices.
20.1 Linux History
Linuxlooksandfeelsmuchlikeanyother UNIXsystem;indeed, UNIXcompat-
ibility has been a major design goal of the Linux project. However, Linux is
muchyoungerthanmost UNIXsystems.Itsdevelopmentbeganin1991,when
a Finnish university student, Linus Torvalds, began creating a small but self-
containedkernelforthe80386processor, thefirsttrue32-bitprocessorinIntel’s
range of PC-compatible CPUs.
775"
3,20.1.1 The Linux Kernel,916,20.1 Linux History,"776 Chapter 20 The Linux System
Earlyinitsdevelopment,theLinuxsourcecodewasmadeavailablefree—
both at no cost and with minimal distributional restrictions—on the Internet.
Asa result,Linux’s historyhas beenone of collaboration by many developers
fromallaroundtheworld,correspondingalmostexclusivelyovertheInternet.
From an initial kernel that partially implemented a small subset of the UNIX
systemservices,theLinuxsystemhasgrowntoincludeallofthefunctionality
expectedof amodern UNIXsystem.
In its early days, Linux development revolved largely around the central
operating-systemkernel—thecore,privilegedexecutivethatmanagesallsys-
tem resources and interacts directly with the computer hardware. We need
much more than this kernel, of course, to produce a full operating system.
We thus need to make a distinction be tween the Linux kernel and a complete
Linux system. The Linux kernel is an original piece of software developed
fromscratchbytheLinuxcommunity.The Linux system ,asweknowittoday ,
includes a multitude of components, some written from scratch, others bor-
rowed from other development projects, and still others created in collabora-
tionwithotherteams.
ThebasicLinuxsystemisastandardenvironmentforapplicationsanduser
programming, but it does not enforce any standard means of managing the
available functionality as a whole. As Linux has matured, a need has arisen
for another layer of functionality on top of the Linux system. This need has
beenmetbyvariousLinuxdistributions.A Linux distribution includesallthe
standard components of the Linux system, plus a set of administrative tools
to simplify the initial installation and subsequent upgrading of Linux and to
manage installation and removal of other packages on the system. A mod-
ern distribution also typically includes tools for management of file systems,
creation and management of user accounts, administration of networks, web
browsers, word processors,and so on.
20.1.1 The Linux Kernel
The first Linux kernel released to the public was version 0.01, dated May 14,
1991. It had no networking, ran only on 80386-compatible Intel processors
andPChardware, and had extremely limited device-driver support. The vir-
tual memory subsystem was also fairly basic and included no support for
memory-mappedfiles;however,eventhisearlyincarnationsupportedshared
pages with copy-on-write and protected address spaces. The only file system
supported was the Minix file system, as the first Linux kernels were cross-
developedon aMinix platform.
Thenextmilestone,Linux1.0,wasreleasedonMarch14,1994.Thisrelease
culminatedthreeyearsofrapiddevelopmentoftheLinuxkernel.Perhapsthe
single biggest new feature was networking: 1.0 included support for UNIX’s
standard TCP/IPnetworking protocols, as well as a BSD-compatible socket
interface for networking programming. Device-driver support was added for
running IPover Ethernet or (via the PPPorSLIPprotocols) over serial lines or
modems.
The1.0kernelalsoincludedanew,muchenhancedfilesystemwithoutthe
limitations of the original Minix file system, and it supported a range of SCSI
controllersforhigh-performancediskaccess.Thedevelopersextendedthevir-"
3,20.1.2 The Linux System,918,20.1.1 The Linux Kernel,"778 Chapter 20 The Linux System
Improvements continued with the release of Linux 2.2 in 1999. A port to
UltraSPARCsystemswasadded.Networkingwasenhancedwithmoreflexible
firewalling, improved routing and traffic management, and support for TCP
large window and selective acknowledgement. Acorn, Apple, and NTdisks
could now be read, and NFSwas enhanced with a new kernel-mode NFS
daemon.Signalhandling,interrupts,andsome I/Owerelockedatafinerlevel
than beforetoimprovesymmetricmultiprocessor( SMP)p e r f o r m a n c e .
Advances in the 2.4 and 2.6 releases of the kernel included increased
support for SMPsystems, journaling file systems, and enhancements to the
memory-managementandblock I/Osystems.Thethreadschedulerwasmod-
ified in version 2.6, providing an efficient O(1) scheduling algorithm. In addi-
tion, the 2.6 kernel was preemptive, allowing a threads to be preempted even
while running in kernelmode.
Linuxkernelversion3.0wasreleasedinJuly2011.Themajorversionbump
from 2 to 3 occurred to commemorate the twentieth anniversary of Linux.
Newfeaturesincludeimprovedvirtuali zationsupport,anewpagewrite-back
facility, improvements to the memory-management system, and yet another
new thread scheduler—the CompletelyFairScheduler( CFS).
Linux kernel version 4.0 was released in April 2015. This time the major
version bump was entirely arbitrary; Linux kernel developers simply grew
tired of ever-larger minor versions. Today Linux kernel versions do not sig-
nify anything other than release ordering. The 4.0 kernel series provided sup-
port for newarchitectures, improvedmo bile functionality, and many iterative
improvements.Wefocusonthisnewestkernelintheremainderofthischapter.
20.1.2 The Linux System
As we noted earlier, the Linux kernel forms the core of the Linux project, but
other components make up a complete Linux operating system. Whereas the
Linux kernel is composed entirely of code written from scratch specifically
for the Linux project, much of the supporting software that makes up the
Linux system is not exclusive to Linux but is common to a number of UNIX-
likeoperatingsystems.Inparticular,Linuxusesmanytoolsdevelopedaspart
of Berkeley’s BSDoperating system, MIT’s X Window System, and the Free
SoftwareFoundation’s GNUproject.
This sharing of tools has worked in both directions. The main system
libraries of Linux were originated by the GNUproject, but the Linux commu-
nitygreatlyimprovedthelibrariesbyaddr essingomissions,inefficiencies,and
bugs. Other components, such as the GNU C compiler (gcc), were already of
sufficientlyhighqualitytobeuseddirectlyinLinux.Thenetworkadministra-
tiontoolsunderLinuxwerederivedfromcodefirstdevelopedfor4.3 BSD,but
morerecent BSDderivatives,suchas FreeBSD,haveborrowedcodefromLinux
in return. Examples of this sharing include the Intel floating-point-emulation
math libraryand the PCsound-hardware devicedrivers.
TheLinuxsystemasawholeismaintainedbyaloosenetworkofdevelop-
ers collaborating over the Internet, with small groups or individuals having
responsibility for maintaining the inte grity of specific components. A small
number of public Internet file-transfer-protocol ( FTP)a r c h i v es i t e sa c ta sd e
facto standard repositories for these components. The File System Hierarchy"
3,20.1.3 Linux Distributions,919,20.1.2 The Linux System,"20.1 Linux History 779
Standard document is also maintained by the Linux community as a means
of ensuring compatibility across the various system components. This stan-
dardspecifiestheoveralllayoutofa standardLinuxfilesystem;itdetermines
underwhichdirectorynamesconfigurationfiles,libraries,systembinaries,and
run-timedata filesshouldbe stored.
20.1.3 Linux Distributions
In theory, anybody can install a Linux system by fetching the latest revisions
ofthenecessarysystemcomponentsfromthe ftpsitesandcompilingthem.In
Linux’searlydays,thisispreciselywhataLinuxuserhadtodo.AsLinuxhas
matured, however, various individuals and groups have attempted to make
this job less painful by providing standard, precompiled sets of packages for
easyinstallation.
These collections, or distributions, include much more than just the basic
Linux system. They typically include extra system-installation and manage-
mentutilities,aswellasprecompiledandready-to-installpackagesofmanyof
the common UNIXtools, such as news servers, web browsers, text-processing
andeditingtools,andevengames.
The first distributions managed these packages by simply providing a
meansofunpackingallthefilesintotheappropriateplaces.Oneoftheimpor-
tant contributions of modern distributions, however, is advanced package
management.Today’sLinuxdistributionsincludeapackage-trackingdatabase
thatallows packages tobe installed,upgraded,or removedpainlessly.
TheSLSdistribution, dating back to the early days of Linux, was the first
collection of Linux packages that was recognizable as a complete distribu-
tion. Although it could be installed as a single entity, SLSlacked the package-
management tools now expected of Linux distributions. The Slackware dis-
tribution represented a great improvement in overall quality, even though it
also had poor package management. In fact, it is still one of the most widely
installeddistributionsin theLinuxcommunity.
Since Slackware’s release, many commercial and noncommercial Linux
distributionshavebecomeavailable. Red Hat andDebianareparticularlypop-
ular distributions; the first comes from a commercial Linux support company
and the second from the free-software Linux community. Other commercially
supported versions of Linux include distributions from Canonical and SuSE,
and many others. There are too many Linux distributions in circulation for us
to list all of them here. The variety of distributions does not prevent Linux
distributionsfrom being compatible,however.The RPMpackage file format is
used, or at least understood, by the majority of distributions, and commer-
cial applications distributed in this format can be installed and run on any
distributionthatcan accept RPMfiles.
20.1.4 Linux Licensing
The Linux kernel is distributed under version 2.0 of the GNUGeneral Public
License( GPL),thetermsofwhich aresetoutbytheFreeSoftwareFoundation.
Linux is not public-domain software. Public domain implies that the authors
have waived copyright rights in the software, but copyright rights in Linux
code are still held by the code’s various authors. Linux is freesoftware, how-"
3,20.1.4 Linux Licensing,919,20.1.3 Linux Distributions,"20.1 Linux History 779
Standard document is also maintained by the Linux community as a means
of ensuring compatibility across the various system components. This stan-
dardspecifiestheoveralllayoutofa standardLinuxfilesystem;itdetermines
underwhichdirectorynamesconfigurationfiles,libraries,systembinaries,and
run-timedata filesshouldbe stored.
20.1.3 Linux Distributions
In theory, anybody can install a Linux system by fetching the latest revisions
ofthenecessarysystemcomponentsfromthe ftpsitesandcompilingthem.In
Linux’searlydays,thisispreciselywhataLinuxuserhadtodo.AsLinuxhas
matured, however, various individuals and groups have attempted to make
this job less painful by providing standard, precompiled sets of packages for
easyinstallation.
These collections, or distributions, include much more than just the basic
Linux system. They typically include extra system-installation and manage-
mentutilities,aswellasprecompiledandready-to-installpackagesofmanyof
the common UNIXtools, such as news servers, web browsers, text-processing
andeditingtools,andevengames.
The first distributions managed these packages by simply providing a
meansofunpackingallthefilesintotheappropriateplaces.Oneoftheimpor-
tant contributions of modern distributions, however, is advanced package
management.Today’sLinuxdistributionsincludeapackage-trackingdatabase
thatallows packages tobe installed,upgraded,or removedpainlessly.
TheSLSdistribution, dating back to the early days of Linux, was the first
collection of Linux packages that was recognizable as a complete distribu-
tion. Although it could be installed as a single entity, SLSlacked the package-
management tools now expected of Linux distributions. The Slackware dis-
tribution represented a great improvement in overall quality, even though it
also had poor package management. In fact, it is still one of the most widely
installeddistributionsin theLinuxcommunity.
Since Slackware’s release, many commercial and noncommercial Linux
distributionshavebecomeavailable. Red Hat andDebianareparticularlypop-
ular distributions; the first comes from a commercial Linux support company
and the second from the free-software Linux community. Other commercially
supported versions of Linux include distributions from Canonical and SuSE,
and many others. There are too many Linux distributions in circulation for us
to list all of them here. The variety of distributions does not prevent Linux
distributionsfrom being compatible,however.The RPMpackage file format is
used, or at least understood, by the majority of distributions, and commer-
cial applications distributed in this format can be installed and run on any
distributionthatcan accept RPMfiles.
20.1.4 Linux Licensing
The Linux kernel is distributed under version 2.0 of the GNUGeneral Public
License( GPL),thetermsofwhich aresetoutbytheFreeSoftwareFoundation.
Linux is not public-domain software. Public domain implies that the authors
have waived copyright rights in the software, but copyright rights in Linux
code are still held by the code’s various authors. Linux is freesoftware, how-"
2,20.2 Design Principles,920,20.1 Linux History,"780 Chapter 20 The Linux System
ever, in the sense that people can copy it, modify it, use it in any manner they
want, and giveaway (or sell)theirowncopies.
The main implication of Linux’s licensing terms is that nobody using
Linux, or creating a derivative of Linux (a legitimate exercise), can distribute
thederivativewithoutincludingtheso urcecode.Softwarereleasedunderthe
GPLcannot be redistributed as a binary-only product. If you release software
that includes any components covered by the GPL, then, under the GPL,y o u
must make source code available alon gside any binary distributions. (This
restrictiondoesnotprohibitmaking—orevenselling—binarysoftwaredistri-
butions,aslongasanybodywhoreceivesbinariesisalsogiventheopportunity
to gettheoriginating sourcecodefor a reasonabledistributioncharge.)
20.2 Design Principles
In its overall design, Linux resembles other traditional, nonmicrokernel UNIX
implementations. It is a multiuser, preemptively multitasking system with a
full set of UNIX-compatible tools. Linux’s file system adheres to traditional
UNIXsemantics, and the standard UNIXnetworking model is fully imple-
mented. The internal details of Linux’s design have been influenced heavily
by thehistory of thisoperatingsystem’sdevelopment.
Although Linux runs on a wide variety of platforms, it was originally
developed exclusively on PCarchitecture. A great deal of that early develop-
ment was carried out by individual enthusiasts rather than by well-funded
developmentorresearchfacilities,sofromthestartLinuxattemptedtosqueeze
as much functionality as possible from limited resources. Today, Linux can
runhappilyon amultiprocessormachine with hundredsof gigabytesofmain
memory and many terabytes of disk space, but it is still capable of operating
usefullyinunder16- MBofRAM.
AsPCs became more powerful and as memory and hard disks became
cheaper,the original,minimalistLinux kernelsgrewto implementmore UNIX
functionality. Speed and efficiency are still important design goals, but much
recent and current work on Linux has concentrated on a third major design
goal: standardization. One of the prices paid for the diversity of UNIXimple-
mentations currently available is that source code written for one may not
necessarily compile or run correctly on another. Even when the same system
callsarepresentontwodifferent UNIXsystems,theydonotnecessarilybehave
in exactly the same way. The POSIXstandards comprise a set of specifications
fordifferentaspectsofoperating-systembehavior.Thereare POSIXdocuments
for common operating-system functionality and for extensions such as pro-
cess threads and real-time operations. Linux is designed to comply with the
relevant POSIXdocuments,andatleasttwoLinuxdistributionshaveachieved
official POSIXcertification.
Because it gives standard interfaces to both the programmer and the user,
Linux presentsfewsurprisesto anybody familiarwith UNIX.W ed on o td e t a i l
these interfaces here. The sections on the programmer interface (Section C.3)
anduserinterface(SectionC.4)of BSDapplyequallywelltoLinux.Bydefault,
however, the Linux programming interface adheres to SVR4 UNIX semantics,
ratherthanto BSDbehavior.Aseparatesetoflibrariesisavailabletoimplement
BSDsemantics inplaces where the two behaviors differsignificantly."
3,20.2.1 Components of a Linux System,921,20.2 Design Principles,"20.2 Design Principles 781
Many other standards exist in the UNIXworld, but full certification of
Linux with respect to these standards is sometimes slowed because certifica-
tionisoftenavailableonly for a fee,and the expenseinvolvedincertifying an
operating system’s compliance with most standards is substantial. However,
supportinga widebaseofapplicationsisimportantforany operatingsystem,
so implementation of standards is a major goal for Linux development, even
without formal certification. In addition to the basic POSIXstandard, Linux
currently supports the POSIXthreading extensions—Pthreads—and a subset
ofthePOSIXextensionsforreal-timeprocesscontrol.
20.2.1 Components of a Linux System
TheLinuxsystemiscomposedofthreemainbodiesofcode,inlinewithmost
traditional UNIXimplementations:
1.Kernel. The kernel is responsible for maintaining all the important
abstractions of the operating system, including such things as virtual
memoryand processes.
2.System libraries . The system libraries define a standard set of functions
throughwhichapplicationscaninteractwiththekernel.Thesefunctions
implementmuchoftheoperating-systemfunctionalitythatdoesnotneed
thefullprivilegesofkernelcode.Themostimportantsystemlibraryisthe
C library ,knownas libc.InadditiontoprovidingthestandardClibrary,
libcimplements the user mode side of the Linux system call interface,
aswellas other criticalsystem-levelinterfaces.
3.System utilities . The system utilities are programs that perform indi-
vidual,specializedmanagementtasks.Somesystemutilitiesareinvoked
just once to initialize and configure some aspect of the system. Others—
known as daemons inUNIXterminology—run permanently, handling
such tasks as responding to incoming network connections, accepting
logonrequestsfromterminals,andupdating logfiles.
Figure 20.1 illustrates the various components that make up a full Linux
system. The most important distinction here is between the kernel and every-
thing else. All the kernel code executes in the processor’s privileged mode
system shared libraries
Linux kernel
loadable kernel modulessystem-
management
programsuser
processesuser
utility
programscompilers
Figure 20.1 Components of the Linux system."
2,20.3 Kernel Modules,923,20.2 Design Principles,"20.3 Kernel Modules 783
The Linux system includes a wide variety of user-mode programs—both
systemutilitiesanduserutilities.Thesystemutilitiesincludealltheprograms
necessary to initialize and then administer the system, such as those to set up
networkinginterfacesandtoaddandremoveusersfromthesystem.Userutil-
ities are also necessary to the basic operation of the system but do not require
elevatedprivilegestorun.Theyinclude simplefile-managementutilitiessuch
as those to copy files, create directories, and edit text files. One of the most
important user utilities is the shell, the standard command-line interface on
UNIXsystems. Linux supports many shells; the most common is the bourne-
again shell (bash).
20.3 Kernel Modules
TheLinuxkernelhastheabilitytoloadandunloadarbitrarysectionsofkernel
codeondemand.Theseloadablekernel modulesruninprivilegedkernelmode
and as a consequence have full access to all the hardware capabilities of the
machine on which they run. In theory, there is no restriction on what a kernel
moduleisallowedtodo.Amongotherth ings,akernelmodulecanimplement
adevicedriver,a filesystem,ora networking protocol.
Kernel modules are convenient for several reasons. Linux’s source code is
free, so anybody wanting to write kernel code is able to compile a modified
kernelandtorebootintothatnewfunct ionality.However,recompiling,relink-
ing,andreloadingtheentirekernelisacumbersomecycle toundertakewhen
you are developing a new driver. If you use kernel modules, you do not have
to make a new kernel to test a new driver—the driver can be compiled on its
ownandloadedintothealreadyrunningkernel.Ofcourse,onceanewdriver
iswritten,itcanbedistributedasamodulesothatotheruserscanbenefitfrom
itwithout having torebuildtheirkernels.
This latter point has another implication. Because it is covered by the
GPLlicense,theLinuxkernelcannot bereleasedwithproprietarycomponents
added to it unless those new components are also releasedunder the GPLand
the source code for them is made availa ble on demand. The kernel’s module
interfaceallowsthirdpartiestowriteanddistribute,ontheirownterms,device
driversor filesystemsthat couldnot be distributedunderthe GPL.
KernelmodulesallowaLinuxsystemtobesetupwithastandardminimal
kernel, without any extra device drivers built in. Any device drivers that the
user needs can be either loaded explicitly by the system at startup or loaded
automatically by the system on demand and unloaded when not in use. For
example,amousedrivercanbeloadedwhena USBmouseispluggedintothe
systemand unloadedwhenthe mouseisunplugged.
The modulesupportunderLinuxhas four components:
1.The module-management system allows modules to be loaded into
memoryand tocommunicate with therestofthe kernel.
2.The module loader and unloader , which are user-mode utilities, work
withthemodule-managementsystemtoloada moduleinto memory."
3,20.3.1 Module Management,924,20.3 Kernel Modules,"784 Chapter 20 The Linux System
3.The driver-registration system allows modules to tell the rest of the
kernelthat a newdriverhas become available.
4.Aconflict-resolutio mechanism allows different device drivers
to reserve hardware resources and to protect those resources from
accidental useby another driver.
20.3.1 Module Management
Loadingamodulerequiresmorethanjust loadingitsbinarycontentsintoker-
nel memory. The system must also make sure that any references the module
makestokernelsymbolsorentrypointsareupdatedtopointtothecorrectloca-
tionsinthekernel’saddressspace.Linuxdealswiththisreferenceupdatingby
splittingthejobofmoduleloadingintotwoseparatesections:themanagement
ofsectionsofmodulecodeinkernelmemoryandthehandlingofsymbolsthat
modulesareallowedto reference.
Linux maintains an internal symbol table in the kernel. This symbol table
doesnotcontainthefullsetofsymbolsdefinedinthekernelduringthelatter’s
compilation; rather, a symbol must be explicitlyexported.The set of exported
symbols constitutes a well-defined interface by which a module can interact
withthe kernel.
Although exporting symbols from a kernel function requires an explicit
requestbytheprogrammer,nospecialeffortisneededtoimportthosesymbols
into a module. Amodule writer just uses the standard external linking of the
C language. Any externalsymbols referencedby the module but not declared
byitaresimplymarkedasunresolvedinthefinalmodulebinaryproducedby
the compiler. When a module is to be loaded into the kernel, a system utility
first scans the module for these unresolved references. All symbols that still
needtoberesolvedarelookedupinthekernel’ssymboltable,andthecorrect
addressesofthosesymbolsinthecurrentlyrunningkernelaresubstitutedinto
themodule’scode.Onlythenisthemodulepassedtothekernelforloading.If
the systemutilitycannot resolveall referencesin themoduleby looking them
up inthe kernel’ssymbol table,thenthe moduleisrejected.
The loading of the module is performed in two stages. First, the module-
loader utility asks the kernel to reserve a continuous area of virtual kernel
memory for the module. The kernel returns the address of the memory allo-
cated, and the loader utility can use this address to relocate the module’s
machine codetothecorrectloadinga ddress.Asecondsystemcallthenpasses
the module, plus any symbol table that the new module wants to export, to
the kernel. The module itself is now copied verbatim into the previously allo-
cated space, and the kernel’s symbol table is updated with the new symbols
for possibleuseby othermodulesnot yetloaded.
The final module-management component is the module requester. The
kernel defines a communication interface to which a module-management
program can connect. With this connection established, the kernelwill inform
the management process whenever a process requests a device driver, file
system, or network service that is not currently loaded and will give the
managertheopportunitytoloadthatser vice.Theoriginalservicerequestwill
completeoncethemoduleisloaded.Themanagerprocessregularlyqueriesthe
kerneltoseewhetheradynamicallyloadedmoduleisstillinuseandunloads
that modulewhenitisno longeractivelyneeded."
3,20.3.2 Driver Registration,925,20.3.1 Module Management,"20.3 Kernel Modules 785
20.3.2 Driver Registration
Onceamoduleisloaded,itremainsnomorethananisolatedregionofmemory
until it lets the rest of the kernel know what new functionality it provides.
The kernel maintains dynamic tables of all known drivers and provides a
set of routines to allow drivers to be added to or removed from these tables
at any time. The kernel makes sure that it calls a module’s startup routine
when that module is loaded and calls th e module’s cleanup routine before
that module is unloaded. These routines are responsible for registering the
module’sfunctionality.
A module may register many types of functionality; it is not limited to
only one type. For example, a device driver might want to register two sep-
aratemechanismsforaccessingthedevice.Registrationtablesinclude,among
others, the following items:
•Device drivers . These drivers include character devices (such as print-
ers, terminals, and mice), block devi ces (including all disk drives), and
network interfacedevices.
•File systems . The file system may be anything that implements Linux’s
virtualfilesystemcallingroutines.Itmightimplementaformatforstoring
files on a disk, but it might equally well be a network file system, such as
NFS,oravirtualfilesystemwhosecontentsaregeneratedondemand,such
as Linux’s /procfilesystem.
•Network protocols .Amodulemayimplementanentirenetworkingproto-
col,suchas TCP,orsimplyanewsetofpacket-filteringrulesforanetwork
firewall.
•Binary format . This format specifies a way of recognizing, loading, and
executinga newtypeof executablefile.
Inaddition,amodulecanregisteranewsetofentriesinthe sysctland/proc
tables,to allow that moduleto be configured dynamically (Section20.7.4).
20.3.3 Conﬂict Resolution
Commercial UNIXimplementationsareusuallysoldtorunonavendor’sown
hardware. One advantage of a single-supplier solution is that the software
vendor has a good idea about what hardware configurations are possible. PC
hardware,however,comesinavastnumberofconfigurations,withlargenum-
bers of possible drivers for devices such as network cards and video display
adapters.Theproblemofmanagingthehardwareconfigurationbecomesmore
severe when modular device drivers are supported, since the currently active
setof devicesbecomesdynamically variable.
Linux provides a central conflict-resolution mechanism to help arbitrate
access tocertain hardwareresources.Itsaims areasfollows:
•To preventmodulesfrom clashing overaccess to hardwareresources
•Toprevent autoprobes —device-driverprobesthatauto-detectdevicecon-
figuration—from interferingwithexistingdevicedrivers"
3,20.3.3 Conflict Resolution,925,20.3.2 Driver Registration,"20.3 Kernel Modules 785
20.3.2 Driver Registration
Onceamoduleisloaded,itremainsnomorethananisolatedregionofmemory
until it lets the rest of the kernel know what new functionality it provides.
The kernel maintains dynamic tables of all known drivers and provides a
set of routines to allow drivers to be added to or removed from these tables
at any time. The kernel makes sure that it calls a module’s startup routine
when that module is loaded and calls th e module’s cleanup routine before
that module is unloaded. These routines are responsible for registering the
module’sfunctionality.
A module may register many types of functionality; it is not limited to
only one type. For example, a device driver might want to register two sep-
aratemechanismsforaccessingthedevice.Registrationtablesinclude,among
others, the following items:
•Device drivers . These drivers include character devices (such as print-
ers, terminals, and mice), block devi ces (including all disk drives), and
network interfacedevices.
•File systems . The file system may be anything that implements Linux’s
virtualfilesystemcallingroutines.Itmightimplementaformatforstoring
files on a disk, but it might equally well be a network file system, such as
NFS,oravirtualfilesystemwhosecontentsaregeneratedondemand,such
as Linux’s /procfilesystem.
•Network protocols .Amodulemayimplementanentirenetworkingproto-
col,suchas TCP,orsimplyanewsetofpacket-filteringrulesforanetwork
firewall.
•Binary format . This format specifies a way of recognizing, loading, and
executinga newtypeof executablefile.
Inaddition,amodulecanregisteranewsetofentriesinthe sysctland/proc
tables,to allow that moduleto be configured dynamically (Section20.7.4).
20.3.3 Conﬂict Resolution
Commercial UNIXimplementationsareusuallysoldtorunonavendor’sown
hardware. One advantage of a single-supplier solution is that the software
vendor has a good idea about what hardware configurations are possible. PC
hardware,however,comesinavastnumberofconfigurations,withlargenum-
bers of possible drivers for devices such as network cards and video display
adapters.Theproblemofmanagingthehardwareconfigurationbecomesmore
severe when modular device drivers are supported, since the currently active
setof devicesbecomesdynamically variable.
Linux provides a central conflict-resolution mechanism to help arbitrate
access tocertain hardwareresources.Itsaims areasfollows:
•To preventmodulesfrom clashing overaccess to hardwareresources
•Toprevent autoprobes —device-driverprobesthatauto-detectdevicecon-
figuration—from interferingwithexistingdevicedrivers"
2,20.4 Process Management,926,20.3 Kernel Modules,"786 Chapter 20 The Linux System
•To resolve conflicts among multiple drivers trying to access the same
hardware—as,forexample,whenboththeparallelprinterdriverandthe
parallelline IP(PLIP) network drivertry totalkto theparallelport
To these ends, the kernel maintains lists of allocated hardware resources.
ThePChas a limited number of possible I/Oports (addresses in its hardware
I/Oaddressspace),interruptlines,and DMAchannels.Whenanydevicedriver
wants to access such a resource, it is expected to reserve the resource with the
kernel database first. This requirement incidentally allows the system admin-
istrator to determine exactly which resources have been allocated by which
driveratany givenpoint.
A module is expected to use this mechanism to reserve in advance any
hardwareresourcesthat itexpectstouse.Ifthereservationisrejectedbecause
the resource is not present or is already in use, then it is up to the module
to decide how to proceed. It may fail in its initialization attempt and request
that it be unloaded if it cannot continue, or it may carry on, using alternative
hardware resources.
20.4 Process Management
A process is the basic context in which all user-requested activity is serviced
withintheoperatingsystem.Tobecompatiblewithother UNIXsystems,Linux
must use a process model similar to those of other versions of UNIX.L i n u x
operates differently from UNIXin a few key places, however. In this section,
we review the traditional UNIXprocess model (Section C.3.2) and introduce
Linux’s threadingmodel.
20.4.1 The fork() and exec() Process Model
The basic principle of UNIXprocess management is to separate into two steps
two operations that are usually comb ined into one: the creation of a new
process and the running of a new program. A new process is created by the
fork()systemcall,andanewprogramisrunafteracallto exec().Theseare
two distinctly separate functions. We can create a new process with fork()
without running a new program—the new subprocess simply continues to
execute exactly the same program, at exactly the same point, that the first
(parent) process was running. In the same way, running a new program does
notrequirethatanewprocessbecreatedfirst.Anyprocessmaycall exec()at
any time. Anew binary object is loaded into the process’s address space and
thenewexecutablestartsexecutinginthe contextof the existingprocess.
This model has the advantage of great simplicity. It is not necessary to
specifyeverydetailoftheenvironmentofanewprograminthesystemcallthat
runsthatprogram.Thenewprogramsimplyrunsinitsexistingenvironment.
Ifaparentprocesswishestomodifytheenvironmentinwhichanewprogram
istoberun,itcanforkandthen,stillrunningtheoriginalexecutableinachild
process, make any system calls it requir es to modify that child process before
finally executingthe new program.
Under UNIX, then, a process encompasses all the information that the
operating system must maintain to track the context of a single execution of a"
3,20.4.1 The fork() and exec() Process Model,926,20.4 Process Management,"786 Chapter 20 The Linux System
•To resolve conflicts among multiple drivers trying to access the same
hardware—as,forexample,whenboththeparallelprinterdriverandthe
parallelline IP(PLIP) network drivertry totalkto theparallelport
To these ends, the kernel maintains lists of allocated hardware resources.
ThePChas a limited number of possible I/Oports (addresses in its hardware
I/Oaddressspace),interruptlines,and DMAchannels.Whenanydevicedriver
wants to access such a resource, it is expected to reserve the resource with the
kernel database first. This requirement incidentally allows the system admin-
istrator to determine exactly which resources have been allocated by which
driveratany givenpoint.
A module is expected to use this mechanism to reserve in advance any
hardwareresourcesthat itexpectstouse.Ifthereservationisrejectedbecause
the resource is not present or is already in use, then it is up to the module
to decide how to proceed. It may fail in its initialization attempt and request
that it be unloaded if it cannot continue, or it may carry on, using alternative
hardware resources.
20.4 Process Management
A process is the basic context in which all user-requested activity is serviced
withintheoperatingsystem.Tobecompatiblewithother UNIXsystems,Linux
must use a process model similar to those of other versions of UNIX.L i n u x
operates differently from UNIXin a few key places, however. In this section,
we review the traditional UNIXprocess model (Section C.3.2) and introduce
Linux’s threadingmodel.
20.4.1 The fork() and exec() Process Model
The basic principle of UNIXprocess management is to separate into two steps
two operations that are usually comb ined into one: the creation of a new
process and the running of a new program. A new process is created by the
fork()systemcall,andanewprogramisrunafteracallto exec().Theseare
two distinctly separate functions. We can create a new process with fork()
without running a new program—the new subprocess simply continues to
execute exactly the same program, at exactly the same point, that the first
(parent) process was running. In the same way, running a new program does
notrequirethatanewprocessbecreatedfirst.Anyprocessmaycall exec()at
any time. Anew binary object is loaded into the process’s address space and
thenewexecutablestartsexecutinginthe contextof the existingprocess.
This model has the advantage of great simplicity. It is not necessary to
specifyeverydetailoftheenvironmentofanewprograminthesystemcallthat
runsthatprogram.Thenewprogramsimplyrunsinitsexistingenvironment.
Ifaparentprocesswishestomodifytheenvironmentinwhichanewprogram
istoberun,itcanforkandthen,stillrunningtheoriginalexecutableinachild
process, make any system calls it requir es to modify that child process before
finally executingthe new program.
Under UNIX, then, a process encompasses all the information that the
operating system must maintain to track the context of a single execution of a"
3,20.4.2 Processes and Threads,929,20.4.1 The fork() and exec() Process Model,"20.4 Process Management 789
•Signal-handler table .UNIXsystemscandeliverasynchronoussignalstoa
process in response to various external events. The signal-handler table
defines the action to take in response to a specific signal. Valid actions
include ignoring the signal, termina ting the process, and invoking a rou-
tine inthe process’saddressspace.
•Virtual memory context . The virtual memory context describes the full
contentsofaprocess’sprivateaddressspace;wediscussitinSection20.6.
20.4.2 Processes and Threads
Linux provides the fork()system call, which duplicates a process without
loading a new executable image. Linux also provides the ability to create
threads via the clone() system call. Linux does not distinguish betweenpro-
cesses and threads, however. In fact, Linux generally uses the term task—
rather than processorthread—when referring to a flow of control within a
program. The clone() system call behaves identically to fork(),e x c e p tt h a t
it accepts as arguments a set of flags that dictate what resources are shared
between the parent and child (whereas a process created with fork()shares
no resourceswith itsparent).The flagsinclude:
flag meaning
CLONE_FS
CLONE_VM
CLONE_SIGHAND
CLONE_FILESFile-system information is shared.
The same memory space is shared.
Signal handlers are shared.
The set of open files is shared.
Thus,if clone() ispassedtheflags CLONE
 FS,CLONE
 VM,CLONE
 SIGHAND ,
andCLONE
 FILES, the parent and child tasks will share the same file-system
information (such as the current working directory), the same memory space,
thesamesignalhandlers,andthesamesetofopenfiles.Using clone() inthis
fashionisequivalenttocreatingathreadinothersystems,sincetheparenttask
sharesmostofitsresourceswithitschildtask.Ifnoneoftheseflagsissetwhen
clone() isinvoked,however,theassociatedresourcesarenotshared,resulting
infunctionality similarto that of the fork()systemcall.
The lack of distinction between processes and threads is possible because
Linux does not hold a process’s entire context within the main process data
structure. Rather, it holds the context within independent subcontexts. Thus,
a process’s file-system context, file-descri ptor table, signal-handler table, and
virtual memory context are held in separate data structures. The process data
structuresimply contains pointers to these other structures,so any number of
processescaneasilyshareasubcontextbypointingtothesamesubcontextand
incrementinga referencecount.
Theargumentstothe clone() systemcalltellitwhichsubcontextstocopy
andwhichtoshare.Thenewprocessisalwaysgivenanewidentityandanew
scheduling context—these are the essent ials of a Linux process. According to
the arguments passed, however, the kernel may either create new subcontext
data structures initialized so as to be copies of the parent’s or set up the new
process to use the same subcontext data structures being used by the parent."
2,20.5 Scheduling,930,20.4 Process Management,"790 Chapter 20 The Linux System
Thefork()system call is nothing more than a special case of clone() that
copiesallsubcontexts, sharing none.
20.5 Scheduling
Schedulingisthejobofallocating CPUtimetodifferenttaskswithinanoperat-
ing system. Linux, like all UNIXsystems, supports preemptive multitasking .
In such a system, the process scheduler decideswhich thread runs and when.
Makingthesedecisionsinawaythatbalancesfairnessandperformanceacross
manydifferentworkloadsisoneofthemorecomplicatedchallengesinmodern
operatingsystems.
Normally, we think of scheduling as the running and interrupting of user
threads, but another aspect of scheduling is also important in Linux: the run-
ning of the various kernel tasks. Kernel tasks encompass both tasks that are
requested by a running thread and tasks that execute internally on behalf of
the kernelitself,such astasks spawned by Linux’s I/Osubsystem.
20.5.1 Thread Scheduling
Linux has two separate process-scheduling algorithms. One is a time-sharing
algorithm for fair, preemptive schedu ling among multiple threads. The other
is designed for real-time tasks, where absolute priorities are more important
than fairness.
The scheduling algorithm used for routine time-sharing tasks received a
major overhaul with version 2.6 of the kernel. Earlier versions ran a variation
ofthetraditional UNIXschedulingalgorithm.Thisalgorithmdoesnotprovide
adequatesupportfor SMPsystems,doesnotscalewellasthenumberoftaskson
thesystemgrows,anddoesnotmaintain fairnessamonginteractivetasks,par-
ticularlyonsystemssuchasdesktopsandmobiledevices.Thethreadscheduler
wasfirstoverhauledwithversion2.5ofthekernel.Version2.5implementeda
scheduling algorithm that selects which task to run in constant time—known
asO(1)—regardless of the number of tasks or processors in the system. The
new scheduler also provided increased support for SMP, including processor
affinityandloadbalancing.Thesechanges,whileimprovingscalability,didnot
improve interactive performance or fairness—and, in fact, made these prob-
lemsworse undercertain workloads. Consequently,the thread schedulerwas
overhauledasecondtime,withLinuxkernelversion2.6.Thisversionushered
inthe Completely Fair Scheduler (CFS).
The Linux scheduler is a preemptive, priority-based algorithm with two
separate priority ranges: a real-time range from 0 to 99 and a nice value
ranging from −20 to 19. Smaller nicevalues indicate higher priorities. Thus,
byincreasingthe nicevalue,youaredecreasingyourpriorityandbeing “nice ”
to therestof thesystem.
CFSis a significant departure from the traditional UNIXprocess scheduler.
In the latter, the core variables in the scheduling algorithm are priority and
time slice. The time slice is the length of time—the sliceof the processor
—that a thread is afforded. Traditional UNIXsystems give processes a fixed
timeslice,perhapswithaboost orpenaltyforhigh-orlow-priorityprocesses,"
3,20.5.1 Thread Scheduling,930,20.5 Scheduling,"790 Chapter 20 The Linux System
Thefork()system call is nothing more than a special case of clone() that
copiesallsubcontexts, sharing none.
20.5 Scheduling
Schedulingisthejobofallocating CPUtimetodifferenttaskswithinanoperat-
ing system. Linux, like all UNIXsystems, supports preemptive multitasking .
In such a system, the process scheduler decideswhich thread runs and when.
Makingthesedecisionsinawaythatbalancesfairnessandperformanceacross
manydifferentworkloadsisoneofthemorecomplicatedchallengesinmodern
operatingsystems.
Normally, we think of scheduling as the running and interrupting of user
threads, but another aspect of scheduling is also important in Linux: the run-
ning of the various kernel tasks. Kernel tasks encompass both tasks that are
requested by a running thread and tasks that execute internally on behalf of
the kernelitself,such astasks spawned by Linux’s I/Osubsystem.
20.5.1 Thread Scheduling
Linux has two separate process-scheduling algorithms. One is a time-sharing
algorithm for fair, preemptive schedu ling among multiple threads. The other
is designed for real-time tasks, where absolute priorities are more important
than fairness.
The scheduling algorithm used for routine time-sharing tasks received a
major overhaul with version 2.6 of the kernel. Earlier versions ran a variation
ofthetraditional UNIXschedulingalgorithm.Thisalgorithmdoesnotprovide
adequatesupportfor SMPsystems,doesnotscalewellasthenumberoftaskson
thesystemgrows,anddoesnotmaintain fairnessamonginteractivetasks,par-
ticularlyonsystemssuchasdesktopsandmobiledevices.Thethreadscheduler
wasfirstoverhauledwithversion2.5ofthekernel.Version2.5implementeda
scheduling algorithm that selects which task to run in constant time—known
asO(1)—regardless of the number of tasks or processors in the system. The
new scheduler also provided increased support for SMP, including processor
affinityandloadbalancing.Thesechanges,whileimprovingscalability,didnot
improve interactive performance or fairness—and, in fact, made these prob-
lemsworse undercertain workloads. Consequently,the thread schedulerwas
overhauledasecondtime,withLinuxkernelversion2.6.Thisversionushered
inthe Completely Fair Scheduler (CFS).
The Linux scheduler is a preemptive, priority-based algorithm with two
separate priority ranges: a real-time range from 0 to 99 and a nice value
ranging from −20 to 19. Smaller nicevalues indicate higher priorities. Thus,
byincreasingthe nicevalue,youaredecreasingyourpriorityandbeing “nice ”
to therestof thesystem.
CFSis a significant departure from the traditional UNIXprocess scheduler.
In the latter, the core variables in the scheduling algorithm are priority and
time slice. The time slice is the length of time—the sliceof the processor
—that a thread is afforded. Traditional UNIXsystems give processes a fixed
timeslice,perhapswithaboost orpenaltyforhigh-orlow-priorityprocesses,"
3,20.5.2 Real-Time Scheduling,932,20.5.1 Thread Scheduling,"792 Chapter 20 The Linux System
20.5.2 Real-Time Scheduling
Linux’s real-time scheduling algorithm is significantly simpler than the fair
scheduling employed for standard time-sharing threads. Linux implements
the two real-time scheduling classes required by POSIX.1b: first-come, first-
served ( FCFS) and round-robin (Section 5.3.1 and Section 5.3.3, respectively).
Inbothcases,eachthreadhasapriority inadditiontoitsschedulingclass.The
scheduler always runs the thread with the highest priority. Among threads of
equalpriority,itrunsthethreadthathasbeenwaitinglongest.Theonlydiffer-
ence between FCFSand round-robin scheduling is that FCFSthreads continue
to run until they either exit or block, whereas a round-robin thread will be
preemptedafterawhileandwillbemovedtotheendoftheschedulingqueue,
so round-robin threads of equal priority will automatically time-share among
themselves.
Linux’s real-time scheduling is soft—rather than hard—real time. The
scheduler offers strict guarantees about the relative priorities of real-time
threads,butthekerneldoesnotofferanyguaranteesabouthowquicklyareal-
time thread willbe scheduledonce that thread becomes runnable. In contrast,
a hard real-time system can guarantee a minimum latency between when a
thread becomesrunnable and when itactuallyruns.
20.5.3 Kernel Synchronization
The way the kernel schedules its own operations is fundamentally different
from the way it schedules threads. A request for kernel-mode execution can
occur in two ways. A running program may request an operating-system
service, either explicitly via a system call or implicitly—for example, when
a page fault occurs. Alternatively, a device controller may deliver a hardware
interrupt that causes the CPUto start executing a kernel-defined handler for
that interrupt.
Theproblemforthekernelisthatallthesetasksmaytrytoaccessthesame
internal data structures. If one kernel task is in the middle of accessing some
data structure when an interrupt service routine executes, then that service
routinecannotaccessormodifythesamedatawithoutriskingdatacorruption.
This fact relates to the idea of critical sections—portions of code that access
shareddataandthusmustnotbeallowedtoexecuteconcurrently.Asaresult,
kernel synchronization involves much more than just thread scheduling. A
framework is required that allows kernel tasks to run without violating the
integrityofshareddata.
Prior to version 2.6, Linux was a nonpreemptive kernel, meaning that a
thread running in kernel mode could not be preempted—even if a higher-
priority thread became available to run. With version 2.6, the Linux kernel
became fully preemptive. Now, a task can be preempted when it is running
inthekernel.
The Linux kernel provides spinlocks and semaphores (as well as reader–
writerversionsofthesetwolocks)forlockinginthekernel.On SMPmachines,
thefundamentallockingmechanismisas pinlock,andthekernelisdesignedso
thatspinlocksareheldforonlyshortdurations.Onsingle-processormachines,
spinlocks are not appropriate for use and are replaced by enabling and dis-
ablingkernelpreemption.Thatis,ratherthanholdingaspinlock,thetaskdis-"
3,20.5.3 Kernel Synchronization,932,20.5.2 Real-Time Scheduling,"792 Chapter 20 The Linux System
20.5.2 Real-Time Scheduling
Linux’s real-time scheduling algorithm is significantly simpler than the fair
scheduling employed for standard time-sharing threads. Linux implements
the two real-time scheduling classes required by POSIX.1b: first-come, first-
served ( FCFS) and round-robin (Section 5.3.1 and Section 5.3.3, respectively).
Inbothcases,eachthreadhasapriority inadditiontoitsschedulingclass.The
scheduler always runs the thread with the highest priority. Among threads of
equalpriority,itrunsthethreadthathasbeenwaitinglongest.Theonlydiffer-
ence between FCFSand round-robin scheduling is that FCFSthreads continue
to run until they either exit or block, whereas a round-robin thread will be
preemptedafterawhileandwillbemovedtotheendoftheschedulingqueue,
so round-robin threads of equal priority will automatically time-share among
themselves.
Linux’s real-time scheduling is soft—rather than hard—real time. The
scheduler offers strict guarantees about the relative priorities of real-time
threads,butthekerneldoesnotofferanyguaranteesabouthowquicklyareal-
time thread willbe scheduledonce that thread becomes runnable. In contrast,
a hard real-time system can guarantee a minimum latency between when a
thread becomesrunnable and when itactuallyruns.
20.5.3 Kernel Synchronization
The way the kernel schedules its own operations is fundamentally different
from the way it schedules threads. A request for kernel-mode execution can
occur in two ways. A running program may request an operating-system
service, either explicitly via a system call or implicitly—for example, when
a page fault occurs. Alternatively, a device controller may deliver a hardware
interrupt that causes the CPUto start executing a kernel-defined handler for
that interrupt.
Theproblemforthekernelisthatallthesetasksmaytrytoaccessthesame
internal data structures. If one kernel task is in the middle of accessing some
data structure when an interrupt service routine executes, then that service
routinecannotaccessormodifythesamedatawithoutriskingdatacorruption.
This fact relates to the idea of critical sections—portions of code that access
shareddataandthusmustnotbeallowedtoexecuteconcurrently.Asaresult,
kernel synchronization involves much more than just thread scheduling. A
framework is required that allows kernel tasks to run without violating the
integrityofshareddata.
Prior to version 2.6, Linux was a nonpreemptive kernel, meaning that a
thread running in kernel mode could not be preempted—even if a higher-
priority thread became available to run. With version 2.6, the Linux kernel
became fully preemptive. Now, a task can be preempted when it is running
inthekernel.
The Linux kernel provides spinlocks and semaphores (as well as reader–
writerversionsofthesetwolocks)forlockinginthekernel.On SMPmachines,
thefundamentallockingmechanismisas pinlock,andthekernelisdesignedso
thatspinlocksareheldforonlyshortdurations.Onsingle-processormachines,
spinlocks are not appropriate for use and are replaced by enabling and dis-
ablingkernelpreemption.Thatis,ratherthanholdingaspinlock,thetaskdis-"
3,20.5.4 Symmetric Multiprocessing,934,20.5.3 Kernel Synchronization,"794 Chapter 20 The Linux System
cuting, then that interrupt can request that the same bottom half execute, but
theexecutionwillbedeferreduntiltheonecurrentlyrunningcompletes.Each
execution of the bottom half can be interruptedby a top half but can never be
interruptedby a similarbottom half.
The top-half/bottom-half architecture is completed by a mechanism for
disabling selected bottom halves while executing normal, foreground kernel
code. The kernel can code critical sections easily using this system. Interrupt
handlers can code their critical sections as bottom halves; and when the fore-
ground kernel wants to enter a critical section, it can disable any relevant
bottom halves to prevent any other critical sections from interrupting it. At
the end of the critical section, the ke rnel can reenable the bottom halves and
runanybottom-halftasksthathavebeenqueuedbytop-halfinterruptservice
routinesduringthe criticalsection.
Figure 20.2 summarizes the various levels of interrupt protection within
thekernel.Eachlevelmaybeinterruptedbycoderunningatahigherlevelbut
willneverbeinterruptedbycoderunningatthesameoralowerlevel.Except
for user-mode code, user threads can always be preemptedby another thread
when atime-sharing schedulinginterruptoccurs.
20.5.4 Symmetric Multiprocessing
The Linux 2.0 kernel was the first stable Linux kernel to support symmetric
multiprocessor (SMP) hardware, allowing separate threads to execute in par-
allel on separate processors. The original implementation of SMPimposed the
restrictionthat only one processor ata time could be executingkernelcode.
In version 2.2 of the kernel, a single kernel spinlock (sometimes termed
BKLfor“big kernel lock ”) was created to allow multiple threads (running on
different processors) to be active in the kernel concurrently. However, the BKL
providedaverycoarseleveloflockinggranularity,resultinginpoorscalability
to machines with many processors and threads. Later releases of the kernel
made the SMPimplementation more scalable by splitting this single kernel
spinlock into multiple locks, each of which protects only a small subset of the
kernel’sdatastructures.Such spinl ocksweredescribedinSection20.5.3.
The3.0and4.0kernelsprovidedadditionalSMPenhancements,including
ever-finer locking, processor affinity, load-balancing algorithms, and support
for hundredsoreventhousands of physical processorsinasinglesystem.
top-half interrupt handlers
bottom-half interrupt handlers
kernel-system service routines (preemptible)
user-mode programs (preemptible)
increasing priority
Figure 20.2 Interrupt protection levels."
2,20.6 Memory Management,935,20.5 Scheduling,"20.6 Memory Management 795
20.6 Memory Management
Memory management under Linux has two components. The first deals with
allocating and freeing physical memory—pages, groups of pages, and small
blocksof RAM.Thesecondhandlesvirtualmemory,whichismemory-mapped
into the address space of running processes. In this section, we describe these
two components and then examine the mechanisms by which the loadable
components of a new program are brought into a process’s virtual memory
inresponseto an exec()systemcall.
20.6.1 Management of Physical Memory
Due to specific hardware constraints, Linux separates physical memory into
fourdifferent zones,o rr e g i o n s :
•ZONE
 DMA
•ZONE
 DMA32
•ZONE
 NORMAL
•ZONE
 HIGHMEM
These zones are architecture specific. For example, on the Intel x86-32
architecture, certain ISA(industry standard architecture) devices can only
access the lower 16- MBof physical memory using DMA. On thesesystems,the
first 16- MBof physical memorycomprise ZONE
 DMA.On other systems,certain
devices can only access the first 4- GBof physical memory, despite supporting
64-bitaddresses.Onsuchsystems,thefirst4 GBofphysicalmemorycomprise
ZONE
 DMA32.ZONE
 HIGHMEM (for “high memory ”) refers to physical memory
that is not mapped into the kernel address space. For example, on the 32-bit
Intel architecture (where 232provides a 4- GBaddress space), the kernel is
mapped into the first 896 MBof the address space; the remaining memory
is referred to as high memory a n di sa l l o c a t e df r o m ZONE
 HIGHMEM . Finally,
ZONE
 NORMAL comprises everything else—the normal, regularly mapped
pages.Whetheran architecturehas agivenzone dependson itsconstraints. A
modern, 64-bit architecture such as Intel x86-64 has a small 16- MBZONE
 DMA
(for legacy devices) and all the rest of its memory in ZONE
 NORMAL,w i t hn o
“highmemory ”.
TherelationshipofzonesandphysicaladdressesontheIntelx86-32archi-
tecture is shown in Figure 20.3. The kernel maintains a list of free pages for
zone physical memory
< 16 MB
16 .. 896 MB
> 896  MBZONE_DMA
ZONE_NORMAL
ZONE_HIGHMEM
Figure 20.3 Relationship of zones and physical addresses in Intel x86-32."
3,20.6.1 Management of Physical Memory,935,20.6 Memory Management,"20.6 Memory Management 795
20.6 Memory Management
Memory management under Linux has two components. The first deals with
allocating and freeing physical memory—pages, groups of pages, and small
blocksof RAM.Thesecondhandlesvirtualmemory,whichismemory-mapped
into the address space of running processes. In this section, we describe these
two components and then examine the mechanisms by which the loadable
components of a new program are brought into a process’s virtual memory
inresponseto an exec()systemcall.
20.6.1 Management of Physical Memory
Due to specific hardware constraints, Linux separates physical memory into
fourdifferent zones,o rr e g i o n s :
•ZONE
 DMA
•ZONE
 DMA32
•ZONE
 NORMAL
•ZONE
 HIGHMEM
These zones are architecture specific. For example, on the Intel x86-32
architecture, certain ISA(industry standard architecture) devices can only
access the lower 16- MBof physical memory using DMA. On thesesystems,the
first 16- MBof physical memorycomprise ZONE
 DMA.On other systems,certain
devices can only access the first 4- GBof physical memory, despite supporting
64-bitaddresses.Onsuchsystems,thefirst4 GBofphysicalmemorycomprise
ZONE
 DMA32.ZONE
 HIGHMEM (for “high memory ”) refers to physical memory
that is not mapped into the kernel address space. For example, on the 32-bit
Intel architecture (where 232provides a 4- GBaddress space), the kernel is
mapped into the first 896 MBof the address space; the remaining memory
is referred to as high memory a n di sa l l o c a t e df r o m ZONE
 HIGHMEM . Finally,
ZONE
 NORMAL comprises everything else—the normal, regularly mapped
pages.Whetheran architecturehas agivenzone dependson itsconstraints. A
modern, 64-bit architecture such as Intel x86-64 has a small 16- MBZONE
 DMA
(for legacy devices) and all the rest of its memory in ZONE
 NORMAL,w i t hn o
“highmemory ”.
TherelationshipofzonesandphysicaladdressesontheIntelx86-32archi-
tecture is shown in Figure 20.3. The kernel maintains a list of free pages for
zone physical memory
< 16 MB
16 .. 896 MB
> 896  MBZONE_DMA
ZONE_NORMAL
ZONE_HIGHMEM
Figure 20.3 Relationship of zones and physical addresses in Intel x86-32."
3,20.6.2 Virtual Memory,938,20.6.1 Management of Physical Memory,"798 Chapter 20 The Linux System
approximately 1.7 KBof memory. When the Linux kernel creates a new task,
itrequeststhenecessarymemoryforthe struct task
 structobjectfromits
cache. The cache will fulfill the request using a struct task
 structobject
that has alreadybeenallocatedinaslaband ismarkedasfree.
In Linux,a slabmay bein one of threepossiblestates:
1.Full.Allobjectsinthe slabaremarkedas used.
2.Empty.Allobjects intheslab aremarkedas free.
3.Partial.The slab consists ofboth used and free objects.
The slab allocator first attempts to satisfy the request with a free object in a
partial slab. If none exists, a free object is assigned from an empty slab. If no
empty slabs are available, a new slab is allocated from contiguous physical
pages and assigned to a cache; memory for the object is allocated from this
slab.
TwoothermainsubsystemsinLinuxdotheirownmanagementofphysical
pages: the page cache and the virtual memory system. These systems are
closelyrelatedtoeachother.The page cache isthekernel’smaincacheforfiles
andisthemainmechanismthroughwhich I/Otoblockdevices(Section20.8.1)
is performed. File systems of all types, including the native Linux disk-based
file systems and the NFSnetworked file system, perform their I/Othrough
the page cache. The page cache stores entire pages of file contents and is not
limitedtoblockdevices.Itcanalsocachenetworkeddata.Thevirtualmemory
system manages the contents of each process’s virtual address space. These
two systems interact closely with each other because reading a page of data
intothepagecacherequiresmappingpagesinthepagecacheusingthevirtual
memorysystem.Inthefollowingsection,welookatthevirtualmemorysystem
ingreaterdetail.
20.6.2 Virtual Memory
The Linux virtual memory system is resp onsible for maintaining the address
spaceaccessibletoeachprocess.Itcreatespagesofvirtualmemoryondemand
and manages loading those pages from disk and swapping them back out to
disk as required. Under Linux, the virtual memory manager maintains two
separateviewsofaprocess’saddressspace:asasetofseparateregionsandas
a setof pages.
The first view of an address space is the logical view, describing instruc-
tionsthatthevirtualmemorysystemhasreceivedconcerningthelayoutofthe
address space. In this view, the address space consists of a set of nonoverlap-
pingregions,eachregionrepresentingacontinuous,page-alignedsubsetofthe
addressspace.Eachregionisdes cribedinternallybyasingle vm
area
 struct
structurethatdefinesthepropertiesoftheregion,includingtheprocess’sread,
write, and executepermissions in the region as well as information about any
files associated with the region. The regions for each address space are linked
intoabalancedbinarytreetoallowfastlookupoftheregioncorrespondingto
any virtualaddress.
The kernel also maintains a second, physical view of each address space.
This view is stored in the hardware page tables for the process. The page-
tableentriesidentifytheexactcurrentlocationofeachpageofvirtualmemory,"
3,20.6.3 Execution and Loading of User Programs,941,20.6.2 Virtual Memory,"20.6 Memory Management 801
20.6.2.4 Kernel Virtual Memory
Linux reserves for its own internal use a constant, architecture-dependent
regionofthevirtualaddressspaceofeveryprocess.Thepage-tableentriesthat
map to these kernel pages are marked as protected, so that the pages are not
visible or modifiable when the processor is running in usermode. This kernel
virtualmemoryareacontainstworegions.Thefirstisastaticareathatcontains
page-tablereferencestoeveryavailablephysicalpageofmemoryinthesystem,
so that a simple translation from physical to virtual addresses occurs when
kernelcodeisrun.Thecoreofthekernel,alongwithallpagesallocatedbythe
normal page allocator,residesinthis region.
The remainder of the kernel’s reserved section of address space is not
reservedfor any specific purpose. Page-table entries in this addressrange can
be modified by the kernel to point to any other areas of memory. The kernel
provides a pair of facilities that allow kernel code to use this virtual memory.
Thevmalloc() function allocates an arbitrary number of physical pages of
memorythatmaynotbephysicallycontiguousintoasingleregionofvirtually
contiguouskernelmemory.The vremap() functionmapsasequenceofvirtual
addressesto point to an area of memory used by a devicedriverfor memory-
mapped I/O.
20.6.3 Execution and Loading of User Programs
The Linux kernel’s execution of user programs is triggered by a call to the
exec()system call. This exec()call commands the kernel to run a new pro-
gramwithinthecurrentprocess,completelyoverwritingthecurrentexecution
contextwiththeinitialcontextofthenewprogram.Thefirstjobofthissystem
service is to verify that the calling process has permission rights to the file
beingexecuted.Oncethatmatterhasbeen checked,thekernelinvokesaloader
routinetostartrunning the program.The loaderdoesnot necessarilyloadthe
contents of the program file into physical memory, but it does at least set up
themappingof the programinto virtualmemory.
There is no single routine in Linux for loading a new program. Instead,
Linux maintains a table of possible loader functions, and it gives each such
function the opportunity to try loading the given file when an exec()sys-
tem call is made. The initial reason for this loader table was that, between the
releasesof the 1.0 and 1.2 kernels, the s tandard format for Linux’s binary files
waschanged.OlderLinuxkernelsunderstoodthe a.outformatforbinaryfiles
—a relatively simple format common on older UNIXsystems. Newer Linux
systems use the more modern ELFformat, now supported by most current
UNIXimplementations. ELFhasanumberofadvantagesover a.out,including
flexibility and extendability. New sections can be added to an ELFbinary (for
example,toaddextradebugginginformation)withoutcausingtheloaderrou-
tinestobecomeconfused.Byallowingregistrationofmultipleloaderroutines,
Linuxcaneasilysupportthe ELFanda.outbinaryformatsinasinglerunning
system.
In Section 20.6.3.1 and Section 20.6. 3.2, we concentrate exclusively on the
loading and running of ELF-format binaries. The procedure for loading a.out
binariesissimplerbut similarinoperation."
2,20.7 File Systems,943,20.6 Memory Management,"20.7 File Systems 803
Directly beyond these fixed-sized regions is a variable-sized region that
programs can expand as needed to hold data allocated at run time. Each
processhas apointer, brk, thatpoints tothe currentextentofthis dataregion,
andprocessescanextendorcontracttheir brkregionwithasinglesystemcall
—sbrk().
Once these mappings have beensetup, th e loaderinitializesthe process’s
program-counter register with the starting point recorded in the ELFheader,
and the processcan be scheduled.
20.6.3.2 Static and Dynamic Linking
Once the program has been loaded and has started running, all the necessary
contents of the binary file have been loaded into the process’s virtual address
space. However, most programs also need to run functions from the system
libraries, and these library function s must also be loaded. In the simplest
case, the necessary library functions are embedded directly in the program’s
executable binary file. Such a program is statically linked to its libraries, and
staticallylinkedexecutablescancommencerunningassoonastheyareloaded.
The main disadvantage of static linking is that every program generated
mustcontaincopiesofexactlythesamecommonsystemlibraryfunctions.Itis
much more efficient, in terms of both physical memory and disk-space usage,
to load the system libraries into memo ry only once. Dynamic linking allows
thatto happen.
Linux implements dynamic linking in user mode through a special linker
library. Every dynamically linked progr am contains a small, statically linked
function that is called when the program starts. This static function just maps
thelinklibraryintomemoryandrunsthe codethatthefunctioncontains.The
linklibrarydeterminesthedynamiclib rariesrequiredbytheprogramandthe
namesofthevariablesandfunctionsneededfromthoselibrariesbyreadingthe
information contained in sections of the ELFbinary. It then maps the libraries
into the middle of virtual memory and resolves the references to the symbols
contained inthose libraries.Itdoesnot matterexactlywhere inmemorythese
shared libraries are mapped: they are compiled into position-independent
code(PIC), which can runat any addressinmemory.
20.7 File Systems
Linux retains UNIX’s standard file-systemmodel.In UNIX, a file does not have
to be an object stored on disk or fetched over a network from a remote file
server. Rather, UNIXfiles can be anything capable of handling the input or
outputofastreamofdata.Devicedriverscanappearasfiles,andinterprocess-
communication channels or network connections also look like files to the
user.
The Linux kernel handles all these types of files by hiding the implemen-
tation details of any single file type behind a layer of software, the virtual file
system ( VFS). Here, we first cover the virtual file system and then discuss the
standardLinuxfilesystem—ext3."
3,20.7.1 The Virtual File System,944,20.7 File Systems,"804 Chapter 20 The Linux System
20.7.1 The Virtual File System
The Linux VFSis designed around object-oriented principles. It has two com-
ponents: a set of definitions that speci fy what file-system objects are allowed
to look like and a layer of software to manipulate the objects. The VFSdefines
four main object types:
•Aninode object representsanindividualfile.
•Afil object representsanopenfile.
•Asuperblock object representsanentirefilesystem.
•Adentry object representsan individualdirectoryentry.
For each of these four object types, the VFSdefines a set of operations.
Every object of one of these types contains a pointer to a function table. The
function table lists the addresses of the actual functions that implement the
definedoperationsforthatobject.Forexample,anabbreviated APIforsomeof
thefile object’s operationsincludes:
•int open(. . .) —O p e nafi l e .
•ssize
 t read(. . .) — Read fromafile.
•ssize
 t write(. . .) — Writeto a file.
•int mmap(. . .) — Memory-mapafile.
The complete definition of the file object is specified in the struct
file
 operations , which is located in the file /usr/include/linux/fs.h .
An implementation of the file object (for a specific file type) is required to
implementeach function specified inthe definitionof the file object.
TheVFSsoftwarelayercan performan operationon oneof the file-system
objects by calling the appropriate function from the object’s function table,
without having to know in advance exactly what kind of object it is dealing
with.The VFSdoesnotknow,orcare,whetheraninoderepresentsanetworked
file, a disk file, a network socket, or a directory file. The appropriate function
forthatfile’s read()operationwillalwaysbeatthesameplaceinitsfunction
table,andthe VFSsoftwarelayerwillcallthatfunctionwithoutcaringhowthe
dataareactually read.
Theinodeandfileobjectsarethemechanismsusedtoaccessfiles.Aninode
objectisadatastructurecontainingpointerstothediskblocksthatcontainthe
actual file contents, and a file object represents a point of access to the data in
anopenfile.Athreadcannotaccessaninode’scontentswithoutfirstobtaining
afileobjectpointingtotheinode.Thefileobjectkeepstrackofwhereinthefile
theprocessiscurrentlyreadingorwriting,tokeeptrackofsequentialfile I/O.It
also remembers the permissions (for example, read or write) requested when
the file was opened and tracks the thread’s activity if necessary to perform
adaptiveread-ahead,fetchingfiledata intomemorybeforethethreadrequests
thedata,to improveperformance.
File objects typically belong to a single process, but inode objects do not.
There is one file object for every instance of an open file, but always only a"
3,20.7.2 The Linux ext3 File System,945,20.7.1 The Virtual File System,"20.7 File Systems 805
single inode object. Even when a file is no longer in use by any process, its
inode object may still be cached by the VFSto improve performance if the file
isusedagaininthenearfuture.Allcachedfiledataarelinkedontoalistinthe
file’s inode object. The inode also maintains standard information about each
file,such as theowner, size,and timemostrecentlymodified.
Directoryfilesaredealtwithslightlydifferentlyfromotherfiles.The UNIX
programming interface defines a number of operations on directories, such
as creating, deleting, and renaming a file in a directory. The system calls for
thesedirectoryoperationsdonotrequirethattheuseropenthefilesconcerned,
unlike the case for reading or writing data. The VFStherefore defines these
directoryoperationsin the inode obj ect, ratherthan inthe fileobject.
The superblock object represents a connected set of files that form a
self-contained file system. The operat ing-system kernel maintains a single
superblock object for each disk device mounted as a file system and for each
networked file system currently connected. The main responsibility of the
superblockobjectistoprovideaccesstoinodes.The VFSidentifieseveryinode
byauniquefile-system/inodenumberpair,anditfindstheinodecorrespond-
ingto aparticularinode number byasking the superblockobject toreturnthe
inodewith that number.
Finally,adentryobjectrepresentsad irectoryentry,whichmayincludethe
name of a directory in the path name of a file (such as /usr) or the actual file
(suchas stdio.h ).Forexample,the file /usr/include/stdio.h contains the
directory entries (1) /,( 2 ) usr,( 3 ) include ,a n d( 4 ) stdio.h .E a c ho ft h e s e
valuesisrepresentedby a separatedentryobject.
As an example of how dentry objects are used, consider the situ-
ation in which a thread wishes to open the file with the pathname
/usr/include/stdio.h using an editor. Because Linux treats directory
names as files, translating this path requires first obtaining the inode for the
root— /. The operating system must then read through this file to obtain
the inode for the file include . It must continue this thread until it obtains
the inode for the file stdio.h . Because path-name translation can be a
time-consuming task, Linux maintains a cache of dentry objects, which is
consulted during path-name translation. Obtaining the inode from the dentry
cache isconsiderably fasterthan having to readthe on-diskfile.
20.7.2 The Linux ext3 File System
The standard on-disk file system used by Linux is called ext3, for historical
reasons. Linux was originally programmed with a Minix-compatible file sys-
tem,toeaseexchangingdatawiththeMinixdevelopmentsystem,butthatfile
systemwasseverelyrestrictedby14-characterfile-namelimitsandamaximum
file-system size of 64- MB. The Minix file system was superseded by a new file
system,whichwaschristenedthe extended file system (extfs).Alaterredesign
to improve performance and scalability and to add a few missing featuresled
tothe second extended file system (ext2).Furtherdevelopmentaddedjournal-
ing capabilities, and the system was renamed the third extended file system
(ext3). Linux kernel developers then augmented ext3 with modern file-system
featuressuchasextents.Thisnewfilesystemiscalledthe fourth extended file
system(ext4). The rest of this section discusses ext3, however, since it remains"
3,20.7.3 Journaling,948,20.7.2 The Linux ext3 File System,"808 Chapter 20 The Linux System
20.7.3 Journaling
The ext3 file system supports a popular feature called journaling ,w h e r e b y
modifications to the file system are written sequentially to a journal. Aset of
operations that performs a specific task is a transaction .O n c eat r a n s a c t i o n
is written to the journal, it is considered to be committed. Meanwhile, the
journal entries relating to the transaction are replayed across the actual file-
system structures. As the changes are made, a pointer is updated to indicate
which actions have completed and whic h are still incomplete.When an entire
committed transaction is completed, it is removed from the journal. The jour-
nal, which is actually a circular buffer, may be in a separate section of the file
system, or it may even be on a separate disk spindle. It is more efficient, but
morecomplex,tohaveitunderseparateread–writeheads,therebydecreasing
headcontention and seektimes.
If the system crashes, some transactions may remain in the journal. Those
transactions were never completed to the file system even though they were
committedbytheoperatingsystem,sotheymustbecompletedoncethesystem
recovers. The transactions can be executed from the pointer until the work is
complete, and the file-system structures remain consistent. The only problem
occurs when a transaction has been aborted—that is, it was not committed
before the system crashed. Any changes from those transactions that were
applied to the file system must be undone, again preserving the consistency
of the file system. This recovery is all that is needed after a crash, eliminating
allproblemswithconsistency checking.
Journalingfilesystemsmayperformsomeoperationsfasterthannonjour-
naling systems, as updates proceed much faster when they are applied to the
in-memoryjournalratherthandirectlytotheon-diskdatastructures.Therea-
sonforthisimprovementisfoundintheperformanceadvantageofsequential
I/Oover random I/O. Costly synchronous random writes to the file system
are turned into much less costly synchronous sequential writes to the file sys-
tem’sjournal.Thosechanges,inturn,a rereplayedasynchronouslyviarandom
writes to the appropriate structures. The overall result is a significant gain in
performanceoffile-systemmetadata-ori entedoperations,such asfilecreation
anddeletion.Duetothisperformanceimprovement,ext3canbeconfiguredto
journal only metadataand not file data.
20.7.4 The Linux Proc File System
The flexibility of the Linux VFSenables us to implement a file system that
does not store data persistently at all but rather provides an interface to some
other functionality.The Linux /procfilesystemisan exampleof a file system
whosecontentsarenotactuallystoredanywherebutarecomputedondemand
according to userfile I/Orequests.
A/procfilesystemisnotuniquetoLinux. UNIXv8introduceda /procfile
systemanditsusehasbeenadoptedandexpandedintomanyotheroperating
systems.Itisanefficientinterfacetothekernel’sprocessnamespaceandhelps
with debugging. Each subdirectory of the file system corresponded not to a
directory on any disk but rather to an active process on the current system. A
listing of the file system reveals one directory per process, with the directory"
3,20.7.4 The Linux Proc File System,948,20.7.3 Journaling,"808 Chapter 20 The Linux System
20.7.3 Journaling
The ext3 file system supports a popular feature called journaling ,w h e r e b y
modifications to the file system are written sequentially to a journal. Aset of
operations that performs a specific task is a transaction .O n c eat r a n s a c t i o n
is written to the journal, it is considered to be committed. Meanwhile, the
journal entries relating to the transaction are replayed across the actual file-
system structures. As the changes are made, a pointer is updated to indicate
which actions have completed and whic h are still incomplete.When an entire
committed transaction is completed, it is removed from the journal. The jour-
nal, which is actually a circular buffer, may be in a separate section of the file
system, or it may even be on a separate disk spindle. It is more efficient, but
morecomplex,tohaveitunderseparateread–writeheads,therebydecreasing
headcontention and seektimes.
If the system crashes, some transactions may remain in the journal. Those
transactions were never completed to the file system even though they were
committedbytheoperatingsystem,sotheymustbecompletedoncethesystem
recovers. The transactions can be executed from the pointer until the work is
complete, and the file-system structures remain consistent. The only problem
occurs when a transaction has been aborted—that is, it was not committed
before the system crashed. Any changes from those transactions that were
applied to the file system must be undone, again preserving the consistency
of the file system. This recovery is all that is needed after a crash, eliminating
allproblemswithconsistency checking.
Journalingfilesystemsmayperformsomeoperationsfasterthannonjour-
naling systems, as updates proceed much faster when they are applied to the
in-memoryjournalratherthandirectlytotheon-diskdatastructures.Therea-
sonforthisimprovementisfoundintheperformanceadvantageofsequential
I/Oover random I/O. Costly synchronous random writes to the file system
are turned into much less costly synchronous sequential writes to the file sys-
tem’sjournal.Thosechanges,inturn,a rereplayedasynchronouslyviarandom
writes to the appropriate structures. The overall result is a significant gain in
performanceoffile-systemmetadata-ori entedoperations,such asfilecreation
anddeletion.Duetothisperformanceimprovement,ext3canbeconfiguredto
journal only metadataand not file data.
20.7.4 The Linux Proc File System
The flexibility of the Linux VFSenables us to implement a file system that
does not store data persistently at all but rather provides an interface to some
other functionality.The Linux /procfilesystemisan exampleof a file system
whosecontentsarenotactuallystoredanywherebutarecomputedondemand
according to userfile I/Orequests.
A/procfilesystemisnotuniquetoLinux. UNIXv8introduceda /procfile
systemanditsusehasbeenadoptedandexpandedintomanyotheroperating
systems.Itisanefficientinterfacetothekernel’sprocessnamespaceandhelps
with debugging. Each subdirectory of the file system corresponded not to a
directory on any disk but rather to an active process on the current system. A
listing of the file system reveals one directory per process, with the directory"
2,20.8 Input and Output,950,20.7 File Systems,"810 Chapter 20 The Linux System
file systemblock
device filecharacter
device file
protocol
driverline
disciplineTTY driverI/O scheduler
SCSI manager
SCSI device
driverblock
device
drivercharacter
device
drivernetwork
socket
network
device
driveruser application
Figure 20.8 Device-driver block structure.
20.8 Input and Output
To the user, the I/Osystem in Linux looks much like that in any UNIXsystem.
That is, to the extent possible, all device drivers appear as normal files. Users
can open an access channel to a device in the same way they open any other
file—devices can appear as objects w ithin the file system. The system admin-
istrator can create special files within a file system that contain references to a
specific device driver, and a user opening such a file will be able to read from
andwritetothedevicereferenced.Byusingthenormalfile-protectionsystem,
which determines who can access which file, the administrator can set access
permissionsforeach device.
Linuxsplitsalldevicesintothreeclasses:blockdevices,character devices,
andnetworkdevices.Figure20.8illustratestheoverallstructureofthedevice-
driversystem.
Block devices include all devices that allow random access to completely
independent,fixed-sizedblocksofdata,includingharddisksandfloppydisks,
CD-ROMsandBlu-raydiscs,andflashmemory.Blockdevicesaretypicallyused
to store file systems, but direct access to a block device is also allowed so
that programs can create and repair the file system that the device contains.
Applications can also access these block devices directly if they wish. For
example, a database application may prefer to perform its own fine-tuned
layout ofdata onto a diskratherthan using the general-purposefilesystem.
Character devices includemostotherdevices,suchasmiceandkeyboards.
The fundamental difference between block and character devices is random
access—block devices are accessed randomly, while character devices are
accessed serially. For example, seeking to a certain position in a file might be
supportedfora DVDbutmakesnosenseforapointingdevicesuchasamouse.
Network devices are dealt with differently from block and character
devices. Users cannot directly transfer data to network devices. Instead, they
must communicate indirectly by opening a connection to the kernel’s net-
working subsystem.Wediscusstheinterfacetonetwork devicesseparatelyin
Section20.10.
20.8.1 Block Devices
Blockdevicesprovidethemaininterfacetoalldiskdevicesinasystem.Perfor-
mance is particularly important for disks, and the block-device system must"
3,20.8.1 Block Devices,950,20.8 Input and Output,"810 Chapter 20 The Linux System
file systemblock
device filecharacter
device file
protocol
driverline
disciplineTTY driverI/O scheduler
SCSI manager
SCSI device
driverblock
device
drivercharacter
device
drivernetwork
socket
network
device
driveruser application
Figure 20.8 Device-driver block structure.
20.8 Input and Output
To the user, the I/Osystem in Linux looks much like that in any UNIXsystem.
That is, to the extent possible, all device drivers appear as normal files. Users
can open an access channel to a device in the same way they open any other
file—devices can appear as objects w ithin the file system. The system admin-
istrator can create special files within a file system that contain references to a
specific device driver, and a user opening such a file will be able to read from
andwritetothedevicereferenced.Byusingthenormalfile-protectionsystem,
which determines who can access which file, the administrator can set access
permissionsforeach device.
Linuxsplitsalldevicesintothreeclasses:blockdevices,character devices,
andnetworkdevices.Figure20.8illustratestheoverallstructureofthedevice-
driversystem.
Block devices include all devices that allow random access to completely
independent,fixed-sizedblocksofdata,includingharddisksandfloppydisks,
CD-ROMsandBlu-raydiscs,andflashmemory.Blockdevicesaretypicallyused
to store file systems, but direct access to a block device is also allowed so
that programs can create and repair the file system that the device contains.
Applications can also access these block devices directly if they wish. For
example, a database application may prefer to perform its own fine-tuned
layout ofdata onto a diskratherthan using the general-purposefilesystem.
Character devices includemostotherdevices,suchasmiceandkeyboards.
The fundamental difference between block and character devices is random
access—block devices are accessed randomly, while character devices are
accessed serially. For example, seeking to a certain position in a file might be
supportedfora DVDbutmakesnosenseforapointingdevicesuchasamouse.
Network devices are dealt with differently from block and character
devices. Users cannot directly transfer data to network devices. Instead, they
must communicate indirectly by opening a connection to the kernel’s net-
working subsystem.Wediscusstheinterfacetonetwork devicesseparatelyin
Section20.10.
20.8.1 Block Devices
Blockdevicesprovidethemaininterfacetoalldiskdevicesinasystem.Perfor-
mance is particularly important for disks, and the block-device system must"
3,20.8.2 Character Devices,951,20.8.1 Block Devices,"20.8 Input and Output 811
provide functionality to ensure that disk access is as fast as possible. This
functionality isachievedthroughthescheduling of I/Ooperations.
In the context of block devices, a block represents the unit with which the
kernelperforms I/O.Whenablockisreadintomemory,itisstoredinabuffer.
The request manager is the layer of software that manages the reading and
writingof buffercontents toand from ablock-devicedriver.
A separate list of requests is kept for each block-device driver. Tradition-
ally,theserequestshavebeenscheduleda ccordingtoaunidirectional-elevator
(C-SCAN) algorithm that exploits the order in which requests are inserted in
andremovedfromthelists.Therequestlistsaremaintainedinsortedorderof
increasing starting-sector number. When a request is accepted for processing
byablock-devicedriver,itisnotremovedfromthelist.Itisremovedonlyafter
theI/Ois complete, at which point the driver continues with the next request
in the list, even if new requests have been inserted in the list before the active
request.Asnew I/Orequestsaremade,therequestmanagerattemptstomerge
requestsinthe lists.
Linux kernel version 2.6 introduced a new I/Oscheduling algorithm.
Althoughasimpleelevatoralgorithmremainsavailable,thedefault I/Osched-
uler is now the Completely Fair Queueing (CFQ) scheduler. The CFQ I/O
scheduler is fundamentally different fro m elevator-based algorithms. Instead
of sorting requests into a list, CFQmaintains a set of lists—by default, one for
each process. Requests originating from a process go in that process’s list. For
example,iftwoprocessesareissuing I/Orequests, CFQwillmaintaintwosep-
aratelistsofrequests,oneforeachprocess.Thelistsaremaintainedaccording
totheC-SCANalgorithm.
CFQservicesthe lists differentlyas well. Where a traditional C-SCANalgo-
rithmisindifferenttoaspecificprocess, CFQserviceseachprocess’slistround-
robin. It pulls a configurable number of requests (by default, four) from each
listbeforemovingontothenext.Thismethodresultsinfairnessattheprocess
level—each process receives an equal fraction of the disk’s bandwidth. The
result is beneficial with interactive workloads where I/Olatency is important.
Inpractice,however, CFQperformswellwith mostworkloads.
20.8.2 Character Devices
Acharacter-device driver can be almost any device driver that does not offer
randomaccesstofixedblocksofdata.Anycharacter-devicedriversregistered
to the Linux kernel must also register a set of functions that implement the
fileI/Ooperations that the driver can handle. The kernel performs almost no
preprocessing of a file read or write request to a character device. It simply
passes the request to the device in question and lets the device deal with the
request.
The main exception to this rule is the special subset of character-device
drivers that implement terminal devices. The kernel maintains a standard
interface to these drivers by means of a set of tty
structstructures. Each of
these structures provides buffering and flow control on the data stream from
theterminaldeviceandfeedsthosedatato a linediscipline.
Aline discipline is an interpreter for the information from the terminal
device.Themostcommonlinedisciplineisthe ttydiscipline,whichgluesthe
terminal’sdata streamonto the standardinput and output streamsof a user’s
runningprocesses,allowingthoseprocessestocommunicate directlywiththe"
2,20.9 Interprocess Communication,952,20.8 Input and Output,"812 Chapter 20 The Linux System
user’s terminal.This job iscomplicatedby thefact that severalsuch processes
may be running simultaneously, and the ttyline discipline is responsible for
attaching and detaching the terminal’s input and output from the various
processes connected to it as those pro cesses are suspended or awakened by
theuser.
Other line disciplines also are implemented that have nothing to do with
I/Oto a user process. The PPPandSLIPnetworking protocols are ways of
encoding a networking connection over a terminal device such as a serial
line. These protocols are implemented under Linux as drivers that at one end
appear to the terminal system as line disciplines and at the other end appear
to the networking system as network-device drivers. After one of these line
disciplineshas beenenabledon a termin aldevice,any dataappearing onthat
terminalwillbe routeddirectlyto theappropriatenetwork-devicedriver.
20.9 Interprocess Communication
Linux provides a rich environment for processes to communicate with each
other. Communication may be just a ma tter of letting another process know
that some event has occurred, or it may involve transferring data from one
processto another.
20.9.1 Synchronization and Signals
The standard Linux mechanism for informing a process that an event has
occurred is the signal. Signals can be sent from any process to any other
process, with restrictions on signals s ent to processes owned by another user.
However, a limited number of signals is available, and they cannot carry
information. Only the fact that a signal has occurred is available to a process.
Signals are not generatedonly by processes. The kernel also generates signals
internally.Forexample,itcansendasignaltoaserverprocesswhendataarrive
on a network channel, to a parent process when a child terminates, or to a
waiting processwhen a timerexpires.
Internally, the Linux kernel does not use signals to communicate with
processes running in kernel mode. If a kernel-mode process is expecting an
event to occur, it will not use signals to receive notification of that event.
Rather,communicationaboutincomingasynchronouseventswithinthekernel
takes place through the use of scheduling states and wait
 queuestructures.
These mechanisms allow kernel-mode processes to inform one another about
relevant events, and they also allow events to be generated by device drivers
orbythenetworkingsystem.Wheneveraprocesswantstowaitforsomeevent
to complete, it places itself on a wait queue associated with that event and
tellstheschedulerthatitisnolongereligibleforexecution.Oncetheeventhas
completed,everyprocessonthewaitqueuewillbeawakened.Thisprocedure
allows multiple processes to wait for a single event. For example, if several
processes are trying to read a file from a disk, then they will all be awakened
once the datahavebeen readinto memorysuccessfully.
Although signals have always been the main mechanism for commu-
nicating asynchronous events among processes, Linux also implements the
semaphore mechanism of SystemV UNIX. Aprocess can wait on a semaphore
aseasilyasitcanwaitforasignal,butsemaphoreshavetwoadvantages:large"
3,20.9.1 Synchronization and Signals,952,20.9 Interprocess Communication,"812 Chapter 20 The Linux System
user’s terminal.This job iscomplicatedby thefact that severalsuch processes
may be running simultaneously, and the ttyline discipline is responsible for
attaching and detaching the terminal’s input and output from the various
processes connected to it as those pro cesses are suspended or awakened by
theuser.
Other line disciplines also are implemented that have nothing to do with
I/Oto a user process. The PPPandSLIPnetworking protocols are ways of
encoding a networking connection over a terminal device such as a serial
line. These protocols are implemented under Linux as drivers that at one end
appear to the terminal system as line disciplines and at the other end appear
to the networking system as network-device drivers. After one of these line
disciplineshas beenenabledon a termin aldevice,any dataappearing onthat
terminalwillbe routeddirectlyto theappropriatenetwork-devicedriver.
20.9 Interprocess Communication
Linux provides a rich environment for processes to communicate with each
other. Communication may be just a ma tter of letting another process know
that some event has occurred, or it may involve transferring data from one
processto another.
20.9.1 Synchronization and Signals
The standard Linux mechanism for informing a process that an event has
occurred is the signal. Signals can be sent from any process to any other
process, with restrictions on signals s ent to processes owned by another user.
However, a limited number of signals is available, and they cannot carry
information. Only the fact that a signal has occurred is available to a process.
Signals are not generatedonly by processes. The kernel also generates signals
internally.Forexample,itcansendasignaltoaserverprocesswhendataarrive
on a network channel, to a parent process when a child terminates, or to a
waiting processwhen a timerexpires.
Internally, the Linux kernel does not use signals to communicate with
processes running in kernel mode. If a kernel-mode process is expecting an
event to occur, it will not use signals to receive notification of that event.
Rather,communicationaboutincomingasynchronouseventswithinthekernel
takes place through the use of scheduling states and wait
 queuestructures.
These mechanisms allow kernel-mode processes to inform one another about
relevant events, and they also allow events to be generated by device drivers
orbythenetworkingsystem.Wheneveraprocesswantstowaitforsomeevent
to complete, it places itself on a wait queue associated with that event and
tellstheschedulerthatitisnolongereligibleforexecution.Oncetheeventhas
completed,everyprocessonthewaitqueuewillbeawakened.Thisprocedure
allows multiple processes to wait for a single event. For example, if several
processes are trying to read a file from a disk, then they will all be awakened
once the datahavebeen readinto memorysuccessfully.
Although signals have always been the main mechanism for commu-
nicating asynchronous events among processes, Linux also implements the
semaphore mechanism of SystemV UNIX. Aprocess can wait on a semaphore
aseasilyasitcanwaitforasignal,butsemaphoreshavetwoadvantages:large"
3,20.9.2 Passing of Data among Processes,953,20.9.1 Synchronization and Signals,"20.10 Network Structure 813
numbersofsemaphorescanbesharedamongmultipleindependentprocesses,
and operations on multiple semaphores can be performed atomically. Inter-
nally, the standard Linux wait queue mechanism synchronizes processes that
are communicating with semaphores.
20.9.2 Passing of Data among Processes
Linux offers several mechanisms for passing data among processes. The stan-
dardUNIX pipemechanismallowsachildprocesstoinheritacommunication
channel from its parent; data written to one end of the pipe can be read at the
other. Under Linux, pipes appear as just another type of inode to virtual file
system software, and each pipe has a pair of wait queues to synchronize the
readerandwriter. UNIXalsodefinesasetofnetworkingfacilitiesthatcansend
streams of data to both local and remote processes. Networking is covered in
Section20.10.
Another process communications method, shared memory, offers an
extremely fast way to communicate large or small amounts of data. Any data
written by one process to a shared memory region can be read immediately
by any other process that has mapped that region into its address space.
The main disadvantage of shared memory is that, on its own, it offers no
synchronization. A process can neither ask the operating system whether a
pieceof sharedmemory has beenwrittento nor suspendexecutionuntil such
a write occurs. Shared memory becomes particularly powerful when used
in conjunction with another interprocess-communication mechanism that
providesthemissing synchronization.
Ashared-memoryregioninLinuxisapersistentobjectthatcanbecreated
or deleted by processes. Such an object is treated as though it were a small,
independent address space. The Linux paging algorithms can elect to page
shared-memory pages out to disk, just as they can page out a process’s data
pages. The shared-memory object acts as a backing store for shared-memory
regions,justasafilecanactasabackingstoreforamemory-mappedmemory
region. When a file is mapped into a virtual address space region, then any
pagefaultsthatoccurcausetheappropriatepageofthefiletobemappedinto
virtualmemory.Similarly,shared-memorymappingsdirectpagefaultstomap
inpagesfromapersistentshared-memoryobject.Alsojustasforfiles,shared-
memory objects remember their contents even if no processes are currently
mappingtheminto virtualmemory.
20.10 Network Structure
Networking is a key area of functionality for Linux. Not only does Linux
supportthestandardInternetprotocolsusedformost UNIX-to-UNIXcommuni-
cations,butitalsoimplementsanumberofprotocolsnativetoother,non- UNIX
operating systems. In particular, since Linux was originally implemented pri-
marily on PCs, rather than on large workstations or on server-class systems,
it supports many of the protocols typically used on PCnetworks, such as
AppleTalkand IPX.
Internally, networking in the Linux kernel is implemented by three layers
ofsoftware:"
2,20.10 Network Structure,953,20.9 Interprocess Communication,"20.10 Network Structure 813
numbersofsemaphorescanbesharedamongmultipleindependentprocesses,
and operations on multiple semaphores can be performed atomically. Inter-
nally, the standard Linux wait queue mechanism synchronizes processes that
are communicating with semaphores.
20.9.2 Passing of Data among Processes
Linux offers several mechanisms for passing data among processes. The stan-
dardUNIX pipemechanismallowsachildprocesstoinheritacommunication
channel from its parent; data written to one end of the pipe can be read at the
other. Under Linux, pipes appear as just another type of inode to virtual file
system software, and each pipe has a pair of wait queues to synchronize the
readerandwriter. UNIXalsodefinesasetofnetworkingfacilitiesthatcansend
streams of data to both local and remote processes. Networking is covered in
Section20.10.
Another process communications method, shared memory, offers an
extremely fast way to communicate large or small amounts of data. Any data
written by one process to a shared memory region can be read immediately
by any other process that has mapped that region into its address space.
The main disadvantage of shared memory is that, on its own, it offers no
synchronization. A process can neither ask the operating system whether a
pieceof sharedmemory has beenwrittento nor suspendexecutionuntil such
a write occurs. Shared memory becomes particularly powerful when used
in conjunction with another interprocess-communication mechanism that
providesthemissing synchronization.
Ashared-memoryregioninLinuxisapersistentobjectthatcanbecreated
or deleted by processes. Such an object is treated as though it were a small,
independent address space. The Linux paging algorithms can elect to page
shared-memory pages out to disk, just as they can page out a process’s data
pages. The shared-memory object acts as a backing store for shared-memory
regions,justasafilecanactasabackingstoreforamemory-mappedmemory
region. When a file is mapped into a virtual address space region, then any
pagefaultsthatoccurcausetheappropriatepageofthefiletobemappedinto
virtualmemory.Similarly,shared-memorymappingsdirectpagefaultstomap
inpagesfromapersistentshared-memoryobject.Alsojustasforfiles,shared-
memory objects remember their contents even if no processes are currently
mappingtheminto virtualmemory.
20.10 Network Structure
Networking is a key area of functionality for Linux. Not only does Linux
supportthestandardInternetprotocolsusedformost UNIX-to-UNIXcommuni-
cations,butitalsoimplementsanumberofprotocolsnativetoother,non- UNIX
operating systems. In particular, since Linux was originally implemented pri-
marily on PCs, rather than on large workstations or on server-class systems,
it supports many of the protocols typically used on PCnetworks, such as
AppleTalkand IPX.
Internally, networking in the Linux kernel is implemented by three layers
ofsoftware:"
2,20.11 Security,956,20.10 Network Structure,"816 Chapter 20 The Linux System
20.11 Security
Linux’ssecuritymodeliscloselyrelatedtotypical UNIXsecuritymechanisms.
The securityconcerns can be classified in two groups:
1.Authentication .Makingsurethatnobodycanaccessthesystemwithout
first provingthat she has entry rights
2.Access control . Providing a mechanism for checking whether a user has
the right to access a certain object and preventing access to objects as
required
20.11.1 Authentication
Authentication in UNIXhas typically been performed through the use of a
publiclyreadablepasswordfile.Auser’spasswordiscombinedwitharandom
“salt”value,andtheresultisencodedwithaone-waytransformationfunction
and stored in the password file. The use of the one-way function means that
theoriginalpasswordcannotbededucedfromthepasswordfileexceptbytrial
and error. When a user presents a password to the system, the password is
recombinedwiththesaltvaluestoredinthepasswordfileandpassedthrough
the same one-way transformation. If the result matches the contents of the
passwordfile,then thepassword isaccepted.
Historically, UNIXimplementations of this mechanism have had several
drawbacks.Passwordswereoftenlimitedtoeightcharacters,andthenumber
of possible salt values was so low that an attacker could easily combine a
dictionary of commonly used passwords with every possible salt value and
have a good chance of matching one or more passwords in the password
file, gaining unauthorized access to any accounts compromised as a result.
Extensions to the password mechanism have been introduced that keep the
encrypted password secret in a file that is not publicly readable, that allow
longerpasswords,orthatusemoresecuremethodsofencodingthepassword.
Otherauthenticationmechanisms hav ebeenintroducedthatlimittheperiods
during which a user is permitted to connect to the system. Also, mechanisms
exist to distribute authentication information to all the related systems in a
network.
Anewsecuritymechanismhasbeendevelopedby UNIXvendorstoaddress
authentication problems. The pluggable authentication modules (PAM) sys-
tem is based on a shared library that can be used by any system component
thatneedstoauthenticateusers.Animp lementationofthissystemisavailable
under Linux. PAMallows authentication modules to be loaded on demand as
specified in a system-wide configuration file. If a new authentication mecha-
nism is added at a later date, it can be added to the configuration file, and all
systemcomponentswillimmediatelybeabletotakeadvantageofit. PAMmod-
ules can specify authentication method s, account restrictions, session-setup
functions,andpassword-changingfunc tions(sothat,whenuserschangetheir
passwords, all the necessary authenti cation mechanisms can be updated at
once)."
3,20.11.1 Authentication,956,20.11 Security,"816 Chapter 20 The Linux System
20.11 Security
Linux’ssecuritymodeliscloselyrelatedtotypical UNIXsecuritymechanisms.
The securityconcerns can be classified in two groups:
1.Authentication .Makingsurethatnobodycanaccessthesystemwithout
first provingthat she has entry rights
2.Access control . Providing a mechanism for checking whether a user has
the right to access a certain object and preventing access to objects as
required
20.11.1 Authentication
Authentication in UNIXhas typically been performed through the use of a
publiclyreadablepasswordfile.Auser’spasswordiscombinedwitharandom
“salt”value,andtheresultisencodedwithaone-waytransformationfunction
and stored in the password file. The use of the one-way function means that
theoriginalpasswordcannotbededucedfromthepasswordfileexceptbytrial
and error. When a user presents a password to the system, the password is
recombinedwiththesaltvaluestoredinthepasswordfileandpassedthrough
the same one-way transformation. If the result matches the contents of the
passwordfile,then thepassword isaccepted.
Historically, UNIXimplementations of this mechanism have had several
drawbacks.Passwordswereoftenlimitedtoeightcharacters,andthenumber
of possible salt values was so low that an attacker could easily combine a
dictionary of commonly used passwords with every possible salt value and
have a good chance of matching one or more passwords in the password
file, gaining unauthorized access to any accounts compromised as a result.
Extensions to the password mechanism have been introduced that keep the
encrypted password secret in a file that is not publicly readable, that allow
longerpasswords,orthatusemoresecuremethodsofencodingthepassword.
Otherauthenticationmechanisms hav ebeenintroducedthatlimittheperiods
during which a user is permitted to connect to the system. Also, mechanisms
exist to distribute authentication information to all the related systems in a
network.
Anewsecuritymechanismhasbeendevelopedby UNIXvendorstoaddress
authentication problems. The pluggable authentication modules (PAM) sys-
tem is based on a shared library that can be used by any system component
thatneedstoauthenticateusers.Animp lementationofthissystemisavailable
under Linux. PAMallows authentication modules to be loaded on demand as
specified in a system-wide configuration file. If a new authentication mecha-
nism is added at a later date, it can be added to the configuration file, and all
systemcomponentswillimmediatelybeabletotakeadvantageofit. PAMmod-
ules can specify authentication method s, account restrictions, session-setup
functions,andpassword-changingfunc tions(sothat,whenuserschangetheir
passwords, all the necessary authenti cation mechanisms can be updated at
once)."
3,20.11.2 Access Control,957,20.11.1 Authentication,"20.11 Security 817
20.11.2 Access Control
Accesscontrolunder UNIXsystems,includingLinux,isperformedthroughthe
useofuniquenumericidentifiers.Auseridentifier( UID)identifiesasingleuser
orasinglesetofaccessrights.Agroupidentifier( GID)isanextraidentifierthat
can be usedto identifyrights belonging tomore than one user.
Access control is applied to various objects in the system. Every file
available in the system is protected by the standard access-control mecha-
nism. In addition, other shared objects, such as shared-memory sections and
semaphores,employthesameaccess system.
Every object in a UNIXsystem under user and group access control has a
singleUIDandasingle GIDassociatedwithit.Userprocessesalsohaveasingle
UID, but they mayhave more than one GID.I fap r o c e s s ’ s UIDmatches the UID
of an object, then the process has user rights orowner rights to that object.
If theUIDsd on o tm a t c hb u ta n y GIDof the process matches the object’s GID,
then group rights areconferred;otherwise,theprocesshas world rights tothe
object.
Linuxperformsaccesscontrolbyassigningobjectsa protection mask that
specifies which access modes—read, write, or execute—are to be granted to
processes with owner, group, or world access. Thus, the owner of an object
mighthavefullread,write,andexecuteaccesstoafile;otherusersinacertain
groupmightbegivenreadaccessbutdeniedwriteaccess;andeverybodyelse
mightbe givenno access atall.
The only exception is the privileged rootUID.Ap r o c e s sw i t ht h i ss p e c i a l
UIDisgrantedautomatic access toany object in thesystem,bypassing normal
access checks. Such processes are also granted permission to perform privi-
leged operations, such as reading any physical memory or opening reserved
network sockets. This mechanism allows the kernel to prevent normal users
from accessing these resources: most of the kernel’s key internal resources are
implicitlyownedby the root UID.
Linuximplementsthestandard UNIX setuidmechanismdescribedinSec-
tion C.3.2. This mechanism allows a pro gram to run with privileges different
from those of the user running the program. For example, the lprprogram
(which submits a job to a print queue) has access to the system’s print queues
even if the user running that program does not. The UNIXimplementation of
setuiddistinguishes between a process’s realandeffective UID.T h er e a l
UIDisthatoftheuserrunningtheprogram;theeffective UIDisthatofthefile’s
owner.
Under Linux, this mechanism is augmented in two ways. First, Linux
implements the POSIXspecification’s saved user-id mechanism, which
allowsaprocesstodropandreacquireitseffective UIDrepeatedly.Forsecurity
reasons,aprogrammaywanttoperformmostofitsoperationsinasafemode,
waivingtheprivilegesgrantedbyits setuidstatus;butitmaywishtoperform
selected operations with all its privileges. Standard UNIXimplementations
achieve this capacity only by swapping the real and effective UIDs. When this
is done, the previous effective UIDis remembered, but the program’s real UID
doesnotalwayscorrespondtothe UIDoftheuserrunningtheprogram.Saved
UIDs allow a process to set its effective UIDto its real UIDand then return to"
2,20.12 Summary,958,20.11 Security,"818 Chapter 20 The Linux System
the previous value of its effective UIDwithout having to modify the real UID
at any time.
The second enhancement provided by Linux is the addition of a process
characteristic that grants just a s ubset of the rights of the effective UID.T h e
fsuidand fsgidprocess properties are used when access rights are granted
to files. The appropriate property is set every time the effective UIDorGIDis
set.However,thefsuidandfsgidcanbesetindependentlyoftheeffectiveids,
allowing a process to access files on behalf of another user without taking on
the identity of that other user in any other way. Specifically, server processes
can use this mechanism to serve files to a certain user without becoming
vulnerabletobeing killedorsuspendedby that user.
Finally, Linux provides a mechanism for flexible passing of rights from
one program to another—a mechanism that has become common in modern
versions of UNIX. When a local network socket has been set up between any
two processes on the system, either of those processes may send to the other
process a file descriptor for one of its open files; the other process receives a
duplicate file descriptor for the same file. This mechanism allows a client to
pass access to a single file selectivelyto some serverprocess without granting
that process any other privileges. For example, it is no longer necessary for a
print server to be able to read all the files of a user who submits a new print
job. The print client can simply pass the server file descriptors for any files to
be printed,denying the serveraccess toany ofthe user’sother files.
20.12 Summary
•Linux is a modern, free operating system based on UNIXstandards. It has
been designed to run efficiently and reliably on common PChardware;
it also runs on a variety of other platforms, such as mobile phones. It
provides a programming interface and user interface compatible with
standard UNIXsystems and can run a large number of UNIXapplications,
including an increasingnumber of commerciallysupportedapplications.
•Linux has not evolved in a vacuum. A complete Linux system includes
manycomponents thatweredevelopedindependentlyofLinux.Thecore
Linux operating-system kernel is entirely original, but it allows much
existing free UNIXsoftware to run, resulting in an entire UNIX-compatible
operatingsystemfreefrom proprietarycode.
•The Linux kernel is implemented as a traditional monolithic kernel for
performance reasons, but it is modular enough in design to allow most
driversto be dynamicallyloadedand unloadedatruntime.
•Linux is a multiuser system, providing protection between processes and
running multiple processesaccording to a time-sharing scheduler.Newly
createdprocessescanshareselectivepartsoftheirexecutionenvironment
withtheirparentprocesses,allowing multithreadedprogramming.
•Interprocess communication is supported by both System V mechanisms
—message queues, semaphores, and shared memory—and BSD’s socket
interface. Multiple networking protocols can be accessed simultaneously
through the socketinterface."
2,Practice Exercises,959,20.12 Summary,"Further Reading 819
•Thememory-managementsystemusespagesharingandcopy-on-writeto
minimize the duplication of data shared by different processes. Pages are
loaded on demand when they are first referencedand are paged back out
to backing store according to an LFUalgorithm if physical memory needs
to be reclaimed.
•To the user, the file system appears as a hierarchical directory tree that
obeysUNIXsemantics. Internally, Linux uses an abstraction layer to man-
age multiple file systems. Device-oriented, networked, and virtual file
systems are supported. Device-oriented file systems access disk storage
through apagecache that isunified with thevirtualmemorysystem.
Practice Exercises
20.1Dynamicallyloadablekernelmodulesgiveflexibilitywhendriversare
added to a system, but do they have disadvantages too? Under what
circumstanceswouldakernelbecompiledintoasinglebinaryfile,and
when would it be better to keep it split into modules? Explain your
answer.
20.2Multithreadingisacommonlyusedprogrammingtechnique.Describe
three different ways to implement threads, and compare these three
methodswiththeLinux clone() mechanism.Whenmightusingeach
alternativemechanism bebetterorworse than using clones?
20.3The Linux kernel does not allow pag ing out of kernel memory. What
effect does this restriction have on the kernel’s design? What are two
advantagesand two disadvantagesof thisdesigndecision?
20.4Discussthreeadvantagesofdynamic(shared)linkageoflibrariescom-
pared with static linkage. Describe two cases in which static linkage is
preferable.
20.5Comparetheuseofnetworkingsocketswiththeuseofsharedmemory
asamechanismforcommunicatingdatabetweenprocessesonasingle
computer.Whataretheadvantagesofeachmethod?Whenmighteach
be preferred?
20.6Atonetime, UNIXsystemsuseddisk-layoutoptimizationsbasedonthe
rotation position of disk data, but modern implementations, includ-
ing Linux, simply optimize for sequential data access. Why do they
do so? Of what hardware characteristics does sequential access take
advantage? Why isrotational optimizationno longerso useful?
Further Reading
The Linux system is a product of the Internet; as a result, much of the avail-
able documentation on Linux is available in some form on the Internet. The
following keysitesreferencemost ofthe usefulinformation available:"
2,Further Reading,959,Practice Exercises,"Further Reading 819
•Thememory-managementsystemusespagesharingandcopy-on-writeto
minimize the duplication of data shared by different processes. Pages are
loaded on demand when they are first referencedand are paged back out
to backing store according to an LFUalgorithm if physical memory needs
to be reclaimed.
•To the user, the file system appears as a hierarchical directory tree that
obeysUNIXsemantics. Internally, Linux uses an abstraction layer to man-
age multiple file systems. Device-oriented, networked, and virtual file
systems are supported. Device-oriented file systems access disk storage
through apagecache that isunified with thevirtualmemorysystem.
Practice Exercises
20.1Dynamicallyloadablekernelmodulesgiveflexibilitywhendriversare
added to a system, but do they have disadvantages too? Under what
circumstanceswouldakernelbecompiledintoasinglebinaryfile,and
when would it be better to keep it split into modules? Explain your
answer.
20.2Multithreadingisacommonlyusedprogrammingtechnique.Describe
three different ways to implement threads, and compare these three
methodswiththeLinux clone() mechanism.Whenmightusingeach
alternativemechanism bebetterorworse than using clones?
20.3The Linux kernel does not allow pag ing out of kernel memory. What
effect does this restriction have on the kernel’s design? What are two
advantagesand two disadvantagesof thisdesigndecision?
20.4Discussthreeadvantagesofdynamic(shared)linkageoflibrariescom-
pared with static linkage. Describe two cases in which static linkage is
preferable.
20.5Comparetheuseofnetworkingsocketswiththeuseofsharedmemory
asamechanismforcommunicatingdatabetweenprocessesonasingle
computer.Whataretheadvantagesofeachmethod?Whenmighteach
be preferred?
20.6Atonetime, UNIXsystemsuseddisk-layoutoptimizationsbasedonthe
rotation position of disk data, but modern implementations, includ-
ing Linux, simply optimize for sequential data access. Why do they
do so? Of what hardware characteristics does sequential access take
advantage? Why isrotational optimizationno longerso useful?
Further Reading
The Linux system is a product of the Internet; as a result, much of the avail-
able documentation on Linux is available in some form on the Internet. The
following keysitesreferencemost ofthe usefulinformation available:"
2,Bibliography,960,Further Reading,"820 Chapter 20 The Linux System
•The Linux Cross-Reference Page ( LXR)(http://lxr.linux.no ) maintains cur-
rent listings of the Linux kernel, browsable via the web and fully cross-
referenced.
•TheKernel Hackers’ Guide providesa helpful overviewof the Linux kernel
componentsandinternalsandislocatedat http://tldp.org/LDP/tlk/tlk.html .
•The Linux Weekly News ( LWN)(http://lwn.net ) provides weekly Linux-
relatednews,includingaverywellresearchedsubsectiononLinuxkernel
news.
ManymailinglistsdevotedtoLinuxarealsoavailable.Themostimportant
are maintained by a mailing-list manager that can be reached at the e-mail
address majordomo@vger.rutgers.edu . Send e-mail to this address with the
single line “help ”in the mail’s body for information on how to access the list
serverand tosubscribe to any lists.
Finally, the Linux system itself can be obtained over the Internet. Com-
plete Linux distributions are available from the home sites of the compa-
nies concerned, and the Linux community also maintains archives of current
system components at several places on the Internet. The most important is
ftp://ftp.kernel.org/pub/linux .
In addition to investigating Internet resources, you can read about the
internalsof the Linuxkernelin[Mauerer(2008)] and [Love (2010)].
The/procfile systemwas introducedin
http://lucasvr.gobolinux.org/etc/Killian84-Procfs-USENIX.pdf , and expanded
in
http://https://www.usenix.org/sites/default/ﬁles/usenix
 winter91
 faulkner.pdf .
Bibliography
[Love (2010)] R. Love, Linux Kernel Development, Third Edition, Developer’s
Library (2010).
[Mauerer (2008)] W. Mauerer, Professional Linux Kernel Architecture , John Wiley
and Sons(2008)."
2,Chapter 20 Exercises,961,Bibliography,"Exercises
Chapter 20 Exercises
20.7What are the advantages and disadvantages of writing an operating
systemina high-levellanguage,such asC?
20.8Inwhatcircumstancesisthesystem-callsequence fork() exec() most
appropriate?Whenis vfork() preferable?
20.9What socket type should be used to implement an intercomputer file-
transfer program? What type should be used for a program that peri-
odically tests to see whether another computer is up on the network?
Explainyour answer.
20.10Linuxrunsonavarietyofhardwareplatforms.WhatstepsmustLinux
developers take to ensure that the system is portable to different pro-
cessors and memory-management architectures and to minimize the
amount of architecture-specifickernelcode?
20.11Whataretheadvantagesanddisadvantagesofmakingonlysomeofthe
symbolsdefinedinsideakernelaccessi bletoaloadablekernelmodule?
20.12What are the primary goals of the conflict-resolution mechanism used
by the Linuxkernelfor loadingkernelmodules?
20.13Discuss how the clone() operation supported by Linux is used to sup-
port both processesand threads.
20.14Would you classify Linux threads as user-level threads or as kernel-
levelthreads?Supportyour answer withtheappropriatearguments.
20.15What extra costs are incurred in the creation and scheduling of a pro-
cess,compared with the cost of acloned thread?
20.16How does Linux’s CompletelyFair Scheduler( CFS) provideimproved
fairnessoveratraditional UNIXprocessscheduler?Whenisthefairness
guaranteed?
20.17WhatarethetwoconfigurablevariablesoftheCompletelyFairSched-
uler (CFS)? What are the pros and cons of setting each of them to very
small andverylargevalues?
20.18TheLinuxschedulerimplements “soft”real-timescheduling.Whatfea-
tures necessary for certain real-time programming tasks are missing?
Howmighttheybeaddedtothekernel?Whatarethecosts(downsides)
of such features?
20.19Under what circumstances would a user process request an operation
that resultsin theallocation of a demand-zeromemoryregion?
20.20What scenarios would cause a page of memory to be mapped into
a user program’s address space with the copy-on-write attribute
enabled?
20.21InLinux,sharedlibrariesperformm anyoperationscentraltotheoper-
ating system. What is the advantage of keeping this functionality out
of the kernel?Arethereany drawbacks? Explainyour answer.EX-58"
1,Chapter 21 Windows,963,Chapter 20 The Linux System,"21CHAPTER
Windows 10
Updated by Alex Ionescu
The Microsoft Windows 10 operating system is a preemptive multitasking
client operating system for microprocessors implementing the Intel IA-32,
AMD64,ARM,andARM64instructionsetarchitectures( ISAs).Microsoft’scorre-
spondingserveroperatingsystem,WindowsServer2016,isbasedonthesame
code as Windows 10 but supports only the 64-bit AMD64ISAs. Windows 10
is the latest in a series of Microsoft operating systems based on its NTcode,
which replaced the earlier systems based on Windows 95/98. In this chapter,
wediscussthekeygoalsofWindows10,thelayeredarchitectureofthesystem
that has made it so easy to use, the file system, the networking features, and
theprogramminginterface.
CHAPTER OBJECTIVES
•Explore the principles underlying Windows 10’s design and the specific
components of the system.
•Provide a detailed discussion of the Windows 10 file system.
•Illustrate the networking protocols supported in Windows 10.
•Describe the interface available in Windows 10 to system and application
programmers.
•Describe the important algorithms implemented with Windows 10.
21.1 History
Inthemid-1980s,Microsoftand IBMcooperatedtodevelopthe OS/2 operating
system, which was written in assembly language for single-processor Intel
80286 systems. In 1988, Microsoft decided to end the joint effort with IBM
and develop its own “new technology ”(orNT) portable operating system to
821"
2,21.1 History,963,Chapter 21 Windows,"21CHAPTER
Windows 10
Updated by Alex Ionescu
The Microsoft Windows 10 operating system is a preemptive multitasking
client operating system for microprocessors implementing the Intel IA-32,
AMD64,ARM,andARM64instructionsetarchitectures( ISAs).Microsoft’scorre-
spondingserveroperatingsystem,WindowsServer2016,isbasedonthesame
code as Windows 10 but supports only the 64-bit AMD64ISAs. Windows 10
is the latest in a series of Microsoft operating systems based on its NTcode,
which replaced the earlier systems based on Windows 95/98. In this chapter,
wediscussthekeygoalsofWindows10,thelayeredarchitectureofthesystem
that has made it so easy to use, the file system, the networking features, and
theprogramminginterface.
CHAPTER OBJECTIVES
•Explore the principles underlying Windows 10’s design and the specific
components of the system.
•Provide a detailed discussion of the Windows 10 file system.
•Illustrate the networking protocols supported in Windows 10.
•Describe the interface available in Windows 10 to system and application
programmers.
•Describe the important algorithms implemented with Windows 10.
21.1 History
Inthemid-1980s,Microsoftand IBMcooperatedtodevelopthe OS/2 operating
system, which was written in assembly language for single-processor Intel
80286 systems. In 1988, Microsoft decided to end the joint effort with IBM
and develop its own “new technology ”(orNT) portable operating system to
821"
3,"21.1.1 Windows XP, Vista, and 7",964,21.1 History,"822 Chapter 21 Windows 10
supportboththe OS/2andPOSIXapplicationprogramminginterfaces( APIs).In
October1988,DaveCutler,thearchitectofthe DECVAX/VMS operatingsystem,
washiredandgiventhecharterofbuildingMicrosoft’snewoperatingsystem.
Originally, the team planned to use the OS/2 API asNT’s native environ-
ment,butduringdevelopment, NTwaschanged touseanew32-bitWindows
API(called Win 32), based on the popular 16-bit APIused in Windows 3.0. The
first versions of NTwere Windows NT3.1 and Windows NT3.1 Advanced
Server. (At that time, 16-bit Windows was at Version 3.1.) Windows NTVer-
sion 4.0 adopted the Windows 95 user in terface and incorporated Internet
web-serverandweb-browsersoftware.Inaddition,user-interfaceroutinesand
all graphics code were moved into the kernel to improve performance (with
the side effect of decreased system reliability and significant loss of security).
Although previous versions of NThad been ported to other microprocessor
architectures (including a brief 64-bit port to Alpha AXP64), the Windows
2000version,releasedinFebruary2000,supportedonly IA-32-compatiblepro-
cessors due to marketplace factors. Windows 2000 incorporated significant
changes. It added Active Directory (an X .500-based directory service), better
networking and laptop support, support for plug-and-play devices, a dis-
tributedfilesystem,and supportfor moreprocessorsandmorememory.
21.1.1 Windows XP, Vista, and 7
In October 2001, Windows XPwas releasedas bothan updateto the Windows
2000desktopoperatingsystemandareplacementforWindows95/98.InApril
2003, the server edition of Windows XP(called Windows Server 2003) became
available.Windows XPupdatedthegraphicaluserinterface( GUI)withavisual
design that took advantage of more recent hardware advances and many
newease-of-use features . Numerous features were added to automatically
repair problems in applications and the operating system itself. Because of
thesechanges,Windows XPprovidedbetternetworkinganddeviceexperience
(including zero-configuration wireless, instant messaging, streaming media,
and digital photography/video). Windows Server 2003 provided dramatic
performanceimprovementsforlargemultiprocessorssystems,aswellasbetter
reliabilityand securitythanearlierWindows operatingsystems.
The long-awaited update to Windows XP, called Windows Vista, was
released in January 2007, but it was not well received. Although Windows
Vistaincludedmanyimprovementsthat latercontinuedintoWindows7,these
improvements were overshadowed by Windows Vista’s perceived sluggish-
ness and compatibility problems. Microsoft responded to criticisms of Win-
dows Vista by improving its engineering processes and working more closely
with the makersof Windows hardware and applications.
The result was Windows 7, which was released in October 2009, along
with corresponding server edition called Windows Server 2008 R2. Among
the significant engineering changes was the increased use of event tracing
rather than counters or profiling to analyze system behavior. Tracing runs
constantly in the system, watching hundr eds of scenarios execute. Scenarios
include process startup and exit, file copy, and web-page load, for example.
When one of these scenarios fails, or when it succeeds but does not perform
well,thetracescan beanalyzed todeterminethecause."
3,21.1.2 Windows 8,965,"21.1.1 Windows XP, Vista, and 7","21.1 History 823
21.1.2 Windows 8
Three years later, in October 2012—amid an industry-wide pivot toward
mobile computing and the world of apps—Microsoft released Windows 8,
which represented the most significant change to the operating system since
Windows XP. Windows 8 included a new user interface (named Metro)a n da
new programming model API(named WinRT). It also included a new way of
managingapplications(whichranunderanewsandboxmechanism)through
apackage system thatexclusivelysupportedthenew Windows Store ,acom-
petitortotheAppleAppStoreandtheAndroidStore.Additionally,Windows
8includedaplethoraofsecurity,boot,andperformanceimprovements.Atthe
same time, support for “subsystems, ”a concept we’ll describe further later in
thechapter,was removed.
To support the new mobile world, Windows 8 was ported to the 32-bit
ARM ISA for the first time and included multiple changes to the power man-
agement and hardware extensibility features of the kernel (discussed later
in this chapter). Microsoft marketed two versions of this port. One version,
calledWindows RT,ranbothWindowsStore–packagedapplicationsandsome
Microsoft-branded “classic ”applications, such as Notepad, Internet Explorer,
andmostimportantly,Office.Theotherversion,calledWindowsPhone,could
only runWindows Store–packagedapplications.
For the first time ever, Microsoft released its own branded mobile hard-
ware,underthe “Surface ”brand,whichincludedtheSurface RT,atabletdevice
that exclusively ran the Windows RToperating system. A bit later, Microsoft
boughtNokiaandbeganreleasingMicrosoft-brandedphonesaswell,running
Windows Phone.
Unfortunately,Windows8wasamarketfailure,forseveralreasons.Onthe
onehand,Metrofocusedonatablet-orie ntedinterfacethatforcedusersaccus-
tomedtoolderWindowsoperatingsystemstocompletelychangethewaythey
worked on their desktop computers. Windows 8, for example, replaced the
startmenuwithtouchscreenfeatures,replacedshortcutswithanimated “tiles, ”
andofferedlittleorno keyboardinputsupport.Ontheotherhand,thedearth
of applications in the Windows Store, which was the only way to obtain apps
for Microsoft’s phone and tablet, led to the market failure of these devices as
well, causing the company to eventually phase out the Surface RTdevice and
writeoffthe Nokiapurchase.
Microsoft quickly sought to address many of these issues with the release
of Windows 8.1 in October 2013. This release addressed many of the usabil-
ity flaws of Windows 8 on nonmobile devices, bringing back more usability
through a traditional keyboard and mouse, and provided ways to avoid the
tile-based Metro interface. It also continued to improve on the many security,
performance,and reliabilitychanges in troducedin Windows 8. Although this
releasewasbetterreceived,thecontinuedlackofapplicationsintheWindows
Store was a problem for the operating system’s mobile market penetration,
while desktop and server application p rogrammers felt abandoned due to a
lackof improvementsintheirarea.
21.1.3 Windows 10
With the release of Windows 10 in July 2015 and its server companion,
Windows Server 2016, in October 2016, Microsoft shifted to a “Windows-"
3,21.1.3 Windows 10,965,21.1.2 Windows 8,"21.1 History 823
21.1.2 Windows 8
Three years later, in October 2012—amid an industry-wide pivot toward
mobile computing and the world of apps—Microsoft released Windows 8,
which represented the most significant change to the operating system since
Windows XP. Windows 8 included a new user interface (named Metro)a n da
new programming model API(named WinRT). It also included a new way of
managingapplications(whichranunderanewsandboxmechanism)through
apackage system thatexclusivelysupportedthenew Windows Store ,acom-
petitortotheAppleAppStoreandtheAndroidStore.Additionally,Windows
8includedaplethoraofsecurity,boot,andperformanceimprovements.Atthe
same time, support for “subsystems, ”a concept we’ll describe further later in
thechapter,was removed.
To support the new mobile world, Windows 8 was ported to the 32-bit
ARM ISA for the first time and included multiple changes to the power man-
agement and hardware extensibility features of the kernel (discussed later
in this chapter). Microsoft marketed two versions of this port. One version,
calledWindows RT,ranbothWindowsStore–packagedapplicationsandsome
Microsoft-branded “classic ”applications, such as Notepad, Internet Explorer,
andmostimportantly,Office.Theotherversion,calledWindowsPhone,could
only runWindows Store–packagedapplications.
For the first time ever, Microsoft released its own branded mobile hard-
ware,underthe “Surface ”brand,whichincludedtheSurface RT,atabletdevice
that exclusively ran the Windows RToperating system. A bit later, Microsoft
boughtNokiaandbeganreleasingMicrosoft-brandedphonesaswell,running
Windows Phone.
Unfortunately,Windows8wasamarketfailure,forseveralreasons.Onthe
onehand,Metrofocusedonatablet-orie ntedinterfacethatforcedusersaccus-
tomedtoolderWindowsoperatingsystemstocompletelychangethewaythey
worked on their desktop computers. Windows 8, for example, replaced the
startmenuwithtouchscreenfeatures,replacedshortcutswithanimated “tiles, ”
andofferedlittleorno keyboardinputsupport.Ontheotherhand,thedearth
of applications in the Windows Store, which was the only way to obtain apps
for Microsoft’s phone and tablet, led to the market failure of these devices as
well, causing the company to eventually phase out the Surface RTdevice and
writeoffthe Nokiapurchase.
Microsoft quickly sought to address many of these issues with the release
of Windows 8.1 in October 2013. This release addressed many of the usabil-
ity flaws of Windows 8 on nonmobile devices, bringing back more usability
through a traditional keyboard and mouse, and provided ways to avoid the
tile-based Metro interface. It also continued to improve on the many security,
performance,and reliabilitychanges in troducedin Windows 8. Although this
releasewasbetterreceived,thecontinuedlackofapplicationsintheWindows
Store was a problem for the operating system’s mobile market penetration,
while desktop and server application p rogrammers felt abandoned due to a
lackof improvementsintheirarea.
21.1.3 Windows 10
With the release of Windows 10 in July 2015 and its server companion,
Windows Server 2016, in October 2016, Microsoft shifted to a “Windows-"
2,21.2 Design Principles,968,21.1 History,"826 Chapter 21 Windows 10
21.2 Design Principles
Microsoft’s design goals for Windows included security, reliability, compati-
bility, high performance, extensibility, portability, and international support.
Someadditionalgoals,suchasenergyefficiencyanddynamicdevicesupport,
have recentlybeenaddedtothis list.Next,wediscuss eachof thesegoalsand
how eachisachievedinWindows 10.
21.2.1 Security
Windows Vista and later security goals required more than just adherence to
the design standards that had enabled Windows NT4.0 to receive a C2 secu-
rity classification from the U.S. government. (A C2 classification signifies a
moderate level of protection from defective software and malicious attacks.
Classifications were defined by the Department of Defense Trusted Com-
puterSystemEvaluationCriteria,alsoknownasthe Orange Book .)Extensive
codereviewandtestingwerecombinedwithsophisticatedautomaticanalysis
toolstoidentifyandinvestigatepotentialdefectsthatmightrepresentsecurity
vulnerabilities. Additionally, bug bounty participation programs allow exter-
nal researchers and security professionals to identify, and submit, previously
unknown security issues in Windows. In exchange, they receive monetary
payment as well as credit in monthly security rollups, which are released by
Microsoft tokeepWindows 10 as secureaspossible.
Windowstraditionallybasedsecurityondiscretionaryaccesscontrols.Sys-
tem objects, including files, registry keys, and kernel synchronization objects,
are protected by access-control lists (ACLs) (see Section 13.4.2). ACLsa r ev u l -
nerable to user and programmer errors, however, as well as to the most com-
mon attacks on consumer systems, in which the user is tricked into running
code, often while browsing the Web. Windows Vista introduced a mechanism
called integrity levels that acts as a rudimentary capability system for con-
trolling access. Objects and processes are marked as having no, low, medium,
orhighsystemintegrity.Theintegrityl eveldetermineswhatrightstheobjects
and processes will have. For example, Windows does not allow a process to
modifyanobjectwithahigherintegritylevel(basedonits mandatorypolicy ),
no matter what the setting of the ACL. Additionally, a process cannot read the
memoryof a higher-integrityprocess,no matterthe ACL.
Windows 10 further strengthened the security model by introducing a
combination of attribute-based access control ( ABAC) and claim-based access
control ( CABC). Both features are used to implement dynamic access control
(DAC)onservereditions,aswellastosupportthecapability-basedsystemused
by Windows Store applications and by Modern and packaged applications.
With attributes and claims, system administrators need not rely on a user’s
name (or the group the user belongs to) as the only means that the security
system can use to filter access to objects such as files. Properties of the user
—such as, say, seniority in the organization, salary, and so on—can also be
considered.Thesepropertiesareencodedas attributes, whicharepairedwith
conditional access control entriesinthe ACL,s u c ha s “Seniority>=10 Years. ”
Windowsusesencryptionaspartofcommonprotocolssuchasthoseused
tocommunicatesecurelywithwebsites.Encryptionisalsousedtoprotectuser
filesstoredonsecondarystorage.Windows7andlaterversionsallowusersto"
3,21.2.1 Security,968,21.2 Design Principles,"826 Chapter 21 Windows 10
21.2 Design Principles
Microsoft’s design goals for Windows included security, reliability, compati-
bility, high performance, extensibility, portability, and international support.
Someadditionalgoals,suchasenergyefficiencyanddynamicdevicesupport,
have recentlybeenaddedtothis list.Next,wediscuss eachof thesegoalsand
how eachisachievedinWindows 10.
21.2.1 Security
Windows Vista and later security goals required more than just adherence to
the design standards that had enabled Windows NT4.0 to receive a C2 secu-
rity classification from the U.S. government. (A C2 classification signifies a
moderate level of protection from defective software and malicious attacks.
Classifications were defined by the Department of Defense Trusted Com-
puterSystemEvaluationCriteria,alsoknownasthe Orange Book .)Extensive
codereviewandtestingwerecombinedwithsophisticatedautomaticanalysis
toolstoidentifyandinvestigatepotentialdefectsthatmightrepresentsecurity
vulnerabilities. Additionally, bug bounty participation programs allow exter-
nal researchers and security professionals to identify, and submit, previously
unknown security issues in Windows. In exchange, they receive monetary
payment as well as credit in monthly security rollups, which are released by
Microsoft tokeepWindows 10 as secureaspossible.
Windowstraditionallybasedsecurityondiscretionaryaccesscontrols.Sys-
tem objects, including files, registry keys, and kernel synchronization objects,
are protected by access-control lists (ACLs) (see Section 13.4.2). ACLsa r ev u l -
nerable to user and programmer errors, however, as well as to the most com-
mon attacks on consumer systems, in which the user is tricked into running
code, often while browsing the Web. Windows Vista introduced a mechanism
called integrity levels that acts as a rudimentary capability system for con-
trolling access. Objects and processes are marked as having no, low, medium,
orhighsystemintegrity.Theintegrityl eveldetermineswhatrightstheobjects
and processes will have. For example, Windows does not allow a process to
modifyanobjectwithahigherintegritylevel(basedonits mandatorypolicy ),
no matter what the setting of the ACL. Additionally, a process cannot read the
memoryof a higher-integrityprocess,no matterthe ACL.
Windows 10 further strengthened the security model by introducing a
combination of attribute-based access control ( ABAC) and claim-based access
control ( CABC). Both features are used to implement dynamic access control
(DAC)onservereditions,aswellastosupportthecapability-basedsystemused
by Windows Store applications and by Modern and packaged applications.
With attributes and claims, system administrators need not rely on a user’s
name (or the group the user belongs to) as the only means that the security
system can use to filter access to objects such as files. Properties of the user
—such as, say, seniority in the organization, salary, and so on—can also be
considered.Thesepropertiesareencodedas attributes, whicharepairedwith
conditional access control entriesinthe ACL,s u c ha s “Seniority>=10 Years. ”
Windowsusesencryptionaspartofcommonprotocolssuchasthoseused
tocommunicatesecurelywithwebsites.Encryptionisalsousedtoprotectuser
filesstoredonsecondarystorage.Windows7andlaterversionsallowusersto"
3,21.2.2 Reliability,970,21.2.1 Security,"828 Chapter 21 Windows 10
difficult, perhaps explaining in part why crimeware applications, such as
adware, credit card fraudware, and ransomware, have become so prevalent.
These types of attacks rely on users to willingly and manually cause harm
to their own computers (such as by double-clicking on applications against
warning, or inputting their credit card number in a fake banking page). No
operatingsystemcanbedesignedtomilitateagainstthegullibilityandcurios-
ityofhumanbeings.Recently,Microsofthasstartedworkingdirectlywithchip
manufacturers,suchasIntel,tobuildsecuritymitigationsdirectlyintothe ISA.
One such mitigation, for example, is Control-flo Enforcement Technology
(CET), which is a hardware implementation of CFGthat also protects against
return-oriented-programming( ROP)attacksbyusinghardwareshadowstacks.
Ashadow stack contains the set of return addresses as stored when a routine
is called. The addresses are checked for a mismatch before the return is exe-
cuted. Amismatch means the stack has been compromised and action should
be taken.
Another important aspect of security is integrity. Windows offers several
digital signature facilities as part of its code integrity features. Windows uses
digital signatures to signoperating system binaries so that it can verify that
thefileswereproducedbyMicrosoftoranotherknowncompany.Innon- IA-32
versionsofWindows, the code integrity moduleisactivatedat boot toensure
that all the loaded modules in the kernel have valid signatures, assuring that
they have not been tampered with. Additionally, ARMversions of Windows 8
extendthecodeintegritymodulewithuser-modecodeintegritychecks,which
validate that all user programs have been signed by Microsoft or delivered
through the Windows Store. A special version of Windows 10 (Windows 10
S, mostly meant for the education market) provides similar signing checks on
allIA-32 and AMD64 systems. Digital signatures are also used as part of Code
IntegrityGuard,whichallowsapplicationstodefendthemselvesagainstload-
ing executable code from secondary storage that has not been appropriately
signed.Forexample,anattackermightreplacethird-partybinarywithhisown,
butthedigitalsignaturewouldfail,andCodeIntegrityGuardwouldnotload
thebinary intothe processes’addressspace.
Finally, enterprise versions of Windows 10 make it possible to opt in to a
new security feature called Device Guard . This mechanism allows organiza-
tionstocustomizethedigitalsigningrequirementsoftheircomputersystems,
as well as blacklist and whitelistindividualsigning certificates or evenbinary
hashes. For example, an organization could choose to allow only user-mode
programssignedbyMicrosoft,Google,orAdobetolaunchontheirenterprise
computers.
21.2.2 Reliability
Windowsmaturedgreatlyasanoperatingsysteminitsfirsttenyears,leading
toWindows2000.Atthesametime,itsreliabilityincreasedduetosuchfactors
asmaturityinthesourcecode,extensivestresstestingofthesystem,improved
CPUarchitectures, and automatic detection of many serious errors in drivers
from both Microsoft and third parties. Windows has subsequently extended
the tools for achieving reliability to include automatic analysis of source code
for errors, tests to detect validation failures, and an application version of the"
3,21.2.3 Windows and Application Compatibility,972,21.2.2 Reliability,"830 Chapter 21 Windows 10
21.2.3 Windows and Application Compatibility
As mentioned, Windows XPwas both an update of Windows 2000 and a
replacementforWindows95/98.Windows2000focusedprimarilyoncompat-
ibility for business applications. The requirements for Windows XPincluded
much higher compatibility with the consumer applications that ran on Win-
dows 95/98. Application compatibility is difficult to achieve, for several rea-
sons. For example, applications may check for a specific version of Windows,
may depend to some extent on the quirks of the implementation of APIs, or
may have latent application bugs that were masked in the previous system.
Applications may also have been compiled for a different instruction set or
have different expectations when run on today’s multi-gigahertz, multicore
systems.Windows10continuestofocusoncompatibilityissuesbyimplement-
ing severalstrategiesto runapplicationsdespiteincompatibilities.
Like Windows XP, Windows 10 has a compatibility layer, called the shim
engine, that sits between applications and the Win 32 APIs. This engine can
make Windows 10 look (almost) bug-for-bug compatible with previous ver-
sions of Windows. Windows 10 ships with a shim database of over 6,500
entries, describing particular quirks and tweaks that must be made for older
applications. Furthermore, through the Application Compatibility Toolkit,
users and administrators can build their own shim databases. Windows 10’s
SwitchBranch mechanism allows developers to choose which Windows ver-
sion they’d like the Win 32 APIto emulate, including all the quirks and/or
bugs of aprevious API.T h e Task Manager ’s“OperatingSystemContext ”col-
umn shows what SwitchBranch operating-system version each application is
running under.
Windows 10,likeearlier NTreleases,maintainssupportforrunningmany
16-bit applications using a thunking, or conversion, layer—called Windows-
on-Windows-32 (WoW32)—that translates 16-bit APIcalls into equivalent 32-
bitcalls.Similarly,the64-bitversionofWindows10providesathunkinglayer,
WoW64, that translates 32-bit APIcalls into native 64-bit calls. Finally, the
ARM64 version of Windows 10 provides a dynamic JITrecompiler, translating
IA-32 code,calledWoWA64.
TheoriginalWindowssubsystemmodelallowsmultipleoperating-system
personalitiestobesupported,aslongast heapplicationsarerebuiltasPortable
Executable ( PE) applications with a Microsoft compiler such as Visual Stu-
dio and source code is available. As noted earlier, although the APIdesigned
for Windows is the Win 32API, some earlier editions of Windows supported a
POSIXsubsystem. POSIXis a standard specification for UNIXthat allows UNIX-
compatible software to be recompiled and run without modification on any
POSIX-compatible operating system. Unfortunately, as Linux has matured, it
hasdriftedfartherandfartherawayfrom POSIXcompatibility,andmanymod-
ern Linux applications now rely on Linux-specific system calls and improve-
mentsto glibcthatarenotstandardized.Additionally,itbecomesimpractical
toaskusers(orevenenterprises)torecompilewithVisualStudioeverysingle
Linux application that they’d like to use. Indeed, compiler differences among
GCC, CLang, and Microsoft’s C/C++ compiler often make doing so impossi-
ble.Therefore,eventhoughthesubsystemmo delstillexistsatanarchitectural
level,theonlysubsystemonWindowsgoingforwardwillbetheWin 32subsys-
temitself,andcompatibilitywithother operatingsystemsisachievedthrough
a newmodelthat usesPico Providersinstead."
3,21.2.4 Performance,973,21.2.3 Windows and Application Compatibility,"21.2 Design Principles 831
This significantly more powerful mode l extends the kernel via the ability
to forward, or proxy, every system call, exception, fault, thread creation and
termination, and process creation, along with a few other internal operations,
toasecondaryexternaldriver(thePicoProvideritself).Thissecondarydriver
nowbecomestheownerofallsuchopera tions.WhilestillusingWindows10’s
scheduler and memory manager (similar to a microkernel), it can implement
its own ABI, system-call interface, executable file format parser, page fault
handling, caching, I/Omodel,securitymodel,and more.
Windows10includesonesuchPicoProvider,calledLxCore,thatisamulti-
megabytereimplementationoftheLinux kernel.(NotethatitisnotLinux,and
it does not share any code with Linux.) This driver is used by the “Windows
Subsystem for Linux ”feature, which can be used to load unmodified Linux
ELFbinaries without the need for source code or recompilation as PEbinaries.
Windows10userscanrunanunmodifiedUbuntuuser-modefilesystem(and,
more recently, Open SUSEandCentOS), servicing it with the apt-get package
management command and running packages as normal. Note that the ker-
nel reimplementation is not complete—many system calls are missing, as is
access to most devices,since no Linux kernel drivers can load. Notably, while
networking is fully supported, as well as serial devices, no GUI/frame-buffer
access ispossible.
As a final compatibility measure, Windows 8.1 and later versions also
include the Hyper-V for Client feature. This allows applications to get bug-
for-bugcompatibilitywithWindows XP,Linux,andeven DOSbyrunningthese
operatingsystemsinsidea virtualmachine.
21.2.4 Performance
Windows was designed to provide high performance on desktop systems
(whicharelargelyconstrainedby I/Operformance),serversystems(wherethe
CPUisoftenthebottleneck),andlargemultithreadedandmultiprocessorenvi-
ronments (where locking performance and cache-line management are keys
toscalability).Tosatisfyperformancerequirements, NTusedavarietyoftech-
niques, such as asynchronous I/O, optimized protocols for networks, kernel-
based graphics rendering, and sophisticated caching of file-system data. The
memory-managementandsynchronizationalgorithmsweredesignedwithan
awarenessoftheperformanceconsiderationsrelatedtocache linesand multi-
processors.
Windows NTwas designed for symmetrical multiprocessing ( SMP); on a
multiprocessorcomputer,severalthreadscanrunatthesametime,eveninthe
kernel.Oneach CPU,W indows NTusespriority-basedpreemptivescheduling
of threads. Except while executing in the dispatcher or at interrupt level,
threads in any process running in Windows can be preempted by higher-
prioritythreads.Thus, thesystemrespondsquickly(seeChapter5).
Windows XPfurther improved performance by reducing the code-path
lengthincriticalfunctionsandimplemen tingmorescalablelockingprotocols,
such as queued spinlocks and pushlocks. ( Pushlocks are like optimized spin-
lockswithread–writelockfeatures.)Thenewlockingprotocolshelpedreduce
systembuscyclesandincludedlock-freelistsandqueues,atomicread–modify
–write operations (like interlocked increment ), and other advanced syn-
chronization techniques. These changes were needed because Windows XP"
3,21.2.5 Extensibility,975,21.2.4 Performance,"21.2 Design Principles 833
lel execution, such as Microsoft’s Concurrency RunTime ( ConcRT)a n dP a r -
allel Processing Library ( PPL), as well as Intel’s Threading Building Blocks
(TBB), are being used to express parallelism in C++ programs. Additionally, a
vendor-neutral standard called OpenMPis supported by almost all compilers.
AlthoughMoore’sLawhasgovernedcomputingforfortyyears,itnowseems
that Amdahl’s Law, which governs parallel computing (see Section 4.2), will
rulethefuture.
Finally, power considerations have complicated design decisions around
high-performance computing—especi ally in mobile systems, where battery
life might trump performance needs, but also in cloud/server environments,
where the cost of electricity might outweigh the need for the fastest possi-
ble computational result. Accordingly, Windows 10 now supports features
that may sometimes sacrifice raw performance for better power efficiency.
Examples include Core Parking, which puts an idle system into a sleep state,
and Heterogeneous Multi Processing ( HMP), which allocates tasks efficiently
among cores.
Tosupporttask-basedparallelism,the AMD64portsofWindows7andlater
versions provide a new form of user-mode scheduling (UMS).UMSallows
programs to be decomposed into tasks, and the tasks are then scheduled on
theavailable CPUsbyaschedulerthatoperatesinusermoderatherthaninthe
kernel.
The advent of multiple CPUs on the smallest computers is only part of
the shift taking place to parallel computing. Graphics processing units ( GPUs)
accelerate the computational algo rithms needed for graphics by using SIMD
architecturestoexecuteasingleinstructionformultipledataatthesametime.
This has given rise to the use of GPUs for general computing, not just graph-
ics. Operating-system support for software like Open CLandCUDAis allow-
ing programs to take advantage of the GPUs. Windows supports the use of
GPUs through software in its Direct Xgraphics support. This software, called
DirectCompute, allows programs to specify computational kernels using the
“high-level shader language ”programming model used by SIMDhardware.
Thecomputationalkernelsrunveryquicklyonthe GPUandreturntheirresults
tothemaincomputationrunningonthe CPU.InWindows10,thenativegraph-
ics stack and many new Windows applications make use of DirectCompute,
and new versions of Task Manager track GPUprocessor and memory usage,
with DirectX now having its own GPUthread scheduler and GPUmemory
manager.
21.2.5 Extensibility
Extensibility refers to the capability of an operating system to keep up with
advances in computing technology. To facilitate change over time, the devel-
opers implemented Windows using a layered architecture. The lowest-level
kernel “executive ”runsinkernelmodeandprovidesthebasicsystemservices
and abstractions that support shared use of the system. On top of the execu-
tive,severalservicesoperateinusermode.Amongthemweretheenvironment
subsystems that emulated different operating systems, which are deprecated
today. Evenin the kernel,Windows uses a layeredarchitecture, with loadable
drivers in the I/Osystem, so new file systems, new kinds of I/Odevices, and
new kinds of networking can be added while the system is running. Drivers"
3,21.2.6 Portability,976,21.2.5 Extensibility,"834 Chapter 21 Windows 10
window
manageruser mode
kernel mode
file systemI/O managercsrsssession
manageruser
processesSCM
graphic
device
drivers
kernelntdll.dllsubsystem dlls
executive
hardware abstraction layer (HAL)
Hyper-V hypervisor
hardwarecache
manager
device
drivers
network
driversobject
managersecurity
reference
monitorplug and
play
managerprocess
managerpower
managerconfigur-
ation
manager
HAL extensionsALPCmemory
managerwininit spooler svchost winlogonenvironment subsystems system processes services applications
Figure 21.1 Windows block diagram.
aren’t limited to providing I/Ofunctionality, however. As we’ve seen, a Pico
Provider is also a type of loadable driver (as are most anti-malware drivers).
Through Pico Providers and the modular structure of the system, additional
operatingsystemsupportcanbeaddedwithoutaffectingtheexecutive.Figure
Figure 21.1shows the architecture of the Windows 10 kerneland subsystems.
Windows also uses a client–server model like the Mach operating system
andsupportsdistributedprocessingthrough remote procedure calls (RPCs)as
defined by the Open Software Foundation. These RPCs take advantage of an
executive component, called the advanced local procedure call (ALPC), that
implements highly scalable communication between separate processes on a
local machine. A combination of TCP/IPpackets and named pipes over the
SMBprotocol is used for communication between processes across a network.
On top of RPC, Windows implements the Distributed Common Object Model
(DCOM) infrastructure, as well as the Windows Management Instrumentation
(WMI) and Windows Remote Management (Win RM) mechanism, all of which
can be used to rapidly extend the syst em with new services and management
capabilities.
21.2.6 Portability
An operating system is portable if it can be movedfrom one CPUarchitecture
toanotherwithrelativelyfewchanges.Windowswasdesignedtobeportable.
Like the UNIXoperating system, Windows is written primarily in C and C++.
Thereisrelativelylittlearchitecture-specificsourcecodeandverylittleassem-"
3,21.2.7 International Support,977,21.2.6 Portability,"21.2 Design Principles 835
bly code. Porting Windows to a new architecture mostly affects the Windows
kernel, since the user-mode code in Windows is almost exclusively written
to be architecture independent. To port Windows, the kernel’s architecture-
s p e c i fi cc o d em u s tb er e w r i t t e nf o rt h et a r g e t CPU, and sometimes conditional
compilationisneededinotherpartsofthekernelbecauseofchangesinmajor
data structures, such as the page-table format. The entire Windows system
mustthenberecompiledfor thenew CPUinstructionset.
Operatingsystemsaresensitivenotonlyto CPUarchitecturebutalsoto CPU
support chips and hardware boot programs. The CPUand support chips are
collectivelyknownasthe chipset.Thesechipsetsandtheassociatedbootcode
determinehowinterruptsaredelivered,describethephysicalcharacteristicsof
each system, and provideinterfaces to deeperaspects of the CPUarchitecture,
such as error recovery and power management. It would be burdensome to
have to port Windows to each type of support chip as well as to each CPU
architecture.Instead,Windowsisolatesmostofthechipset-dependentcodein
adynamiclinklibrary( DLL),calledthe hardware-abstraction layer (HAL),that
isloadedwiththe kernel.
The Windows kernel depends on the HALinterfaces rather than on the
underlying chipset details. This allows the single set of a kernel and driver
binariesforaparticular CPUtobeusedwithdifferentchipsetssimplybyload-
ingadifferentversionofthe HAL.Originally,tosupportthemanyarchitectures
that Windows ran on, and the many computer companies and designs in the
market, over 450 different HALs existed. Over time, the advent of standards
such as the Advanced Configuration and Power Interface ( ACPI), the increas-
ingsimilarityofcomponentsavailablei nthemarketplace,andthemergingof
computermanufacturersledtochanges;today,the AMD64portofWindows10
comeswithasingle HAL.Interestingly,though,nosuchdevelopmentshaveyet
occurredinthemarketformobiledevices.Today,Windowssupportsalimited
numberof ARMchipsets—andmusthavetheappropriate HALcodeforeachof
them.Toavoidgoingbacktoamodelofmultiple HALs,Windows8introduced
theconceptof HALExtensions,whichare DLLsthatareloadeddynamicallyby
theHALbasedonthedetectedSoC(systemonachip)components,suchasthe
interruptcontroller,timermanager, and DMAcontroller.
Over the years, Windows has been ported to a number of different CPU
architectures: Intel IA-32-compatible 32-bit CPUs,AMD64-compatible and IA64
64-bitCPUs, and DECAlpha, DECAlphaAXP64,MIPS,a n dP o w e r PC CPUs.
Mostofthese CPUarchitecturesfailedintheconsumer desktopmarket.When
Windows 7 shipped, only the IA-32 and AMD64 architectures were supported
on client computers, along with AMD64 on servers. With Windows 8, 32-bit
ARMwas added,and Windows 10now supports ARM64 aswell.
21.2.7 International Support
Windows was designed for international and multinational use. It provides
support for different locales via the national-language-support (NLS)API.
TheNLS API provides specialized routines to format dates, time, and money
in accordance with national customs. String comparisons are specialized to
account for varying character sets. UNICODE is Windows’s native character
code, specifically in its UTL-16LE encoding format (which is different from"
3,21.2.8 Energy Efficiency,978,21.2.7 International Support,"836 Chapter 21 Windows 10
Linux’s and the Web’s standard UTF-8). Windows supports ANSIcharacters
by converting them to UNICODE characters before manipulating them (8-bit
to 16-bit conversion).
System text strings are kept in resource tables inside files that can be
replacedtolocalizethesystemfordifferentlanguages.BeforeWindows Vista,
Microsoft shipped these resource tables inside the DLLs themselves, which
meant that different executable binaries existed for each different version of
Windowsandonlyonelanguagewasavailableatasingletime.WithWindows
Vista’s multiple user interface (MUI) support, multiple locales can be used
concurrently, which is important to multilingual individuals and businesses.
Thiswasachievedbymovingalloftheresourcetablesintoseparate .muifiles
that live in the appropriate language directory alongside the .dllfile, with
supportintheloadertopicktheappropriatefilebasedonthecurrentlyselected
language.
21.2.8 Energy Efﬁciency
Increasing energy efficiency causes batteries to last longer for laptops and
Internet-onlynetbooks,savessignificantoperatingcostsforpowerandcooling
of data centers, and contributes to green initiatives aimed at lowering energy
consumption by businesses and consumers. For some time, Windows has
implementedseveralstrategiesfordecreasingenergyuse.The CPUsaremoved
tolowerpowerstates—forexample,byloweringclockfrequency—whenever
possible. In addition, when a computer is not being actively used, Windows
mayputtheentirecomputerintoalow-powerstate(sleep)ormayevensaveall
ofmemorytosecondarystorageandshutthecomputeroff(hibernation).When
theuserreturns,thecomputerpowersupandcontinuesfromitspreviousstate,
so theuserdoesnot needtoreboot andrestartapplications.
The longer a CPUcan stayunused,themoreenergycan be saved.Because
computersaresomuchfasterthanhumanbeings,alotofenergycanbesaved
justwhilehumansarethinking.Theproblemisthatmanyprogramsarepolled
to wait for activity, and software timers are frequently expiring, keeping the
CPUfrom stayingidlelong enough tosave much energy.
Windows 7 extends CPUidle time by delivering clock-tick interrupts only
tological CPU0andallothercurrentlyactive CPUs(skippingidleones)andby
coalescing eligible software timers into smaller numbers of events. On server
systems, it also “parks ”entireCPUs when systems are not heavily loaded.
Additionally, timer expiration is not distributed, and a single CPUis typically
in charge of handling all software timer expirations. A thread that was run-
ning on, say, logical CPU3 does not cause CPU3 to wake up and service this
expirationifitiscurrentlyidlewhenanother,nonsleeping CPUcouldhandleit
instead.
While these measures helped, they were not enough to increase battery
life in mobile systems such as phones, which have a fraction of the battery
capacityoflaptops.Windows8thusintroducedanumberoffeaturestofurther
optimize battery life. First, the Win RTprogramming model does not allow for
precisetimerswithaguaranteedexpirationtime.Alltimersregisteredthrough
the new APIare candidates for coalescing, unlike Win 32timers, which had to
be manually opted in. Next, the concept of a dynamic tick was introduced,in"
3,21.2.9 Dynamic Device Support,979,21.2.8 Energy Efficiency,"21.2 Design Principles 837
whichCPU0isnolongerthe clock owner ,andthelast-active CPUtakesonthis
responsibility.
More significantly, the entire Metro/Modern/ UWPapplication model
deliveredthroughtheWindowsStoreincludesafeature,the Process Lifetime
Manager (PLM), that automatically suspends all of the threads in a process
that has been idle for more than a few seconds. This not only mitigates the
constant polling behavior of many applic ations, but also removes the ability
forUWPapplications to do their own background work (such as querying the
GPSlocation), forcing them to deal with a system of brokers that efficiently
coalesce audio, location, download, and other requests and can cache data
whiletheprocessis suspended.
Finally, using a new component called the Desktop Activity Moderator
(DAM), Windows 8 and later versions support a new type of system state
called Connected Standby .Imagine putting a computer to sleep—this action
takes several seconds, after which everything on the computer appears to
disappear,withallthehardwareturningoff.Pressingabuttononthekeyboard
wakesupthecomputer,whichtakesafewadditionalseconds,andeverything
resumes. On a phone or tablet, however, putting the device to sleep is not
expected to take seconds—users want their screen to turn off immediately.
But if Windows merely turned off the screen, all programs would continue
running, and legacy Win 32applications, lacking a PLMand timer coalescing,
would continue to poll, perhaps evenwaking up the screenagain. Batterylife
would drain significantly.
Connected Standby addresses this problem by virtually freezing the com-
puterwhenthepowerbuttonispressedorthescreenturnsoff—withoutreally
puttingthecomputertosleep.Thehardwareclockisstopped,allprocessesand
servicesare suspended, and all timer expirations are delayed 30 minutes. The
net effect, even though the computer is still running, is that it runs in such a
almost-totalstateofidlenessthattheprocessorandperipheralscaneffectively
run in their lowest power state. Special hardware and firmware are required
to fully support this mode; for example, the Surface-branded tablet hardware
includesthiscapability.
21.2.9 Dynamic Device Support
Early in the history of the PCindustry, computer configurations were fairly
static, although new devices might occasionally be plugged into the serial,
printer, or game ports on the back of a computer. The next steps toward
dynamicconfigurationof PCswerelaptopdocksand PCMCIAcards.Usingsuch
a device, a PCcould quickly be connected to or disconnected from a full set
of peripherals. Contemporary PCs are designed to enable users to plug and
unpluga huge host of peripheralsfrequently.
Support for dynamic configuration of devices is continually evolving in
Windows. The system can automatically recognize devices when they are
pluggedinandcanfind,install,andloadtheappropriatedrivers—oftenwith-
outuserintervention.Whendevicesareunplugged,thedriversautomatically
unload, and system execution continues without disrupting other software.
Additionally, Windows Update permits downloading of third-party drivers"
2,21.3 System Components,980,21.2 Design Principles,"838 Chapter 21 Windows 10
directly through Microsoft, avoiding the usage of installation DVDso rh a v i n g
the userscour the manufacturer’s website.
Beyond peripherals, Windows Serveralso supports dynamic hot-add and
hot-replace of CPUsa n dRAM,a sw e l la sd y n a m i ch o t - r e m o v eo f RAM.T h e s e
features allow the components to be added, replaced, or removed without
system interruption. While of limited us e in physical servers, this technology
is key to dynamic scalability in cloud comp uting, especially in Infrastructure-
as-a-Service (IaaS) and cloud computing environments. In these scenarios,
a physical machine can be configured to support a limited number of its
processors based on a service fee, which can then be dynamically upgraded,
withoutrequiringareboot,throughacompatiblehypervisorsuchasHyper-V
and a simplesliderinthe owner’s userinterface.
21.3 System Components
The architecture of Windows is a layered system of modules operating at
specific privilege levels, as shown earlier in Figure 21.1. By default, these
privilegelevels are first implemented by the processor (providing a “vertical ”
privilegeisolationbetweenusermodeandkernelmode).Windows10canalso
use its Hyper-V hypervisor to provide an orthogonal (logically independent)
security model through Virtual Trust Levels (VTLs). When users enable this
feature, the system operates in a Virtual Secure Mode ( VSM). In this mode,
the layered privileged system now has two implementations, one called the
Normal World ,o rVTL0, and one called the Secure World ,o rVTL1. Within
each of theseworlds,wefind a usermodeand akernelmode.
Let’slookat this structurein somewhat more detail.
•IntheNormalWorld,inkernelmodeare(1)the HALanditsextensionsand
(2)thekernelanditsexecutive,whichloaddriversand DLLdependencies.
In user mode are a collection of systemprocesses, the Win 32environment
subsystem,andvariousservices.
•I nt h eS e c u r eW o r l d ,i f VSMis enabled, are a secure kernel and executive
(within which a secure micro-HALis embedded). Acollection of isolated
Trustlets (discussedlater)runinsecureusermode.
•Finally, the bottommost layer in Secure World runs in a special processor
mode (called, for example, VMXRoot Mode on Intel processors), which
containstheHyper-Vhypervisorcomponent,which useshardwarevirtu-
alizationtoconstructtheNormal-to-Secure-Worldboundary.(Theuser-to-
kernelboundary isprovidedby the CPUnatively.)
One of the chief advantages of this type of architecture is that interactions
betweenmodules,and betweenprivilegelevels,arekeptsimple,and that iso-
lationneedsandsecurityneedsarenotnecessarilyconflatedthroughprivilege.
Forexample,asecure,protectedcomponentthatstorespasswordscanitselfbe
unprivileged. In the past, operating-syst em designers chose to meet isolation
needsby making thesecurecomponent highly privileged,but thisresultsina
netloss for thesecurityof thesystemwhen this component iscompromised.
Theremainderof this sectiondescribestheselayersand subsystems."
3,21.3.1 Hyper-V Hypervisor,981,21.3 System Components,"21.3 System Components 839
21.3.1 Hyper-V Hypervisor
Thehypervisoristhefirstcomponentinitializedonasystemwith VSMenabled,
which happens as soon as the user enables the Hyper-V component. It is
used both to provide hardware virtualization features for running separate
virtual machines and to provide the VTLboundary and related access to the
hardware’s Second Level Address Translation ( SLAT) functionality (discussed
shortly). The hypervisor uses a CPU-specific virtualization extension, such as
AMD’s Pacifica ( SVMX) or Intel’s Vanderpool ( VT-x),to interceptany interrupt,
exception, memory access, instruction, port, or register access that it chooses
anddeny,modify,orredirecttheeffect,source,ordestinationoftheoperation.
It also provides a hypercall interface, which enables it to communicate with
the kernel in VTL0, the secure kernel in VTL1, and all other running virtual
machine kernelsand securekernels.
21.3.2 Secure Kernel
Thesecurekernelactsasthekernel-modeenvironmentofisolated( VTL1)user-
modeTrustletapplications(applicatio nsthatimplementpartsoftheWindows
securitymodel).Itprovidesthesamesystem-callinterfacethatthekerneldoes,
so that all interrupts, exceptions, and attempts to enter kernel mode from a
VTL1Trustletresultinenteringthesecurekernelinstead.However,thesecure
kernel is not involved in context switching, thread scheduling, memory man-
agement, interprocess-communication , or any of the other standard kernel
tasks.Additionally,nokernel-modedriversarepresentin VTL1.Inanattempt
to reduce the attack surface of the Secure World, these complex implementa-
tionsremaintheresponsibilityofNormalWorldcomponents.Thus,thesecure
kernel acts as a type of “proxy kernel ”that hands off the management of its
resources, paging, scheduling, and m ore, to the regular kernel services in VTL
0.ThisdoesmaketheSecureWorldvulnerabletodenial-of-serviceattacks,but
that is a reasonable tradeoff of the security design, which values data privacy
andintegrityoverserviceguarantees.
In addition to forwarding system calls, the secure kernel’s other responsi-
bilityisprovidingaccesstothehardwaresecrets,thetrustedplatformmodule
(TPM), and code integrity policies that were captured at boot. With this infor-
mation, Trustlets can encrypt and dec rypt data with keys that the Normal
World cannot obtain and can sign and attest (co-sign by Microsoft) reports
with integrity tokens that cannot be faked or replicated outside of the Secure
World. Using a CPUfeature called Second Level Address Translation ( SLAT),
thesecurekernelalsoprovidestheabilitytoallocatevirtualmemoryinsucha
way that the physical pages backing it cannot be seen at all from the Normal
World.Windows 10 uses thesecapabilities to provideadditional protectionof
enterprisecredentialsthrough afeaturecalledCredentialGuard.
Furthermore,whenDeviceGuard(mentionedearlier)isactivated,ittakes
advantage of VTL1 capabilities by moving all digital signature checking into
thesecurekernel.Thismeansthatevenifattackedthroughasoftwarevulner-
ability,thenormalkernelcannotbeforcedtoloadunsigneddrivers,asthe VTL
1 boundary would have to be breached for that to occur. On a Device Guard–
protectedsystem,for a kernel-modepage in VTL0 to be authorized for execu-
tion, the kernel must first ask permission from the secure kernel, and only the
securekernelcangrant thispageexecutableaccess. Moresecuredeployments"
3,21.3.2 Secure Kernel,981,21.3.1 Hyper-V Hypervisor,"21.3 System Components 839
21.3.1 Hyper-V Hypervisor
Thehypervisoristhefirstcomponentinitializedonasystemwith VSMenabled,
which happens as soon as the user enables the Hyper-V component. It is
used both to provide hardware virtualization features for running separate
virtual machines and to provide the VTLboundary and related access to the
hardware’s Second Level Address Translation ( SLAT) functionality (discussed
shortly). The hypervisor uses a CPU-specific virtualization extension, such as
AMD’s Pacifica ( SVMX) or Intel’s Vanderpool ( VT-x),to interceptany interrupt,
exception, memory access, instruction, port, or register access that it chooses
anddeny,modify,orredirecttheeffect,source,ordestinationoftheoperation.
It also provides a hypercall interface, which enables it to communicate with
the kernel in VTL0, the secure kernel in VTL1, and all other running virtual
machine kernelsand securekernels.
21.3.2 Secure Kernel
Thesecurekernelactsasthekernel-modeenvironmentofisolated( VTL1)user-
modeTrustletapplications(applicatio nsthatimplementpartsoftheWindows
securitymodel).Itprovidesthesamesystem-callinterfacethatthekerneldoes,
so that all interrupts, exceptions, and attempts to enter kernel mode from a
VTL1Trustletresultinenteringthesecurekernelinstead.However,thesecure
kernel is not involved in context switching, thread scheduling, memory man-
agement, interprocess-communication , or any of the other standard kernel
tasks.Additionally,nokernel-modedriversarepresentin VTL1.Inanattempt
to reduce the attack surface of the Secure World, these complex implementa-
tionsremaintheresponsibilityofNormalWorldcomponents.Thus,thesecure
kernel acts as a type of “proxy kernel ”that hands off the management of its
resources, paging, scheduling, and m ore, to the regular kernel services in VTL
0.ThisdoesmaketheSecureWorldvulnerabletodenial-of-serviceattacks,but
that is a reasonable tradeoff of the security design, which values data privacy
andintegrityoverserviceguarantees.
In addition to forwarding system calls, the secure kernel’s other responsi-
bilityisprovidingaccesstothehardwaresecrets,thetrustedplatformmodule
(TPM), and code integrity policies that were captured at boot. With this infor-
mation, Trustlets can encrypt and dec rypt data with keys that the Normal
World cannot obtain and can sign and attest (co-sign by Microsoft) reports
with integrity tokens that cannot be faked or replicated outside of the Secure
World. Using a CPUfeature called Second Level Address Translation ( SLAT),
thesecurekernelalsoprovidestheabilitytoallocatevirtualmemoryinsucha
way that the physical pages backing it cannot be seen at all from the Normal
World.Windows 10 uses thesecapabilities to provideadditional protectionof
enterprisecredentialsthrough afeaturecalledCredentialGuard.
Furthermore,whenDeviceGuard(mentionedearlier)isactivated,ittakes
advantage of VTL1 capabilities by moving all digital signature checking into
thesecurekernel.Thismeansthatevenifattackedthroughasoftwarevulner-
ability,thenormalkernelcannotbeforcedtoloadunsigneddrivers,asthe VTL
1 boundary would have to be breached for that to occur. On a Device Guard–
protectedsystem,for a kernel-modepage in VTL0 to be authorized for execu-
tion, the kernel must first ask permission from the secure kernel, and only the
securekernelcangrant thispageexecutableaccess. Moresecuredeployments"
3,21.3.3 Hardware-Abstraction Layer,982,21.3.2 Secure Kernel,"840 Chapter 21 Windows 10
(such as in embeddedor high-risk systems) can require this level of signature
validationforuser-modepagesas well.
Additionally, work is being done to allow special classes of hardware
devices, such as USBwebcams and smartcard readers, to be directly managed
byuser-modedriversrunningin VTL1(usingthe UMDFframeworkdescribed
later), allowing biometric data to be securely captured in VTL1w i t h o u ta n y
component in the Normal World being able to interceptit. Currently,the only
Trustlets allowed are those that providethe Microsoft-signed implementation
of Credential Guard and virtual- TPMsupport. Newer versions of Windows
10 will also support VSM Enclaves , which will allow validly signed (but not
necessarily Microsoft-signed) third-party code wishing to perform its own
cryptographic calculations to do so. Software enclaves will allow regular VTL
0 applications to “call into ”an enclave, which will run executable code on top
of inputdata andreturn presumablyencryptedoutputdata.
Formoreinformationonthesecurekernel,see https://blogs.technet.micro
soft.com/ash/2016/03/02/windows-10-d evice-guard-and-credential-guard-d
emystiﬁed/ .
21.3.3 Hardware-Abstraction Layer
TheHALis the layer of software that hides hardware chipset differences
from upper levels of the operating system. The HALexports a virtual hard-
ware interface that is used by the kernel dispatcher, the executive, and the
device drivers. Only a single version of each device driver is required for
eachCPUarchitecture,nomatterwhatsupportchipsmightbepresent.Device
drivers map devices and access them directly, but the chipset-specific details
of mapping memory, configuring I/Obuses, setting up DMA, and coping with
motherboard-specific facilitiesareallprovidedby the HALinterfaces.
21.3.4 Kernel
The kernel layer of Windows has the following main responsibilities: thread
scheduling and context switching, low-level processor synchronization, inter-
rupt and exception handling, and switching between user mode and kernel
mode through the system-call interface. Additionally, the kernel layer imple-
mentstheinitialcodethattakesoverfromthebootloader,formalizingthetran-
sition into the Windows operating system. It also implements the initial code
that safely crashes the kernelin case of an unexpectedexception, assertion, or
otherinconsistency.Thekernelismost lyimplementedintheClanguage,using
assemblylanguageonlywhenabsolutelynecessarytointerfacewiththelowest
levelofthe hardwarearchitectureand whendirectregisteraccess is needed.
21.3.4.1 Dispatcher
The dispatcherprovidesthe foundation forthe executiveand the subsystems.
Most of the dispatcher is never paged out of memory, and its execution is
never preempted. Its main responsibilit ies are thread scheduling and context
switching,implementationofsynchroni zationprimitives,timermanagement,
software interrupts (asynchronous and deferred procedure calls), interproces-
sor interrupts ( IPIs) and exception dispatching. It also manages hardware and"
3,21.3.4 Kernel,982,21.3.3 Hardware-Abstraction Layer,"840 Chapter 21 Windows 10
(such as in embeddedor high-risk systems) can require this level of signature
validationforuser-modepagesas well.
Additionally, work is being done to allow special classes of hardware
devices, such as USBwebcams and smartcard readers, to be directly managed
byuser-modedriversrunningin VTL1(usingthe UMDFframeworkdescribed
later), allowing biometric data to be securely captured in VTL1w i t h o u ta n y
component in the Normal World being able to interceptit. Currently,the only
Trustlets allowed are those that providethe Microsoft-signed implementation
of Credential Guard and virtual- TPMsupport. Newer versions of Windows
10 will also support VSM Enclaves , which will allow validly signed (but not
necessarily Microsoft-signed) third-party code wishing to perform its own
cryptographic calculations to do so. Software enclaves will allow regular VTL
0 applications to “call into ”an enclave, which will run executable code on top
of inputdata andreturn presumablyencryptedoutputdata.
Formoreinformationonthesecurekernel,see https://blogs.technet.micro
soft.com/ash/2016/03/02/windows-10-d evice-guard-and-credential-guard-d
emystiﬁed/ .
21.3.3 Hardware-Abstraction Layer
TheHALis the layer of software that hides hardware chipset differences
from upper levels of the operating system. The HALexports a virtual hard-
ware interface that is used by the kernel dispatcher, the executive, and the
device drivers. Only a single version of each device driver is required for
eachCPUarchitecture,nomatterwhatsupportchipsmightbepresent.Device
drivers map devices and access them directly, but the chipset-specific details
of mapping memory, configuring I/Obuses, setting up DMA, and coping with
motherboard-specific facilitiesareallprovidedby the HALinterfaces.
21.3.4 Kernel
The kernel layer of Windows has the following main responsibilities: thread
scheduling and context switching, low-level processor synchronization, inter-
rupt and exception handling, and switching between user mode and kernel
mode through the system-call interface. Additionally, the kernel layer imple-
mentstheinitialcodethattakesoverfromthebootloader,formalizingthetran-
sition into the Windows operating system. It also implements the initial code
that safely crashes the kernelin case of an unexpectedexception, assertion, or
otherinconsistency.Thekernelismost lyimplementedintheClanguage,using
assemblylanguageonlywhenabsolutelynecessarytointerfacewiththelowest
levelofthe hardwarearchitectureand whendirectregisteraccess is needed.
21.3.4.1 Dispatcher
The dispatcherprovidesthe foundation forthe executiveand the subsystems.
Most of the dispatcher is never paged out of memory, and its execution is
never preempted. Its main responsibilit ies are thread scheduling and context
switching,implementationofsynchroni zationprimitives,timermanagement,
software interrupts (asynchronous and deferred procedure calls), interproces-
sor interrupts ( IPIs) and exception dispatching. It also manages hardware and"
3,21.3.5 Executive,990,21.3.4 Kernel,"848 Chapter 21 Windows 10
Exceptionhandlingismorecomplexforuser-modeprocesses,becausethe
Windows error reporting ( WER) service sets up an ALPCerror port for every
process, on top of the Win 32environment subsystem, which sets up an ALPC
exception port for every process it creates. (For details on ports, see Section
21.3.5.4.)Furthermore,if a process is being debugged,it getsa debuggerport.
If a debugger port is registered, the exc eption handler sends the exception to
theport.Ifthedebuggerportisnotfoundordoesnothandlethatexception,the
dispatcherattemptstofind an appropriateexceptionhandler.Ifnone exists,it
contactsthedefaultunhandledexceptionhandler,whichwillnotify WERofthe
process crash so that a crash dump can be generated and sent to Microsoft. If
thereisahandler,butitrefusestohandletheexception,thedebuggeriscalled
againtocatchtheerrorfordebugging.Ifnodebuggerisrunning,amessageis
senttotheprocess’sexceptionporttogi vetheenvironmentsubsystemachance
to react to the exception. Finally, a message is sent to WERthrough the error
port, in the case where the unhandled exception handler may not have had a
chance to do so, and then the kernelsimpl y terminatesthe process containing
the thread that caused the exception.
WERwilltypicallysendtheinformationbacktoMicrosoftforfurtheranal-
ysis,unless the userhas optedout or is using a local error-reportingserver.In
somecases,Microsoft’sautomatedanalysismaybeabletorecognizetheerror
immediatelyand suggesta fix orworkaround.
The interrupt dispatcher in the kernel handles interrupts by calling either
an interrupt service routine ( ISR) supplied by a device driver or a kernel trap-
handler routine. The interrupt is represented by an interrupt object that con-
tains all the information needed to handle the interrupt. Using an interrupt
object makes it easy to associate interrupt-service routines with an interrupt
without having to access the interrupthardware directly.
Differentprocessorarchitectureshavedifferenttypesandnumbersofinter-
rupts. For portability, the interrupt dispatcher maps the hardware interrupts
into a standardset.
The kernel uses an interrupt-dispatch table to bind each interrupt level
to a service routine. In a multiprocessor computer, Windows keeps a separate
interrupt-dispatch table ( IDT) for each processor core, and each processor’s
IRQLcanbesetindependentlytomaskoutinterrupts.Allinterruptsthatoccur
at a level equal to or less than the IRQLof a processor are blocked until the
IRQLis lowered by a kernel-level thread or by an ISRreturning from interrupt
processing.Windowstakesadvantageof thispropertyandusessoftwareinter-
ruptsto deliver APCsa n dDPCs, to performsystem functions such as synchro-
nizing threads with I/Ocompletion, to start thread execution, and to handle
timers.
21.3.5 Executive
The Windows executive provides a set of services that all environment sub-
systems use. To give you a good basic overview, we discuss the following
services here: object manager, virtual memory manager, process manager,
advanced local procedure call facility, I/Omanager, cache manager, security
reference monitor, plug-and-play and power managers, registry, and startup.
Note, though, that the Windows executive includes more than two dozen ser-
vicesintotal."
2,21.4 Terminal Services and Fast User Switching,1016,21.3 System Components,"874 Chapter 21 Windows 10
givesdriversachancetoreinitializedevicesandgivestheappearanceofafull
boot while work isstilloccurring.
21.4 Terminal Services and Fast User Switching
Windows supports a GUI-based console that interfaces with the user via key-
board, mouse, and display. Most systems also support audio and video. For
example,audioinputisusedbyCortana,Windows’svoice-recognitionandvir-
tualassistantsoftware,whichispower edbymachinelearning.Cortanamakes
the system more convenient and can also increase its accessibility for users
withmotor disabilities.Windows 7 addedsupportfor multi-touch hardware ,
allowing users to input data by touching the screen with one or more fingers.
Video-inputcapabilityisusedbothforaccessibilityandforsecurity:Windows
Hello is a security feature in which adv anced 3D heat-sensing, face-mapping
camerasandsensorscanbeusedtouniquelyidentifytheuserwithoutrequir-
ingtraditionalcredentials.InnewerversionsofWindows10,eye-motionsens-
ing hardware—in which mouse input is replaced by information on the posi-
tionandgazeoftheeyeballs—canbeusedforaccessibility.Otherfutureinput
experiences will likely evolve from Microsoft’s HoloLens augmented-reality
product.
ThePCwas, of course, envisioned as a personalcomputer —an inherently
single-user machine. For some time, however, Windows has supported the
sharingofa PCamongmultipleusers.Eachuserwhoisloggedonusingthe GUI
hasa sessioncreatedtorepresentthe GUIenvironmenthewillbeusingandto
contain all the processes necessary to run his applications. Windows allows
multiple sessions to exist at the same time on a single machine. However,
client versions of Windows support only a single console, consisting of all the
monitors, keyboards, and mice connected to the PC. Only one session can be
connected to the console at a time. From the logon screen displayed on the
console, users can create new sessions or attach to an existing session. This
allows multiple users to share a single PCwithout having to log off and on
between users. Microsoft calls this use of sessions fastuserswitching. macOS
has a similarfeature.
Au s e ro no n e PCcan also create a new session or connect to an existing
session on another computer, which becomes a remote desktop .T h et e r m i n a l
services feature ( TS) makes the connection through a protocol called Remote
DesktopProtocol( RDP).Usersoftenemploythisfeaturetoconnecttoasession
on a work PCfrom a home PC. Remote desktops can also be used for remote
troubleshooting scenarios: a remote user can be invited to share a session
with the user logged on to the session on the console. The remote user can
watch the user’s actions and can even be given control of the desktop to
help resolve computing problems. This latter use of terminal services uses
the“mirroring ”feature,wherethealternativeuserissharingthesamesession
insteadof creatinga separateone.
Many corporations use corporate systems maintained in data centers to
run all user sessions that access corporate resources, rather than allowing
users to access those resources from their PCs, by exclusivelydedicatingthese
machines as terminal servers. Each server computer may handle hundreds of
remote-desktop sessions. This is a form of thin-client computing ,i nw h i c h"
2,21.5 File System,1017,21.4 Terminal Services and Fast User Switching,"21.5 File System 875
individual computers rely on a server for many functions. Relying on data-
centerterminalserversimprovesthere liability,manageability,andsecurityof
corporate computing resources.
21.5 File System
The native file system in Windows is NTFS. It is used for all local volumes.
However,associated USBthumbdrives,flashmemoryoncameras,andexternal
storagedevicesmaybeformattedwiththe32-bit FATfilesystemforportability.
FATis a much older file-system format that is understood by many systems
besides Windows, such as the software running on cameras. A disadvantage
is that the FATfile system does not restrict file access to authorized users. The
onlysolutionforsecuringdatawith FATistorunanapplicationtoencryptthe
databeforestoringit on thefile system.
In contrast, NTFSusesACLs to control access to individual files and sup-
portsimplicitencryptionofindividual filesorentirevolumes(usingWindows
BitLocker feature). NTFSimplements many other features as well, including
data recovery, fault tolerance, very large files and file systems, multiple data
streams, UNICODE names,sparsefiles,journaling,volumeshadowcopies,and
filecompression.
21.5.1 NTFS Internal Layout
Thefundamentalentityin NTFSisthevolume.AvolumeiscreatedbytheWin-
dows logical disk management utility and is based on a logical disk partition.
Avolume may occupy a portion of a device or an entire device, or may span
several devices. The volume manager can protect the contents of the volume
withvariouslevelsof RAID.
NTFSdoes not deal with individual sectors of a storage device but instead
uses clusters as the units of storage allocation. The cluster size, which is a
power of 2, is configured when an NTFSfile system is formatted. The default
cluster size is based on the volume size—4 KBfor volumes larger than 2 GB.
Given the size of today’s storage devices, it may make sense to use cluster
sizeslargerthantheWindowsdefaultst oachievebetterperformance,although
theseperformancegainswillcomeattheexpenseofmoreinternalfragmenta-
tion.
NTFSuses logical cluster numbers (LCNs) as storage addresses. It assigns
thembynumberingclustersfromthebeginningofthedevicetotheend.Using
this scheme, the system can calculate a physical storage offset (in bytes) by
multiplyingthe LCNby theclustersize.
A file in NTFSis not a simple byte stream as it is in UNIX; rather, it is a
structured object consisting of typed attributes .E a c ha t t r i b u t eo fafi l ei sa n
independentbytestreamthatcanbecreated,deleted,read,andwritten.Some
attribute types are standard for all files, including the file name (or names, if
the file has aliases, such as an MS-DOSshort name), the creation time, and the
securitydescriptorthat specifiestheaccess controllist.Userdataarestoredin
dataattributes .
Mosttraditionaldatafileshavean unnamed dataattributethatcontainsall
the file’s data. However, additional data streams can be created with explicit
names. The IProp interfaces of the Component Object Model (discussed later"
3,21.5.1 NTFS Internal Layout,1017,21.5 File System,"21.5 File System 875
individual computers rely on a server for many functions. Relying on data-
centerterminalserversimprovesthere liability,manageability,andsecurityof
corporate computing resources.
21.5 File System
The native file system in Windows is NTFS. It is used for all local volumes.
However,associated USBthumbdrives,flashmemoryoncameras,andexternal
storagedevicesmaybeformattedwiththe32-bit FATfilesystemforportability.
FATis a much older file-system format that is understood by many systems
besides Windows, such as the software running on cameras. A disadvantage
is that the FATfile system does not restrict file access to authorized users. The
onlysolutionforsecuringdatawith FATistorunanapplicationtoencryptthe
databeforestoringit on thefile system.
In contrast, NTFSusesACLs to control access to individual files and sup-
portsimplicitencryptionofindividual filesorentirevolumes(usingWindows
BitLocker feature). NTFSimplements many other features as well, including
data recovery, fault tolerance, very large files and file systems, multiple data
streams, UNICODE names,sparsefiles,journaling,volumeshadowcopies,and
filecompression.
21.5.1 NTFS Internal Layout
Thefundamentalentityin NTFSisthevolume.AvolumeiscreatedbytheWin-
dows logical disk management utility and is based on a logical disk partition.
Avolume may occupy a portion of a device or an entire device, or may span
several devices. The volume manager can protect the contents of the volume
withvariouslevelsof RAID.
NTFSdoes not deal with individual sectors of a storage device but instead
uses clusters as the units of storage allocation. The cluster size, which is a
power of 2, is configured when an NTFSfile system is formatted. The default
cluster size is based on the volume size—4 KBfor volumes larger than 2 GB.
Given the size of today’s storage devices, it may make sense to use cluster
sizeslargerthantheWindowsdefaultst oachievebetterperformance,although
theseperformancegainswillcomeattheexpenseofmoreinternalfragmenta-
tion.
NTFSuses logical cluster numbers (LCNs) as storage addresses. It assigns
thembynumberingclustersfromthebeginningofthedevicetotheend.Using
this scheme, the system can calculate a physical storage offset (in bytes) by
multiplyingthe LCNby theclustersize.
A file in NTFSis not a simple byte stream as it is in UNIX; rather, it is a
structured object consisting of typed attributes .E a c ha t t r i b u t eo fafi l ei sa n
independentbytestreamthatcanbecreated,deleted,read,andwritten.Some
attribute types are standard for all files, including the file name (or names, if
the file has aliases, such as an MS-DOSshort name), the creation time, and the
securitydescriptorthat specifiestheaccess controllist.Userdataarestoredin
dataattributes .
Mosttraditionaldatafileshavean unnamed dataattributethatcontainsall
the file’s data. However, additional data streams can be created with explicit
names. The IProp interfaces of the Component Object Model (discussed later"
3,21.5.2 Recovery,1019,21.5.1 NTFS Internal Layout,"21.5 File System 877
beencorruptedandneedstobecheckedforconsistencyusingthe chkdsk
program.
•The attribute-definitio table indicates which attribute types are used in
the volumeand what operationscan beperformedoneachof them.
•The root directory is thetop-leveldirectoryinthefile-systemhierarchy.
•The bitmap fil indicateswhich clusterson avolumeareallocatedtofiles
and which are free.
•Theboot fil containsthestartupcodeforWindowsandmustbelocatedat
aparticularsecondarystoragedeviceaddresssothatitcanbefoundeasily
by a simple ROMbootstrap loader.The boot file also contains the physical
addressof the MFT.
•The bad-cluster filekeepstrackofanybadareasonthevolume; NTFSuses
this record for error recovery.
Keeping all the NTFSmetadata in actual files has a useful property. As
discussed in Section 21.3.5.6, the cac he manager caches file data. Since all
theNTFSmetadata reside in files, these data can be cached using the same
mechanisms usedfor ordinarydata.
21.5.2 Recovery
In many simple file systems, a power failure at the wrong time can damage
thefile-systemdatastructuressoseverel ythattheentirevolumeisscrambled.
ManyUNIXfile systems,including UFSbut not ZFS, store redundant metadata
on the storage device, and they recover from crashes by using the fsckpro-
gram to check all the file-system data st ructures and restore them forcibly to
a consistent state. Restoring them of ten involves deleting damaged files and
freeing data clusters that had been written with user data but not properly
recorded in the file system’s metadata structures. This checking can be a slow
processand can resultin the lossof significant amounts of data.
NTFStakes a different approach to file-system robustness. In NTFS,a l lfi l e -
systemdata-structureupdatesareperformedinsidetransactions.Beforeadata
structure is altered, the transaction writes a log record that contains redo and
undo information. After the data struct ure has been changed, the transaction
writesa commit recordtothe logto signifythat thetransaction succeeded.
After a crash, the system can restore the file-system data structures to
a consistent state by processing the log records, first redoing the operations
for committed transactions (to be sure their changes reached the file system
data structures)and then undoing the operations for transactions that did not
commitsuccessfullybeforethecrash.Periodically(usuallyevery5seconds),a
checkpoint record is written to the log. The system does not need log records
prior to the checkpoint to recover from a crash. They can be discarded, so the
logfiledoesnotgrowwithoutbounds.Thefirsttimeaftersystemstartupthat
anNTFSvolumeisaccessed, NTFSautomaticallyperformsfile-systemrecovery.
This scheme does not guarantee that all the user-file contents are correct
aftera crash. It ensuresonly that the file-systemdata structures (the metadata
files)areundamagedandreflectsomeconsistentstatethatexistedpriortothe"
3,21.5.3 Security,1020,21.5.2 Recovery,"878 Chapter 21 Windows 10
crash.Itwouldbepossibletoextendthetransactionschemetocoveruserfiles,
and Microsofttook some stepstodo thisin Windows Vista.
The logis storedin the third metadatafile at the beginning ofthe volume.
It is created with a fixed maximum size when the file system is formatted. It
hastwosections:the loggingarea, whichisacircularqueueoflogrecords,and
therestart area, which holds context information, such as the position in the
logging area where NTFSshould start reading during a recovery. In fact, the
restart area holds two copies of its information, so recovery is still possible if
one copy isdamagedduring the crash.
The logging functionality is provided by the log-file service. In addition
towritingthelogrecordsandperformingrecoveryactions,thelog-fileservice
keepstrackofthefreespaceinthelogfile.Ifthefreespacegetstoolow,thelog-
fileservicequeuespendingtransactions,and NTFShaltsallnew I/Ooperations.
After the in-progress operations complete, NTFScalls the cache manager to
flushalldataandthenresetsthelogfileandperformsthequeuedtransactions.
21.5.3 Security
The security of an NTFSvolume is derived from the Windows object model.
EachNTFSfilereferencesasecuritydescriptor,whichspecifiestheownerofthe
file, and an access-control list, which contains the access permissions granted
or denied to each user or group listed. Early versions of NTFSused a separate
security descriptor as an attribute o f each file. Beginning with Windows 2000,
the security-descriptor attribute poi nts to a shared copy, with a significant
savings in storage space and caching space; many, many files have identical
securitydescriptors.
In normal operation, NTFSdoes not enforce permissions on traversal of
directories in file path names. However, for compatibility with POSIX,t h e s e
checks can be enabled. The latter option is inherently more expensive, since
modernparsingoffilepathnamesusesprefixmatchingratherthandirectory-
by-directoryparsingofpathnames.Prefixmatchingisanalgorithmthatlooks
upstringsinacacheandfindstheentrywiththelongestmatch—forexample,
anentryfor ∖foo∖bar∖dirwouldbeamatchfor ∖foo∖bar∖dir2∖dir3∖myfile.
The prefix-matching cache allows path-name traversal to begin much deeper
inthetree,savingmanysteps.Enforcingtraversalchecksmeansthattheuser’s
access must be checked at eachdirectorylevel.For instance, a usermight lack
permission to traverse ∖foo∖bar, so starting at the access for ∖foo∖bar∖dir
would be an error.
21.5.4 Compression
NTFScan perform data compression on individual files or on all data files
in a directory. To compress a file, NTFSdivides the file’s data into compres-
sion units , which are blocks of 16 contiguous clusters. When a compression
unit is written, a data-compression algorithm is applied. If the result fits into
fewer than 16 clusters, the compressed version is stored. When reading, NTFS
can determine whether data have been compressed: if they have been, the
length of the stored compression unit is less than 16 clusters. To improve per-
formance when reading contiguous compression units, NTFSprefetches and
decompressesaheadof theapplicationrequests."
3,21.5.4 Compression,1020,21.5.3 Security,"878 Chapter 21 Windows 10
crash.Itwouldbepossibletoextendthetransactionschemetocoveruserfiles,
and Microsofttook some stepstodo thisin Windows Vista.
The logis storedin the third metadatafile at the beginning ofthe volume.
It is created with a fixed maximum size when the file system is formatted. It
hastwosections:the loggingarea, whichisacircularqueueoflogrecords,and
therestart area, which holds context information, such as the position in the
logging area where NTFSshould start reading during a recovery. In fact, the
restart area holds two copies of its information, so recovery is still possible if
one copy isdamagedduring the crash.
The logging functionality is provided by the log-file service. In addition
towritingthelogrecordsandperformingrecoveryactions,thelog-fileservice
keepstrackofthefreespaceinthelogfile.Ifthefreespacegetstoolow,thelog-
fileservicequeuespendingtransactions,and NTFShaltsallnew I/Ooperations.
After the in-progress operations complete, NTFScalls the cache manager to
flushalldataandthenresetsthelogfileandperformsthequeuedtransactions.
21.5.3 Security
The security of an NTFSvolume is derived from the Windows object model.
EachNTFSfilereferencesasecuritydescriptor,whichspecifiestheownerofthe
file, and an access-control list, which contains the access permissions granted
or denied to each user or group listed. Early versions of NTFSused a separate
security descriptor as an attribute o f each file. Beginning with Windows 2000,
the security-descriptor attribute poi nts to a shared copy, with a significant
savings in storage space and caching space; many, many files have identical
securitydescriptors.
In normal operation, NTFSdoes not enforce permissions on traversal of
directories in file path names. However, for compatibility with POSIX,t h e s e
checks can be enabled. The latter option is inherently more expensive, since
modernparsingoffilepathnamesusesprefixmatchingratherthandirectory-
by-directoryparsingofpathnames.Prefixmatchingisanalgorithmthatlooks
upstringsinacacheandfindstheentrywiththelongestmatch—forexample,
anentryfor ∖foo∖bar∖dirwouldbeamatchfor ∖foo∖bar∖dir2∖dir3∖myfile.
The prefix-matching cache allows path-name traversal to begin much deeper
inthetree,savingmanysteps.Enforcingtraversalchecksmeansthattheuser’s
access must be checked at eachdirectorylevel.For instance, a usermight lack
permission to traverse ∖foo∖bar, so starting at the access for ∖foo∖bar∖dir
would be an error.
21.5.4 Compression
NTFScan perform data compression on individual files or on all data files
in a directory. To compress a file, NTFSdivides the file’s data into compres-
sion units , which are blocks of 16 contiguous clusters. When a compression
unit is written, a data-compression algorithm is applied. If the result fits into
fewer than 16 clusters, the compressed version is stored. When reading, NTFS
can determine whether data have been compressed: if they have been, the
length of the stored compression unit is less than 16 clusters. To improve per-
formance when reading contiguous compression units, NTFSprefetches and
decompressesaheadof theapplicationrequests."
3,"21.5.5 Mount Points, Symbolic Links, and Hard Links",1021,21.5.4 Compression,"21.5 File System 879
For sparse files or files that contain mostly zeros, NTFSuses another tech-
nique to save space. Clusters that contain only zeros because they have never
been written are not actually allocated or stored on storage devices. Instead,
gapsareleftinthesequenceofvirtual-clusternumbersstoredinthe MFTentry
forthe file. When readinga file, if NTFSfinds agap inthe virtual-clusternum-
bers, it just zero-fills that portion of the caller’s buffer. This technique is also
usedby UNIX.
21.5.5 Mount Points, Symbolic Links, and Hard Links
Mount points are a form of symbolic link specific to directories on NTFSthat
were introducedin Windows 2000. They providea mechanism for organizing
s t o r a g ev o l u m e st h a ti sm o r efl e x i b l et h a nt h eu s eo fg l o b a ln a m e s( l i k ed r i v e
letters).Amountpointisimplementedasasymboliclinkwithassociateddata
containingthetruevolumename.Ultimately,mountpointswillsupplantdrive
letterscompletely,buttherewillbealongtransitionduetothedependenceof
many applicationsonthe drive-letterscheme.
Windows Vista introduced support for a more general form of symbolic
links,similartothosefoundin UNIX.Thelinkscanbeabsoluteorrelative,can
point to objects that do not exist, and can point to both files and directories
evenacrossvolumes. NTFSalsosupports hard links ,whereasinglefilehasan
entryin more than one directoryof the same volume.
21.5.6 Change Journal
NTFSkeeps a journal describing all changes that have been made to the file
system.User-modeservicescan receivenotifications of changes to the journal
and then identify what files have changed by reading from the journal. The
search indexer service uses the change journal to identify files that need to be
re-indexed. The file-replication service uses it to identify files that need to be
replicatedacross thenetwork.
21.5.7 Volume Shadow Copies
Windowsimplementsthecapabilityofbringingavolumetoaknownstateand
then creating a shadow copy that can be used to back up a consistent view of
the volume. This technique is known as snapshots in some other file systems.
Making a shadow copy of a volume is a form of copy-on-write, where blocks
modified after the shadow copy is created are stored in their original form in
the copy. Achieving a consistent state for the volumerequiresthe cooperation
of applications, since the system cannot know when the data used by the
application are in a stable state from which the application could be safely
restarted.
TheserverversionofWindowsusesshadowcopiestoefficientlymaintain
old versions of files stored on file servers. This allows users to see documents
astheyexistedatearlierpointsintime.Ausercanthus recoverfilesthatwere
accidentallydeletedorsimplylookatapreviousversionofthefile,allwithout
pullingoutbackup media."
3,21.5.6 Change Journal,1021,"21.5.5 Mount Points, Symbolic Links, and Hard Links","21.5 File System 879
For sparse files or files that contain mostly zeros, NTFSuses another tech-
nique to save space. Clusters that contain only zeros because they have never
been written are not actually allocated or stored on storage devices. Instead,
gapsareleftinthesequenceofvirtual-clusternumbersstoredinthe MFTentry
forthe file. When readinga file, if NTFSfinds agap inthe virtual-clusternum-
bers, it just zero-fills that portion of the caller’s buffer. This technique is also
usedby UNIX.
21.5.5 Mount Points, Symbolic Links, and Hard Links
Mount points are a form of symbolic link specific to directories on NTFSthat
were introducedin Windows 2000. They providea mechanism for organizing
s t o r a g ev o l u m e st h a ti sm o r efl e x i b l et h a nt h eu s eo fg l o b a ln a m e s( l i k ed r i v e
letters).Amountpointisimplementedasasymboliclinkwithassociateddata
containingthetruevolumename.Ultimately,mountpointswillsupplantdrive
letterscompletely,buttherewillbealongtransitionduetothedependenceof
many applicationsonthe drive-letterscheme.
Windows Vista introduced support for a more general form of symbolic
links,similartothosefoundin UNIX.Thelinkscanbeabsoluteorrelative,can
point to objects that do not exist, and can point to both files and directories
evenacrossvolumes. NTFSalsosupports hard links ,whereasinglefilehasan
entryin more than one directoryof the same volume.
21.5.6 Change Journal
NTFSkeeps a journal describing all changes that have been made to the file
system.User-modeservicescan receivenotifications of changes to the journal
and then identify what files have changed by reading from the journal. The
search indexer service uses the change journal to identify files that need to be
re-indexed. The file-replication service uses it to identify files that need to be
replicatedacross thenetwork.
21.5.7 Volume Shadow Copies
Windowsimplementsthecapabilityofbringingavolumetoaknownstateand
then creating a shadow copy that can be used to back up a consistent view of
the volume. This technique is known as snapshots in some other file systems.
Making a shadow copy of a volume is a form of copy-on-write, where blocks
modified after the shadow copy is created are stored in their original form in
the copy. Achieving a consistent state for the volumerequiresthe cooperation
of applications, since the system cannot know when the data used by the
application are in a stable state from which the application could be safely
restarted.
TheserverversionofWindowsusesshadowcopiestoefficientlymaintain
old versions of files stored on file servers. This allows users to see documents
astheyexistedatearlierpointsintime.Ausercanthus recoverfilesthatwere
accidentallydeletedorsimplylookatapreviousversionofthefile,allwithout
pullingoutbackup media."
3,21.5.7 Volume Shadow Copies,1021,21.5.6 Change Journal,"21.5 File System 879
For sparse files or files that contain mostly zeros, NTFSuses another tech-
nique to save space. Clusters that contain only zeros because they have never
been written are not actually allocated or stored on storage devices. Instead,
gapsareleftinthesequenceofvirtual-clusternumbersstoredinthe MFTentry
forthe file. When readinga file, if NTFSfinds agap inthe virtual-clusternum-
bers, it just zero-fills that portion of the caller’s buffer. This technique is also
usedby UNIX.
21.5.5 Mount Points, Symbolic Links, and Hard Links
Mount points are a form of symbolic link specific to directories on NTFSthat
were introducedin Windows 2000. They providea mechanism for organizing
s t o r a g ev o l u m e st h a ti sm o r efl e x i b l et h a nt h eu s eo fg l o b a ln a m e s( l i k ed r i v e
letters).Amountpointisimplementedasasymboliclinkwithassociateddata
containingthetruevolumename.Ultimately,mountpointswillsupplantdrive
letterscompletely,buttherewillbealongtransitionduetothedependenceof
many applicationsonthe drive-letterscheme.
Windows Vista introduced support for a more general form of symbolic
links,similartothosefoundin UNIX.Thelinkscanbeabsoluteorrelative,can
point to objects that do not exist, and can point to both files and directories
evenacrossvolumes. NTFSalsosupports hard links ,whereasinglefilehasan
entryin more than one directoryof the same volume.
21.5.6 Change Journal
NTFSkeeps a journal describing all changes that have been made to the file
system.User-modeservicescan receivenotifications of changes to the journal
and then identify what files have changed by reading from the journal. The
search indexer service uses the change journal to identify files that need to be
re-indexed. The file-replication service uses it to identify files that need to be
replicatedacross thenetwork.
21.5.7 Volume Shadow Copies
Windowsimplementsthecapabilityofbringingavolumetoaknownstateand
then creating a shadow copy that can be used to back up a consistent view of
the volume. This technique is known as snapshots in some other file systems.
Making a shadow copy of a volume is a form of copy-on-write, where blocks
modified after the shadow copy is created are stored in their original form in
the copy. Achieving a consistent state for the volumerequiresthe cooperation
of applications, since the system cannot know when the data used by the
application are in a stable state from which the application could be safely
restarted.
TheserverversionofWindowsusesshadowcopiestoefficientlymaintain
old versions of files stored on file servers. This allows users to see documents
astheyexistedatearlierpointsintime.Ausercanthus recoverfilesthatwere
accidentallydeletedorsimplylookatapreviousversionofthefile,allwithout
pullingoutbackup media."
2,21.6 Networking,1022,21.5 File System,"880 Chapter 21 Windows 10
21.6 Networking
Windows supports both peer-to-peer and client–server networking. It also
has facilities for network management. The networking components in Win-
dows provide data transport, interprocess communication, file sharing across
a network,and theability tosendprintjobs to remoteprinters.
21.6.1 Network Interfaces
TodescribenetworkinginWindows,wemustfirstmentiontwooftheinternal
networkinginterfaces:the Network Device Interface specificatio (NDIS)and
theTransport Driver Interface (TDI).TheNDISinterfacewasdevelopedin1989
byMicrosoftand3Comtoseparatenetworkadaptersfromtransportprotocols
so that either could be changed without affecting the other. NDISresides at
the interface between the data-link and network layers in the ISOmodel and
enables many protocols to operate over many different network adapters. In
terms of the ISOmodel, the TDIis the interface between the transport layer
(layer4)andthesessionlayer(layer5).Th isinterfaceenablesanysession-layer
component to use any available transpo rt mechanism. (Similar reasoning led
to the streams mechanism in UNIX.) TheTDIsupports both connection-based
and connectionless transport and has functions to send any type of data.
21.6.2 Protocols
Windows implements transport protocols as drivers. These drivers can be
loaded and unloaded from the system dynamically, although in practice the
system typically has to be rebooted after a change. Windows comes with
severalnetworking protocols.Next,we discussa number of theseprotocols.
21.6.2.1 Server Message Block
The Server Message Block (SMB) protocol was first introduced in MS-DOS
3.1. The system uses the protocol to send I/Orequests over the network.
TheSMBprotocol has four message types. Session control messages are
commandsthatstartandendaredirectorconnectiontoasharedresourceatthe
server. Aredirector uses Filemessages to access files at the server. Printer
messages are used to send data to a remote print queue and to receive status
information fromthequeue,and Message messagesareusedtocommunicate
with another workstation. A version of the SMBprotocol was published as
theCommon Internet File System (CIFS) and is supported on a number of
operatingsystems.
21.6.2.2 Transmission Control Protocol/Internet Protocol
Thetransmissioncontrolprotocol/Internetprotocol( TCP/IP)suitethatisused
on the Internet has become the de facto standard networking infrastructure.
Windows uses TCP/IPto connect to a wide variety of operating systems
and hardware platforms. The Windows TCP/IPpackage includes the simple
network-management protocol ( SNMP), the dynamic host-configuration pro-
tocol (DHCP), and the older Windows Internet name service ( WINS). Windows
Vista introduced a new implementation of TCP/IPthat supports both IPv4
andIPv6in the same network stack. This new implementation also supports"
3,21.6.1 Network Interfaces,1022,21.6 Networking,"880 Chapter 21 Windows 10
21.6 Networking
Windows supports both peer-to-peer and client–server networking. It also
has facilities for network management. The networking components in Win-
dows provide data transport, interprocess communication, file sharing across
a network,and theability tosendprintjobs to remoteprinters.
21.6.1 Network Interfaces
TodescribenetworkinginWindows,wemustfirstmentiontwooftheinternal
networkinginterfaces:the Network Device Interface specificatio (NDIS)and
theTransport Driver Interface (TDI).TheNDISinterfacewasdevelopedin1989
byMicrosoftand3Comtoseparatenetworkadaptersfromtransportprotocols
so that either could be changed without affecting the other. NDISresides at
the interface between the data-link and network layers in the ISOmodel and
enables many protocols to operate over many different network adapters. In
terms of the ISOmodel, the TDIis the interface between the transport layer
(layer4)andthesessionlayer(layer5).Th isinterfaceenablesanysession-layer
component to use any available transpo rt mechanism. (Similar reasoning led
to the streams mechanism in UNIX.) TheTDIsupports both connection-based
and connectionless transport and has functions to send any type of data.
21.6.2 Protocols
Windows implements transport protocols as drivers. These drivers can be
loaded and unloaded from the system dynamically, although in practice the
system typically has to be rebooted after a change. Windows comes with
severalnetworking protocols.Next,we discussa number of theseprotocols.
21.6.2.1 Server Message Block
The Server Message Block (SMB) protocol was first introduced in MS-DOS
3.1. The system uses the protocol to send I/Orequests over the network.
TheSMBprotocol has four message types. Session control messages are
commandsthatstartandendaredirectorconnectiontoasharedresourceatthe
server. Aredirector uses Filemessages to access files at the server. Printer
messages are used to send data to a remote print queue and to receive status
information fromthequeue,and Message messagesareusedtocommunicate
with another workstation. A version of the SMBprotocol was published as
theCommon Internet File System (CIFS) and is supported on a number of
operatingsystems.
21.6.2.2 Transmission Control Protocol/Internet Protocol
Thetransmissioncontrolprotocol/Internetprotocol( TCP/IP)suitethatisused
on the Internet has become the de facto standard networking infrastructure.
Windows uses TCP/IPto connect to a wide variety of operating systems
and hardware platforms. The Windows TCP/IPpackage includes the simple
network-management protocol ( SNMP), the dynamic host-configuration pro-
tocol (DHCP), and the older Windows Internet name service ( WINS). Windows
Vista introduced a new implementation of TCP/IPthat supports both IPv4
andIPv6in the same network stack. This new implementation also supports"
3,21.6.2 Protocols,1022,21.6.1 Network Interfaces,"880 Chapter 21 Windows 10
21.6 Networking
Windows supports both peer-to-peer and client–server networking. It also
has facilities for network management. The networking components in Win-
dows provide data transport, interprocess communication, file sharing across
a network,and theability tosendprintjobs to remoteprinters.
21.6.1 Network Interfaces
TodescribenetworkinginWindows,wemustfirstmentiontwooftheinternal
networkinginterfaces:the Network Device Interface specificatio (NDIS)and
theTransport Driver Interface (TDI).TheNDISinterfacewasdevelopedin1989
byMicrosoftand3Comtoseparatenetworkadaptersfromtransportprotocols
so that either could be changed without affecting the other. NDISresides at
the interface between the data-link and network layers in the ISOmodel and
enables many protocols to operate over many different network adapters. In
terms of the ISOmodel, the TDIis the interface between the transport layer
(layer4)andthesessionlayer(layer5).Th isinterfaceenablesanysession-layer
component to use any available transpo rt mechanism. (Similar reasoning led
to the streams mechanism in UNIX.) TheTDIsupports both connection-based
and connectionless transport and has functions to send any type of data.
21.6.2 Protocols
Windows implements transport protocols as drivers. These drivers can be
loaded and unloaded from the system dynamically, although in practice the
system typically has to be rebooted after a change. Windows comes with
severalnetworking protocols.Next,we discussa number of theseprotocols.
21.6.2.1 Server Message Block
The Server Message Block (SMB) protocol was first introduced in MS-DOS
3.1. The system uses the protocol to send I/Orequests over the network.
TheSMBprotocol has four message types. Session control messages are
commandsthatstartandendaredirectorconnectiontoasharedresourceatthe
server. Aredirector uses Filemessages to access files at the server. Printer
messages are used to send data to a remote print queue and to receive status
information fromthequeue,and Message messagesareusedtocommunicate
with another workstation. A version of the SMBprotocol was published as
theCommon Internet File System (CIFS) and is supported on a number of
operatingsystems.
21.6.2.2 Transmission Control Protocol/Internet Protocol
Thetransmissioncontrolprotocol/Internetprotocol( TCP/IP)suitethatisused
on the Internet has become the de facto standard networking infrastructure.
Windows uses TCP/IPto connect to a wide variety of operating systems
and hardware platforms. The Windows TCP/IPpackage includes the simple
network-management protocol ( SNMP), the dynamic host-configuration pro-
tocol (DHCP), and the older Windows Internet name service ( WINS). Windows
Vista introduced a new implementation of TCP/IPthat supports both IPv4
andIPv6in the same network stack. This new implementation also supports"
3,21.6.3 Redirectors and Servers,1024,21.6.2 Protocols,"882 Chapter 21 Windows 10
21.6.2.7 Remote Procedure Calls
Remote procedure calls ( RPCs), mentioned earlier, are client–server mecha-
nisms that enable an application on one machine to make a procedure call to
codeonanothermachine.Theclientcallsalocalprocedure—astubroutine—
which packsitsargumentsintoa messa geandsendsthemacross thenetwork
to a particular server process. The client-side stub routine then blocks. Mean-
while, the server unpacks the message, calls the procedure, packs the return
results into a message, and sends them back to the client stub. The client stub
unblocks, receives the message, unpacks the results of the RPC,a n dr e t u r n s
themtothecaller.Thispackingo fargumentsissometimescalled marshaling .
Theclientstubcodeandthedescriptorsnecessarytopackandunpacktheargu-
ments for an RPCare compiled from a specification written in the Microsoft
Interface Definitio Language .
The Windows RPCmechanism follows the widely used distributed-
computing-environment standard for RPCmessages, so programs written to
use Windows RPCs are highly portable. The RPCstandard is detailed. It hides
many of the architectural differences among computers, such as the sizes
of binary numbers and the order of bytes and bits in computer words, by
specifyingstandarddataformats for RPCmessages.
21.6.2.8 Component Object Model
The Component Object Model (COM) is a mechanism for interprocess com-
munication that was developed for Windows. A COMobject provides a well-
defined interface to manipulate the data in the object. For instance, COMis
the infrastructure used by Microsoft’s Object Linking and Embedding (OLE)
technology for inserting spreadsheets into Microsoft Word documents. Many
Windowsservicesprovide COMinterfaces.Inaddition,adistributedextension
called DCOMcanbeusedoveranetworkutilizing RPCtoprovideatransparent
methodof developingdistributedapplications.
21.6.3 Redirectors and Servers
In Windows, an application can use the Windows I/O APIto access files from
a remote computer as though they were local, provided that the remote com-
puterisrunninga CIFSserversuchasthoseprovidedbyWindows.A redirector
is the client-side object that forwards I/Orequests to a remote system, where
theyaresatisfiedbyaserver.Forperformanceandsecurity,theredirectorsand
serversruninkernelmode.
Inmoredetail,access to a remotefileoccurs as follows:
1.Theapplicationcallsthe I/Omanagertorequestthatafilebeopenedwith
a filename in thestandard UNCformat.
2.TheI/Omanager builds an I/Orequest packet, as described in Section
21.3.5.5.
3.TheI/Omanagerrecognizesthattheaccessisforaremotefileandcallsa
drivercalleda Multiple UNC Provider (MUP)."
3,21.6.4 Domains,1026,21.6.3 Redirectors and Servers,"884 Chapter 21 Windows 10
21.6.4 Domains
Manynetworkedenvironmentshavenat uralgroupsofusers,suchasstudents
in a computer laboratory at school or employees in one department in a busi-
ness. Frequently, we want all the members of the group to be able to access
sharedresourcesontheirvariouscomputersinthegroup.Tomanagetheglobal
accessrightswithinsuchgroups,Windowsusestheconceptofadomain.Pre-
viously, these domains had no relationship whatsoever to the domain-name
system ( DNS) that maps Internet host names to IPaddresses. Now, however,
theyarecloselyrelated.
Specifically, a Windows domain is a group of Windows workstations and
serversthatshareacommonsecuritypolicyanduserdatabase.SinceWindows
uses the Kerberosprotocol for trust and authentication, a Windows domain is
the same thing as a Kerberos realm. Windows uses a hierarchical approach
for establishing trust relationships between related domains. The trust rela-
tionships are based on DNSand allow transitive trusts that can flow up and
down the hierarchy. This approach reduces the number of trusts required for
ndomains from n∗(n−1) to O(n). The workstations in the domain trust
the domain controller to give correct information about the access rights of
each user (loaded into the user’s access token by lsaas). All users retain the
ability to restrict access to their own workstations, however, no matter what
any domain controllermay say.
21.6.5 Active Directory
Active Directory is the Windows implementation of Lightweight Directory-
Access Protocol (LDAP) services. Active Directory stores the topology infor-
mation about the domain, keeps the domain-based user and group accounts
andpasswords,andprovidesadomain-basedstoreforWindowsfeaturesthat
need it, such as Windows group policy . Administrators use group policies to
establish uniform standards for desktop preferences and software. For many
corporate information-technology groups, uniformity drastically reduces the
cost of computing.
21.7 Programmer Interface
TheWin 32 APIisthefundamentalinterfacetothecapabilitiesofWindows.This
section describes five main aspects of the Win 32 API: access to kernel objects,
sharing of objects betweenprocesses,processmanagement, interprocesscom-
munication, and memorymanagement.
21.7.1 Access to Kernel Objects
The Windows kernel provides many serv ices that application programs can
use. Application programs obtain these services by manipulating kernel
objects. A process gains access to a kernel object named XXXby calling the
Create XXXfunction to open a handle to an instance of XXX.T h i sh a n d l ei s
unique to the process. Depending on w hich object is being opened, if the
Create() function fails, it may return 0, or it may return a special constant
named INVALID
 HANDLE
 VALUE. Aprocess can close any handle by calling the"
3,21.6.5 Active Directory,1026,21.6.4 Domains,"884 Chapter 21 Windows 10
21.6.4 Domains
Manynetworkedenvironmentshavenat uralgroupsofusers,suchasstudents
in a computer laboratory at school or employees in one department in a busi-
ness. Frequently, we want all the members of the group to be able to access
sharedresourcesontheirvariouscomputersinthegroup.Tomanagetheglobal
accessrightswithinsuchgroups,Windowsusestheconceptofadomain.Pre-
viously, these domains had no relationship whatsoever to the domain-name
system ( DNS) that maps Internet host names to IPaddresses. Now, however,
theyarecloselyrelated.
Specifically, a Windows domain is a group of Windows workstations and
serversthatshareacommonsecuritypolicyanduserdatabase.SinceWindows
uses the Kerberosprotocol for trust and authentication, a Windows domain is
the same thing as a Kerberos realm. Windows uses a hierarchical approach
for establishing trust relationships between related domains. The trust rela-
tionships are based on DNSand allow transitive trusts that can flow up and
down the hierarchy. This approach reduces the number of trusts required for
ndomains from n∗(n−1) to O(n). The workstations in the domain trust
the domain controller to give correct information about the access rights of
each user (loaded into the user’s access token by lsaas). All users retain the
ability to restrict access to their own workstations, however, no matter what
any domain controllermay say.
21.6.5 Active Directory
Active Directory is the Windows implementation of Lightweight Directory-
Access Protocol (LDAP) services. Active Directory stores the topology infor-
mation about the domain, keeps the domain-based user and group accounts
andpasswords,andprovidesadomain-basedstoreforWindowsfeaturesthat
need it, such as Windows group policy . Administrators use group policies to
establish uniform standards for desktop preferences and software. For many
corporate information-technology groups, uniformity drastically reduces the
cost of computing.
21.7 Programmer Interface
TheWin 32 APIisthefundamentalinterfacetothecapabilitiesofWindows.This
section describes five main aspects of the Win 32 API: access to kernel objects,
sharing of objects betweenprocesses,processmanagement, interprocesscom-
munication, and memorymanagement.
21.7.1 Access to Kernel Objects
The Windows kernel provides many serv ices that application programs can
use. Application programs obtain these services by manipulating kernel
objects. A process gains access to a kernel object named XXXby calling the
Create XXXfunction to open a handle to an instance of XXX.T h i sh a n d l ei s
unique to the process. Depending on w hich object is being opened, if the
Create() function fails, it may return 0, or it may return a special constant
named INVALID
 HANDLE
 VALUE. Aprocess can close any handle by calling the"
2,21.7 Programmer Interface,1026,21.6 Networking,"884 Chapter 21 Windows 10
21.6.4 Domains
Manynetworkedenvironmentshavenat uralgroupsofusers,suchasstudents
in a computer laboratory at school or employees in one department in a busi-
ness. Frequently, we want all the members of the group to be able to access
sharedresourcesontheirvariouscomputersinthegroup.Tomanagetheglobal
accessrightswithinsuchgroups,Windowsusestheconceptofadomain.Pre-
viously, these domains had no relationship whatsoever to the domain-name
system ( DNS) that maps Internet host names to IPaddresses. Now, however,
theyarecloselyrelated.
Specifically, a Windows domain is a group of Windows workstations and
serversthatshareacommonsecuritypolicyanduserdatabase.SinceWindows
uses the Kerberosprotocol for trust and authentication, a Windows domain is
the same thing as a Kerberos realm. Windows uses a hierarchical approach
for establishing trust relationships between related domains. The trust rela-
tionships are based on DNSand allow transitive trusts that can flow up and
down the hierarchy. This approach reduces the number of trusts required for
ndomains from n∗(n−1) to O(n). The workstations in the domain trust
the domain controller to give correct information about the access rights of
each user (loaded into the user’s access token by lsaas). All users retain the
ability to restrict access to their own workstations, however, no matter what
any domain controllermay say.
21.6.5 Active Directory
Active Directory is the Windows implementation of Lightweight Directory-
Access Protocol (LDAP) services. Active Directory stores the topology infor-
mation about the domain, keeps the domain-based user and group accounts
andpasswords,andprovidesadomain-basedstoreforWindowsfeaturesthat
need it, such as Windows group policy . Administrators use group policies to
establish uniform standards for desktop preferences and software. For many
corporate information-technology groups, uniformity drastically reduces the
cost of computing.
21.7 Programmer Interface
TheWin 32 APIisthefundamentalinterfacetothecapabilitiesofWindows.This
section describes five main aspects of the Win 32 API: access to kernel objects,
sharing of objects betweenprocesses,processmanagement, interprocesscom-
munication, and memorymanagement.
21.7.1 Access to Kernel Objects
The Windows kernel provides many serv ices that application programs can
use. Application programs obtain these services by manipulating kernel
objects. A process gains access to a kernel object named XXXby calling the
Create XXXfunction to open a handle to an instance of XXX.T h i sh a n d l ei s
unique to the process. Depending on w hich object is being opened, if the
Create() function fails, it may return 0, or it may return a special constant
named INVALID
 HANDLE
 VALUE. Aprocess can close any handle by calling the"
3,21.7.1 Access to Kernel Objects,1026,21.7 Programmer Interface,"884 Chapter 21 Windows 10
21.6.4 Domains
Manynetworkedenvironmentshavenat uralgroupsofusers,suchasstudents
in a computer laboratory at school or employees in one department in a busi-
ness. Frequently, we want all the members of the group to be able to access
sharedresourcesontheirvariouscomputersinthegroup.Tomanagetheglobal
accessrightswithinsuchgroups,Windowsusestheconceptofadomain.Pre-
viously, these domains had no relationship whatsoever to the domain-name
system ( DNS) that maps Internet host names to IPaddresses. Now, however,
theyarecloselyrelated.
Specifically, a Windows domain is a group of Windows workstations and
serversthatshareacommonsecuritypolicyanduserdatabase.SinceWindows
uses the Kerberosprotocol for trust and authentication, a Windows domain is
the same thing as a Kerberos realm. Windows uses a hierarchical approach
for establishing trust relationships between related domains. The trust rela-
tionships are based on DNSand allow transitive trusts that can flow up and
down the hierarchy. This approach reduces the number of trusts required for
ndomains from n∗(n−1) to O(n). The workstations in the domain trust
the domain controller to give correct information about the access rights of
each user (loaded into the user’s access token by lsaas). All users retain the
ability to restrict access to their own workstations, however, no matter what
any domain controllermay say.
21.6.5 Active Directory
Active Directory is the Windows implementation of Lightweight Directory-
Access Protocol (LDAP) services. Active Directory stores the topology infor-
mation about the domain, keeps the domain-based user and group accounts
andpasswords,andprovidesadomain-basedstoreforWindowsfeaturesthat
need it, such as Windows group policy . Administrators use group policies to
establish uniform standards for desktop preferences and software. For many
corporate information-technology groups, uniformity drastically reduces the
cost of computing.
21.7 Programmer Interface
TheWin 32 APIisthefundamentalinterfacetothecapabilitiesofWindows.This
section describes five main aspects of the Win 32 API: access to kernel objects,
sharing of objects betweenprocesses,processmanagement, interprocesscom-
munication, and memorymanagement.
21.7.1 Access to Kernel Objects
The Windows kernel provides many serv ices that application programs can
use. Application programs obtain these services by manipulating kernel
objects. A process gains access to a kernel object named XXXby calling the
Create XXXfunction to open a handle to an instance of XXX.T h i sh a n d l ei s
unique to the process. Depending on w hich object is being opened, if the
Create() function fails, it may return 0, or it may return a special constant
named INVALID
 HANDLE
 VALUE. Aprocess can close any handle by calling the"
3,21.7.2 Sharing Objects Between Processes,1027,21.7.1 Access to Kernel Objects,"21.7 Programmer Interface 885
SECURITY
 ATTRIBUTES sa;
sa.nlength = sizeof(sa);
sa.lpSecurityDescriptor = NULL;
sa.bInheritHandle = TRUE;
HANDLE hSemaphore = CreateSemaphore(&sa, 1, 1, NULL);
WCHAR wszCommandline[MAX
 PATH];
StringCchPrintf(wszCommandLine,
 countof(wszCommandLine),
L""another
 process.exe %d"", hSemaphore);
CreateProcess(L""another
 process.exe"", wszCommandline,
NULL, NULL, TRUE, . . .);
Figure 21.7 Code enabling a child to share an object by inheriting a handle.
CloseHandle() function, and the systemmay deletethe object if the count of
handlesreferencingtheobject inallprocessesdropsto zero.
21.7.2 Sharing Objects Between Processes
Windows provides three ways to share objects between processes. The first
way is for a child process to inherit a handle to the object. When the parent
calls the Create XXXfunction, the parent supplies a SECURITIES
 ATTRIBUTES
structure with the bInheritHandle field set to TRUE. This field creates an
inheritable handle. Next, the child process is created, passing a value of TRUE
to the CreateProcess() function’s bInheritHandle argument. Figure 21.7
shows a code sample that creates a semaphore handle inherited by a child
process.
Assuming the child process knows which handles are shared, the parent
andchildcanachieveinterprocesscommunicationthroughthesharedobjects.
In the example in Figure 21.7, the child process gets the value of the handle
from the first command-line argument and then shares the semaphore with
the parentprocess.
The second way to share objects is for one process to give the object a
name when the object is created and for the second process to openthe name.
This method has two drawbacks: Wind ows does not provide a way to check
whether an object with the chosen name already exists, and the object name
spaceisglobal,withoutregardtotheobjecttype.Forinstance,twoapplications
may create and share a single object named “foo”when two distinctobjects—
possibly of different types—were desired.
Named objects have the advantage th at unrelated processes can readily
sharethem.Thefirstprocesscallsoneofthe Create XXXfunctionsandsupplies
an a m ea sap a r a m e t e r .T h es e c o n dp r o c e s sg e t sah a n d l et os h a r et h eo b j e c t
by calling OpenXXX() (orCreate XXX) with the same name, as shown in the
exampleinFigure21.8.
Thethirdwaytoshareobjectsisviathe DuplicateHandle() function.This
method requires some other method of interprocess communication to pass
the duplicated handle. Given a handle to a process and the value of a handle
within that process, a second process can get a handle to the same object and
thus shareit.Anexampleofthis methodisshown in Figure21.9."
3,21.7.3 Process Management,1028,21.7.2 Sharing Objects Between Processes,"886 Chapter 21 Windows 10
// Process A
...
HANDLE hSemaphore = CreateSemaphore(NULL, 1, 1, L""MySEM1"");
...
// Process B
...
HANDLE hSemaphore = OpenSemaphore(SEMAPHORE
 ALL
ACCESS,
FALSE, L""MySEM1"");
...
Figure 21.8 Code for sharing an object by name lookup.
21.7.3 Process Management
InWindows,a processisaloadedinstanceofanapplicationanda threadisan
executable unit of code that can be scheduled by the kernel dispatcher. Thus,
a process contains one or more threads. A process is created when a thread
in some other process calls the CreateProcess() API. This routine loads any
dynamic link libraries used by the process and creates an initial thread in the
process. Additional threads can be created by the CreateThread() function.
// Process A wants to give Process B access to a semaphore
// Process A
DWORD dwProcessBId; // must; from some IPC mechanism
HANDLE hSemaphore = CreateSemaphore(NULL, 1, 1, NULL);
HANDLE hProcess = OpenProcess(PROCESS
 DUP
HANDLE, FALSE,
dwProcessBId);
HANDLE hSemaphoreCopy;
DuplicateHandle(GetCurrentProcess(), hSemaphore,
hProcess, &hSemaphoreCopy,
0, FALSE, DUPLICATE
 SAME
 ACCESS);
// send the value of the semaphore to Process B
// using a message or shared memory object
...
// Process B
HANDLE hSemaphore = // value of semaphore from message
// use hSemaphore to access the semaphore
...
Figure 21.9 Code for sharing an object by passing a handle."
3,21.7.4 IPC Using Windows Messaging,1033,21.7.3 Process Management,"21.7 Programmer Interface 891
NTOS executive
only primary thread runs in user-mode
trap code switches to parked KT
KT blocks    primary returns to user-mode
KT unblocks and parks     queue UT completionthread parking
UT completion listkernel
user
_user-mode
schedulertrap codeprimary
threadKT0
UT0
UT1 UT0KT1 KT2KT0 blocks
___
Figure 21.10 User-mode scheduling.
21.7.3.8 Winsock
Winsock istheWindowssockets API.Winsockisasession-layerinterfacethatis
largelycompatiblewith BSDsocketsbuthassomeaddedWindowsextensions.
It provides a standardized interface to many transport protocols that may
have different addressing schemes, so that any Winsock application can run
onanyWinsock-compliantprotocolstack.Winsockunderwentamajorupdate
in Windows Vista to add tracing, IPv6support, impersonation, new security
APIs, andmany other features.
Winsock follows the Windows Open System Architecture ( WOSA)m o d e l ,
which provides a standard service provider interface ( SPI) between applica-
tions and networking protocols. Applications can load and unload layered
protocols that build additional functionality, such as additional security, on
top of the transport protocol layers. Winsock supports asynchronous opera-
tions and notifications, reliable multica sting, secure sockets, and kernel mode
sockets.Italsosupportssimplerusagemodels,likethe WSAConnectByName()
function, which acceptsthe targetasstringsspecifyingthe name or IPaddress
ofthe serverandthe serviceorport number ofthe destinationport.
21.7.4 IPC Using Windows Messaging
Win32applications handle interprocess communication in several ways.
The typical high-performance way is by using local RPCs or named pipes.
Anotherisbyusingsharedkernelobject s,suchasnamedsectionobjects,anda
synchronizationobject,suchasanevent.YetanotherisbyusingtheWindows
messaging facility—an approach that is particularly popular for Win 32
GUIapplications. One thread can send a message to another thread or to a
windowbycalling PostMessage() ,PostThreadMessage() ,SendMessage() ,
SendThreadMessage() ,orSendMessageCallback() .Postingamessageand
sendingamessagedifferinthisway:Thepostroutinesareasynchronous;they"
3,21.7.5 Memory Management,1034,21.7.4 IPC Using Windows Messaging,"892 Chapter 21 Windows 10
return immediately, and the calling thread does not know when the message
is actually delivered.The send routines are synchronous; they block the caller
until themessagehas beendeliveredand processed.
In addition to sending a message, a thread can send data with the mes-
sage. Since processes have separate address spaces, the data must be copied.
The system copies data by calling SendMessage() to send a message of type
WM
COPYDATA with a COPYDATASTRUCT data structure that contains the length
andaddressofthedatatobetransferred.Whenthemessageissent,Windows
copies the data to a new block of memory and givesthe virtual addressof the
newblock to thereceivingprocess.
Every Win 32 GUIthread has its own input queue from which it receives
messages.IfaWin 32applicationdoesnotcall GetMessage() tohandleevents
on its input queue, the queue fills up; and after about five seconds, the task
managermarkstheapplicationas “NotResponding. ”Notethatmessagepass-
ing is subject to the integrity level mechanism introduced earlier. Thus, a pro-
cessmaynotsendamessagesuchas WM
COPYDATA toaprocesswithahigher
integrity level,unless a special Windows APIis used to remove the protection
(ChangeWindowMessageFilterEx).
21.7.5 Memory Management
TheWin 32APIprovidesseveralwaysforanapplicationtousememory:virtual
memory,memory-mappedfiles,heaps,thread-localstorage,and AWEphysical
memory.
21.7.5.1 Virtual Memory
An application calls VirtualAlloc() to reserve or commit virtual memory
and VirtualFree() to de-commit or release the memory. These functions
enable the application to specify the v irtual address at which the memory is
allocated. (Otherwise, a random address is selected, which is recommended
for security reasons.) The functions operate on multiples of the memory page
size but, for historical reasons, always return memory allocated on a 64- KB
boundary. Examples of these functions appear in Figure 21.11. The Virtu-
alAllocEx() andVirtualFreeEx() functionscanbeusedtoallocateandfree
memory in a separate process, while VirtualAllocExNuma() can be used to
leveragememorylocality on NUMAsystems.
21.7.5.2 Memory-Mapped Files
Another way for an application to use memory is by memory-mapping a file
into its address space. Memory mapping is also a convenient way for two
processestosharememory:bothprocessesmapthesamefileintotheirvirtual
memory. Memory mapping is a multistage process, as you can see in the
exampleinFigure21.12.
Ifaprocesswantstomapsomeaddressspacejusttoshareamemoryregion
with another process, no file is needed. The process calls CreateFileMap-
ping()with a file handle of 0xffffffff , a particular size, and (optionally) a
name.Theresultingfile-mappingobjectcanbesharedbyinheritance,byname
lookup (ifitwas named),or by handleduplication."
2,21.8 Summary,1037,21.7 Programmer Interface,"21.8 Summary 895
// reserve a slot for a variable
DWORD dwVarIndex = T1sAlloc();
// make sure a slot was available
if (dwVarIndex == TLS
 OUT
OF
INDEXES)
return;
// set it to the value 10
T1sSetValue(dwVarIndex, (LPVOID)10);
// get the value
DWORD dwVar = (DWORD)(DWORD
 PTR)T1sGetValue(dwVarIndex);
// release the index
T1sFree(dwVarIndex);
Figure 21.13 Code for dynamic thread-local storage.
requestfreephysicalpagesof RAMfromthememorymanager(through Allo-
cateUserPhysicalPages() ) and later commit virtual memory on top of the
physicalpagesusing VirtualAlloc() .Byrequestingvariousregionsofphys-
ical memory (including scatter-gather support), a user-mode application can
accessmorephysicalmemorythanvirtualaddressspace;thisisusefulon32-bit
systems,whichmayhavemorethan4GBof RAM).Inaddition,theapplication
can bypass the memory manager’s caching, paging, and coloring algorithms.
Similar to UMS,AWEmay thus offer a way for certain applications to extract
additional performance or customization beyond what Windows offers by
default. SQLServer,for example,uses AWEmemory.
To use a thread-local static variable, the application declares the variable
asfollows to ensurethateverythreadhas itsown privatecopy:
declspec(thread) DWORD cur
pos = 0 ;
21.8 Summary
•Microsoft designed Windows to be an extensible, portable operating sys-
tem—one ableto takeadvantageofnew techniques andhardware.
•Windowssupportsmultipleoperatingenvironmentsandsymmetricmul-
tiprocessing, including both 32-bit and 64-bit processors and NUMAcom-
puters.
•The useof kernelobjects to providebasicservices,along withsupportfor
client–server computing, enables Windows to support a wide variety of
applicationenvironments.
•Windows provides virtual memory, integrated caching, and preemptive
scheduling."
2,Practice Exercises,1038,21.8 Summary,"896 Chapter 21 Windows 10
•To protect user data and guarantee program integrity,Windows supports
elaborate security mechanisms and exploit mitigations and takes advan-
tage of hardware virtualization.
•Windows runs on a wide variety of computers, so users can choose and
upgradehardware tomatch theirbudgetsand performancerequirements
without needingtoalterthe applicationstheyrun.
•By including internationalization features, Windows can run in a variety
of countriesand many languages.
•Windows has sophisticated scheduling and memory-management algo-
rithmsfor performance and scalability.
•Recent versions of Windows have added power management and fast
sleep and wake features, and decreased resource use in several areas to
be more usefulon mobile systemssuch as phonesand tablets.
•The Windows volume manager and NTFSfile system provide a sophisti-
catedsetof featuresfor desktopas wellasserversystems.
•The Win 32 APIprogramming environment is feature rich and expansive,
allowingprogrammerstouseallofWindows’sfeaturesintheirprograms.
Practice Exercises
21.1What type of operating system is Windows? Describe two of its major
features.
21.2Listthedesigngoalsof Windows. Describetwo indetail.
21.3Describethebooting processfora Windows system.
21.4Describethethreemainarchitecturallayersof theWindows kernel.
21.5What is the job of the object manager?
21.6What typesof servicesdoestheprocessmanager provide?
21.7What is alocal procedurecall?
21.8What are the responsibilitiesof the I/Omanager?
21.9What types of networking does Windows support? How does Win-
dows implement transport protocols? Describe two networking pro-
tocols.
21.10How isthe NTFSnamespaceorganized?
21.11How does NTFShandle data structures? How does NTFSrecover from
a systemcrash? What isguaranteedafterarecoverytakesplace?
21.12How doesWindows allocateusermemory?
21.13Describesomeofthewaysinwhichanapplicationcanusememoryvia
theWin 32 API."
2,Further Reading,1039,Practice Exercises,"Further Reading 897
Further Reading
[Russinovich et al. (2017)] give a deepoverviewof Windows 10 and consider-
able technical detailabout systeminternals and components.
Bibliography
[Russinovich et al. (2017)] M.Russinovich,D.A.Solomon,andA.Ionescu, Win-
dows Internals–Part 1, SeventhEdition, Microsoft Press(2017)."
2,Bibliography,1039,Further Reading,"Further Reading 897
Further Reading
[Russinovich et al. (2017)] give a deepoverviewof Windows 10 and consider-
able technical detailabout systeminternals and components.
Bibliography
[Russinovich et al. (2017)] M.Russinovich,D.A.Solomon,andA.Ionescu, Win-
dows Internals–Part 1, SeventhEdition, Microsoft Press(2017)."
2,Chapter 21 Exercises,1040,Bibliography,"Exercises
Chapter 21 Exercises
21.14Underwhatcircumstanceswouldoneusethedeferredprocedurecalls
facility inWindows?
21.15What isa handle,and how doesa processobtaina handle?
21.16Describe the management scheme of the virtual memory manager.
How doesthe VMmanagerimproveperformance?
21.17Describeausefulapplicationoftheno-accesspagefacilityprovidedin
Windows.
21.18Describe the three techniques used for communicating data in a local
procedure call. What settings are most conducive to the application of
the differentmessage-passingtechniques?
21.19What manages caching in Windows? How isthe cache managed?
21.20How does the NTFSdirectory structure differ from the directory struc-
tureusedin UNIXoperatingsystems?
21.21What isa process,andhow isitmanaged inWindows?
21.22WhatisthefiberabstractionprovidedbyWindows?Howdoesitdiffer
from the thread abstraction?
21.23How does user-mode scheduling ( UMS) in Windows 7 differ from
fibers? What aresometrade-offsbetweenfibers and UMS?
21.24 UMSconsidersathreadtohavetwoparts,a UTandaKT.Howmightit
beusefultoallow UTstocontinueexecutinginparallelwiththeir KTs?
21.25What is the performance trade-off of allowing KTsa n dUTst oe x e c u t e
on differentprocessors?
21.26Why doesthe self-map occupy large amounts of virtual addressspace
but no additionalvirtualmemory?
21.27How does the self-map make it easy for the VMmanager to move the
page-tablepagestoandfromdisk?Wherearethepage-tablepageskept
on disk?
21.28When a Windows system hibernates, the system is powered off. Sup-
pose you changed the CPUor the amount of RAMon a hibernating
system. Doyou think that would work? Why orwhy not?
21.29Giveanexampleshowinghowtheuseofasuspendcountishelpfulin
suspendingand resumingthreadsinWindows.EX-60"
0,PART TEN APPENDICES,1043,PART NINE CASE STUDIES,"AAppendix Inﬂuential
Operating
Systems
Nowthatyouunderstandthefundamentalconceptsofoperatingsystems( CPU
scheduling, memory management, processes, and so on), we are in a position
to examine how these concepts have been applied in severalolder and highly
influential operating systems. Some of them (such as the XDS-940and the THE
system) were one-of-a-kind systems; others (such as OS/360)a r ew i d e l yu s e d .
The order of presentation highlights the similarities and differences of the
systems; it is not strictly chronological or ordered by importance. The serious
studentof operatingsystemsshouldbe familiarwithallthesesystems.
Inthebibliographicalnotesattheendofthechapter,weincludereferences
tofurtherreadingabouttheseearlysystems.Thepapers,writtenbythedesign-
ers of the systems, are important both for their technical content and for their
styleand flavor.
CHAPTER OBJECTIVES
•Explain how operating-system features migrate over time from large com-
puter systems to smaller ones.
Discuss the features of several historically important operating systems.
A.1 Feature Migration
Onereasontostudyearlyarchitecturesandoperatingsystemsisthatafeature
that once ran only on huge systems may eventually make its way into very
small systems. Indeed, an examination of operating systems for mainframes
and microcomputers shows that many features once available only on main-
frames have been adopted for microcomputers. The same operating-system
concepts are thus appropriate for various classes of computers: mainframes,
minicomputers,microcomputers,andhandhelds.Tounderstandmodernoper-
atingsystems,then,youneedtorecogn izethethemeoffeaturemigrationand
thelong historyof many operating-systemfeatures,asshown inFigureA.1.
AgoodexampleoffeaturemigrationstartedwiththeMultiplexedInforma-
tionandComputingServices( MULTICS )operatingsystem. MULTICS wasdevel-
1"
1,Appendix A Influential Operating Systems,1043,PART TEN APPENDICES,"AAppendix Inﬂuential
Operating
Systems
Nowthatyouunderstandthefundamentalconceptsofoperatingsystems( CPU
scheduling, memory management, processes, and so on), we are in a position
to examine how these concepts have been applied in severalolder and highly
influential operating systems. Some of them (such as the XDS-940and the THE
system) were one-of-a-kind systems; others (such as OS/360)a r ew i d e l yu s e d .
The order of presentation highlights the similarities and differences of the
systems; it is not strictly chronological or ordered by importance. The serious
studentof operatingsystemsshouldbe familiarwithallthesesystems.
Inthebibliographicalnotesattheendofthechapter,weincludereferences
tofurtherreadingabouttheseearlysystems.Thepapers,writtenbythedesign-
ers of the systems, are important both for their technical content and for their
styleand flavor.
CHAPTER OBJECTIVES
•Explain how operating-system features migrate over time from large com-
puter systems to smaller ones.
Discuss the features of several historically important operating systems.
A.1 Feature Migration
Onereasontostudyearlyarchitecturesandoperatingsystemsisthatafeature
that once ran only on huge systems may eventually make its way into very
small systems. Indeed, an examination of operating systems for mainframes
and microcomputers shows that many features once available only on main-
frames have been adopted for microcomputers. The same operating-system
concepts are thus appropriate for various classes of computers: mainframes,
minicomputers,microcomputers,andhandhelds.Tounderstandmodernoper-
atingsystems,then,youneedtorecogn izethethemeoffeaturemigrationand
thelong historyof many operating-systemfeatures,asshown inFigureA.1.
AgoodexampleoffeaturemigrationstartedwiththeMultiplexedInforma-
tionandComputingServices( MULTICS )operatingsystem. MULTICS wasdevel-
1"
2,A.1 Feature Migration,1043,Appendix A Influential Operating Systems,"AAppendix Inﬂuential
Operating
Systems
Nowthatyouunderstandthefundamentalconceptsofoperatingsystems( CPU
scheduling, memory management, processes, and so on), we are in a position
to examine how these concepts have been applied in severalolder and highly
influential operating systems. Some of them (such as the XDS-940and the THE
system) were one-of-a-kind systems; others (such as OS/360)a r ew i d e l yu s e d .
The order of presentation highlights the similarities and differences of the
systems; it is not strictly chronological or ordered by importance. The serious
studentof operatingsystemsshouldbe familiarwithallthesesystems.
Inthebibliographicalnotesattheendofthechapter,weincludereferences
tofurtherreadingabouttheseearlysystems.Thepapers,writtenbythedesign-
ers of the systems, are important both for their technical content and for their
styleand flavor.
CHAPTER OBJECTIVES
•Explain how operating-system features migrate over time from large com-
puter systems to smaller ones.
Discuss the features of several historically important operating systems.
A.1 Feature Migration
Onereasontostudyearlyarchitecturesandoperatingsystemsisthatafeature
that once ran only on huge systems may eventually make its way into very
small systems. Indeed, an examination of operating systems for mainframes
and microcomputers shows that many features once available only on main-
frames have been adopted for microcomputers. The same operating-system
concepts are thus appropriate for various classes of computers: mainframes,
minicomputers,microcomputers,andhandhelds.Tounderstandmodernoper-
atingsystems,then,youneedtorecogn izethethemeoffeaturemigrationand
thelong historyof many operating-systemfeatures,asshown inFigureA.1.
AgoodexampleoffeaturemigrationstartedwiththeMultiplexedInforma-
tionandComputingServices( MULTICS )operatingsystem. MULTICS wasdevel-
1"
2,A.2 Early Systems,1044,A.1 Feature Migration,"2 Appendix A Influentia Operating Systems
mainframes1950
no
software
no
softwaremultiprocessor batchcompilers time
shareddistributed
systems
resident
monitorsfault  tolerantnetworkedmultiuser
no
softwarecompilers
no
software interactivecompilers
compilers
interactive
networkedtime
sharedresident
monitorsfault  tolerant multiuser
networked
clustered
multiusermultiprocessor
multiprocessor1960 1970
MULTICS1980 1990 2000 
minicomputers
desktop computers
handheld computersUNIX
UNIX
networked
UNIX
smart phones2010
LINUX
multiprocessor
networked
interactiveLINUX
Figure A.1 Migration of operating-system concepts and features.
opedfrom1965to1970attheMassachusettsInstituteofTechnology( MIT)asa
computing utility.Itranonalarge,complexmainframecomputer(the GE-645).
Manyoftheideasthatweredevelopedfor MULTICS weresubsequentlyusedat
BellLaboratories(oneoftheoriginalpartnersinthedevelopmentof MULTICS )
in the design of UNIX.T h eUNIXoperating system was designed around 1970
foraPDP-11minicomputer.Around1980,thefeaturesof UNIXbecamethebasis
forUNIX-like operating systems on microcomputers, and these features are
included in several more recent operating systems for microcomputers, such
as Microsoft Windows, Windows XP,a n dt h em a c OSoperating system. Linux
includessomeof thesesamefeatures,and theycan now befound on PDAs.
A.2 Early Systems
Weturnourattentionnowtoahistoricaloverviewofearlycomputersystems.
We should note that the history of computing starts far before “computers ”
with looms and calculators. We begin our discussion, however, with the com-
putersof thetwentiethcentury.
Before the 1940s, computing devices were designed and implemented to
performspecific,fixedtasks.Modifyingoneofthosetasksrequiredagreatdeal
ofeffortandmanuallabor.Allthatchangedinthe1940swhenAlanTuringand
JohnvonNeumann(andcolleagues),bothseparatelyandtogether,workedon
theideaofamoregeneral-purpose stored program computer.Suchamachine"
3,A.2.1 Dedicated Computer Systems,1045,A.2 Early Systems,"A.2 Early Systems 3
has both a program store and a data store, where the program store provides
instructionsabout what to doto the data.
This fundamental computer concept quickly generated a number of
general-purpose computers, but much of the history of these machines is
blurred by time and the secrecy of their development during World War II. It
islikelythatthefirstworking stored-programgeneral-purposecomputerwas
the Manchester Mark 1, which ran successfully in 1949. The first commercial
computer—the Ferranti Mark 1, which went on sale in 1951—was its
offspring.
Early computers were physically enor mous machines run from consoles.
The programmer, who was also the operator of the computer system, would
writeaprogramandthenwouldoperateitdirectlyfromtheoperator’sconsole.
First,theprogramwouldbeloadedmanuallyintomemoryfromthefrontpanel
switches (one instruction at a time), from paper tape, or from punched cards.
T h e nt h ea p p r o p r i a t eb u t t o n sw o u l db ep u s h e dt os e tt h es t a r t i n ga d d r e s s
and to start the execution of the program. As the program ran, the program-
mer/operatorcouldmonitoritsexecuti onbythedisplaylightsontheconsole.
If errors were discovered, the programmer could halt the program, examine
the contents of memory and registers, and debug the program directly from
the console. Output was printed or was punched onto paper tape or cards for
laterprinting.
A.2.1 Dedicated Computer Systems
As time went on, additional software and hardware were developed. Card
readers, line printers, and magnetic tape became commonplace. Assemblers,
loaders, and linkers were designed to ease the programming task. Libraries
of common functions were created. Common functions could then be copied
into a new program without having to be written again, providing software
reusability.
The routines that performed I/Owere especially important. Each new I/O
device had its own characteristics, requiring careful programming. A special
subroutine called a device driver—was written for each I/Odevice. Adevice
driver knows how the buffers, flags, registers, control bits, and status bits for
a particular device should be used. Each type of device has its own driver.
A simple task, such as reading a character from a paper-tape reader, might
involve complex sequences of device-specific operations. Rather than writing
the necessary code every time, the device driver was simply used from the
library.
Later,compilersfor FORTRAN ,COBOL,andotherlanguagesappeared,mak-
ingtheprogrammingtaskmucheasierbuttheoperationofthecomputermore
complex. To prepare a FORTRAN program for execution, for example, the pro-
grammer would first need to load the FORTRAN compiler into the computer.
The compiler was normally kept on magnetic tape, so the proper tape would
n e e dt ob em o u n t e do nat a p ed r i v e .T h ep r o g r a mw o u l db er e a dt h r o u g ht h e
card reader and written onto another tape. The FORTRAN compiler produced
assembly-language output, which the n had to be assembled. This procedure
requiredmounting another tape with the assembler. The output of the assem-
blerwouldneedtobelinkedtosupporting libraryroutines.Finally,thebinary
object form of the program would be readyto execute.It could be loadedinto
memoryanddebuggedfrom theconsole, as before."
3,A.2.2 Shared Computer Systems,1046,A.2.1 Dedicated Computer Systems,"4 Appendix A Influentia Operating Systems
Asignificant amount of setup time could be involved in the running of a
job. Eachjob consistedof many separatesteps:
1.Loadingthe FORTRAN compilertape
2.Running the compiler
3.Unloading thecompilertape
4.Loadingthe assemblertape
5.Running the assembler
6.Unloading theassemblertape
7.Loadingthe object program
8.Running the object program
If an error occurred during any step, the programmer/operator might have
to start over at the beginning. Each job step might involve the loading and
unloading of magnetictapes,papertapes,and punch cards.
Thejobsetuptimewasarealproblem.Whiletapeswerebeingmountedor
the programmer was operating the console, the CPUsat idle. Remember that,
in the early days, few computers were available, and they were expensive. A
computer might have cost millions of dollars, not including the operational
costs of power, cooling, programmers, and so on. Thus, computer time was
extremely valuable, and owners wanted their computers to be used as much
as possible. They needed high utilization to get as much as they could from
theirinvestments.
A.2.2 Shared Computer Systems
The solution was twofold. First, a professional computer operator was hired.
The programmer no longer operated the machine. As soon as one job was
finished,theoperatorcouldstartthenext.Sincetheoperatorhadmoreexperi-
ence with mounting tapes than a programmer, setup time was reduced. The
programmer provided whatever cards or tapes were needed, as well as a
short description of how the job was to be run. Of course, the operator could
not debug an incorrect program at the console, since the operator would not
understand the program. Therefore, in the case of program error, a dump of
memory and registerswas taken, and the programmerhad to debug from the
dump. Dumping the memory and registers allowed the operator to continue
immediatelywiththenextjobbutlefttheprogrammerwiththemoredifficult
debuggingproblem.
Second,jobswithsimilarneedswerebatchedtogetherandrunthroughthe
computer as a group to reduce setup time. For instance, suppose the operator
receivedone FORTRAN job,one COBOLjob,andanother FORTRAN job.Ifsheran
them in that order, she would have to set up for FORTRAN (load the compiler
tapesandsoon),thensetupfor COBOL,a n dth ensetupfo r FORTRAN again.If
she ran the two FORTRAN programsas a batch, however,she couldsetuponly
once for FORTRAN , savingoperatortime."
3,A.2.3 Overlapped I/O,1049,A.2.2 Shared Computer Systems,"A.2 Early Systems 7
back to the monitor, which reads the next control card, loads the appropriate
program,andsoon.Thiscycleisrepeateduntilallcontrolcardsareinterpreted
forthe job.Then the monitorautomatically continues with the nextjob.
The switch to batch systems with automatic job sequencing was made to
improve performance. The problem, quite simply, is that humans are consid-
erably slower than computers. Consequently, it is desirable to replace human
operation with operating-system software. Automatic job sequencing elimi-
natesthe need for human setuptime and job sequencing.
Even with this arrangement, however, the CPUis often idle. The problem
is the speed of the mechanical I/Odevices, which are intrinsically slower
than electronic devices. Even a slow CPUworks in the microsecond range,
with thousands of instructions executed per second. A fast card reader, in
contrast,mightread1,200cardsperminute(or20cardspersecond).Thus,the
differenceinspeedbetweenthe CPUanditsI/Odevicesmaybethreeordersof
magnitudeormore.Overtime,ofcourse,improvementsintechnologyresulted
in faster I/Odevices. Unfortunately, CPUspeeds increased even faster, so that
theproblemwas not only unresolvedbut alsoexacerbated.
A.2.3 Overlapped I/O
One common solution to the I/Oproblem was to replace slow card readers
(input devices) and line printers (output devices) with magnetic-tape units.
Most computer systems in the late 1950s and early 1960s were batch systems
readingfromcardreadersandwritingtolineprintersorcardpunches.The CPU
didnot readdirectlyfromcards,however;instead,thecardswerefirst copied
ontoamagnetictapeviaaseparatedevice.Whenthetapewassufficientlyfull,
itwastakendownandcarriedovertothecomputer.Whenacardwasneeded
forinputtoaprogram,theequivalentrecordwasreadfromthetape.Similarly,
outputwaswrittentothetape,andthecontentsofthetapewereprintedlater.
The card readers and line printers were operated off-line, rather than by the
maincomputer(FigureA.4).
An obvious advantage of off-line operation was that the main computer
was no longer constrained by the speed of the card readers and line printers
but was limited only by the speed of the much faster magnetic tape units.
The technique of using magnetic tape for all I/Ocould be applied with any
(b)(a)CPU
card reader
card readerline printer
tape drives tape drives line printerCPUon-line
on-line
Figure A.4 Operation of I/O devices (a) on-line and (b) off-line."
2,A.3 Atlas,1051,A.2 Early Systems,"A.3 Atlas 9
Spooling is also used for processing data at remote sites. The CPUsends
the data via communication paths to a remote printer (or accepts an entire
inputjobfromaremotecardreader).Theremoteprocessingisdoneatitsown
speed, with no CPUintervention. The CPUjust needs to be notified when the
processingiscompleted,sothat itcan spoolthe nextbatch of data.
Spooling overlaps the I/Oof one job with the computation of other jobs.
Eveninasimplesystem,thespoolermaybereadingtheinputofonejobwhile
printingtheoutputofadifferentjob.Dur ingthistime,stillanotherjob(orother
jobs) may be executed,reading its “cards ”from disk and “printing ”its output
linesonto thedisk.
Spooling has a direct beneficial effect on the performance of the system.
For the cost of some disk space and a few tables, the computation of one job
and the I/Oof other jobs can take place at the same time. Thus, spooling can
keepboththe CPUandthe I/Odevicesworkingatmuchhigherrates.Spooling
leads naturally to multiprogramming, which is the foundation of all modern
operatingsystems.
A.3 Atlas
The Atlas operating system was designed at the University of Manchester in
England in the late1950s and early 1960s. Many of its basic featuresthat were
novel at the time have become standard parts of modern operating systems.
Devicedriverswerea major part of the system.Inaddition,system calls were
addedby a setof specialinstructionscalled extra codes .
Atlas was a batch operating system with spooling. Spooling allowed the
systemtoschedulejobsaccordingtotheavailabilityofperipheraldevices,such
as magnetic tape units, paper tape reade rs, paper tape punches, line printers,
cardreaders,and card punches.
The most remarkable feature of Atlas, however, was its memory manage-
ment. Core memory was new and expensive at the time. Many computers,
like the IBM650, used a drum for primary memory. The Atlas system used a
drumforitsmainmemory,butithadasmallamountofcorememorythatwas
usedasacacheforthedrum.Demandpagingwasusedtotransferinformation
betweencorememoryand thedrumautomatically.
The Atlas system used a British computer with 48-bit words. Addresses
were 24 bits but were encoded in decimal, which allowed 1 million words to
be addressed. At that time, this was an extremely large address space. The
physical memory for Atlas was a 98- KB-word drum and 16- KBwords of core.
Memory was divided into 512-word pages, providing 32 frames in physical
memory. An associative memory of 32 registers implemented the mapping
froma virtualaddressto a physicaladdress.
If a page fault occurred, a page-replacement algorithm was invoked. One
memory frame was always kept empty, so that a drum transfer could start
immediately. The page-replacement algorithm attempted to predict future
memory-accessing behavior based on past behavior. A reference bit for each
frame was set whenever the frame was accessed. The referencebits were read
intomemoryevery1,024instructions,andthelast32valuesofthesebitswere
retained. This history was used to define the time since the most recent ref-"
2,A.4 XDS-940,1052,A.3 Atlas,"10 Appendix A Influentia Operating Systems
erence ( t1) and the interval between the last two references ( t2). Pages were
chosen forreplacementinthe following order:
1.Any page with t1>t2+ 1 is considered to be no longer in use and is
replaced.
2.Ift1≤t2for all pages, then replace the page with the largest value for t2
−t1.
The page-replacement algorithm assumes that programs access memory in
loops.Ifthetimebetweenthelasttworeferencesis t2,thenanotherreferenceis
expected t2timeunitslater.Ifareferencedoesnotoccur( t1>t2),itisassumed
that the page is no longer being used, and the page is replaced. If all pages
are still in use, then the page that will not be needed for the longest time is
replaced.Thetimetothe nextreferenceisexpectedtobe t2−t1.
A.4 XDS-940
TheXDS-940operating system was designed at the University of California at
Berkeley in the early 1960s. Like the Atlas system, it used paging for memory
management.UnliketheAtlassystem,itwasatime-sharedsystem.Thepaging
was used only for relocation; it was not used for demand paging. The virtual
memoryofanyuserprocesswasmadeupof16- KBwords,whereasthephysical
memorywasmadeupof64- KBwords.Eachpagewasmadeupof2- KBwords.
The page table was kept in registers. Since physical memory was larger than
virtual memory, several user processes could be in memory at the same time.
The number of users could be increased by page sharing when the pages
contained read-only reentrant code. Processes were kept on a drum and were
swappedinandout of memoryas necessary.
TheXDS-940system was constructed from a modified XDS-930.T h em o d -
ifications were typical of the changes made to a basic computer to allow an
operating system to be written properly. A user-monitor mode was added.
Certain instructions, such as I/Oand halt, were defined to be privileged. An
attempt to execute a privileged instruction in user mode would trap to the
operatingsystem.
Asystem-callinstructionwasaddedtotheuser-modeinstructionset.This
instructionwasusedtocreatenewresources,suchasfiles,allowingtheoperat-
ingsystemtomanagethephysicalresourc es.Files,forexample,wereallocated
in 256-word blocks on the drum. A bitmap was used to manage free drum
blocks. Each file had an index block with pointers to the actual data blocks.
Indexblocks werechained together.
TheXDS-940system also provided system calls to allow processes to cre-
ate, start, suspend, and destroy subprocesses. Aprogrammer could construct
a system of processes. Separate processes could share memory for communi-
cation and synchronization. Process creation defined a tree structure, where a
process is the root and its subprocesses are nodes below it in the tree. Each of
thesubprocessescould, inturn, createmoresubprocesses."
2,A.5 THE,1053,A.4 XDS-940,"A.6 RC 4000 11
A.5 THE
TheTHEoperating system was designed at the Technische Hogeschool in
EindhovenintheNetherlandsinthemid-1960s.Itwasabatchsystemrunning
on a Dutch computer, the EL X8, with 32- KBof 27-bit words. The system was
mainlynotedforitscleandesign,particularlyitslayerstructure,anditsuseof
asetof concurrent processesemployingsemaphoresforsynchronization.
Unlike the processes in the XDS-940system, the set of processes in the
THEsystem was static. The operating system itself was designed as a set of
cooperatingprocesses.Inaddition,fiveuserprocesseswerecreatedthatserved
as the active agents to compile, execute, and print user programs. When one
jobwasfinished,theprocesswouldreturntotheinputqueuetoselectanother
job.
Apriority CPU-schedulingalgorithmwasused.Theprioritieswererecom-
puted every 2 seconds and were inversely proportional to the amount of CPU
timeusedrecently(inthelast8to10seconds).Thisschemegavehigherpriority
toI/O-bound processesand to new processes.
Memorymanagementwaslimitedbythelackofhardwaresupport.How-
ever,sincethesystemwaslimitedanduserprogramscouldbewrittenonlyin
Algol, a software paging scheme was used. The Algol compiler automatically
generatedcallstosystemroutines,whichmadesuretherequestedinformation
was in memory, swapping if necessary. The backing store was a 512- KB-word
drum.A512-word pagewas used,withan LRUpage-replacementstrategy.
Another major concern of the THEsystem was deadlock control. The
banker’s algorithmwas usedto providedeadlockavoidance.
Closely related to the THEsystem is the Venus system. The Venus system
wasalsoalayer-structureddesign,usingsemaphorestosynchronizeprocesses.
Thelowerlevelsofthedesignwereimplementedinmicrocode,however,pro-
vidingamuchfastersystem.Paged-segmentedmemorywasusedformemory
management. In addition, the system was designed as a time-sharing system
ratherthana batch system.
A.6 RC 4000
TheRC4000 system, like the THEsystem, was notable primarily for its design
concepts. It was designed in the late 1960s for the Danish 4000 computer
by Regnecentralen, particularly by Brinch-Hansen. The objective was not to
designa batch system, or a time-sharing system, or any other specific system.
Rather,thegoalwastocreateanoperating-systemnucleus,orkernel,onwhich
a complete operating system could be built. Thus, the system structure was
layered,and only thelowerlevels—comprisingthekernel—wereprovided.
The kernel supported a collection of concurrent processes. Around-robin
CPUschedulerwasused.Althoughprocessescouldsharememory,theprimary
communicationandsynchronizationmechanismwasthe message system pro-
videdbythekernel.Processescouldcommunicatewitheachotherbyexchang-
ingfixed-sizedmessagesofeightwordsinlength.Allmessageswerestoredin
buffers from a common buffer pool. When a message buffer was no longer
required,itwas returnedtothe commonpool."
2,A.6 RC 4000,1053,A.5 THE,"A.6 RC 4000 11
A.5 THE
TheTHEoperating system was designed at the Technische Hogeschool in
EindhovenintheNetherlandsinthemid-1960s.Itwasabatchsystemrunning
on a Dutch computer, the EL X8, with 32- KBof 27-bit words. The system was
mainlynotedforitscleandesign,particularlyitslayerstructure,anditsuseof
asetof concurrent processesemployingsemaphoresforsynchronization.
Unlike the processes in the XDS-940system, the set of processes in the
THEsystem was static. The operating system itself was designed as a set of
cooperatingprocesses.Inaddition,fiveuserprocesseswerecreatedthatserved
as the active agents to compile, execute, and print user programs. When one
jobwasfinished,theprocesswouldreturntotheinputqueuetoselectanother
job.
Apriority CPU-schedulingalgorithmwasused.Theprioritieswererecom-
puted every 2 seconds and were inversely proportional to the amount of CPU
timeusedrecently(inthelast8to10seconds).Thisschemegavehigherpriority
toI/O-bound processesand to new processes.
Memorymanagementwaslimitedbythelackofhardwaresupport.How-
ever,sincethesystemwaslimitedanduserprogramscouldbewrittenonlyin
Algol, a software paging scheme was used. The Algol compiler automatically
generatedcallstosystemroutines,whichmadesuretherequestedinformation
was in memory, swapping if necessary. The backing store was a 512- KB-word
drum.A512-word pagewas used,withan LRUpage-replacementstrategy.
Another major concern of the THEsystem was deadlock control. The
banker’s algorithmwas usedto providedeadlockavoidance.
Closely related to the THEsystem is the Venus system. The Venus system
wasalsoalayer-structureddesign,usingsemaphorestosynchronizeprocesses.
Thelowerlevelsofthedesignwereimplementedinmicrocode,however,pro-
vidingamuchfastersystem.Paged-segmentedmemorywasusedformemory
management. In addition, the system was designed as a time-sharing system
ratherthana batch system.
A.6 RC 4000
TheRC4000 system, like the THEsystem, was notable primarily for its design
concepts. It was designed in the late 1960s for the Danish 4000 computer
by Regnecentralen, particularly by Brinch-Hansen. The objective was not to
designa batch system, or a time-sharing system, or any other specific system.
Rather,thegoalwastocreateanoperating-systemnucleus,orkernel,onwhich
a complete operating system could be built. Thus, the system structure was
layered,and only thelowerlevels—comprisingthekernel—wereprovided.
The kernel supported a collection of concurrent processes. Around-robin
CPUschedulerwasused.Althoughprocessescouldsharememory,theprimary
communicationandsynchronizationmechanismwasthe message system pro-
videdbythekernel.Processescouldcommunicatewitheachotherbyexchang-
ingfixed-sizedmessagesofeightwordsinlength.Allmessageswerestoredin
buffers from a common buffer pool. When a message buffer was no longer
required,itwas returnedtothe commonpool."
2,A.7 CTSS,1054,A.6 RC 4000,"12 Appendix A Influentia Operating Systems
Amessage queue was associated with each process. It contained all the
messages that had been sent to that process but had not yet been received.
Messages were removed from the queue in FIFOorder. The system supported
four primitiveoperations,which wereexecutedatomically:
•send-message (inreceiver, inmessage, outbuffer)
•wait-message (outsender, outmessage, outbuffer)
•send-answer (outresult, inmessage, inbuffer)
•wait-answer (outresult, outmessage, inbuffer)
The last two operations allowed processes to exchange several messages at a
time.
Theseprimitivesrequiredthat a processserviceitsmessagequeuein FIFO
orderandthatitblockitselfwhileothe rprocesseswerehandlingitsmessages.
Toremovetheserestrictions,thedevelopersprovidedtwoadditionalcommu-
nication primitives that allowed a process to wait for the arrival of the next
messageorto answer and serviceitsqueueinany order:
•wait-event (inprevious-buffer, outnext-buffer, outresult)
•get-event (outbuffer)
I/Odevices were also treated as processes. The device drivers were code
that converted the device interrupts and registers into messages. Thus, a pro-
cesswouldwritetoaterminalbysendi ngthatterminalamessage.Thedevice
driverwouldreceivethemessageandoutputthecharactertotheterminal.An
inputcharacterwouldinterruptthesystemandtransfertoadevicedriver.The
devicedriverwouldcreateamessagefromtheinputcharacterandsendittoa
waiting process.
A.7 CTSS
TheCompatibleTime-SharingSystem( CTSS)wasdesignedat MITasanexper-
imental time-sharing system and first appeared in 1961. It was implemented
onanIBM7090andeventuallysupportedupto32interactiveusers.Theusers
wereprovidedwithasetofinteractiv ecommandsthatallowedthemtomanip-
ulatefilesand to compileandrunprogramsthrougha terminal.
The7090hada32- KBmemorymadeupof36-bitwords.Themonitorused
5-KBwords, leaving 27 KBfor the users. User memory images were swapped
between memory and a fast drum. CPUscheduling employed a multilevel-
feedback-queue algorithm. The time quantum for level iwas 2∗itime units.
If a program did not finish its CPUburst in one time quantum, it was moved
downtothenextlevelofthequeue,givingittwiceasmuchtime.Theprogram
at the highest level(with the shortest quantum) was run first. The initial level
ofaprogramwasdeterminedbyitssize,sothatthetimequantumwasatleast
as long asthe swap time.
CTSSwas extremely successful and was in use as late as 1972. Although
it was limited, it succeeded in demonstrating that time sharing was a con-"
2,A.8 MULTICS,1055,A.7 CTSS,"A.9 IBM OS/360 13
venient and practical mode of computing. One result of CTSSwas increased
developmentoftime-sharingsystems. Anotherresultwasthedevelopmentof
MULTICS .
A.8 MULTICS
TheMULTICS operating system was designed from 1965 to 1970 at MITas a
natural extension of CTSS.CTSSand other early time-sharing systems were so
successful that they created an immediate desire to proceed quickly to bigger
and better systems. As larger computers became available, the designers of
CTSSset out to create a time-sharing utility. Computing service would be
provided like electrical power. Large computer systems would be connected
by telephone wires to terminals in offices and homes throughout a city. The
operatingsystemwouldbeatime-sharedsystemrunningcontinuouslywitha
vastfilesystemofsharedprogramsand data.
MULTICS was designed by a team from MIT,GE(which later sold its com-
puterdepartmenttoHoneywell),andBellLaboratories(whichdroppedoutof
the project in 1969). The basic GE635 computer was modified to a new com-
putersystemcalledthe GE645,mainlybytheadditionofpaged-segmentation
memoryhardware.
InMULTICS , avirtualaddresswas composedof an18-bit segmentnumber
and a 16-bit word offset. The segments were then paged in 1- KB-word pages.
The second-chance page-replacementalgorithmwas used.
Thesegmentedvirtualaddressspacewasmergedintothefilesystem;each
segment was a file. Segments were addressed by the name of the file. The file
systemitselfwasamultileveltreestructure,allowinguserstocreatetheirown
subdirectorystructures.
LikeCTSS,MULTICS used a multilevelfeedback queue for CPUscheduling.
Protection was accomplished through an access list associated with each file
and a set of protection rings for executing processes. The system, which was
written almost entirely in PL/1, comprised about 300,000 lines of code. It was
extendedtoamultiprocessorsystem,allowinga CPUtobetakenoutofservice
formaintenance whilethesystemcontinued running.
A.9 IBM OS/360
The longest line of operating-system developmentis undoubtedly that of IBM
computers. The early IBMcomputers, such as the IBM7090 and the IBM7094,
areprimeexamplesofthedevelopmentofcommon I/Osubroutines,followed
bydevelopmentofaresidentmonitor,privilegedinstructions,memoryprotec-
tion, and simple batch processing. These systems were developed separately,
often at independent sites. As a result, IBMwas faced with many different
computers,withdifferentlanguages and differentsystemsoftware.
TheIBM/360—which first appeared in the mid 1960s—was designed to
alter this situation. The IBM/360was designed as a family of computers span-
ning the complete range from small business machines to large scientific
machines.Onlyonesetofsoftwarewouldbeneededforthesesystems,which
allusedthesameoperatingsystem: OS/360.Thisarrangementwasintendedto"
2,A.9 IBM OS/360,1055,A.8 MULTICS,"A.9 IBM OS/360 13
venient and practical mode of computing. One result of CTSSwas increased
developmentoftime-sharingsystems. Anotherresultwasthedevelopmentof
MULTICS .
A.8 MULTICS
TheMULTICS operating system was designed from 1965 to 1970 at MITas a
natural extension of CTSS.CTSSand other early time-sharing systems were so
successful that they created an immediate desire to proceed quickly to bigger
and better systems. As larger computers became available, the designers of
CTSSset out to create a time-sharing utility. Computing service would be
provided like electrical power. Large computer systems would be connected
by telephone wires to terminals in offices and homes throughout a city. The
operatingsystemwouldbeatime-sharedsystemrunningcontinuouslywitha
vastfilesystemofsharedprogramsand data.
MULTICS was designed by a team from MIT,GE(which later sold its com-
puterdepartmenttoHoneywell),andBellLaboratories(whichdroppedoutof
the project in 1969). The basic GE635 computer was modified to a new com-
putersystemcalledthe GE645,mainlybytheadditionofpaged-segmentation
memoryhardware.
InMULTICS , avirtualaddresswas composedof an18-bit segmentnumber
and a 16-bit word offset. The segments were then paged in 1- KB-word pages.
The second-chance page-replacementalgorithmwas used.
Thesegmentedvirtualaddressspacewasmergedintothefilesystem;each
segment was a file. Segments were addressed by the name of the file. The file
systemitselfwasamultileveltreestructure,allowinguserstocreatetheirown
subdirectorystructures.
LikeCTSS,MULTICS used a multilevelfeedback queue for CPUscheduling.
Protection was accomplished through an access list associated with each file
and a set of protection rings for executing processes. The system, which was
written almost entirely in PL/1, comprised about 300,000 lines of code. It was
extendedtoamultiprocessorsystem,allowinga CPUtobetakenoutofservice
formaintenance whilethesystemcontinued running.
A.9 IBM OS/360
The longest line of operating-system developmentis undoubtedly that of IBM
computers. The early IBMcomputers, such as the IBM7090 and the IBM7094,
areprimeexamplesofthedevelopmentofcommon I/Osubroutines,followed
bydevelopmentofaresidentmonitor,privilegedinstructions,memoryprotec-
tion, and simple batch processing. These systems were developed separately,
often at independent sites. As a result, IBMwas faced with many different
computers,withdifferentlanguages and differentsystemsoftware.
TheIBM/360—which first appeared in the mid 1960s—was designed to
alter this situation. The IBM/360was designed as a family of computers span-
ning the complete range from small business machines to large scientific
machines.Onlyonesetofsoftwarewouldbeneededforthesesystems,which
allusedthesameoperatingsystem: OS/360.Thisarrangementwasintendedto"
2,A.10 TOPS-20,1057,A.9 IBM OS/360,"A.11 CP/M and MS/DOS 15
puterscame along and decreasedthe needfor large monolithic systems.They
werefollowedbyworkstationsand thenpersonalcomputers,which putcom-
putingpowercloser andcloser tothe endusers.
A.10 TOPS-20
DECcreated many influential computer systems during its history. Probably
the most famous operating system associated with DECisVMS, a popular
business-oriented system that is still in use today as Open VMS,ap r o d u c to f
Hewlett-Packard.Butperhapsthemostinfluentialof DEC’soperatingsystems
wasTOPS-20.
TOPS-20started life as a research project at Bolt, Beranek, and Newman
(BBN) around 1970. BBNtook the business-oriented DEC PDP-10 computer run-
ningTOPS-10,addeda hardwarememory-pagingsystemtoimplementvirtual
memory, and wrote a new operating system for that computer to take advan-
tage of the new hardware features. The result was TENEX, a general-purpose
time-sharing system. DECthen purchased the rights to TENEXand created a
new computer with a built-in hardware pager. The resulting system was the
DECSYSTEM-20 and the TOPS-20operatingsystem.
TOPS-20had an advanced command-line interpreterthat providedhelp as
needed to users. That, in combination with the power of the computer and
its reasonable price, made the DECSYSTEM-20 the most popular time-sharing
system of its time. In 1984, DECstopped work on its line of 36-bit PDP-10
computerstoconcentrate on 32-bit VAXsystemsrunning VMS.
A.11 CP/M and MS/DOS
Early hobbyist computers were typically built from kits and ran a single pro-
gramatatime.Thesystemsevolvedintomoreadvancedsystemsascomputer
components improved. An early “standard ”operating system for these com-
puters of the 1970s was CP/M, short for Control Program/Monitor, written by
GaryKindallofDigitalResearch,Inc. CP/Mranprimarilyonthefirst “personal
computer ”CPU, the 8-bit Intel 8080. CP/Moriginally supported only 64 KB of
memoryandranonlyoneprogramatatime.Ofcourse,itwastext-based,with
a command interpreter. The command in terpreter resembled those in other
operatingsystemsof the time,suchas the TOPS-10fromDEC.
WhenIBMenteredthe personal computer business, it decidedto have Bill
Gates and company write a new operating system for its 16-bit CPUof choice
—theIntel8086.Thisoperatingsystem, MS-DOS,wassimilarto CP/Mbuthad
arichersetofbuilt-incommands,againmostlymodeledafter TOPS-10.MS-DOS
became the most popular personal-computer operating system of its time,
startingin1981andcontinuingdevelopmentuntil2000.Itsupported640KBof
memory,withtheabilitytoaddress “extended ”and “expanded ”memorytoget
somewhat beyond that limit. It lacked fundamental current operating-system
features,however,especiallyprotectedmemory."
2,A.11 CP/M and MS/DOS,1057,A.10 TOPS-20,"A.11 CP/M and MS/DOS 15
puterscame along and decreasedthe needfor large monolithic systems.They
werefollowedbyworkstationsand thenpersonalcomputers,which putcom-
putingpowercloser andcloser tothe endusers.
A.10 TOPS-20
DECcreated many influential computer systems during its history. Probably
the most famous operating system associated with DECisVMS, a popular
business-oriented system that is still in use today as Open VMS,ap r o d u c to f
Hewlett-Packard.Butperhapsthemostinfluentialof DEC’soperatingsystems
wasTOPS-20.
TOPS-20started life as a research project at Bolt, Beranek, and Newman
(BBN) around 1970. BBNtook the business-oriented DEC PDP-10 computer run-
ningTOPS-10,addeda hardwarememory-pagingsystemtoimplementvirtual
memory, and wrote a new operating system for that computer to take advan-
tage of the new hardware features. The result was TENEX, a general-purpose
time-sharing system. DECthen purchased the rights to TENEXand created a
new computer with a built-in hardware pager. The resulting system was the
DECSYSTEM-20 and the TOPS-20operatingsystem.
TOPS-20had an advanced command-line interpreterthat providedhelp as
needed to users. That, in combination with the power of the computer and
its reasonable price, made the DECSYSTEM-20 the most popular time-sharing
system of its time. In 1984, DECstopped work on its line of 36-bit PDP-10
computerstoconcentrate on 32-bit VAXsystemsrunning VMS.
A.11 CP/M and MS/DOS
Early hobbyist computers were typically built from kits and ran a single pro-
gramatatime.Thesystemsevolvedintomoreadvancedsystemsascomputer
components improved. An early “standard ”operating system for these com-
puters of the 1970s was CP/M, short for Control Program/Monitor, written by
GaryKindallofDigitalResearch,Inc. CP/Mranprimarilyonthefirst “personal
computer ”CPU, the 8-bit Intel 8080. CP/Moriginally supported only 64 KB of
memoryandranonlyoneprogramatatime.Ofcourse,itwastext-based,with
a command interpreter. The command in terpreter resembled those in other
operatingsystemsof the time,suchas the TOPS-10fromDEC.
WhenIBMenteredthe personal computer business, it decidedto have Bill
Gates and company write a new operating system for its 16-bit CPUof choice
—theIntel8086.Thisoperatingsystem, MS-DOS,wassimilarto CP/Mbuthad
arichersetofbuilt-incommands,againmostlymodeledafter TOPS-10.MS-DOS
became the most popular personal-computer operating system of its time,
startingin1981andcontinuingdevelopmentuntil2000.Itsupported640KBof
memory,withtheabilitytoaddress “extended ”and “expanded ”memorytoget
somewhat beyond that limit. It lacked fundamental current operating-system
features,however,especiallyprotectedmemory."
2,A.12 Macintosh Operating System and Windows,1058,A.11 CP/M and MS/DOS,"16 Appendix A Influentia Operating Systems
A.12 Macintosh Operating System and Windows
With the advent of 16-bit CPUs, operating systems for personal computers
couldbecomemoreadvanced,featurerich,andusable.The Apple Macintosh
computerwasarguablythefirstcomputerwitha GUIdesignedforhomeusers.
It was certainly the most successful for a while, starting at its launch in 1984.
It used a mouse for screen pointing and selecting and came with many utility
programsthattookadvantageofthenewuserinterface.Hard-diskdriveswere
relatively expensive in 1984, so it came only with a 400-KB-capacity floppy
driveby default.
TheoriginalMac OSranonlyonApplecomputersandslowlywaseclipsed
by Microsoft Windows (starting with Version 1.0 in 1985), which was licensed
torunonmanydifferentcomputersfromamultitudeofcompanies.Asmicro-
processor CPUs evolved to 32-bit chips with advanced features, such as pro-
tectedmemoryandcontextswitching, theseoperatingsystemsaddedfeatures
thathadpreviouslybeenfoundonlyonmainframesandminicomputers.Over
time,personalcomputersbecameaspowerfulasthosesystemsandmoreuse-
ful for many purposes. Minicomputers died out, replaced by general- and
special-purpose “servers. ”Although personal computers continue to increase
in capacity and performance,serverstend to stay ahead of them in amount of
memory, disk space, and number and speed of available CPUs. Today, servers
typically run in data centers or machine rooms, while personal computers sit
onor nextto desksand talkto eachother andserversacross a network.
The desktop rivalry between Apple and Microsoft continues today, with
new versions of Windows and Mac OStrying to outdo each other in fea-
tures, usability, and application functionality. Other operating systems, such
as Amiga OSandOS/2, have appeared over time but have not been long-term
competitors to the two leading desktop operating systems.Meanwhile, Linux
initsmany formscontinues to gaininpopularityamong moretechnical users
—andevenwithnontechnicalusersonsystemslikethe One Laptop per Child
(OLPC) children’sconnected computer network( http://laptop.org/ ).
A.13 Mach
The Mach operating system traces its ancestry to the Accent operating sys-
tem developed at Carnegie Mellon University ( CMU). Mach’s communication
system and philosophy are derived from Accent, but many other significant
portions of the system (for example, the virtual memory system and task and
threadmanagement) weredevelopedfromscratch.
WorkonMachbeganinthemid1980.Theoperatingsystemwasdesigned
withthe following threecritical goalsinmind:
1.Emulate 4.3 BSD UNIX so that theexecutablefilesfrom a UNIXsystemcan
run correctlyunderMach.
2.Be a modern operating system that supports many memory models, as
wellas paralleland distributedcomputing.
3.Havea kernelthat is simplerandeasiertomodifythan 4.3 BSD."
2,A.13 Mach,1058,A.12 Macintosh Operating System and Windows,"16 Appendix A Influentia Operating Systems
A.12 Macintosh Operating System and Windows
With the advent of 16-bit CPUs, operating systems for personal computers
couldbecomemoreadvanced,featurerich,andusable.The Apple Macintosh
computerwasarguablythefirstcomputerwitha GUIdesignedforhomeusers.
It was certainly the most successful for a while, starting at its launch in 1984.
It used a mouse for screen pointing and selecting and came with many utility
programsthattookadvantageofthenewuserinterface.Hard-diskdriveswere
relatively expensive in 1984, so it came only with a 400-KB-capacity floppy
driveby default.
TheoriginalMac OSranonlyonApplecomputersandslowlywaseclipsed
by Microsoft Windows (starting with Version 1.0 in 1985), which was licensed
torunonmanydifferentcomputersfromamultitudeofcompanies.Asmicro-
processor CPUs evolved to 32-bit chips with advanced features, such as pro-
tectedmemoryandcontextswitching, theseoperatingsystemsaddedfeatures
thathadpreviouslybeenfoundonlyonmainframesandminicomputers.Over
time,personalcomputersbecameaspowerfulasthosesystemsandmoreuse-
ful for many purposes. Minicomputers died out, replaced by general- and
special-purpose “servers. ”Although personal computers continue to increase
in capacity and performance,serverstend to stay ahead of them in amount of
memory, disk space, and number and speed of available CPUs. Today, servers
typically run in data centers or machine rooms, while personal computers sit
onor nextto desksand talkto eachother andserversacross a network.
The desktop rivalry between Apple and Microsoft continues today, with
new versions of Windows and Mac OStrying to outdo each other in fea-
tures, usability, and application functionality. Other operating systems, such
as Amiga OSandOS/2, have appeared over time but have not been long-term
competitors to the two leading desktop operating systems.Meanwhile, Linux
initsmany formscontinues to gaininpopularityamong moretechnical users
—andevenwithnontechnicalusersonsystemslikethe One Laptop per Child
(OLPC) children’sconnected computer network( http://laptop.org/ ).
A.13 Mach
The Mach operating system traces its ancestry to the Accent operating sys-
tem developed at Carnegie Mellon University ( CMU). Mach’s communication
system and philosophy are derived from Accent, but many other significant
portions of the system (for example, the virtual memory system and task and
threadmanagement) weredevelopedfromscratch.
WorkonMachbeganinthemid1980.Theoperatingsystemwasdesigned
withthe following threecritical goalsinmind:
1.Emulate 4.3 BSD UNIX so that theexecutablefilesfrom a UNIXsystemcan
run correctlyunderMach.
2.Be a modern operating system that supports many memory models, as
wellas paralleland distributedcomputing.
3.Havea kernelthat is simplerandeasiertomodifythan 4.3 BSD."
2,A.14 Capability-based Systems—Hydra and CAP,1060,A.13 Mach,"18 Appendix A Influentia Operating Systems
Today, the only remaining pure Mach implementation is in GNU HURD ,a
little-usedoperatingsystem.Machstillliveson,however,in XNU—thekernel
driving mac OSand the i OSvariants. XNU—whose codebase Apple obtained
with the acquisition of NeXTand its NeXTSTEPoperating system—is a Mach
corewithatoplayerof BSD APIs.Applecontinuestosupportandmaintainthe
MachAPIs (still accessible through specialized system calls known as traps,
andviaMachMessages),andthekernelcontinuesevolvingwithnewfeatures
to thisday.
Some previous editions of Operating System Concepts included an entire
chapteronMach.Thischapter,asitappe aredinthefourthedition,isavailable
onthe web( http://www.os-book.com ).
A.14 Capability-based Systems—Hydra and CAP
Inthis section,we surveytwo capability-basedprotectionsystems.Thesesys-
tems differ in their complexity and in the types of policies that can be imple-
mented on them. Neither system is widely used, but both provide interesting
provinggroundsfor protectiontheories.
A.14.1 Hydra
Hydraisacapability-basedprotectionsystemthatprovidesconsiderableflex-
ibility. The system implements a fixed set of possible access rights, including
suchbasicformsofaccessastherighttoread,write,orexecuteamemoryseg-
ment.Inaddition,auser(oftheprotectionsystem)candeclareotherrights.The
interpretationofuser-definedrightsisperformedsolelybytheuser’sprogram,
but the system provides access protection for the use of these rights, as well
as for the use of system-defined rights. These facilities constitute a significant
developmentinprotectiontechnology.
Operationsonobjectsaredefinedprocedurally.Theproceduresthatimple-
ment such operations are themselves a form of object, and they are accessed
indirectlybycapabilities.Thenamesofuser-definedproceduresmustbeiden-
tified to the protection system if it is to deal with objects of the user-defined
type. When the definition of an object is made known to Hydra, the names
of operations on the type become auxiliary rights . Auxiliary rights can be
described in a capability for an instan ce of the type. For a process to perform
anoperationonatypedobject,thecapabilityitholdsforthatobjectmustcon-
tain the name of the operation being invoked among its auxiliary rights. This
restriction enables discrimination of access rights to be made on an instance-
by-instance andprocess-by-processbasis.
Hydraalsoprovides rights amplificatio .Thisschemeallowsaprocedure
to be certified as trustworthy to act on a formal parameter of a specified type
onbehalfofanyprocessthatholdsarighttoexecutetheprocedure.Therights
held by a trustworthy procedure are independent of, and may exceed, the
rights held by the calling process. However, such a procedure must not be
regarded as universally trustworthy (the procedure is not allowed to act on
othertypes,forinstance),andthetrustworthinessmustnotbeextendedtoany
other proceduresorprogramsegmentsthat mightbe executedby a process."
3,A.14.1 Hydra,1060,A.14 Capability-based Systems—Hydra and CAP,"18 Appendix A Influentia Operating Systems
Today, the only remaining pure Mach implementation is in GNU HURD ,a
little-usedoperatingsystem.Machstillliveson,however,in XNU—thekernel
driving mac OSand the i OSvariants. XNU—whose codebase Apple obtained
with the acquisition of NeXTand its NeXTSTEPoperating system—is a Mach
corewithatoplayerof BSD APIs.Applecontinuestosupportandmaintainthe
MachAPIs (still accessible through specialized system calls known as traps,
andviaMachMessages),andthekernelcontinuesevolvingwithnewfeatures
to thisday.
Some previous editions of Operating System Concepts included an entire
chapteronMach.Thischapter,asitappe aredinthefourthedition,isavailable
onthe web( http://www.os-book.com ).
A.14 Capability-based Systems—Hydra and CAP
Inthis section,we surveytwo capability-basedprotectionsystems.Thesesys-
tems differ in their complexity and in the types of policies that can be imple-
mented on them. Neither system is widely used, but both provide interesting
provinggroundsfor protectiontheories.
A.14.1 Hydra
Hydraisacapability-basedprotectionsystemthatprovidesconsiderableflex-
ibility. The system implements a fixed set of possible access rights, including
suchbasicformsofaccessastherighttoread,write,orexecuteamemoryseg-
ment.Inaddition,auser(oftheprotectionsystem)candeclareotherrights.The
interpretationofuser-definedrightsisperformedsolelybytheuser’sprogram,
but the system provides access protection for the use of these rights, as well
as for the use of system-defined rights. These facilities constitute a significant
developmentinprotectiontechnology.
Operationsonobjectsaredefinedprocedurally.Theproceduresthatimple-
ment such operations are themselves a form of object, and they are accessed
indirectlybycapabilities.Thenamesofuser-definedproceduresmustbeiden-
tified to the protection system if it is to deal with objects of the user-defined
type. When the definition of an object is made known to Hydra, the names
of operations on the type become auxiliary rights . Auxiliary rights can be
described in a capability for an instan ce of the type. For a process to perform
anoperationonatypedobject,thecapabilityitholdsforthatobjectmustcon-
tain the name of the operation being invoked among its auxiliary rights. This
restriction enables discrimination of access rights to be made on an instance-
by-instance andprocess-by-processbasis.
Hydraalsoprovides rights amplificatio .Thisschemeallowsaprocedure
to be certified as trustworthy to act on a formal parameter of a specified type
onbehalfofanyprocessthatholdsarighttoexecutetheprocedure.Therights
held by a trustworthy procedure are independent of, and may exceed, the
rights held by the calling process. However, such a procedure must not be
regarded as universally trustworthy (the procedure is not allowed to act on
othertypes,forinstance),andthetrustworthinessmustnotbeextendedtoany
other proceduresorprogramsegmentsthat mightbe executedby a process."
3,A.14.2 Cambridge CAP System,1062,A.14.1 Hydra,"20 Appendix A Influentia Operating Systems
A.14.2 Cambridge CAP System
A different approach to capability-based protection has been taken in the
design of the Cambridge CAPsystem. CAP’s capability system is simpler and
superficially less powerful than that of Hydra. However, closer examination
shows that it, too, can be used to provide secure protection of user-defined
objects. CAPhas two kinds of capabilities. The ordinary kind is called a data
capability . It can be used to provideaccess to objects, but the only rights pro-
vided are the standard read, write, and execute of the individual storage seg-
mentsassociatedwiththeobject.Dataca pabilitiesareinterpretedbymicrocode
intheCAPmachine.
Thesecondkindofcapabilityistheso-called software capability ,whichis
protected,butnotinterpreted,bythe CAPmicrocode.Itisinterpretedbya pro-
tected(that is, privileged)procedure,which may be writtenby an application
programmer as part of a subsystem. Aparticular kind of rights amplification
is associated with a protected procedure. When executing the code body of
suchaprocedure,aprocesstemporarilyacquirestherighttoreadorwritethe
contents of a software capability itself. This specific kind of rights amplifica-
tion corresponds to an implementation of the sealandunsealprimitives on
capabilities.Ofcourse,thisprivilegeisstillsubjecttotypeverificationtoensure
that only software capabilities for a specified abstract type are passed to any
such procedure. Universal trust is not placed in any code other than the CAP
machine’s microcode. (See the bibliographical notes at the end of the chapter
for references.)
The interpretation of a software capability is left completely to the sub-
system, through the protected procedures it contains. This scheme allows a
variety of protection policies to be implemented. Although programmers can
define their own protected procedures (any of which might be incorrect), the
security of the overall system cannot be compromised. The basic protection
system will not allow an unverified, user-defined, protected procedure access
to any storage segments (or capabilitie s) that do not belong to the protection
environmentinwhich it resides.Themost seriousconsequence of aninsecure
protectedprocedureisaprotectionbreakdownofthesubsystemforwhichthat
procedurehas responsibility.
The designers of the CAPsystem have noted that the use of software
capabilities allowed them to realize considerable economies in formulating
andimplementingprotectionpoliciescommensuratewiththerequirementsof
abstract resources. However, subsystem designers who want to make use of
thisfacilitycannotsimplystudyareferencemanual,asisthecasewithHydra.
Instead, they must learn the principles and techniques of protection, since the
systemprovidesthem withno libraryof procedures.
A.15 Other Systems
Thereare,of course,other operatingsystems,andmost of themhaveinterest-
ing properties. The MCPoperating system for the Burroughs computer family
was the first to be written in a system programming language. It supported
segmentation and multiple CPUs. TheSCOPEoperating system for the CDC
6600 was also a multi- CPUsystem. The coordination and synchronization of
themultipleprocessesweresurprisinglywelldesigned."
2,A.15 Other Systems,1062,A.14 Capability-based Systems—Hydra and CAP,"20 Appendix A Influentia Operating Systems
A.14.2 Cambridge CAP System
A different approach to capability-based protection has been taken in the
design of the Cambridge CAPsystem. CAP’s capability system is simpler and
superficially less powerful than that of Hydra. However, closer examination
shows that it, too, can be used to provide secure protection of user-defined
objects. CAPhas two kinds of capabilities. The ordinary kind is called a data
capability . It can be used to provideaccess to objects, but the only rights pro-
vided are the standard read, write, and execute of the individual storage seg-
mentsassociatedwiththeobject.Dataca pabilitiesareinterpretedbymicrocode
intheCAPmachine.
Thesecondkindofcapabilityistheso-called software capability ,whichis
protected,butnotinterpreted,bythe CAPmicrocode.Itisinterpretedbya pro-
tected(that is, privileged)procedure,which may be writtenby an application
programmer as part of a subsystem. Aparticular kind of rights amplification
is associated with a protected procedure. When executing the code body of
suchaprocedure,aprocesstemporarilyacquirestherighttoreadorwritethe
contents of a software capability itself. This specific kind of rights amplifica-
tion corresponds to an implementation of the sealandunsealprimitives on
capabilities.Ofcourse,thisprivilegeisstillsubjecttotypeverificationtoensure
that only software capabilities for a specified abstract type are passed to any
such procedure. Universal trust is not placed in any code other than the CAP
machine’s microcode. (See the bibliographical notes at the end of the chapter
for references.)
The interpretation of a software capability is left completely to the sub-
system, through the protected procedures it contains. This scheme allows a
variety of protection policies to be implemented. Although programmers can
define their own protected procedures (any of which might be incorrect), the
security of the overall system cannot be compromised. The basic protection
system will not allow an unverified, user-defined, protected procedure access
to any storage segments (or capabilitie s) that do not belong to the protection
environmentinwhich it resides.Themost seriousconsequence of aninsecure
protectedprocedureisaprotectionbreakdownofthesubsystemforwhichthat
procedurehas responsibility.
The designers of the CAPsystem have noted that the use of software
capabilities allowed them to realize considerable economies in formulating
andimplementingprotectionpoliciescommensuratewiththerequirementsof
abstract resources. However, subsystem designers who want to make use of
thisfacilitycannotsimplystudyareferencemanual,asisthecasewithHydra.
Instead, they must learn the principles and techniques of protection, since the
systemprovidesthem withno libraryof procedures.
A.15 Other Systems
Thereare,of course,other operatingsystems,andmost of themhaveinterest-
ing properties. The MCPoperating system for the Burroughs computer family
was the first to be written in a system programming language. It supported
segmentation and multiple CPUs. TheSCOPEoperating system for the CDC
6600 was also a multi- CPUsystem. The coordination and synchronization of
themultipleprocessesweresurprisinglywelldesigned."
2,Further Reading,1063,A.15 Other Systems,"Bibliography 21
History is litteredwith operating systems that suited a purpose for a time
(beitalongorashorttime)andthen,whenfaded,werereplacedbyoperating
systemsthathadmorefeatures,supportednewerhardware,wereeasiertouse,
orwerebettermarketed.Wearesurethis trendwillcontinue inthefuture.
Further Reading
Loomsandcalculatorsaredescribedin[Frah(2001)]andshowngraphicallyin
[Frauenfelder(2005)].
The Manchester Mark 1 is discussed by [Rojas and Hashagen (2000)], and
itsoffspring,theFerrantiMark 1,isdescribedby [Ceruzzi(1998)].
[Kilburn et al. (1961)] and [Howarth et al. (1961)] examine the Atlas oper-
atingsystem.
TheXDS-940operating system is described by [Lichtenberger and Pirtle
(1965)].
TheTHEoperating system is coveredby [Dijkstra (1968)] and by [McKeag
andWilson (1976)].
The Venussystemisdescribedby [Liskov(1972)].
[Brinch-Hansen (1970)] and [Brinch-Hansen (1973)] discuss the RC4000
system.
TheCompatibleTime-SharingSystem( CTSS)ispresentedby[Corbatoetal.
(1962)].
TheMULTICS operating system is described by [Corbato and Vyssotsky
(1965)] and [Organick (1972)].
[Mealy et al. (1966)] presented the IBM/360. [Lett and Konigsford (1968)]
coverTSS/360.
CP/67is described by [Meyer and Seaw right (1970)] and [Parmelee et al.
(1972)].
DEC VMS is discussed by [Kenah et al. (1988)], and TENEXis described by
[Bobrow etal.(1972)].
AdescriptionoftheAppleMacintoshappearsin[Apple(1987)]. Formore
information on these operating systems and their history, see [Freiberger and
Swaine (2000)].
TheMachoperatingsystemanditsancestor,theAccentoperatingsystem,
are described by [Rashid and Robertson (1981)]. Mach’s communication
system is covered by [Rashid (1986)], [Tevanian et al. (1989)], and [Accetta
et al. (1986)]. The Mach scheduler is described in detail by [Tevanian
et al. (1987a)] and [Black (1990)]. An early version of the Mach shared-
memory and memory-mapping system is presented by [Tevanian et al.
(1987b)]. A good resource describing the Mach project can be found at
http://www.cs.cmu.edu/afs/cs/project/mach/public/www/mach.html .
[McKeag and Wilson (1976)] discuss the MCPoperating system for the
Burroughscomputerfamilyaswellasthe SCOPEoperatingsystemforthe CDC
6600.
The Hydra system was described by [Wulf et al. (1981)]. The CAPsystem
was described by [Needham and Walker (1977)]. [Organick (1972)] discussed
theMULTICS ring-protectionsystem."
2,Bibliography,1064,Further Reading,"22 Appendix A Influentia Operating Systems
Bibliography
[Accetta et al. (1986)] M .A c c e t t a ,R .B a r o n ,W .B o l o s k y ,D .B .G o l u b ,R .R a s h i d ,
A.Tevanian,andM.Young, “Mach:ANewKernelFoundationfor UNIXDevel-
opment ”,Proceedings of the Summer USENIX Conference (1986), pages 93–112.
[Apple (1987)] Apple Technical Introduction to the Macintosh Family . Addison-
Wesley (1987).
[Black (1990)] D. L. Black, “Scheduling Support for Concurrency and Paral-
lelism in the Mach Operating System ”,IEEE Computer , Volume 23, Number 5
(1990), pages 35–43.
[Bobrow et al. (1972)] D.G.Bobrow ,J.D.Burchfiel,D.L.Murphy ,andR.S.T om-
linson, “TENEX,aPagedTimeSharingSystemforthePDP-10 ”,Communications
of the ACM ,Volume15,Number3 (1972).
[Brinch-Hansen (1970)] P. Brinch-Hansen, “The Nucleus of a Multiprogram-
ming System ”,Communications of the ACM ,Volume13, Number4 (1970), pages
238–241 and 250.
[Brinch-Hansen (1973)] P. Brinch-Hansen, Operating System Principles ,P r e n t i c e
Hall (1973).
[Ceruzzi (1998)] P.E.Ceruzzi, A History of Modern Computing , MITPress(1998).
[Corbato and Vyssotsky (1965)] F.J.CorbatoandV.A.Vyssotsky, “Introduction
and Overview of the MULTICS System ”,Proceedings of the AFIPS Fall Joint
Computer Conference (1965), pages185–196.
[Corbato et al. (1962)] F. J. Corbato, M. Merwin-Daggett, and R. C. Daley, “An
ExperimentalTime-SharingSystem ”,Proceedings of the AFIPS Fall Joint Computer
Conference (1962), pages335–344.
[Dijkstra (1968)] E. W. Dijkstra, “The Structure of the THE Multiprogramming
System ”,Communications of the ACM , Volume 11, Number 5 (1968), pages 341–
346.
[Frah (2001)] G. Frah, The Universal History of Computing , John Wiley and Sons
(2001).
[Frauenfelder (2005)] M. Frauenfelder, The Computer—An Illustrated History ,
CarltonBooks (2005).
[Freiberger and Swaine (2000)] P.FreibergerandM.Swaine, Fire in the Valley—
The Making of the Personal Computer ,McGraw-Hill (2000).
[Howarth et al. (1961)] D. J. Howarth, R. B. Payne, and F. H. Sumner, “The
Manchester University Atlas Operating System, Part II: User’s Description ”,
Computer Journal ,Volume4,Number3(1961), pages 226–229.
[Kenah et al. (1988)] L. J. Kenah, R. E. Goldenberg, and S. F. Bate, V AX/VMS
Internals and Data Structures ,Digital Press(1988).
[Kilburn et al. (1961)] T.Kilburn,D.J.Howarth,R.B.Payne,andF.H.Sumner,
“TheManchesterUniversityAtlasOperatingSystem,PartI:InternalOrganiza-
tion ”,Computer Journal ,Volume4,Number3 (1961), pages222–225."
1,Appendix B Windows,1067,Appendix A Influential Operating Systems,"BAppendix
Windows 7
Updated by Dave Probert
The Microsoft Windows 7 operating system is a 32-/64-bit preemptive mul-
titasking client operating system for microprocessors implementing the Intel
IA-32and AMD64instructionsetarchitectures( ISAs).Microsoft’scorresponding
server operating system, Windows Server 2008 R2, is based on the same code
as Windows 7 but supports only the 64-bit AMD64 and IA64 (Itanium) ISAs.
Windows 7 is the latest in a series of Microsoft operating systems based on
itsNTcode, which replaced the earlier systems based on Windows 95/98. In
thisappendix,wediscussthekeygoalso fWindows7,thelayeredarchitecture
of the system that has made it so easy to use, the file system, the networking
features,andthe programminginterface.
CHAPTER OBJECTIVES
•Explore the principles underlying Windows 7’s design and the specific
components of the system.
•Provide a detailed discussion of the Windows 7 file system.
•Illustrate the networking protocols supported in Windows 7.
•Describe the interface available in Windows 7 to system and application
programmers.
•Describe the important algorithms implemented with Windows 7.
B.1 History
Inthemid-1980s,Microsoftand IBMcooperatedtodevelopthe OS/2 operating
system, which was written in assembly language for single-processor Intel
80286 systems. In 1988, Microsoft decided to end the joint effort with IBM
and develop its own “new technology ”(orNT) portable operating system to
supportboththe OS/2andPOSIXapplication-programminginterfaces( APIs).In
1"
2,B.1 History,1067,Appendix B Windows,"BAppendix
Windows 7
Updated by Dave Probert
The Microsoft Windows 7 operating system is a 32-/64-bit preemptive mul-
titasking client operating system for microprocessors implementing the Intel
IA-32and AMD64instructionsetarchitectures( ISAs).Microsoft’scorresponding
server operating system, Windows Server 2008 R2, is based on the same code
as Windows 7 but supports only the 64-bit AMD64 and IA64 (Itanium) ISAs.
Windows 7 is the latest in a series of Microsoft operating systems based on
itsNTcode, which replaced the earlier systems based on Windows 95/98. In
thisappendix,wediscussthekeygoalso fWindows7,thelayeredarchitecture
of the system that has made it so easy to use, the file system, the networking
features,andthe programminginterface.
CHAPTER OBJECTIVES
•Explore the principles underlying Windows 7’s design and the specific
components of the system.
•Provide a detailed discussion of the Windows 7 file system.
•Illustrate the networking protocols supported in Windows 7.
•Describe the interface available in Windows 7 to system and application
programmers.
•Describe the important algorithms implemented with Windows 7.
B.1 History
Inthemid-1980s,Microsoftand IBMcooperatedtodevelopthe OS/2 operating
system, which was written in assembly language for single-processor Intel
80286 systems. In 1988, Microsoft decided to end the joint effort with IBM
and develop its own “new technology ”(orNT) portable operating system to
supportboththe OS/2andPOSIXapplication-programminginterfaces( APIs).In
1"
2,B.2 Design Principles,1069,B.1 History,"B.2 Design Principles 3
perspective, but machine-virtualizat ion technologies are now becoming the
dominant way ofrunning multipleoperatingsystemson asinglemachine.
Windows 7 is a multiuser operating system, supporting simultaneous
access through distributed services or through multiple instances of the GUI
viathe Windows terminalservices.The servereditionsof Windows 7 support
simultaneous terminal server sessions from Windows desktop systems. The
desktopeditionsof terminalservermu ltiplexthe keyboard,mouse, and mon-
itor between virtual terminal sessions for each logged-on user. This feature,
calledfastuserswitching ,allowsuserstopreempteachotherattheconsoleof
aPCwithout having to logoff and logon.
We noted earlier that some GUIimplementation moved into kernel mode
in Windows NT4.0. It started to move into user mode again with Windows
Vista, which included the desktop window manager (DWM)a sau s e r - m o d e
process. DWMimplementsthedesktopcompositingofWindows,providingthe
Windows AerointerfacelookontopoftheWindowsDirectXgraphicsoftware.
DirectX continues to run in the kernel, as does the code implementing Win-
dows’previouswindowingandgraphicsmodels(Win32kandGDI).Windows
7 made substantial changes to the DWM, significantly reducing its memory
footprintand improvingitsperformance.
Windows XPwasthe firstversionofWindowstoshipa64-bitversion(for
theIA64 in 2001 and the AMD64 in 2005). Internally, the native NTfile system
(NTFS) and many of the Win 32 APIs have always used 64-bit integers where
appropriate—so the major extension to 64-bit in Windows XPwas support
for largevirtualaddresses.However,64-bit editionsof Windows also support
much larger physical memories. By the time Windows 7 shipped, the AMD64
ISAhadbecomeavailableonalmostall CPUsfrombothIntelandAMD.Inaddi-
tion, by that time, physical memories on client systems frequently exceeded
the 4-GBlimit of the IA-32. As a result,the 64-bit versionof Windows 7 is now
commonly installed on larger client systems. Because the AMD64 architecture
supports high-fidelity IA-32 compatibility at the level of individual processes,
32- and64-bit applications canbe freelymixedina singlesystem.
IntherestofourdescriptionofWindows7,wewillnotdistinguishbetween
the client editions of Windows 7 and the corresponding server editions. They
are based on the same core components and run the same binary files for
the kernel and most drivers. Similarly, although Microsoft ships a variety of
different editions of each release to address different market price points, few
of the differences between editions are reflected in the core of the system. In
thischapter,we focus primarilyon thecore components of Windows 7.
B.2 Design Principles
Microsoft’s design goals for Windows included security, reliability, Windows
andPOSIXapplication compatibility,high performance, extensibility,portabil-
ity, and international support. Some additional goals, energy efficiency and
dynamicdevicesupport,haverecentlybeenaddedtothislist.Next,wediscuss
eachof thesegoals and howit isachievedinWindows 7.
B.2.1 Security
Windows7securitygoalsrequiredmorethanjustadherencetothedesignstan-
dards that had enabled Windows NT4.0 to receive a C2 security classification"
3,B.2.1 Security,1069,B.2 Design Principles,"B.2 Design Principles 3
perspective, but machine-virtualizat ion technologies are now becoming the
dominant way ofrunning multipleoperatingsystemson asinglemachine.
Windows 7 is a multiuser operating system, supporting simultaneous
access through distributed services or through multiple instances of the GUI
viathe Windows terminalservices.The servereditionsof Windows 7 support
simultaneous terminal server sessions from Windows desktop systems. The
desktopeditionsof terminalservermu ltiplexthe keyboard,mouse, and mon-
itor between virtual terminal sessions for each logged-on user. This feature,
calledfastuserswitching ,allowsuserstopreempteachotherattheconsoleof
aPCwithout having to logoff and logon.
We noted earlier that some GUIimplementation moved into kernel mode
in Windows NT4.0. It started to move into user mode again with Windows
Vista, which included the desktop window manager (DWM)a sau s e r - m o d e
process. DWMimplementsthedesktopcompositingofWindows,providingthe
Windows AerointerfacelookontopoftheWindowsDirectXgraphicsoftware.
DirectX continues to run in the kernel, as does the code implementing Win-
dows’previouswindowingandgraphicsmodels(Win32kandGDI).Windows
7 made substantial changes to the DWM, significantly reducing its memory
footprintand improvingitsperformance.
Windows XPwasthe firstversionofWindowstoshipa64-bitversion(for
theIA64 in 2001 and the AMD64 in 2005). Internally, the native NTfile system
(NTFS) and many of the Win 32 APIs have always used 64-bit integers where
appropriate—so the major extension to 64-bit in Windows XPwas support
for largevirtualaddresses.However,64-bit editionsof Windows also support
much larger physical memories. By the time Windows 7 shipped, the AMD64
ISAhadbecomeavailableonalmostall CPUsfrombothIntelandAMD.Inaddi-
tion, by that time, physical memories on client systems frequently exceeded
the 4-GBlimit of the IA-32. As a result,the 64-bit versionof Windows 7 is now
commonly installed on larger client systems. Because the AMD64 architecture
supports high-fidelity IA-32 compatibility at the level of individual processes,
32- and64-bit applications canbe freelymixedina singlesystem.
IntherestofourdescriptionofWindows7,wewillnotdistinguishbetween
the client editions of Windows 7 and the corresponding server editions. They
are based on the same core components and run the same binary files for
the kernel and most drivers. Similarly, although Microsoft ships a variety of
different editions of each release to address different market price points, few
of the differences between editions are reflected in the core of the system. In
thischapter,we focus primarilyon thecore components of Windows 7.
B.2 Design Principles
Microsoft’s design goals for Windows included security, reliability, Windows
andPOSIXapplication compatibility,high performance, extensibility,portabil-
ity, and international support. Some additional goals, energy efficiency and
dynamicdevicesupport,haverecentlybeenaddedtothislist.Next,wediscuss
eachof thesegoals and howit isachievedinWindows 7.
B.2.1 Security
Windows7securitygoalsrequiredmorethanjustadherencetothedesignstan-
dards that had enabled Windows NT4.0 to receive a C2 security classification"
3,B.2.2 Reliability,1070,B.2.1 Security,"4 Appendix B Windows 7
from the U.S. government. (A C2 classification signifies a moderate level of
protectionfromdefectivesoftwareand maliciousattacks.Classificationswere
defined by the Department of Defense Trusted Computer System Evaluation
Criteria, also known as the Orange Book .) Extensive code review and testing
were combined with sophisticated automatic analysis tools to identify and
investigatepotentialdefectsthat migh trepresentsecurityvulnerabilities.
Windows bases security on discretionary access controls. System objects,
including files, registry settings, and kernel objects, are protected by access-
control lists (ACLs) (see Section 13.4.2). ACLs are vulnerable to user and pro-
grammererrors,however,aswellastothemostcommonattacksonconsumer
systems, in which the user is tricked into running code, often while browsing
the web. Windows 7 includes a mechanism called integrity levels that acts as
ar u dim en t a r y capability systemfor controlling access. Objects and processes
aremarkedashavinglow,medium,orhighintegrity.Windowsdoesnotallow
a processtomodifyanobject witha higherintegritylevel,no matterwhat the
settingof the ACL.
Other security measures include address-space layout randomization
(ASLR),nonexecutablestacksandheaps,andencryptionand digital signature
facilities. ASLRthwarts many forms of attack by preventing small amounts of
injectedcodefromjumpingeasilytocodethatisalreadyloadedinaprocessas
part of normal operation. This safeguard makes it likely that a system under
attack willfail orcrash ratherthanlettheattacking codetakecontrol.
Recent chips from both Intel and AMDare based on the AMD64 architec-
ture, which allows memory pages to be marked so that they cannot contain
executableinstructioncode.Windowstriestomarkstacksandmemoryheaps
so that they cannot be used to execute code, thus preventing attacks in which
a program bug allows a buffer to overflow and then is tricked into executing
the contents of the buffer. This technique cannot be applied to all programs,
becausesomerelyonmodifyingdataandexecutingit.Acolumnlabeled “data
execution prevention ”in the Windows task manager shows which processes
aremarkedtopreventtheseattacks.
W indowsusesencryptionaspartofcommonprotocols,suchasthoseused
to communicate securely with websites. Encryption is also used to protect
user files stored on disk from prying eyes. Windows 7 allows users to easily
encryptvirtuallyawholedisk,aswellasremovablestoragedevicessuchas USB
flash drives, with a feature called BitLocker. If a computer with an encrypted
disk is stolen, the thieves will need very sophisticated technology (such as an
electron microscope) to gain access to any of the computer’s files. Windows
usesdigitalsignaturesto signoperatingsystembinariessoitcanverifythatthe
fileswereproducedbyMicrosoftoranotherknowncompany.Insomeeditions
ofWindows,a code integrity moduleisactivatedatboottoensurethatallthe
loaded modules in the kernel have valid signatures, assuring that they have
not beentamperedwithby anoff-line attack.
B.2.2 Reliability
Windowsmaturedgreatlyasanoperatingsysteminitsfirsttenyears,leading
toWindows2000.Atthesametime,itsreliabilityincreasedduetosuchfactors
asmaturityinthesourcecode,extensivestresstestingofthesystem,improved
CPUarchitectures, and automatic detection of many serious errors in drivers
from both Microsoft and third parties. Windows has subsequently extended"
3,B.2.3 Windows and POSIX Application Compatibility,1071,B.2.2 Reliability,"B.2 Design Principles 5
the tools for achieving reliability to include automatic analysis of source code
forerrors,teststhatincludeprovidinginvalidorunexpectedinputparameters
(knownas fuzzing)todetectvalidationfailures,andanapplicationversionof
the driver verifier that applies dynamic checking for an extensive set of com-
mon user-mode programming errors. Oth er improvements in reliability have
resultedfrommovingmorecodeoutofthekernelandintouser-modeservices.
Windowsprovidesextensivesupportforwritingdriversinusermode.System
facilities that were once in the kernel and are now in user mode include the
DesktopWindow Manager andmuch of thesoftware stackfor audio.
OneofthemostsignificantimprovementsintheWindowsexperiencecame
from adding memory diagnostics as an option at boot time. This addition is
especially valuable because so few consumer PCs have error-correcting mem-
ory.Whenbad RAMstartstodropbitshereandthere,theresultisfrustratingly
erratic behavior in the system. The availability of memory diagnostics has
greatlyreducedthestresslevelsof userswithbad RAM.
Windows7introducedafault-tolerantmemoryheap.Theheaplearnsfrom
applicationcrashesandautomaticallyin sertsmitigationsintofutureexecution
of an application that has crashed. This makes the application more reliable
even if it contains common bugs such as using memory after freeing it or
accessing pastthe end of the allocation.
Achieving high reliability in Windows is particularly challenging because
almost one billion computers run Windows. Even reliability problems that
affect only a small percentage of users still impact tremendous numbers of
human beings. The complexity of the Windows ecosystem also adds to the
challenges.Millionsofinstancesofapplications,drivers,andothersoftwareare
being constantly downloaded and run on Windows systems. Of course, there
is also a constant stream of malware attacks. As Windows itself has become
harderto attack directly,exploitsincreasinglytargetpopular applications.
Tocopewiththesechallenges,Microsoftisincreasinglyrelyingoncommu-
nications from customer machines to collect large amounts of data from the
ecosystem. Machines can be sampled to see how they are performing, what
software they are running, and what problems they are encountering. Cus-
tomerscansenddatatoMicrosoftwhensystemsorsoftwarecrashesorhangs.
This constant stream of data from customer machines is collected very care-
fully, with the users’ consent and without invading privacy. The result is that
Microsoft is building an ever-improving picture of what is happening in the
Windows ecosystem that allows continuous improvements through software
updates,aswellas providingdatato guidefuturereleasesof Windows.
B.2.3 Windows and POSIX Application Compatibility
As mentioned, Windows XPwas both an update of Windows 2000 and a
replacementforWindows95/98.Windows2000focusedprimarilyoncompat-
ibilityforbusinessapplications.TherequirementsforWindows XPincludeda
much greater compatibility with the consumer applications that ran on Win-
dows 95/98. Application compatibility is difficult to achieve because many
applications check for a particular version of Windows, may depend to some
extentonthequirksoftheimplementationof APIs,mayhavelatentapplication
bugsthatweremaskedintheprevioussystem,andsoforth.Applicationsmay"
3,B.2.4 High Performance,1072,B.2.3 Windows and POSIX Application Compatibility,"6 Appendix B Windows 7
alsohavebeencompiledforadifferentinstructionset.Windows7implements
severalstrategiestorunapplications despiteincompatibilities.
Like Windows XP, Windows 7 has a compatibility layer that sits between
applications and the Win 32 APIs. This layer makes Windows 7 look (almost)
bug-for-bug compatible with previous versions of Windows. Windows 7, like
earlierNTreleases, maintains support for running many 16-bit applications
using athunking , or conversion, layer that translates 16-bit APIcalls into
equivalent 32-bit calls. Similarly, the 64-bit version of Windows 7 provides a
thunking layerthat translates32-bit APIcallsinto native64-bit calls.
TheWindowssubsystemmodelallowsmu ltipleoperating-systemperson-
alitiestobesupported.Asnotedearlier,althoughtheAPImostcommonlyused
with Windows is the Win 32 API, some editions of Windows 7 support a POSIX
subsystem. POSIXisastandardspecificationfor UNIXthatallowsmostavailable
UNIX-compatible softwareto compileand runwithout modification.
Asafinal compatibilitymeasure,severaleditionsofWindows 7providea
virtualmachinethatrunsWindows XPinsideWindows7.Thisallowsapplica-
tions togetbug-for-bug compatibilitywithWindows XP.
B.2.4 High Performance
Windows was designed to provide high performance on desktop systems
(whicharelargelyconstrainedby I/Operformance),serversystems(wherethe
CPUisoftenthebottleneck),andlargemultithreadedandmultiprocessorenvi-
ronments (where locking performance and cache-line management are keys
toscalability).Tosatisfyperformancerequirements, NTusedavarietyoftech-
niques, such as asynchronous I/O, optimized protocols for networks, kernel-
based graphics rendering, and sophisticated caching of file-system data. The
memory-managementandsynchronizationalgorithmsweredesignedwithan
awarenessoftheperformanceconsiderationsrelatedtocache linesandmulti-
processors.
Windows NTwas designed for symmetrical multiprocessing ( SMP); on a
multiprocessorcomputer,severalthreadscanrunatthesametime,eveninthe
kernel.Oneach CPU,W in do w s NTusespriority-basedpreemptivescheduling
of threads. Except while executing in the kernel dispatcher or at interrupt
level,threadsinanyprocessrunninginWindowscanbepreemptedbyhigher-
prioritythreads.Thus, thesystemrespondsquickly(seeChapter5).
The subsystems that constitute Windows NTcommunicate with one
another efficiently through a local procedure call (LPC) facility that provides
high-performance message passing. When a thread requests a synchronous
service from another process through an LPC, the servicing thread is marked
ready, and its priority is temporarily boosted to avoid the scheduling delays
that would occur if ithadto wait forthreadsalreadyinthe queue.
Windows XPfurther improved performance by reducing the code-path
length in critical functions, using better algorithms and per-processor data
structures, using memory coloring for non-uniform memory access (NUMA)
machines,andimplementingmorescalab lelocking protocols,suchasqueued
spinlocks. The new locking protoco ls helped reduce system bus cycles and
included lock-free lists and queues, atomic read–modify–write operations
(likeinterlockedincrement),and otheradvancedsynchronization techniques."
3,B.2.5 Extensibility,1074,B.2.4 High Performance,"8 Appendix B Windows 7
quickly on the GPUand return their results to the main computation running
on theCPU.
B.2.5 Extensibility
Extensibility refers to the capacity of an operating system to keep up with
advances in computing technology. To facilitate change over time, the devel-
opersimplementedWindowsusingalayeredarchitecture.TheWindowsexec-
utiverunsinkernelmodeandprovidesthebasicsystemservicesandabstrac-
tions that support shared use of the system. On top of the executive, several
serversubsystemsoperateinusermode.Amongthemare environmental sub-
systems that emulatedifferentoperating systems.Thus, programs writtenfor
theWin 32APIsandPOSIXallrunonWindowsintheappropriateenvironment.
Because of the modular structure, additional environmental subsystems can
beaddedwithoutaffectingtheexecuti ve.Inaddition,Windowsusesloadable
drivers in the I/Osystem, so new file systems, new kinds of I/Odevices, and
newkindsofnetworkingcanbeaddedwhilethesystemisrunning.Windows
uses a client–server model like the Mach operating system and supports dis-
tributed processing by remote procedure calls (RPCs) as defined by the Open
SoftwareFoundation.
B.2.6 Portability
An operating system is portable if it can be moved from one CPUarchitec-
turetoanotherwithfewchanges.Windowswasdesignedtobeportable.Like
theUNIXoperating system, Windows is written primarily in C and C++. The
architecture-specific source code is relatively small, and there is very little
use of assembly code. Porting Windows to a new architecture mostly affects
the Windows kernel, since the user-mo de code in Windows is almost exclu-
sively written to be architecture independent. To port Windows, the kernel’s
architecture-specific code must be ported, and sometimes conditional compi-
lation is needed in other parts of the kernel because of changes in major data
structures, such as the page-table format. The entire Windows system must
thenberecompiledfor thenew CPUinstructionset.
Operating systems are sensitive not only to CPUarchitecture but also to
CPUsupport chips and hardware boot programs. The CPUand support chips
arecollectivelyknownasa chipset.Thesechipsetsandtheassociatedbootcode
determinehowinterruptsaredelivered,describethephysicalcharacteristicsof
each system, and provide interfaces to deeperaspects of the CPUarchitecture,
such as error recovery and power management. It would be burdensome to
have to port Windows to each type of support chip as well as to each CPU
architecture.Instead,Windowsisolatesmostofthechipset-dependentcodein
adynamiclinklibrary( DLL),calledthe hardware-abstraction layer (HAL),that
isloadedwiththekernel.TheWindows kerneldependsonthe HALinterfaces
rather than on the underlying chipset details. This allows the single set of
kernelanddriverbinariesforaparticular CPUtobeusedwithdifferentchipsets
simplyby loadinga differentversionof the HAL.
Over the years, Windows has been ported to a number of different CPU
architectures: Intel IA-32-compatible 32-bit CPUs,AMD64-compatible and IA64
64-bitCPUs, theDECAlpha, and the MIPSand Power PC CPUs. Most of these
CPUarchitecturesfailedinthemarket.WhenWindows7shipped,onlythe IA-"
3,B.2.6 Portability,1074,B.2.5 Extensibility,"8 Appendix B Windows 7
quickly on the GPUand return their results to the main computation running
on theCPU.
B.2.5 Extensibility
Extensibility refers to the capacity of an operating system to keep up with
advances in computing technology. To facilitate change over time, the devel-
opersimplementedWindowsusingalayeredarchitecture.TheWindowsexec-
utiverunsinkernelmodeandprovidesthebasicsystemservicesandabstrac-
tions that support shared use of the system. On top of the executive, several
serversubsystemsoperateinusermode.Amongthemare environmental sub-
systems that emulatedifferentoperating systems.Thus, programs writtenfor
theWin 32APIsandPOSIXallrunonWindowsintheappropriateenvironment.
Because of the modular structure, additional environmental subsystems can
beaddedwithoutaffectingtheexecuti ve.Inaddition,Windowsusesloadable
drivers in the I/Osystem, so new file systems, new kinds of I/Odevices, and
newkindsofnetworkingcanbeaddedwhilethesystemisrunning.Windows
uses a client–server model like the Mach operating system and supports dis-
tributed processing by remote procedure calls (RPCs) as defined by the Open
SoftwareFoundation.
B.2.6 Portability
An operating system is portable if it can be moved from one CPUarchitec-
turetoanotherwithfewchanges.Windowswasdesignedtobeportable.Like
theUNIXoperating system, Windows is written primarily in C and C++. The
architecture-specific source code is relatively small, and there is very little
use of assembly code. Porting Windows to a new architecture mostly affects
the Windows kernel, since the user-mo de code in Windows is almost exclu-
sively written to be architecture independent. To port Windows, the kernel’s
architecture-specific code must be ported, and sometimes conditional compi-
lation is needed in other parts of the kernel because of changes in major data
structures, such as the page-table format. The entire Windows system must
thenberecompiledfor thenew CPUinstructionset.
Operating systems are sensitive not only to CPUarchitecture but also to
CPUsupport chips and hardware boot programs. The CPUand support chips
arecollectivelyknownasa chipset.Thesechipsetsandtheassociatedbootcode
determinehowinterruptsaredelivered,describethephysicalcharacteristicsof
each system, and provide interfaces to deeperaspects of the CPUarchitecture,
such as error recovery and power management. It would be burdensome to
have to port Windows to each type of support chip as well as to each CPU
architecture.Instead,Windowsisolatesmostofthechipset-dependentcodein
adynamiclinklibrary( DLL),calledthe hardware-abstraction layer (HAL),that
isloadedwiththekernel.TheWindows kerneldependsonthe HALinterfaces
rather than on the underlying chipset details. This allows the single set of
kernelanddriverbinariesforaparticular CPUtobeusedwithdifferentchipsets
simplyby loadinga differentversionof the HAL.
Over the years, Windows has been ported to a number of different CPU
architectures: Intel IA-32-compatible 32-bit CPUs,AMD64-compatible and IA64
64-bitCPUs, theDECAlpha, and the MIPSand Power PC CPUs. Most of these
CPUarchitecturesfailedinthemarket.WhenWindows7shipped,onlythe IA-"
3,B.2.7 International Support,1075,B.2.6 Portability,"B.2 Design Principles 9
32 and AMD64 architectures were supported on client computers, along with
AMD64 andIA64 onservers.
B.2.7 International Support
Windows was designed for international and multinational use. It provides
support for different locales via the national-language-support (NLS)API.
TheNLS API provides specialized routines to format dates, time, and money
in accordance with national customs. String comparisons are specialized to
account for varying character sets. UNICODE is Windows’s native character
code. Windows supports ANSIcharacters by converting them to UNICODE
characters before manipulating them (8 -bit to 16-bit conversion). System text
strings are kept in resource files that can be replaced to localize the system
for different languages. Multiple locales can be used concurrently, which is
importantto multilingualindividualsand businesses.
B.2.8 Energy Efﬁciency
Increasing energy efficiency for computers causes batteries to last longer for
laptopsand netbooks, savessignificant operating costs for power and cooling
of data centers, and contributes to green initiatives aimed at lowering energy
consumption by businesses and consumers. For some time, Windows has
implementedseveralstrategiesfordecreasingenergyuse.The CPUsaremoved
tolowerpowerstates—forexample,byloweringclockfrequency—whenever
possible. In addition, when a computer is not being actively used, Windows
may put the entire computer into a low-power state (sleep) or may even save
all of memory to disk and shut the computer off (hibernation). When the user
returns,the computerpowersup and continues from itspreviousstate,sothe
userdoesnot needto rebootand restartapplications.
Windows7addedsomenewstrategiesforsavingenergy.Thelongera CPU
canstayunused,themoreenergycanbesaved.Becausecomputersaresomuch
faster than human beings, a lot of energy can be saved just while humans are
thinking. The problem is that too many programs are constantly polling to
see what is happening in the system. A swarm of software timers are firing,
keepingthe CPUfromstayingidlelongenoughtosavemuchenergy.Windows
7extends CPUidletimebyskippingclockticks,coalescingsoftwaretimersinto
smaller numbers of events, and “parking ”entireCPUs when systems are not
heavilyloaded.
B.2.9 Dynamic Device Support
Early in the history of the PCindustry, computer configurations were fairly
static. Occasionally, new devices might be plugged into the serial, printer, or
game ports on the back of a computer, but that was it. The next steps toward
dynamicconfiguration of PCswerelaptopdocksand PCMIAcards.A PCcould
suddenly be connected to or disconnected from a whole set of peripherals. In
acontemporary PC,thesituationhascompletelychanged. PCsaredesignedto
let users to plug and unplug a huge host of peripherals all the time; external
disks,thumb drives,cameras, andthe likeareconstantly coming and going.
Support for dynamic configuration of devices is continually evolving in
Windows. The system can automatically recognize devices when they are"
3,B.2.8 Energy Efficiency,1075,B.2.7 International Support,"B.2 Design Principles 9
32 and AMD64 architectures were supported on client computers, along with
AMD64 andIA64 onservers.
B.2.7 International Support
Windows was designed for international and multinational use. It provides
support for different locales via the national-language-support (NLS)API.
TheNLS API provides specialized routines to format dates, time, and money
in accordance with national customs. String comparisons are specialized to
account for varying character sets. UNICODE is Windows’s native character
code. Windows supports ANSIcharacters by converting them to UNICODE
characters before manipulating them (8 -bit to 16-bit conversion). System text
strings are kept in resource files that can be replaced to localize the system
for different languages. Multiple locales can be used concurrently, which is
importantto multilingualindividualsand businesses.
B.2.8 Energy Efﬁciency
Increasing energy efficiency for computers causes batteries to last longer for
laptopsand netbooks, savessignificant operating costs for power and cooling
of data centers, and contributes to green initiatives aimed at lowering energy
consumption by businesses and consumers. For some time, Windows has
implementedseveralstrategiesfordecreasingenergyuse.The CPUsaremoved
tolowerpowerstates—forexample,byloweringclockfrequency—whenever
possible. In addition, when a computer is not being actively used, Windows
may put the entire computer into a low-power state (sleep) or may even save
all of memory to disk and shut the computer off (hibernation). When the user
returns,the computerpowersup and continues from itspreviousstate,sothe
userdoesnot needto rebootand restartapplications.
Windows7addedsomenewstrategiesforsavingenergy.Thelongera CPU
canstayunused,themoreenergycanbesaved.Becausecomputersaresomuch
faster than human beings, a lot of energy can be saved just while humans are
thinking. The problem is that too many programs are constantly polling to
see what is happening in the system. A swarm of software timers are firing,
keepingthe CPUfromstayingidlelongenoughtosavemuchenergy.Windows
7extends CPUidletimebyskippingclockticks,coalescingsoftwaretimersinto
smaller numbers of events, and “parking ”entireCPUs when systems are not
heavilyloaded.
B.2.9 Dynamic Device Support
Early in the history of the PCindustry, computer configurations were fairly
static. Occasionally, new devices might be plugged into the serial, printer, or
game ports on the back of a computer, but that was it. The next steps toward
dynamicconfiguration of PCswerelaptopdocksand PCMIAcards.A PCcould
suddenly be connected to or disconnected from a whole set of peripherals. In
acontemporary PC,thesituationhascompletelychanged. PCsaredesignedto
let users to plug and unplug a huge host of peripherals all the time; external
disks,thumb drives,cameras, andthe likeareconstantly coming and going.
Support for dynamic configuration of devices is continually evolving in
Windows. The system can automatically recognize devices when they are"
3,B.2.9 Dynamic Device Support,1075,B.2.8 Energy Efficiency,"B.2 Design Principles 9
32 and AMD64 architectures were supported on client computers, along with
AMD64 andIA64 onservers.
B.2.7 International Support
Windows was designed for international and multinational use. It provides
support for different locales via the national-language-support (NLS)API.
TheNLS API provides specialized routines to format dates, time, and money
in accordance with national customs. String comparisons are specialized to
account for varying character sets. UNICODE is Windows’s native character
code. Windows supports ANSIcharacters by converting them to UNICODE
characters before manipulating them (8 -bit to 16-bit conversion). System text
strings are kept in resource files that can be replaced to localize the system
for different languages. Multiple locales can be used concurrently, which is
importantto multilingualindividualsand businesses.
B.2.8 Energy Efﬁciency
Increasing energy efficiency for computers causes batteries to last longer for
laptopsand netbooks, savessignificant operating costs for power and cooling
of data centers, and contributes to green initiatives aimed at lowering energy
consumption by businesses and consumers. For some time, Windows has
implementedseveralstrategiesfordecreasingenergyuse.The CPUsaremoved
tolowerpowerstates—forexample,byloweringclockfrequency—whenever
possible. In addition, when a computer is not being actively used, Windows
may put the entire computer into a low-power state (sleep) or may even save
all of memory to disk and shut the computer off (hibernation). When the user
returns,the computerpowersup and continues from itspreviousstate,sothe
userdoesnot needto rebootand restartapplications.
Windows7addedsomenewstrategiesforsavingenergy.Thelongera CPU
canstayunused,themoreenergycanbesaved.Becausecomputersaresomuch
faster than human beings, a lot of energy can be saved just while humans are
thinking. The problem is that too many programs are constantly polling to
see what is happening in the system. A swarm of software timers are firing,
keepingthe CPUfromstayingidlelongenoughtosavemuchenergy.Windows
7extends CPUidletimebyskippingclockticks,coalescingsoftwaretimersinto
smaller numbers of events, and “parking ”entireCPUs when systems are not
heavilyloaded.
B.2.9 Dynamic Device Support
Early in the history of the PCindustry, computer configurations were fairly
static. Occasionally, new devices might be plugged into the serial, printer, or
game ports on the back of a computer, but that was it. The next steps toward
dynamicconfiguration of PCswerelaptopdocksand PCMIAcards.A PCcould
suddenly be connected to or disconnected from a whole set of peripherals. In
acontemporary PC,thesituationhascompletelychanged. PCsaredesignedto
let users to plug and unplug a huge host of peripherals all the time; external
disks,thumb drives,cameras, andthe likeareconstantly coming and going.
Support for dynamic configuration of devices is continually evolving in
Windows. The system can automatically recognize devices when they are"
2,B.3 System Components,1076,B.2 Design Principles,"10 Appendix B Windows 7
OS/2
applications
OS/2
subsystemWin16
applicationsMS-DOS
applications
Win18
VDM
window
manageruser mode
file systemI/O managerMS-DOS
VDM
Win32
subsystemPOSIX
subsystemlogon
process
security
subsystem
authentication
package
security account
manager databaseWin32
applicationsPOSIX
applications
graphic
device
driverskernelexecutive
hardware abstraction layer
hardwarecache
manager
device
drivers
network
driversobject
managersecurity
reference
monitorprocess
managerplug and
play
managervirtual
memory
managerlocal
procedure
call
facility
Figure B.1 Windows block diagram.
pluggedinandcanfind,install,andloadtheappropriatedrivers—oftenwith-
outuserintervention.Whendevicesareunplugged,thedriversautomatically
unload,and systemexecutioncontinues without disruptingothersoftware.
B.3 System Components
Thearchitectureof Windows isalayeredsystemofmodules,asshown inFig-
ureB.1.Themainlayersarethe HAL,thekernel,andtheexecutive,allofwhich
runinkernelmode,andacollectionofsubsystemsandservicesthatruninuser
mode. The user-mode subsystems fall into two categories: the environmental
subsystems, which emulate different operating systems, and the protection
subsystems , which providesecurityfunctions. One of the chief advantagesof
this type of architecture is that intera ctions between modules are kept simple.
The remainderofthis sectiondescribestheselayersandsubsystems.
B.3.1 Hardware-Abstraction Layer
TheHALis the layer of software that hides hardware chipset differences
from upper levels of the operating system. The HALexports a virtual hard-
ware interface that is used by the kernel dispatcher, the executive, and the
device drivers. Only a single version of each device driver is required for"
3,B.3.1 Hardware-Abstraction Layer,1076,B.3 System Components,"10 Appendix B Windows 7
OS/2
applications
OS/2
subsystemWin16
applicationsMS-DOS
applications
Win18
VDM
window
manageruser mode
file systemI/O managerMS-DOS
VDM
Win32
subsystemPOSIX
subsystemlogon
process
security
subsystem
authentication
package
security account
manager databaseWin32
applicationsPOSIX
applications
graphic
device
driverskernelexecutive
hardware abstraction layer
hardwarecache
manager
device
drivers
network
driversobject
managersecurity
reference
monitorprocess
managerplug and
play
managervirtual
memory
managerlocal
procedure
call
facility
Figure B.1 Windows block diagram.
pluggedinandcanfind,install,andloadtheappropriatedrivers—oftenwith-
outuserintervention.Whendevicesareunplugged,thedriversautomatically
unload,and systemexecutioncontinues without disruptingothersoftware.
B.3 System Components
Thearchitectureof Windows isalayeredsystemofmodules,asshown inFig-
ureB.1.Themainlayersarethe HAL,thekernel,andtheexecutive,allofwhich
runinkernelmode,andacollectionofsubsystemsandservicesthatruninuser
mode. The user-mode subsystems fall into two categories: the environmental
subsystems, which emulate different operating systems, and the protection
subsystems , which providesecurityfunctions. One of the chief advantagesof
this type of architecture is that intera ctions between modules are kept simple.
The remainderofthis sectiondescribestheselayersandsubsystems.
B.3.1 Hardware-Abstraction Layer
TheHALis the layer of software that hides hardware chipset differences
from upper levels of the operating system. The HALexports a virtual hard-
ware interface that is used by the kernel dispatcher, the executive, and the
device drivers. Only a single version of each device driver is required for"
3,B.3.2 Kernel,1077,B.3.1 Hardware-Abstraction Layer,"B.3 System Components 11
eachCPUarchitecture,nomatterwhatsupportchipsmightbepresent.Device
drivers map devices and access them directly, but the chipset-specific details
of mapping memory, configuring I/Obuses, setting up DMA, and coping with
motherboard-specificfacilitiesareallprovidedby the HALinterfaces.
B.3.2 Kernel
ThekernellayerofWindowshasfourmain responsibilities:threadscheduling,
low-level processor synchronization, interrupt and exception handling, and
switching between user mode and kernel mode. The kernel is implemented
in the C language, using assembly language only where absolutely necessary
tointerfacewiththe lowestlevelofthe hardwarearchitecture.
Thekernelisorganizedaccordingtoobject-orienteddesignprinciples.An
object type inWindowsisasystem-defineddatatypethathasasetofattributes
(data values) and a set of methods (for example, functions or operations). An
objectis an instance of an object type. The kernel performs its job by using a
setofkernelobjectswhoseattributesstorethekerneldataandwhosemethods
performthe kernelactivities.
B.3.2.1 Kernel Dispatcher
The kernel dispatcher provides the foundation for the executive and the sub-
systems. Most of the dispatcher is never paged out of memory, and its execu-
tion is never preempted. Its main respon sibilities are thread scheduling and
context switching, implementation of synchronization primitives, timer man-
agement, software interrupts (asynchronous and deferred procedure calls),
andexceptiondispatching.
B.3.2.2 Threads and Scheduling
Like many other modern operating systems, Windows uses processes and
threads for executable code. Each process has one or more threads, and each
threadhasitsownschedulingstate,includingactualpriority,processoraffinity,
andCPUusage information.
There are six possible thread states: ready,standby ,running ,waiting ,
transition ,a n d terminated .Readyindicates that the thread is waiting to
run. The highest-priority ready thread is moved to the standby state, which
means it is the next thread to run. In a multiprocessor system, each processor
keeps one thread in a standby state. Athread is running when it is executing
on a processor. It runs until it is preempted by a higher-priority thread, until
itterminates,untilitsallottedexecutiontime(quantum)ends,oruntilitwaits
on a dispatcher object, such as an event signaling I/Ocompletion. Athread is
in the waiting state when it is waiting for a dispatcher object to be signaled.
Athread is in the transition state while it waits for resources necessary for
execution;forexample,itmaybewaitingforitskernelstacktobeswappedin
fromdisk.Athread entersthe terminated state when itfinishes execution.
The dispatcher uses a 32-level priority scheme to determine the order of
threadexecution.Prioritiesaredivided intotwoclasses:variableclassandreal-
time class. The variable class contains threads having priorities from 1 to 15,
and the real-time class contains threads with priorities ranging from 16 to 31."
3,B.3.3 Executive,1082,B.3.2 Kernel,"16 Appendix B Windows 7
by a kernel-level thread or by an ISRreturning from interrupt processing.
Windows takes advantage of this property and uses software interrupts to
deliver APCsa n dDPCs, to perform system functions such as synchronizing
threadswith I/Ocompletion,tostart threadexecution,and to handletimers.
B.3.2.6 Switching between User-Mode and Kernel-Mode Threads
What theprogrammerthinksofasathreadintraditionalWindows isactually
two threads: a user-mode thread (UT)a n da kernel-mode thread (KT). Each
has its own stack, register values, and execution context. A UTrequests a
system service by executing an instruction that causes a trap to kernel mode.
The kernel layer runs a trap handler that switches between the UTand the
corresponding KT.W h ena KThas completeditskernelexecutionand isready
to switch back to the corresponding UT, the kernel layer is called to make the
switch to the UT,which continues itsexecutioninusermode.
Windows 7 modifies the behavior of the kernel layer to support user-
mode scheduling of the UTs. User-mode schedulers in Windows 7 support
cooperative scheduling. A UTcan explicitly yield to another UTby calling
the user-mode scheduler; it is not nec essary to enter the kernel. User-mode
schedulingis explainedinmore detailinSectionB.7.3.7.
B.3.3 Executive
The Windows executive provides a set of services that all environmental sub-
systems use. The services are grouped as follows: object manager, virtual
memorymanager,processmanager,advancedlocalprocedurecallfacility, I/O
manager,cachemanager,securityreferencemonitor,plug-and-playandpower
managers,registry,andbooting.
B.3.3.1 Object Manager
For managing kernel-mode entities, Windows uses a generic set of interfaces
that are manipulated by user-mode programs. Windows calls these entities
objects, and the executive component that manipulates them is the object
manager . Examples of objects are semaphores, mutexes, events, processes,
and threads; all these are dispatcher objects . Threads can block in the ker-
nel dispatcher waiting for any of thes e objects to be signaled. The process,
thread, and virtual memory APIs use process and thread handles to identify
the process or thread to be operated on. Other examples of objects include
files, sections, ports, and various internal I/Oobjects. File objects are used to
maintain the open state of files and devices. Sections are used to map files.
Local-communication endpointsareimplementedasportobjects.
User-mode code accesses these obje cts using an opaque value called a
handle, which is returned by many APIs. Each process has a handle table
containing entries that track the objects used by the process. The system pro-
cess, which contains the kernel, has its own handle table, which is protected
fromusercode.ThehandletablesinWindowsarerepresentedbyatreestruc-
ture,whichcanexpandfromholding1,024handlestoholdingover16million.
Kernel-modecodecanaccessanob jectbyusingeitherahandleora referenced
pointer."
2,B.4 Terminal Services and Fast User Switching,1100,B.3 System Components,"34 Appendix B Windows 7
•CSRSSistheWin 32environmentalsubsystemprocess.Itisstartedinevery
session—unlike the POSIXsubsystem, which is started only on demand
when a POSIXpr ocessiscr eated.
•WINLOGON is run in each Windows session other than session 0 to log on
au s er .
The system optimizes the boot process by prepaging from files on disk
based on previous boots of the system. Disk access patterns at boot are also
used to lay out system files on disk to reduce the number of I/Ooperations
required.Theprocessesnecessarytostartthesystemarereducedbygrouping
servicesintofewerprocesses.Allofthe seapproachescontributetoadramatic
reduction in system boot time. Of course, system boot time is less important
thanitoncewasbecauseofthesleepandh ibernationcapabilitiesofWindows.
B.4 Terminal Services and Fast User Switching
Windows supports a GUI-based console that interfaces with the user via key-
board,mouse,anddisplay.Mostsystemsalsosupportaudioandvideo.Audio
inputisusedbyWindowsvoice-recognit ionsoftware;voicerecognitionmakes
the system more convenient and increases its accessibility for users with dis-
abilities.Windows7addedsupportfor multi-touch hardware ,allowingusers
to input data by touching the screen and making gestures with one or more
fingers.Eventually,thevideo-inputcapability,whichiscurrentlyusedforcom-
municationapplications,islikelytobeusedforvisuallyinterpretinggestures,
as Microsoft has demonstrated for its Xbox 360 Kinect product. Other future
input experiences may evolve from Microsoft’s surface computer .M o s to f t e n
installed at public venues, such as hotels and conference centers, the surface
computer is a table surface with special cameras underneath. It can track the
actions of multipleusersat once and recognizeobjects that areplacedontop.
ThePCwas, of course, envisioned as a personalcomputer —an inherently
single-usermachine.ModernWindows,however,supportsthesharingofa PC
among multipleusers.Eachuserthatisloggedonusingthe GUIhas a session
createdtorepresentthe GUIenvironmenthewillbeusingandtocontainallthe
processescreatedtorunhisapplications.Windowsallowsmultiplesessionsto
exist at the same time on a single machine. However, Windows only supports
asingleconsole,consistingofallthem onitors,keyboards,andmiceconnected
tothePC.Onlyonesessioncanbeconnectedtotheconsoleatatime.Fromthe
logonscreendisplayedontheconsole,userscan createnewsessionsor attach
to an existing session that was previously created. This allows multiple users
toshareasingle PCwithouthavingtologoffandonbetweenusers.Microsoft
calls thisuseof sessions fastuserswitching .
Users can also create new sessions, or connect to existing sessions, on one
PCfrom a session running on another Windows PC. The terminal server ( TS)
connectsoneofthe GUIwindowsinauser’slocalsessiontotheneworexisting
session, called a remote desktop , on the remote computer. The most common
use of remote desktops is for users to connect to a session on their work PC
from theirhome PC.
Many corporations use corporate terminal-server systems maintained in
datacenterstorunallusersessionsthataccesscorporateresources,ratherthan"
2,B.5 File System,1101,B.4 Terminal Services and Fast User Switching,"B.5 File System 35
allowinguserstoaccessthoseresourcesfromthe PCsineachuser’soffice.Each
server computer may handle many dozens of remote-desktop sessions. This
is a form of thin-client computing, in which individual computers rely on a
server for many functions. Relying on data-center terminal servers improves
reliability,manageability,and securityof thecorporate computing resources.
TheTSisalsousedbyWindowstoimplement remote assistance .Aremote
usercanbeinvitedtoshareasessionwiththeuserloggedontothesessionon
the console. The remote user can watch the user’s actions and even be given
control of thedesktopto helpresolvecomputing problems.
B.5 File System
The native file system in Windows is NTFS. It is used for all local volumes.
However,associated USBthumbdrives,flashmemoryoncameras,andexternal
disks may be formatted with the 32-bit FATfile system for portability. FATis a
much older file-system format that is understood by many systems besides
Windows, such as the software running on cameras. A disadvantage is that
theFATfile system does not restrict file access to authorized users. The only
solutionforsecuringdatawith FATistorunanapplicationtoencryptthedata
beforestoringiton thefilesystem.
In contrast, NTFSusesACLs to control access to individual files and sup-
portsimplicitencryptionofindividual filesorentirevolumes(usingWindows
BitLocker feature). NTFSimplements many other features as well, including
data recovery, fault tolerance, very large files and file systems, multiple data
streams, UNICODE names,sparsefiles,journaling,volumeshadowcopies,and
filecompression.
B.5.1 NTFS Internal Layout
The fundamental entity in NTFSis a volume. Avolume is created by the Win-
dows logical disk management utility and is based on a logical disk partition.
Avolumemayoccupyaportionofadiskoranentiredisk,ormayspanseveral
disks.
NTFSdoes not deal with individualsectors of a disk but instead uses clus-
tersas the units of disk allocation. A clusteris a number of disksectors that is
apowerof2.Theclustersizeisconfiguredwhenan NTFSfilesystemisformat-
ted. The default cluster size is based on the volume size—4 KBfor volumes
larger than 2 GB. Given the size of today’s disks, it may make sense to use
cluster sizes larger than the Windows defaults to achieve better performance,
although these performance gains will come at the expense of more internal
fragmentation.
NTFSuses logical cluster numbers (LCNs)asdiskaddresses.Itassignsthem
by numbering clusters from the beginning of the disk to the end. Using this
scheme,thesystemcancalculateaphysicaldiskoffset(inbytes)bymultiplying
theLCNby theclustersize.
A file in NTFSis not a simple byte stream as it is in UNIX; rather, it is a
structured object consisting of typed attributes .E a c ha t t r i b u t eo fafi l ei sa n
independentbytestreamthatcanbecreated,deleted,read,andwritten.Some
attribute types are standard for all files, including the file name (or names, if
the file has aliases, such as an MS-DOSshort name), the creation time, and the"
3,B.5.1 NTFS Internal Layout,1101,B.5 File System,"B.5 File System 35
allowinguserstoaccessthoseresourcesfromthe PCsineachuser’soffice.Each
server computer may handle many dozens of remote-desktop sessions. This
is a form of thin-client computing, in which individual computers rely on a
server for many functions. Relying on data-center terminal servers improves
reliability,manageability,and securityof thecorporate computing resources.
TheTSisalsousedbyWindowstoimplement remote assistance .Aremote
usercanbeinvitedtoshareasessionwiththeuserloggedontothesessionon
the console. The remote user can watch the user’s actions and even be given
control of thedesktopto helpresolvecomputing problems.
B.5 File System
The native file system in Windows is NTFS. It is used for all local volumes.
However,associated USBthumbdrives,flashmemoryoncameras,andexternal
disks may be formatted with the 32-bit FATfile system for portability. FATis a
much older file-system format that is understood by many systems besides
Windows, such as the software running on cameras. A disadvantage is that
theFATfile system does not restrict file access to authorized users. The only
solutionforsecuringdatawith FATistorunanapplicationtoencryptthedata
beforestoringiton thefilesystem.
In contrast, NTFSusesACLs to control access to individual files and sup-
portsimplicitencryptionofindividual filesorentirevolumes(usingWindows
BitLocker feature). NTFSimplements many other features as well, including
data recovery, fault tolerance, very large files and file systems, multiple data
streams, UNICODE names,sparsefiles,journaling,volumeshadowcopies,and
filecompression.
B.5.1 NTFS Internal Layout
The fundamental entity in NTFSis a volume. Avolume is created by the Win-
dows logical disk management utility and is based on a logical disk partition.
Avolumemayoccupyaportionofadiskoranentiredisk,ormayspanseveral
disks.
NTFSdoes not deal with individualsectors of a disk but instead uses clus-
tersas the units of disk allocation. A clusteris a number of disksectors that is
apowerof2.Theclustersizeisconfiguredwhenan NTFSfilesystemisformat-
ted. The default cluster size is based on the volume size—4 KBfor volumes
larger than 2 GB. Given the size of today’s disks, it may make sense to use
cluster sizes larger than the Windows defaults to achieve better performance,
although these performance gains will come at the expense of more internal
fragmentation.
NTFSuses logical cluster numbers (LCNs)asdiskaddresses.Itassignsthem
by numbering clusters from the beginning of the disk to the end. Using this
scheme,thesystemcancalculateaphysicaldiskoffset(inbytes)bymultiplying
theLCNby theclustersize.
A file in NTFSis not a simple byte stream as it is in UNIX; rather, it is a
structured object consisting of typed attributes .E a c ha t t r i b u t eo fafi l ei sa n
independentbytestreamthatcanbecreated,deleted,read,andwritten.Some
attribute types are standard for all files, including the file name (or names, if
the file has aliases, such as an MS-DOSshort name), the creation time, and the"
3,B.5.2 Recovery,1103,B.5.1 NTFS Internal Layout,"B.5 File System 37
copy of the first 16 entries of the MFT. The next few files are also special in
purpose.Theyincludethe filesdescribedbelow.
•The logfilerecordsall metadataupdatestothe filesystem.
•The volumefilecontainsthenameofthevolume,theversionof NTFSthat
formatted the volume, and a bit that tells whether the volume may have
beencorruptedandneedstobecheckedforconsistencyusingthe chkdsk
program.
•The attribute-definitio table indicates which attribute types are used in
the volumeand what operationscan beperformedoneachof them.
•The root directory is thetop-leveldirectoryinthefile-systemhierarchy.
•The bitmap fil indicateswhich clustersonavolumeareallocatedtofiles
and which arefree.
•The boot fil contains the startup code for Windows and must be located
at aparticulardiskaddresssothat itcan befoundeasilybya simple ROM
bootstrap loader. The boot file also contains the physical address of the
MFT.
•The bad-cluster filekeepstrackofanybadareasonthevolume; NTFSuses
this record for error recovery.
Keepingallthe NTFSmetadatainactualfileshasausefulproperty.Asdis-
cussedinSectionB.3.3.6,thecachema nagercachesfiledata.Sinceallthe NTFS
metadata residein files, these data can be cached using the same mechanisms
usedfor ordinarydata.
B.5.2 Recovery
In many simple file systems, a power failure at the wrong time can damage
thefile-systemdatastructuressoseverel ythattheentirevolumeisscrambled.
ManyUNIXfile systems,including UFSbut not ZFS, store redundant metadata
onthedisk,andtheyrecoverfromcrashesbyusingthe fsckprogramtocheck
all the file-system data structures and restore them forcibly to a consistent
state. Restoring them often involves deleting damaged files and freeing data
clustersthat had beenwrittenwith user data but not properlyrecordedinthe
filesystem’smetadatastructures.Thischeckingcanbeaslowprocessandcan
cause the lossof significant amounts of data.
NTFStakes a different approach to file-system robustness. In NTFS,a l lfi l e -
systemdata-structureupdatesareperformedinsidetransactions.Beforeadata
structure is altered, the transaction writes a log record that contains redo and
undo information. After the data struct ure has been changed, the transaction
writesa commit recordtothe logto signifythat thetransaction succeeded.
After a crash, the system can restore the file-system data structures to
a consistent state by processing the log records, first redoing the operations
for committed transactions and then undoing the operations for transactions
that did not commit successfully before the crash. Periodically (usually every
5 seconds), a checkpoint record is written to the log. The system does not
need log records prior to the checkpoint to recover from a crash. They can be"
3,B.5.3 Security,1104,B.5.2 Recovery,"38 Appendix B Windows 7
discarded, so the log file does not grow without bounds. The first time after
system startup that an NTFSvolume is accessed, NTFSautomatically performs
file-systemrecovery.
This scheme does not guarantee that all the user-file contents are correct
after a crash. It ensures only that the file-systemdata structures(the metadata
files)areundamagedand reflectsomeconsistentstatethatexistedpriortothe
crash.Itwouldbepossibletoextendthetransactionschemetocoveruserfiles,
and Microsofttook somestepstodo thisin Windows Vista.
The logis storedin thethirdmetadatafile at thebeginning ofthe volume.
It is created with a fixed maximum size when the file system is formatted. It
hastwosections:the loggingarea ,whichisacircularqueueoflogrecords,and
therestart area , which holds context information, such as the position in the
logging area where NTFSshould start reading during a recovery. In fact, the
restart area holds two copies of its information, so recovery is still possible if
one copy isdamagedduring thecrash.
The logging functionality is provided by the log-file service . In addition
towritingthelogrecordsandperformingrecoveryactions,thelog-fileservice
keepstrackofthefreespaceinthelogfile.Ifthefreespacegetstoolow,thelog-
fileservicequeuespendingtransactions,and NTFShaltsallnew I/Ooperations.
After the in-progress operations complete, NTFScalls the cache manager to
flushalldataandthenresetsthelogfileandperformsthequeuedtransactions.
B.5.3 Security
The security of an NTFSvolume is derived from the Windows object model.
EachNTFSfilereferencesasecuritydescriptor,whichspecifiestheownerofthe
file, and an access-control list, which contains the access permissions granted
or denied to each user or group listed. Early versions of NTFSused a separate
security descriptor as an attribute o f each file. Beginning with Windows 2000,
the security-descriptors attribute poi nts to a shared copy, with a significant
savings in disk and caching space; many, many files have identical security
descriptors.
In normal operation, NTFSdoes not enforce permissions on traversal of
directories in file path names. However, for compatibility with POSIX,t h e s e
checks can be enabled. Traversal checks are inherently more expensive, since
modernparsingoffilepathnamesusesprefixmatchingratherthandirectory-
by-directoryparsingofpathnames.Prefixmatchingisanalgorithmthatlooks
upstringsinacacheandfindstheentrywiththelongestmatch—forexample,
anentryfor ∖foo∖bar∖dirwouldbeamatchfor ∖foo∖bar∖dir2∖dir3∖myfile.
The prefix-matching cache allows path-name traversal to begin much deeper
inthetree,savingmanysteps.Enforcingtraversalchecksmeansthattheuser’s
access must be checked at eachdirectorylevel.For instance, a usermight lack
permission to traverse ∖foo∖bar, so starting at the access for ∖foo∖bar∖dir
would bean error.
B.5.4 Volume Management and Fault Tolerance
FtDiskis the fault-tolerant disk driver for Windows. When installed, it pro-
videsseveralwaystocombinemultiplediskdrivesintoonelogicalvolumeso
as toimproveperformance,capacity, orreliability."
3,B.5.4 Volume Management and Fault Tolerance,1104,B.5.3 Security,"38 Appendix B Windows 7
discarded, so the log file does not grow without bounds. The first time after
system startup that an NTFSvolume is accessed, NTFSautomatically performs
file-systemrecovery.
This scheme does not guarantee that all the user-file contents are correct
after a crash. It ensures only that the file-systemdata structures(the metadata
files)areundamagedand reflectsomeconsistentstatethatexistedpriortothe
crash.Itwouldbepossibletoextendthetransactionschemetocoveruserfiles,
and Microsofttook somestepstodo thisin Windows Vista.
The logis storedin thethirdmetadatafile at thebeginning ofthe volume.
It is created with a fixed maximum size when the file system is formatted. It
hastwosections:the loggingarea ,whichisacircularqueueoflogrecords,and
therestart area , which holds context information, such as the position in the
logging area where NTFSshould start reading during a recovery. In fact, the
restart area holds two copies of its information, so recovery is still possible if
one copy isdamagedduring thecrash.
The logging functionality is provided by the log-file service . In addition
towritingthelogrecordsandperformingrecoveryactions,thelog-fileservice
keepstrackofthefreespaceinthelogfile.Ifthefreespacegetstoolow,thelog-
fileservicequeuespendingtransactions,and NTFShaltsallnew I/Ooperations.
After the in-progress operations complete, NTFScalls the cache manager to
flushalldataandthenresetsthelogfileandperformsthequeuedtransactions.
B.5.3 Security
The security of an NTFSvolume is derived from the Windows object model.
EachNTFSfilereferencesasecuritydescriptor,whichspecifiestheownerofthe
file, and an access-control list, which contains the access permissions granted
or denied to each user or group listed. Early versions of NTFSused a separate
security descriptor as an attribute o f each file. Beginning with Windows 2000,
the security-descriptors attribute poi nts to a shared copy, with a significant
savings in disk and caching space; many, many files have identical security
descriptors.
In normal operation, NTFSdoes not enforce permissions on traversal of
directories in file path names. However, for compatibility with POSIX,t h e s e
checks can be enabled. Traversal checks are inherently more expensive, since
modernparsingoffilepathnamesusesprefixmatchingratherthandirectory-
by-directoryparsingofpathnames.Prefixmatchingisanalgorithmthatlooks
upstringsinacacheandfindstheentrywiththelongestmatch—forexample,
anentryfor ∖foo∖bar∖dirwouldbeamatchfor ∖foo∖bar∖dir2∖dir3∖myfile.
The prefix-matching cache allows path-name traversal to begin much deeper
inthetree,savingmanysteps.Enforcingtraversalchecksmeansthattheuser’s
access must be checked at eachdirectorylevel.For instance, a usermight lack
permission to traverse ∖foo∖bar, so starting at the access for ∖foo∖bar∖dir
would bean error.
B.5.4 Volume Management and Fault Tolerance
FtDiskis the fault-tolerant disk driver for Windows. When installed, it pro-
videsseveralwaystocombinemultiplediskdrivesintoonelogicalvolumeso
as toimproveperformance,capacity, orreliability."
3,B.5.5 Compression,1106,B.5.4 Volume Management and Fault Tolerance,"40 Appendix B Windows 7
is a software technique performed by the file system. If a disk block goes
bad,NTFSsubstitutes a different, unalloca ted block by changing any affected
pointersinthe MFT.NTFSalsomakesanotethatthebadblockshouldneverbe
allocated to any file.
When a disk block goes bad, the usual outcome is a data loss. But sector
sparing or cluster remapping can be combined with fault-tolerant volumes to
mask the failure of a disk block. If a read fails, the system reconstructs the
missingdatabyreadingthemirrororbycalculatingthe exclusive or parity
in a stripe set with parity. The reconstructed data are stored in a new location
that isobtained by sectorsparingor clusterremapping.
B.5.5 Compression
NTFScan perform data compression on individual files or on all data files
in a directory. To compress a file, NTFSdivides the file’s data into compres-
sion units , which are blocks of 16 contiguous clusters. When a compression
unit is written, a data-compression algorithm is applied. If the result fits into
fewer than 16 clusters, the compressed version is stored. When reading, NTFS
can determine whether data have been compressed: if they have been, the
length of the stored compression unit is less than 16 clusters. To improve per-
formance when reading contiguous compression units, NTFSprefetches and
decompressesaheadof theapplicationrequests.
For sparse files or files that contain mostly zeros, NTFSuses another tech-
nique to save space. Clusters that contain only zeros because they have never
beenwrittenare not actually allocatedor storedon disk.Instead,gaps are left
in the sequence of virtual-cluster numbers stored in the MFTentry for the file.
When reading a file, if NTFSfinds a gap in the virtual-cluster numbers, it just
zero-fillsthatportionofthecaller’sbuffer.Thistechniqueisalsousedby UNIX.
B.5.6 Mount Points, Symbolic Links, and Hard Links
Mount points are a form of symbolic link specific to directories on NTFSthat
were introduced in Windows 2000. They providea mechanism for organizing
disk volumes that is more flexible than the use of global names (like drive
letters). A mount point is implemented as a symbolic link with associated
data that contains the true volume name. Ultimately, mount points will sup-
plant drive letters completely, but there will be a long transition due to the
dependenceof many applicationson thedrive-letterscheme.
Windows Vista introduced support for a more general form of symbolic
links,similartothosefoundin UNIX.Thelinkscanbeabsoluteorrelative,can
point to objects that do not exist, and can point to both files and directories
evenacrossvolumes. NTFSalsosupports hard links ,whereasinglefilehasan
entryin more than one directoryofthe same volume.
B.5.7 Change Journal
NTFSkeeps a journal describing all changes that have been made to the file
system. User-modeservicescan receivenotifications of changes to the journal
and then identify what files have changed by reading from the journal. The
search indexer service uses the change journal to identify files that need to be"
3,"B.5.6 Mount Points, Symbolic Links, and Hard Links",1106,B.5.5 Compression,"40 Appendix B Windows 7
is a software technique performed by the file system. If a disk block goes
bad,NTFSsubstitutes a different, unalloca ted block by changing any affected
pointersinthe MFT.NTFSalsomakesanotethatthebadblockshouldneverbe
allocated to any file.
When a disk block goes bad, the usual outcome is a data loss. But sector
sparing or cluster remapping can be combined with fault-tolerant volumes to
mask the failure of a disk block. If a read fails, the system reconstructs the
missingdatabyreadingthemirrororbycalculatingthe exclusive or parity
in a stripe set with parity. The reconstructed data are stored in a new location
that isobtained by sectorsparingor clusterremapping.
B.5.5 Compression
NTFScan perform data compression on individual files or on all data files
in a directory. To compress a file, NTFSdivides the file’s data into compres-
sion units , which are blocks of 16 contiguous clusters. When a compression
unit is written, a data-compression algorithm is applied. If the result fits into
fewer than 16 clusters, the compressed version is stored. When reading, NTFS
can determine whether data have been compressed: if they have been, the
length of the stored compression unit is less than 16 clusters. To improve per-
formance when reading contiguous compression units, NTFSprefetches and
decompressesaheadof theapplicationrequests.
For sparse files or files that contain mostly zeros, NTFSuses another tech-
nique to save space. Clusters that contain only zeros because they have never
beenwrittenare not actually allocatedor storedon disk.Instead,gaps are left
in the sequence of virtual-cluster numbers stored in the MFTentry for the file.
When reading a file, if NTFSfinds a gap in the virtual-cluster numbers, it just
zero-fillsthatportionofthecaller’sbuffer.Thistechniqueisalsousedby UNIX.
B.5.6 Mount Points, Symbolic Links, and Hard Links
Mount points are a form of symbolic link specific to directories on NTFSthat
were introduced in Windows 2000. They providea mechanism for organizing
disk volumes that is more flexible than the use of global names (like drive
letters). A mount point is implemented as a symbolic link with associated
data that contains the true volume name. Ultimately, mount points will sup-
plant drive letters completely, but there will be a long transition due to the
dependenceof many applicationson thedrive-letterscheme.
Windows Vista introduced support for a more general form of symbolic
links,similartothosefoundin UNIX.Thelinkscanbeabsoluteorrelative,can
point to objects that do not exist, and can point to both files and directories
evenacrossvolumes. NTFSalsosupports hard links ,whereasinglefilehasan
entryin more than one directoryofthe same volume.
B.5.7 Change Journal
NTFSkeeps a journal describing all changes that have been made to the file
system. User-modeservicescan receivenotifications of changes to the journal
and then identify what files have changed by reading from the journal. The
search indexer service uses the change journal to identify files that need to be"
3,B.5.7 Change Journal,1106,"B.5.6 Mount Points, Symbolic Links, and Hard Links","40 Appendix B Windows 7
is a software technique performed by the file system. If a disk block goes
bad,NTFSsubstitutes a different, unalloca ted block by changing any affected
pointersinthe MFT.NTFSalsomakesanotethatthebadblockshouldneverbe
allocated to any file.
When a disk block goes bad, the usual outcome is a data loss. But sector
sparing or cluster remapping can be combined with fault-tolerant volumes to
mask the failure of a disk block. If a read fails, the system reconstructs the
missingdatabyreadingthemirrororbycalculatingthe exclusive or parity
in a stripe set with parity. The reconstructed data are stored in a new location
that isobtained by sectorsparingor clusterremapping.
B.5.5 Compression
NTFScan perform data compression on individual files or on all data files
in a directory. To compress a file, NTFSdivides the file’s data into compres-
sion units , which are blocks of 16 contiguous clusters. When a compression
unit is written, a data-compression algorithm is applied. If the result fits into
fewer than 16 clusters, the compressed version is stored. When reading, NTFS
can determine whether data have been compressed: if they have been, the
length of the stored compression unit is less than 16 clusters. To improve per-
formance when reading contiguous compression units, NTFSprefetches and
decompressesaheadof theapplicationrequests.
For sparse files or files that contain mostly zeros, NTFSuses another tech-
nique to save space. Clusters that contain only zeros because they have never
beenwrittenare not actually allocatedor storedon disk.Instead,gaps are left
in the sequence of virtual-cluster numbers stored in the MFTentry for the file.
When reading a file, if NTFSfinds a gap in the virtual-cluster numbers, it just
zero-fillsthatportionofthecaller’sbuffer.Thistechniqueisalsousedby UNIX.
B.5.6 Mount Points, Symbolic Links, and Hard Links
Mount points are a form of symbolic link specific to directories on NTFSthat
were introduced in Windows 2000. They providea mechanism for organizing
disk volumes that is more flexible than the use of global names (like drive
letters). A mount point is implemented as a symbolic link with associated
data that contains the true volume name. Ultimately, mount points will sup-
plant drive letters completely, but there will be a long transition due to the
dependenceof many applicationson thedrive-letterscheme.
Windows Vista introduced support for a more general form of symbolic
links,similartothosefoundin UNIX.Thelinkscanbeabsoluteorrelative,can
point to objects that do not exist, and can point to both files and directories
evenacrossvolumes. NTFSalsosupports hard links ,whereasinglefilehasan
entryin more than one directoryofthe same volume.
B.5.7 Change Journal
NTFSkeeps a journal describing all changes that have been made to the file
system. User-modeservicescan receivenotifications of changes to the journal
and then identify what files have changed by reading from the journal. The
search indexer service uses the change journal to identify files that need to be"
3,B.5.8 Volume Shadow Copies,1107,B.5.7 Change Journal,"B.6 Networking 41
re-indexed. The file-replication service uses it to identify files that need to be
replicatedacross thenetwork.
B.5.8 Volume Shadow Copies
Windows implements the capability of bringing a volume to a known state
and then creating a shadow copy that can be used to back up a consistent
view of the volume. This technique is known as snapshots in some other file
systems.Makingashadowcopyofavolumeisaformofcopy-on-write,where
blocks modified after the shadow copy is created are stored in their original
form in the copy. To achieve a consistent state for the volume requires the
cooperationofapplications,sincethesystemcannotknowwhenthedataused
by the application are in a stable state from which the application could be
safelyrestarted.
TheserverversionofWindowsusesshadowcopiestoefficientlymaintain
old versions of files stored on file servers. This allows users to see documents
storedonfileserversas theyexistedat earlierpoints intime.Theusercan use
this feature to recover files that were accidentally deleted or simply to look at
apreviousversionof thefile,all without pullingout backup media.
B.6 Networking
Windows supports both peer-to-peer and client–server networking. It also
has facilities for network management. The networking components in Win-
dows provide data transport, interprocess communication, file sharing across
anetwork, andthe abilityto sendprintjobs toremoteprinters.
B.6.1 Network Interfaces
TodescribenetworkinginWindows,wemustfirstmentiontwooftheinternal
networking interfaces: the network device interface specificatio (NDIS)a n d
thetransport driver interface (TDI).TheNDISinterfacewasdevelopedin1989
byMicrosoftand3Comtoseparatenetworkadaptersfromtransportprotocols
so that either could be changed without affecting the other. NDISresides at
the interface between the data-link and network layers in the ISOmodel and
enables many protocols to operate over many different network adapters. In
terms of the ISOmodel, the TDIis the interface between the transport layer
(layer4)andthesessionlayer(layer5).Th isinterfaceenablesanysession-layer
component to use any available transpo rt mechanism. (Similar reasoning led
to the streams mechanism in UNIX.) TheTDIsupports both connection-based
and connectionless transportand has functions to send any typeof data.
B.6.2 Protocols
Windows implements transport protocols as drivers. These drivers can be
loaded and unloaded from the system dynamically, although in practice the
system typically has to be rebooted after a change. Windows comes with
severalnetworking protocols. Next,wediscuss anumber of theseprotocols."
2,B.6 Networking,1107,B.5 File System,"B.6 Networking 41
re-indexed. The file-replication service uses it to identify files that need to be
replicatedacross thenetwork.
B.5.8 Volume Shadow Copies
Windows implements the capability of bringing a volume to a known state
and then creating a shadow copy that can be used to back up a consistent
view of the volume. This technique is known as snapshots in some other file
systems.Makingashadowcopyofavolumeisaformofcopy-on-write,where
blocks modified after the shadow copy is created are stored in their original
form in the copy. To achieve a consistent state for the volume requires the
cooperationofapplications,sincethesystemcannotknowwhenthedataused
by the application are in a stable state from which the application could be
safelyrestarted.
TheserverversionofWindowsusesshadowcopiestoefficientlymaintain
old versions of files stored on file servers. This allows users to see documents
storedonfileserversas theyexistedat earlierpoints intime.Theusercan use
this feature to recover files that were accidentally deleted or simply to look at
apreviousversionof thefile,all without pullingout backup media.
B.6 Networking
Windows supports both peer-to-peer and client–server networking. It also
has facilities for network management. The networking components in Win-
dows provide data transport, interprocess communication, file sharing across
anetwork, andthe abilityto sendprintjobs toremoteprinters.
B.6.1 Network Interfaces
TodescribenetworkinginWindows,wemustfirstmentiontwooftheinternal
networking interfaces: the network device interface specificatio (NDIS)a n d
thetransport driver interface (TDI).TheNDISinterfacewasdevelopedin1989
byMicrosoftand3Comtoseparatenetworkadaptersfromtransportprotocols
so that either could be changed without affecting the other. NDISresides at
the interface between the data-link and network layers in the ISOmodel and
enables many protocols to operate over many different network adapters. In
terms of the ISOmodel, the TDIis the interface between the transport layer
(layer4)andthesessionlayer(layer5).Th isinterfaceenablesanysession-layer
component to use any available transpo rt mechanism. (Similar reasoning led
to the streams mechanism in UNIX.) TheTDIsupports both connection-based
and connectionless transportand has functions to send any typeof data.
B.6.2 Protocols
Windows implements transport protocols as drivers. These drivers can be
loaded and unloaded from the system dynamically, although in practice the
system typically has to be rebooted after a change. Windows comes with
severalnetworking protocols. Next,wediscuss anumber of theseprotocols."
3,B.6.1 Network Interfaces,1107,B.6 Networking,"B.6 Networking 41
re-indexed. The file-replication service uses it to identify files that need to be
replicatedacross thenetwork.
B.5.8 Volume Shadow Copies
Windows implements the capability of bringing a volume to a known state
and then creating a shadow copy that can be used to back up a consistent
view of the volume. This technique is known as snapshots in some other file
systems.Makingashadowcopyofavolumeisaformofcopy-on-write,where
blocks modified after the shadow copy is created are stored in their original
form in the copy. To achieve a consistent state for the volume requires the
cooperationofapplications,sincethesystemcannotknowwhenthedataused
by the application are in a stable state from which the application could be
safelyrestarted.
TheserverversionofWindowsusesshadowcopiestoefficientlymaintain
old versions of files stored on file servers. This allows users to see documents
storedonfileserversas theyexistedat earlierpoints intime.Theusercan use
this feature to recover files that were accidentally deleted or simply to look at
apreviousversionof thefile,all without pullingout backup media.
B.6 Networking
Windows supports both peer-to-peer and client–server networking. It also
has facilities for network management. The networking components in Win-
dows provide data transport, interprocess communication, file sharing across
anetwork, andthe abilityto sendprintjobs toremoteprinters.
B.6.1 Network Interfaces
TodescribenetworkinginWindows,wemustfirstmentiontwooftheinternal
networking interfaces: the network device interface specificatio (NDIS)a n d
thetransport driver interface (TDI).TheNDISinterfacewasdevelopedin1989
byMicrosoftand3Comtoseparatenetworkadaptersfromtransportprotocols
so that either could be changed without affecting the other. NDISresides at
the interface between the data-link and network layers in the ISOmodel and
enables many protocols to operate over many different network adapters. In
terms of the ISOmodel, the TDIis the interface between the transport layer
(layer4)andthesessionlayer(layer5).Th isinterfaceenablesanysession-layer
component to use any available transpo rt mechanism. (Similar reasoning led
to the streams mechanism in UNIX.) TheTDIsupports both connection-based
and connectionless transportand has functions to send any typeof data.
B.6.2 Protocols
Windows implements transport protocols as drivers. These drivers can be
loaded and unloaded from the system dynamically, although in practice the
system typically has to be rebooted after a change. Windows comes with
severalnetworking protocols. Next,wediscuss anumber of theseprotocols."
3,B.6.2 Protocols,1107,B.6.1 Network Interfaces,"B.6 Networking 41
re-indexed. The file-replication service uses it to identify files that need to be
replicatedacross thenetwork.
B.5.8 Volume Shadow Copies
Windows implements the capability of bringing a volume to a known state
and then creating a shadow copy that can be used to back up a consistent
view of the volume. This technique is known as snapshots in some other file
systems.Makingashadowcopyofavolumeisaformofcopy-on-write,where
blocks modified after the shadow copy is created are stored in their original
form in the copy. To achieve a consistent state for the volume requires the
cooperationofapplications,sincethesystemcannotknowwhenthedataused
by the application are in a stable state from which the application could be
safelyrestarted.
TheserverversionofWindowsusesshadowcopiestoefficientlymaintain
old versions of files stored on file servers. This allows users to see documents
storedonfileserversas theyexistedat earlierpoints intime.Theusercan use
this feature to recover files that were accidentally deleted or simply to look at
apreviousversionof thefile,all without pullingout backup media.
B.6 Networking
Windows supports both peer-to-peer and client–server networking. It also
has facilities for network management. The networking components in Win-
dows provide data transport, interprocess communication, file sharing across
anetwork, andthe abilityto sendprintjobs toremoteprinters.
B.6.1 Network Interfaces
TodescribenetworkinginWindows,wemustfirstmentiontwooftheinternal
networking interfaces: the network device interface specificatio (NDIS)a n d
thetransport driver interface (TDI).TheNDISinterfacewasdevelopedin1989
byMicrosoftand3Comtoseparatenetworkadaptersfromtransportprotocols
so that either could be changed without affecting the other. NDISresides at
the interface between the data-link and network layers in the ISOmodel and
enables many protocols to operate over many different network adapters. In
terms of the ISOmodel, the TDIis the interface between the transport layer
(layer4)andthesessionlayer(layer5).Th isinterfaceenablesanysession-layer
component to use any available transpo rt mechanism. (Similar reasoning led
to the streams mechanism in UNIX.) TheTDIsupports both connection-based
and connectionless transportand has functions to send any typeof data.
B.6.2 Protocols
Windows implements transport protocols as drivers. These drivers can be
loaded and unloaded from the system dynamically, although in practice the
system typically has to be rebooted after a change. Windows comes with
severalnetworking protocols. Next,wediscuss anumber of theseprotocols."
3,B.6.3 Redirectors and Servers,1110,B.6.2 Protocols,"44 Appendix B Windows 7
DCOMthat can be used over a network utilizing RPCto provide a transparent
methodof developingdistributedapplications.
B.6.3 Redirectors and Servers
In Windows, an application can use the Windows I/O APIto access files from
a remote computer as though they were local, provided that the remote com-
puterisrunninga CIFSserversuchasthoseprovidedbyWindows.A redirector
is the client-side object that forwards I/Orequests to a remote system, where
theyaresatisfiedbyaserver.Forperformanceandsecurity,theredirectorsand
serversruninkernelmode.
Inmoredetail,access to a remotefileoccurs as follows:
1.Theapplicationcallsthe I/Omanagertorequestthatafilebeopenedwith
a filename inthestandard UNCformat.
2.TheI/Omanager builds an I/Orequest packet, as described in Section
B.3.3.5.
3.TheI/Omanagerrecognizesthattheaccessisforaremotefileandcallsa
drivercalleda multiple universal-naming-convention provider (MUP).
4.TheMUPsends the I/Orequest packet asynchronously to all registered
redirectors.
5.A redirector that can satisfy the request responds to the MUP.T oa v o i d
asking all theredirectorsthesame questionin thefuture,the MUPusesa
cache torememberwhich redirectorcan handle this file.
6.The redirectorsendsthe network requestto theremotesystem.
7.Theremote-systemnetworkdriversreceivetherequestandpassittothe
serverdriver.
8.Theserverdriverhandstherequesttotheproperlocalfile-systemdriver.
9.The properdevicedriveriscalledto access thedata.
10.The results are returned to the server driver, which sends the data back
to the requesting redirector. The redirector then returns the data to the
calling applicationviathe I/Omanager.
AsimilarprocessoccursforapplicationsthatusetheWin 32network API,rather
than the UNCservices, except that a module called a multi-provider router is
usedinsteadofa MUP.
For portability, redirectors and servers use the TDI APIfor network trans-
port. The requests themselves are expressed in a higher-level protocol, which
bydefaultisthe SMBprotocoldescribedinSectionB.6.2.Thelistofredirectors
ismaintainedinthe systemhiveof theregistry.
B.6.3.1 Distributed File System
UNCnames are not always convenient, because multiple file servers may be
availabletoservethesamecontentand UNCnamesexplicitlyincludethename"
3,B.6.4 Domains,1111,B.6.3 Redirectors and Servers,"B.6 Networking 45
of the server.Windows supports a distributed file-syste (DFS)p r o t o c o lt h a t
allowsanetworkadministratortoserveupfilesfrommultipleserversusinga
singledistributedname space.
B.6.3.2 Folder Redirection and Client-Side Caching
To improve the PCexperience for users who frequently switch among com-
puters,Windows allows administratorstogiveusers roaming profile ,w h ic h
keepusers’preferencesandothersettingsonservers. Folder redirection isthen
usedto automaticallystorea user’sdocuments and otherfileson aserver.
This works well until one of the computers is no longer attached to the
network,aswhenausertakesa laptopontoanairplane.Togiveusersoff-line
access to their redirected files, Windows uses client-side caching (CSC).CSC
is also used when the computer is on-line to keep copies of the server files
on the local machine for better performance. The files are pushed up to the
serverastheyarechanged.Ifthecomputerbecomesdisconnected,thefilesare
still available, and the update of the server is deferred until the next time the
computerisonline.
B.6.4 Domains
Manynetworkedenvironmentshavenat uralgroupsofusers,suchasstudents
in a computer laboratory at school or employees in one department in a busi-
ness. Frequently, we want all the members of the group to be able to access
sharedresourcesontheirvariouscomputersinthegroup.Tomanagetheglobal
accessrightswithinsuchgroups,Windowsusestheconceptofadomain.Pre-
viously, these domains had no relationship whatsoever to the domain-name
system ( DNS) that maps Internet host names to IPaddresses. Now, however,
theyarecloselyrelated.
Specifically, a Windows domain is a group of Windows workstations and
serversthatshareacommonsecuritypolicyanduserdatabase.SinceWindows
usesthe Kerberosprotocol for trustand authentication, a Windows domain is
the same thing as a Kerberos realm. Windows uses a hierarchical approach
for establishing trust relationships between related domains. The trust rela-
tionships are based on DNSand allow transitive trusts that can flow up and
down the hierarchy. This approach reduces the number of trusts required for
ndomains from n∗(n−1) to O(n). The workstations in the domain trust the
domain controller to give correct information about the access rights of each
user(loadedintotheuser’saccesstokenby LSASS).Allusersretaintheabilityto
restrictaccesstotheirownworkstations,however,nomatterwhatanydomain
controllermaysay.
B.6.5 Active Directory
Active Directory is the Windows implementation of lightweight directory-
access protocol (LDAP) services. Active Directory stores the topology infor-
mation about the domain, keeps the domain-based user and group accounts
andpasswords,andprovidesadomain-basedstoreforWindowsfeaturesthat
need it, such as Windows group policy . Administrators use group policies to
establish uniform standards for desktop preferences and software. For many"
3,B.6.5 Active Directory,1111,B.6.4 Domains,"B.6 Networking 45
of the server.Windows supports a distributed file-syste (DFS)p r o t o c o lt h a t
allowsanetworkadministratortoserveupfilesfrommultipleserversusinga
singledistributedname space.
B.6.3.2 Folder Redirection and Client-Side Caching
To improve the PCexperience for users who frequently switch among com-
puters,Windows allows administratorstogiveusers roaming profile ,w h ic h
keepusers’preferencesandothersettingsonservers. Folder redirection isthen
usedto automaticallystorea user’sdocuments and otherfileson aserver.
This works well until one of the computers is no longer attached to the
network,aswhenausertakesa laptopontoanairplane.Togiveusersoff-line
access to their redirected files, Windows uses client-side caching (CSC).CSC
is also used when the computer is on-line to keep copies of the server files
on the local machine for better performance. The files are pushed up to the
serverastheyarechanged.Ifthecomputerbecomesdisconnected,thefilesare
still available, and the update of the server is deferred until the next time the
computerisonline.
B.6.4 Domains
Manynetworkedenvironmentshavenat uralgroupsofusers,suchasstudents
in a computer laboratory at school or employees in one department in a busi-
ness. Frequently, we want all the members of the group to be able to access
sharedresourcesontheirvariouscomputersinthegroup.Tomanagetheglobal
accessrightswithinsuchgroups,Windowsusestheconceptofadomain.Pre-
viously, these domains had no relationship whatsoever to the domain-name
system ( DNS) that maps Internet host names to IPaddresses. Now, however,
theyarecloselyrelated.
Specifically, a Windows domain is a group of Windows workstations and
serversthatshareacommonsecuritypolicyanduserdatabase.SinceWindows
usesthe Kerberosprotocol for trustand authentication, a Windows domain is
the same thing as a Kerberos realm. Windows uses a hierarchical approach
for establishing trust relationships between related domains. The trust rela-
tionships are based on DNSand allow transitive trusts that can flow up and
down the hierarchy. This approach reduces the number of trusts required for
ndomains from n∗(n−1) to O(n). The workstations in the domain trust the
domain controller to give correct information about the access rights of each
user(loadedintotheuser’saccesstokenby LSASS).Allusersretaintheabilityto
restrictaccesstotheirownworkstations,however,nomatterwhatanydomain
controllermaysay.
B.6.5 Active Directory
Active Directory is the Windows implementation of lightweight directory-
access protocol (LDAP) services. Active Directory stores the topology infor-
mation about the domain, keeps the domain-based user and group accounts
andpasswords,andprovidesadomain-basedstoreforWindowsfeaturesthat
need it, such as Windows group policy . Administrators use group policies to
establish uniform standards for desktop preferences and software. For many"
2,B.7 Programmer Interface,1112,B.6 Networking,"46 Appendix B Windows 7
corporate information-technology groups, this uniformity drastically reduces
thecost of computing.
B.7 Programmer Interface
TheWin 32 APIisthefundamentalinterfacetothecapabilitiesofWindows.This
section describes five main aspects of the Win 32 API: access to kernel objects,
sharing of objects betweenprocesses,processmanagement, interprocesscom-
munication, and memorymanagement.
B.7.1 Access to Kernel Objects
The Windows kernel provides many serv ices that application programs can
use. Application programs obtain these services by manipulating kernel
objects. A process gains access to a kernel object named XXXby calling the
Create XXXfunction to open a handle to an instance of XXX.T h i sh a n d l ei s
unique to the process. Depending on w hich object is being opened, if the
Create() function fails, it may return 0, or it may return a special constant
named INVALID
 HANDLE
 VALUE. Aprocess can close any handle by calling the
CloseHandle() function, and the system may deletethe object if the count of
handlesreferencingthe objectinallprocessesdropstozero.
B.7.2 Sharing Objects between Processes
Windows provides three ways to share objects between processes. The first
way is for a child process to inherit a handle to the object. When the parent
calls the Create XXXfunction, the parent supplies a SECURITIES
 ATTRIBUTES
structure with the bInheritHandle field set to TRUE. This field creates an
inheritable handle. Next, the child process is created, passing a value of TRUE
to the CreateProcess() function’s bInheritHandle argument. Figure B.8
shows a code sample that creates a semaphore handle inherited by a child
process.
SECURITY
 ATTRIBUTES sa;
sa.nlength = sizeof(sa);
sa.lpSecurityDescriptor = NULL;
sa.bInheritHandle = TRUE;
Handle a
 semaphore = CreateSemaphore(&sa, 1, 1, NULL);
char comand
 line[132];
ostrstream ostring(command
 line, sizeof(command
 line));
ostring << a
 semaphore << ends;
CreateProcess(""another
 process.exe"", command
 line,
NULL, NULL, TRUE, . . .);
Figure B.8 Code enabling a child to share an object by inheriting a handle."
3,B.7.1 Access to Kernel Objects,1112,B.7 Programmer Interface,"46 Appendix B Windows 7
corporate information-technology groups, this uniformity drastically reduces
thecost of computing.
B.7 Programmer Interface
TheWin 32 APIisthefundamentalinterfacetothecapabilitiesofWindows.This
section describes five main aspects of the Win 32 API: access to kernel objects,
sharing of objects betweenprocesses,processmanagement, interprocesscom-
munication, and memorymanagement.
B.7.1 Access to Kernel Objects
The Windows kernel provides many serv ices that application programs can
use. Application programs obtain these services by manipulating kernel
objects. A process gains access to a kernel object named XXXby calling the
Create XXXfunction to open a handle to an instance of XXX.T h i sh a n d l ei s
unique to the process. Depending on w hich object is being opened, if the
Create() function fails, it may return 0, or it may return a special constant
named INVALID
 HANDLE
 VALUE. Aprocess can close any handle by calling the
CloseHandle() function, and the system may deletethe object if the count of
handlesreferencingthe objectinallprocessesdropstozero.
B.7.2 Sharing Objects between Processes
Windows provides three ways to share objects between processes. The first
way is for a child process to inherit a handle to the object. When the parent
calls the Create XXXfunction, the parent supplies a SECURITIES
 ATTRIBUTES
structure with the bInheritHandle field set to TRUE. This field creates an
inheritable handle. Next, the child process is created, passing a value of TRUE
to the CreateProcess() function’s bInheritHandle argument. Figure B.8
shows a code sample that creates a semaphore handle inherited by a child
process.
SECURITY
 ATTRIBUTES sa;
sa.nlength = sizeof(sa);
sa.lpSecurityDescriptor = NULL;
sa.bInheritHandle = TRUE;
Handle a
 semaphore = CreateSemaphore(&sa, 1, 1, NULL);
char comand
 line[132];
ostrstream ostring(command
 line, sizeof(command
 line));
ostring << a
 semaphore << ends;
CreateProcess(""another
 process.exe"", command
 line,
NULL, NULL, TRUE, . . .);
Figure B.8 Code enabling a child to share an object by inheriting a handle."
3,B.7.2 Sharing Objects between Processes,1112,B.7.1 Access to Kernel Objects,"46 Appendix B Windows 7
corporate information-technology groups, this uniformity drastically reduces
thecost of computing.
B.7 Programmer Interface
TheWin 32 APIisthefundamentalinterfacetothecapabilitiesofWindows.This
section describes five main aspects of the Win 32 API: access to kernel objects,
sharing of objects betweenprocesses,processmanagement, interprocesscom-
munication, and memorymanagement.
B.7.1 Access to Kernel Objects
The Windows kernel provides many serv ices that application programs can
use. Application programs obtain these services by manipulating kernel
objects. A process gains access to a kernel object named XXXby calling the
Create XXXfunction to open a handle to an instance of XXX.T h i sh a n d l ei s
unique to the process. Depending on w hich object is being opened, if the
Create() function fails, it may return 0, or it may return a special constant
named INVALID
 HANDLE
 VALUE. Aprocess can close any handle by calling the
CloseHandle() function, and the system may deletethe object if the count of
handlesreferencingthe objectinallprocessesdropstozero.
B.7.2 Sharing Objects between Processes
Windows provides three ways to share objects between processes. The first
way is for a child process to inherit a handle to the object. When the parent
calls the Create XXXfunction, the parent supplies a SECURITIES
 ATTRIBUTES
structure with the bInheritHandle field set to TRUE. This field creates an
inheritable handle. Next, the child process is created, passing a value of TRUE
to the CreateProcess() function’s bInheritHandle argument. Figure B.8
shows a code sample that creates a semaphore handle inherited by a child
process.
SECURITY
 ATTRIBUTES sa;
sa.nlength = sizeof(sa);
sa.lpSecurityDescriptor = NULL;
sa.bInheritHandle = TRUE;
Handle a
 semaphore = CreateSemaphore(&sa, 1, 1, NULL);
char comand
 line[132];
ostrstream ostring(command
 line, sizeof(command
 line));
ostring << a
 semaphore << ends;
CreateProcess(""another
 process.exe"", command
 line,
NULL, NULL, TRUE, . . .);
Figure B.8 Code enabling a child to share an object by inheriting a handle."
3,B.7.3 Process Management,1113,B.7.2 Sharing Objects between Processes,"B.7 Programmer Interface 47
// Process A
...
HANDLE a
 semaphore = CreateSemaphore(NULL, 1, 1, ""MySEM1"");
...
// Process B
...
HANDLE b
 semaphore = OpenSemaphore(SEMAPHORE
 ALL
ACCESS,
FALSE, ""MySEM1"");
...
Figure B.9 Code for sharing an object by name lookup.
Assuming the child process knows which handles are shared, the parent
andchildcanachieveinterprocesscommunicationthroughthesharedobjects.
In the example in Figure B.8, the child process gets the value of the handle
from the first command-line argument and then shares the semaphore with
theparentprocess.
The second way to share objects is for one process to give the object a
name when the object is created and for the second process to openthe name.
This method has two drawbacks: Wind ows does not provide a way to check
whether an object with the chosen name already exists, and the object name
spaceisglobal,withoutregardtotheobjecttype.Forinstance,twoapplications
may create and share a single object named “foo”when two distinctobjects—
possibly of different types—were desired.
Named objects have the advantage th at unrelated processes can readily
sharethem.Thefirstprocesscallsoneofthe Create XXXfunctionsandsupplies
an a m ea sap a r a m e t e r .T h es e c o n dp r o c e s sg e t sah a n d l et os h a r et h eo b j e c t
by calling OpenXXX() (orCreate XXX) with the same name, as shown in the
exampleinFigur eB.9.
Thethirdwaytoshareobjectsisviathe DuplicateHandle() function.This
method requires some other method of interprocess communication to pass
the duplicated handle. Given a handle to a process and the value of a handle
within that process, a second process can get a handle to the same object and
thus shareit.Anexampleofthis methodisshown inFigureB.10.
B.7.3 Process Management
InWindows,a processisaloadedinstanceofanapplicationanda threadisan
executable unit of code that can be scheduled by the kernel dispatcher. Thus,
a process contains one or more threads. A process is created when a thread
in some other process calls the CreateProcess() API. This routine loads any
dynamic link libraries used by the process and creates an initial thread in the
process. Additional threads can be created by the CreateThread() function.
Each thread is created with its own stack, which defaults to 1 MBunless
otherwise specifiedin an argumentto CreateThread() ."
3,B.7.4 IPC Using Windows Messaging,1118,B.7.3 Process Management,"52 Appendix B Windows 7
NTOS executive
Only primary thread runs in user-mode
Trap code switches to parked KT
KT blocks =  primary returns to user-mode
KT unblocks & parks =  queue UT completionthread parking
UT completion listkernel
user
user-mode
schedulertrap codeprimary
threadKT0
UT0
UT1 UT0KT1 KT2KT0 blocks
>
>
Figure B.11 User-mode scheduling.
structs,aswellasrudimentaryresourcemanagementandtasksynchronization
primitives.Thekeyfeaturesof UMSaredepictedinFigureB.11.
B.7.3.8 Winsock
Winsock is the Windows sockets API. Winsock is a session-layer interface
that is largely compatible with UNIXsockets but has some added Windows
extensions. It provides a standardized interface to many transport protocols
that may have different addressing schemes, so that any Winsock application
canrunonanyWinsock-compliantprotocolstack.Winsockunderwentamajor
update in Windows Vista to add tracing, IPv6support, impersonation, new
security APIs and many other features.
Winsock follows the Windows Open System Architecture ( WOSA)m o d e l ,
which provides a standard service provider interface ( SPI) between applica-
tions and networking protocols. Applications can load and unload layered
protocols that build additional functionality, such as additional security, on
top of the transport protocol layers. Winsock supports asynchronous opera-
tions and notifications, reliable multica sting, secure sockets, and kernel mode
sockets.Thereisalsosupportforsimplerusagemodels,likethe WSAConnect-
ByName() function, which accepts the targetas stringsspecifying the name or
IPaddressoftheserverandtheserviceorportnumberofthedestinationport.
B.7.4 IPCUsing Windows Messaging
Win32applications handle interprocess communication in several ways. One
way is by using shared kernel objects. Another is by using the Windows
messaging facility, an approach that is particularly popular for Win 32
GUIapplications. One thread can send a message to another thread or to a
windowbycalling PostMessage() ,PostThreadMessage() ,SendMessage() ,
SendThreadMessage() ,orSendMessageCallback() .Postingamessageand
sendingamessagedifferinthisway:thepostroutinesareasynchronous, they
return immediately, and the calling thread does not know when the message"
3,B.7.5 Memory Management,1119,B.7.4 IPC Using Windows Messaging,"B.7 Programmer Interface 53
// allocate 16 MB at the top of our address space
void *buf = VirtualAlloc(0, 0x1000000, MEM
 RESERVE | MEM
 TOP
DOWN,
PAGE
 READWRITE);
// commit the upper 8 MB of the allocated space
VirtualAlloc(buf + 0x800000, 0x800000, MEM
 COMMIT, PAGE
 READWRITE);
// do something with the memory
...
// now decommit the memory
VirtualFree(buf + 0x800000, 0x800000, MEM
 DECOMMIT);
// release all of the allocated address space
VirtualFree(buf, 0, MEM
 RELEASE);
Figure B.12 Code fragments for allocating virtual memory.
is actually delivered.The send routines are synchronous: they block the caller
untilthemessagehas beendeliveredandprocessed.
In addition to sending a message, a thread can send data with the mes-
sage. Since processes have separate address spaces, the data must be copied.
The system copies data by calling SendMessage() to send a message of type
WM
COPYDATA with a COPYDATASTRUCT data structure that contains the length
andaddressofthedatatobetransferred.Whenthemessageissent,Windows
copies the data to a new block of memory and givesthe virtual addressof the
newblock tothe receivingprocess.
Every Win 32thread has its own input queue from which it receives mes-
sages. If a Win 32application does not call GetMessage() to handle events on
its input queue, the queue fills up, and after about five seconds, the system
markstheapplicationas “Not Responding ”.
B.7.5 Memory Management
TheWin 32APIprovidesseveralwaysforanapplicationtousememory:virtual
memory,memory-mappedfiles,heaps,and thread-localstorage.
B.7.5.1 Virtual Memory
An application calls VirtualAlloc() to reserve or commit virtual memory
and VirtualFree() to decommit or release the memory. These functions
enable the application to specify the v irtual address at which the memory is
allocated. They operate on multiples of the memory page size. Examples of
thesefunctions appearinFigureB.12.
Aprocessmaylocksomeofitscommittedpagesintophysicalmemoryby
calling VirtualLock() . The maximum number of pages a process can lock is
30,unlesstheprocessfirstcalls SetProcessWorkingSetSize() toincreasethe
maximumworking-setsize.
B.7.5.2 Memory-Mapping Files
Another way for an application to use memory is by memory-mapping a file
into its address space. Memory mapping is also a convenient way for two"
2,B.8 Summary,1121,B.7 Programmer Interface,"Summary 55
// reserve a slot for a variable
DWORD var
 index = T1sAlloc();
// set it to the value 10
T1sSetValue(var
 index, 10);
// get the value
int var T1sGetValue(var
 index);
// release the index
T1sFree(var
 index);
Figure B.14 Code for dynamic thread-local storage.
tation problem. The Windows 7 hea p manager automatically turns on LFHas
appropriate.
B.7.5.4 Thread-Local Storage
Afourthwayforapplicationstousememoryisthrougha thread-local storage
(TLS) mechanism. Functions that rely on global or static data typically fail to
work properly in a multithreaded environment. For instance, the C run-time
function strtok() uses a static variable to keep track of its current position
while parsing a string. For two concurrent threads to execute strtok() cor-
rectly,theyneedseparate current position variables. TLSprovidesawayto
maintain instances of variables that are global to the function being executed
but not sharedwithany otherthread.
TLSprovides both dynamic and static methods of creating thread-local
storage.ThedynamicmethodisillustratedinFigureB.14.The TLSmechanism
allocates global heap storage and attach es it to the thread environment block
thatWindowsallocatestoeveryuser-modethread.The TEBisreadilyaccessible
by each thread and is used not just for TLSbut for all the per-thread state
informationinusermode.
To use a thread-local static variable, the application declares the variable
asfollows to ensurethateverythreadhas itsown privatecopy:
declspec(thread) DWORD cur
pos = 0 ;
B.8 Summary
Microsoft designed Windows to be an extensible, portable operating system
—one able to take advantage of new techniques and hardware. Windows
supports multiple operating environments and symmetric multiprocessing,
including both 32-bit and 64-bit processors and NUMAcomputers. The use of
kernel objects to provide basic services, along with support for client–server
computing,enablesWindowstosupportaw idevarietyofapplicationenviron-
ments.Windowsprovidesvirtualmemory,integratedcaching,andpreemptive
scheduling. It supports elaborate securi ty mechanisms and includes interna-
tionalizationfeatures.Windowsrunsonawidevarietyofcomputers,sousers
can choose and upgrade hardware to match their budgets and performance
requirementswithout needingtoa lterthe applicationstheyrun."
2,Practice Exercises,1122,B.8 Summary,"56 Appendix B Windows 7
Practice Exercises
B.1What type of operating system is Windows? Describe two of its major
features.
B.2Listthedesigngoalsof Windows. Describetwo indetail.
B.3Describethebooting processfora Windows system.
B.4Describethethreemainarchitecturallayersof theWindows kernel.
B.5What is thejob of theobject manager?
B.6What typesof servicesdoesthe processmanager provide?
B.7What is alocal procedurecall?
B.8What arethe responsibilitiesof the I/Omanager?
B.9WhattypesofnetworkingdoesWindowssupport?HowdoesWindows
implementtransport protocols?Describetwo networking protocols.
B.10How isthe NTFSnamespaceorganized?
B.11Howdoes NTFShandle datastructures?Howdoes NTFSrecoverfroma
systemcrash?What isguaranteedaftera recoverytakesplace?
B.12HowdoesWindows allocate usermemory?
B.13Describesomeofthewaysinwhichanapplicationcanusememoryvia
theWin 32 API.
Further Reading
[Russinovich et al. (2017)] provides an overview of Windows 7 and consider-
able technical detail about system internals and components. [Brown (2000)]
presentsdetailsof the securityarchitectureofWindows.
The Microsoft Developer Network Library ( http://msdn.microsoft.com )
supplies a wealth of information on Windows and other Microsoft products,
including documentation of allthepublished APIs.
[Iseminger(2000)]providesagoodreferenceontheWindowsActiveDirec-
tory. Detailed discussions of writing programs that use the Win 32 APIappear
in[Richter (1997)].
The source code for a 2005 WRKversion of the Windows kernel, together
withacollectionofslidesandother CRKcurriculummaterials,isavailablefrom
www.microsoft.com/WindowsAcademic foruseby universities.
Bibliography
[Brown (2000)] K. Brown, Programming Windows Security , Addison-Wesley
(2000).
[Iseminger (2000)] D. Iseminger, Active Directory Services for Microsoft Windows
2000. Technical Reference ,MicrosoftPress (2000)."
2,Further Reading,1122,Practice Exercises,"56 Appendix B Windows 7
Practice Exercises
B.1What type of operating system is Windows? Describe two of its major
features.
B.2Listthedesigngoalsof Windows. Describetwo indetail.
B.3Describethebooting processfora Windows system.
B.4Describethethreemainarchitecturallayersof theWindows kernel.
B.5What is thejob of theobject manager?
B.6What typesof servicesdoesthe processmanager provide?
B.7What is alocal procedurecall?
B.8What arethe responsibilitiesof the I/Omanager?
B.9WhattypesofnetworkingdoesWindowssupport?HowdoesWindows
implementtransport protocols?Describetwo networking protocols.
B.10How isthe NTFSnamespaceorganized?
B.11Howdoes NTFShandle datastructures?Howdoes NTFSrecoverfroma
systemcrash?What isguaranteedaftera recoverytakesplace?
B.12HowdoesWindows allocate usermemory?
B.13Describesomeofthewaysinwhichanapplicationcanusememoryvia
theWin 32 API.
Further Reading
[Russinovich et al. (2017)] provides an overview of Windows 7 and consider-
able technical detail about system internals and components. [Brown (2000)]
presentsdetailsof the securityarchitectureofWindows.
The Microsoft Developer Network Library ( http://msdn.microsoft.com )
supplies a wealth of information on Windows and other Microsoft products,
including documentation of allthepublished APIs.
[Iseminger(2000)]providesagoodreferenceontheWindowsActiveDirec-
tory. Detailed discussions of writing programs that use the Win 32 APIappear
in[Richter (1997)].
The source code for a 2005 WRKversion of the Windows kernel, together
withacollectionofslidesandother CRKcurriculummaterials,isavailablefrom
www.microsoft.com/WindowsAcademic foruseby universities.
Bibliography
[Brown (2000)] K. Brown, Programming Windows Security , Addison-Wesley
(2000).
[Iseminger (2000)] D. Iseminger, Active Directory Services for Microsoft Windows
2000. Technical Reference ,MicrosoftPress (2000)."
2,Bibliography,1122,Further Reading,"56 Appendix B Windows 7
Practice Exercises
B.1What type of operating system is Windows? Describe two of its major
features.
B.2Listthedesigngoalsof Windows. Describetwo indetail.
B.3Describethebooting processfora Windows system.
B.4Describethethreemainarchitecturallayersof theWindows kernel.
B.5What is thejob of theobject manager?
B.6What typesof servicesdoesthe processmanager provide?
B.7What is alocal procedurecall?
B.8What arethe responsibilitiesof the I/Omanager?
B.9WhattypesofnetworkingdoesWindowssupport?HowdoesWindows
implementtransport protocols?Describetwo networking protocols.
B.10How isthe NTFSnamespaceorganized?
B.11Howdoes NTFShandle datastructures?Howdoes NTFSrecoverfroma
systemcrash?What isguaranteedaftera recoverytakesplace?
B.12HowdoesWindows allocate usermemory?
B.13Describesomeofthewaysinwhichanapplicationcanusememoryvia
theWin 32 API.
Further Reading
[Russinovich et al. (2017)] provides an overview of Windows 7 and consider-
able technical detail about system internals and components. [Brown (2000)]
presentsdetailsof the securityarchitectureofWindows.
The Microsoft Developer Network Library ( http://msdn.microsoft.com )
supplies a wealth of information on Windows and other Microsoft products,
including documentation of allthepublished APIs.
[Iseminger(2000)]providesagoodreferenceontheWindowsActiveDirec-
tory. Detailed discussions of writing programs that use the Win 32 APIappear
in[Richter (1997)].
The source code for a 2005 WRKversion of the Windows kernel, together
withacollectionofslidesandother CRKcurriculummaterials,isavailablefrom
www.microsoft.com/WindowsAcademic foruseby universities.
Bibliography
[Brown (2000)] K. Brown, Programming Windows Security , Addison-Wesley
(2000).
[Iseminger (2000)] D. Iseminger, Active Directory Services for Microsoft Windows
2000. Technical Reference ,MicrosoftPress (2000)."
1,Appendix C BSD UNIX,1125,Appendix B Windows,"CAppendix
BSD UNIX
This chapter was firs written in 1991 and has been updated over time.
In Chapter 20, we presented an in-depth examination of the Linux operating
system.Inthischapter,weexamineanotherpopular UNIXversion—Unix BSD.
We start by presenting a brief history of the UNIXoperating system. We then
describe the system’s user and programmer interfaces. Finally, we discuss the
internal data structures and algorithms usedby the FreeBSDkernel to support
theuser–programmerinterface.
C.1 UNIX History
The first version of UNIXwas developed in 1969 by Ken Thompson of the
Research Group at Bell Laboratories to use an otherwise idle PDP-7.T h o m p -
son was soon joined by Dennis Ritchie and they, with other members of the
ResearchGroup,producedtheearlyversionsof UNIX.
Ritchiehadpreviouslyworkedonthe MULTICS project,and MULTICS hada
stronginfluenceontheneweroperatingsystem.Eventhename UNIXisapun
onMULTICS .Thebasicorganizationofthefilesystem,theideaofthecommand
interpreter (or the shell) as a user process, the use of a separate process for
eachcommand,theoriginalline-editingcharacters(#toerasethelastcharacter
and @ to erase the entire line), and numerous other features came directly
fromMULTICS .Ideasfromotheroperatingsystems,suchas MIT’sCTSSandthe
XDS-940system,werealsoused.
Ritchie and Thompson worked quietly on UNIXfor many years. They
moved it to a PDP-11/20 for a second version; for a third version, they rewrote
mostoftheoperatingsysteminthesystems-programminglanguageC,instead
of the previouslyused assembly language. C was developedat BellLaborato-
ries to support UNIX.UNIXwas also moved to larger PDP-11models, such as
the11/45and11/70.Multiprogrammingandotherenhancementswereadded
whenitwasrewritteninCandmovedtosystems(suchasthe11/45)thathad
hardwaresupportfor multiprogramming.
AsUNIXdeveloped, it became widely used within Bell Laboratories and
gradually spread to a few universities. The first version widely available out-
1"
2,C.1 UNIX History,1125,Appendix C BSD UNIX,"CAppendix
BSD UNIX
This chapter was firs written in 1991 and has been updated over time.
In Chapter 20, we presented an in-depth examination of the Linux operating
system.Inthischapter,weexamineanotherpopular UNIXversion—Unix BSD.
We start by presenting a brief history of the UNIXoperating system. We then
describe the system’s user and programmer interfaces. Finally, we discuss the
internal data structures and algorithms usedby the FreeBSDkernel to support
theuser–programmerinterface.
C.1 UNIX History
The first version of UNIXwas developed in 1969 by Ken Thompson of the
Research Group at Bell Laboratories to use an otherwise idle PDP-7.T h o m p -
son was soon joined by Dennis Ritchie and they, with other members of the
ResearchGroup,producedtheearlyversionsof UNIX.
Ritchiehadpreviouslyworkedonthe MULTICS project,and MULTICS hada
stronginfluenceontheneweroperatingsystem.Eventhename UNIXisapun
onMULTICS .Thebasicorganizationofthefilesystem,theideaofthecommand
interpreter (or the shell) as a user process, the use of a separate process for
eachcommand,theoriginalline-editingcharacters(#toerasethelastcharacter
and @ to erase the entire line), and numerous other features came directly
fromMULTICS .Ideasfromotheroperatingsystems,suchas MIT’sCTSSandthe
XDS-940system,werealsoused.
Ritchie and Thompson worked quietly on UNIXfor many years. They
moved it to a PDP-11/20 for a second version; for a third version, they rewrote
mostoftheoperatingsysteminthesystems-programminglanguageC,instead
of the previouslyused assembly language. C was developedat BellLaborato-
ries to support UNIX.UNIXwas also moved to larger PDP-11models, such as
the11/45and11/70.Multiprogrammingandotherenhancementswereadded
whenitwasrewritteninCandmovedtosystems(suchasthe11/45)thathad
hardwaresupportfor multiprogramming.
AsUNIXdeveloped, it became widely used within Bell Laboratories and
gradually spread to a few universities. The first version widely available out-
1"
3,C.1.1 UNIX Support Group,1126,C.1 UNIX History,"2 Appendix C BSD UNIX
sideBellLaboratorieswasVersion6,releasedin1976.(Theversionnumberfor
earlyUNIXsystems corresponds to the edition number of the UNIX Program-
mer’s Manual that was current when the distribution was made; the code and
themanual wererevisedindependently.)
In 1978, Version 7 was distributed. This UNIXsystem ran on the PDP-11/70
and the Interdata 8/32 and is the ancestor of most modern UNIXsystems. In
particular, it was soon ported to other PDP-11models and to the VAXcom-
puter line. The version available on the VAXwas known as 32V. Research has
continued since then.
C.1.1 UNIX Support Group
After the distribution of Version 7 in 1978, the UNIXSupport Group ( USG)
assumed administrative control and responsibility from the Research Group
fordistributionsof UNIXwithinAT&T,theparentorganizationforBellLabora-
tories.UNIXwas becoming a product, rather than simply a research tool. The
ResearchGroupcontinuedtodeveloptheirownversionsof UNIX,however,to
supporttheirinternalcomputing.Version8includedafacilitycalledthe stream
I/Osystem, which allows flexible configuration of kernel IPCmodules. It also
contained RFS,aremotefilesystemsimilartoSun’s NFS.Thecurrentversionis
Version10,releasedin1989 andavailableonly withinBellLaboratories.
USGmainly provided support for UNIXwithin AT&T. The first external
distributionfrom USGwasSystemIII,in1982.SystemIIIincorporatedfeatures
of Version 7 and 32V, as well as features of several UNIXsystems developed
by groups other than Research. For example, features of UNIX/RT ,ar e a l - t i m e
UNIXsystem,andnumerousportionsof theProgrammer’sWorkBench ( PWB)
softwaretools packagewereincludedinSystemIII.
USGreleased System V in 1983; it is largely derived from System III.
The divestiture of the various Bell operating companies from AT&TleftAT&T
in a position to market System V aggressively. USGwas restructured as the
UNIXSystem Development Laboratory ( USDL), which released UNIXSystem
V Release 2 (V.2) in 1984. UNIXSystem V Release 2, Version 4 (V.2.4) added a
newimplementationofvirtualmemorywithcopy-on-writepagingandshared
memory. USDLw a si nt u r nr e p l a c e db y AT&TInformation Systems ( ATTIS),
which distributed System V Release 3 (V.3) in 1987. V.3 adapts the V8 imple-
mentationofthestream I/Osystemandmakesitavailableas STREAMS .Italso
includes RFS,t h eNFS-likeremotefilesystemmentionedearlier.
C.1.2 Berkeley Begins Development
Thesmallsize,modularity,andcleandesignofearly UNIXsystemsledto UNIX-
basedworkatnumerousothercomputer-scienceorganizations,suchas RAND,
BBN,theUniversityofIllinois,Harvard,Purdue,and DEC.Themostinfluential
UNIXdevelopmentgroupoutsideofBellLaboratoriesand AT&T,however,has
beentheUniversityof CaliforniaatBerkeley.
BillJoyandOzalpBabaogludidthefirstBerkeley VAX UNIX workin1978.
They added virtual memory, demand paging, and page replacement to 32V
to produce 3BSD UNIX . This version was the first to implement any of these
facilities on a UNIXsystem. The large virtual memory space of 3BSDallowed
the development of very large programs, such as Berkeley’s own Franz LISP.
The memory-management work convinced the Defense Advanced Research"
3,C.1.2 Berkeley Begins Development,1126,C.1.1 UNIX Support Group,"2 Appendix C BSD UNIX
sideBellLaboratorieswasVersion6,releasedin1976.(Theversionnumberfor
earlyUNIXsystems corresponds to the edition number of the UNIX Program-
mer’s Manual that was current when the distribution was made; the code and
themanual wererevisedindependently.)
In 1978, Version 7 was distributed. This UNIXsystem ran on the PDP-11/70
and the Interdata 8/32 and is the ancestor of most modern UNIXsystems. In
particular, it was soon ported to other PDP-11models and to the VAXcom-
puter line. The version available on the VAXwas known as 32V. Research has
continued since then.
C.1.1 UNIX Support Group
After the distribution of Version 7 in 1978, the UNIXSupport Group ( USG)
assumed administrative control and responsibility from the Research Group
fordistributionsof UNIXwithinAT&T,theparentorganizationforBellLabora-
tories.UNIXwas becoming a product, rather than simply a research tool. The
ResearchGroupcontinuedtodeveloptheirownversionsof UNIX,however,to
supporttheirinternalcomputing.Version8includedafacilitycalledthe stream
I/Osystem, which allows flexible configuration of kernel IPCmodules. It also
contained RFS,aremotefilesystemsimilartoSun’s NFS.Thecurrentversionis
Version10,releasedin1989 andavailableonly withinBellLaboratories.
USGmainly provided support for UNIXwithin AT&T. The first external
distributionfrom USGwasSystemIII,in1982.SystemIIIincorporatedfeatures
of Version 7 and 32V, as well as features of several UNIXsystems developed
by groups other than Research. For example, features of UNIX/RT ,ar e a l - t i m e
UNIXsystem,andnumerousportionsof theProgrammer’sWorkBench ( PWB)
softwaretools packagewereincludedinSystemIII.
USGreleased System V in 1983; it is largely derived from System III.
The divestiture of the various Bell operating companies from AT&TleftAT&T
in a position to market System V aggressively. USGwas restructured as the
UNIXSystem Development Laboratory ( USDL), which released UNIXSystem
V Release 2 (V.2) in 1984. UNIXSystem V Release 2, Version 4 (V.2.4) added a
newimplementationofvirtualmemorywithcopy-on-writepagingandshared
memory. USDLw a si nt u r nr e p l a c e db y AT&TInformation Systems ( ATTIS),
which distributed System V Release 3 (V.3) in 1987. V.3 adapts the V8 imple-
mentationofthestream I/Osystemandmakesitavailableas STREAMS .Italso
includes RFS,t h eNFS-likeremotefilesystemmentionedearlier.
C.1.2 Berkeley Begins Development
Thesmallsize,modularity,andcleandesignofearly UNIXsystemsledto UNIX-
basedworkatnumerousothercomputer-scienceorganizations,suchas RAND,
BBN,theUniversityofIllinois,Harvard,Purdue,and DEC.Themostinfluential
UNIXdevelopmentgroupoutsideofBellLaboratoriesand AT&T,however,has
beentheUniversityof CaliforniaatBerkeley.
BillJoyandOzalpBabaogludidthefirstBerkeley VAX UNIX workin1978.
They added virtual memory, demand paging, and page replacement to 32V
to produce 3BSD UNIX . This version was the first to implement any of these
facilities on a UNIXsystem. The large virtual memory space of 3BSDallowed
the development of very large programs, such as Berkeley’s own Franz LISP.
The memory-management work convinced the Defense Advanced Research"
3,C.1.3 The Spread of UNIX,1128,C.1.2 Berkeley Begins Development,"4 Appendix C BSD UNIX
C.1.3 The Spread of UNIX
UNIX 4 BSD was the operating system of choice for the VAXfrom its initial
release(in1979)untilthereleaseofUltrix, DEC’sBSDimplementation.Indeed,
4B S Dis still the best choice for many research and networking installations.
The current set of UNIXoperating systems is not limited to those from Bell
Laboratories (which is currently owned by Lucent Technology) and Berkeley,
however.SunMicrosystemshelpedpopularizethe BSDflavorof UNIXbyship-
ping it on Sun workstations. As UNIXgrew in popularity, it was moved to
many computers and computer systems. A wide variety of UNIXandUNIX-
like operating systems have been created. DECsupported its UNIX(Ultrix) on
its workstations and is replacing Ultrix with another UNIX-derived operating
system, OSF/1. Microsoft rewrote UNIXfor the Intel 8088 family and called
itXENIX, and its Windows NToperating system was heavily influenced by
UNIX.IBMhasUNIX(AIX)o ni t s PCs, workstations, and mainframes. In fact,
UNIXisavailableonalmostallgeneral-purposecomputers.Itrunsonpersonal
computers, workstations, minicomputers, mainframes, and supercomputers,
fromAppleMacintoshIIstoCrayIIs.Becauseofitswideavailability,itisused
in environments ranging from academic to military to manufacturing process
control. Most of these systems are based on Version 7, System III, 4.2 BSD,o r
SystemV.
The wide popularity of UNIXwith computer vendors has made UNIXthe
mostportableofoperatingsystems,anduserscanexpecta UNIXenvironment
independent of any specific computer manufacturer. But the large number of
implementationsofthesystemhasledtoremarkablevariationintheprogram-
minganduserinterfacesdistributedbythevendors.Fortruevendorindepen-
dence, application-program developersneed consistent interfaces.Such inter-
faceswouldallowall “UNIX ”applicationstorunonall UNIXsystems,whichis
certainlynotthecurrentsituation.Thisissuehasbecomeimportantas UNIXhas
becomethepreferredprogram-developmentplatformforapplicationsranging
from databases to graphics and networking, and it has led to a strong market
demandfor UNIXstandards.
Several standardization projects have been undertaken. The first was the
/usr/group1984Standard ,sponsored by the UniForumindustryuser’sgroup.
Sincethen,manyofficialstandardsbodieshavecontinuedtheeffort,including
IEEEandISO(thePOSIXstandard). The X/Open Group international consor-
tiumcompleted XPG3,a CommonApplicationEnvironment,which subsumes
theIEEEinterface standard. Unfortunately, XPG3is based on a draft of the
ANSICstandardratherthanthefinalspecification, andthereforeneededtobe
redoneas XPG4.In1989,the ANSIstandardsbodystandardizedtheCprogram-
ming language, producing an ANSIC specification that vendorswerequick to
adopt.
As such projects continue, the flavors of UNIXwill converge and lead
to one programming interface to UNIX, allowing UNIXto become even more
popular. In fact, two separate sets of powerful UNIXvendors are working on
thisproblem:The AT&T-guided UNIXInternational( UI)andtheOpenSoftware
Foundation ( OSF) have both agreed to follow the POSIXstandard. Recently,
many of the vendors involved in those two groups have agreed on further
standardization(the COSEagreement)."
3,C.1.4 History of FreeBSD,1130,C.1.3 The Spread of UNIX,"6 Appendix C BSD UNIX
TheUNIXsystem has grown from a personal project of two Bell Labora-
tories employees to an operating system defined by multinational standard-
ization bodies. At the same time, UNIXis an excellent vehicle for academic
study, and we believe it will remain an important part of operating-system
theory and practice. For example, the Tunis operating system, the Xinu oper-
ating system, and the Minix operating system are based on the concepts of
UNIXbutweredevelopedexplicitlyforclassroomstudy.Thereisaplethoraof
ongoing UNIX-related research systems, including Mach, Chorus, Comandos,
and Roisin. The original developers, Ritchie and Thompson, were honored in
1983bytheAssociationforComputingMachineryTuringAwardfortheirwork
onUNIX.
C.1.4 History of FreeBSD
The specific UNIXversion used in this chapter is the Intel version of FreeBSD.
This system implementsmany interestin goperating-systemconcepts, such as
demand paging with clustering, as well as networking. The FreeBSDproject
began in early 1993 to produce a snapshot of 386 BSDto solve problems that
couldnotberesolvedusingtheexistingpatchmechanism.386 BSDwasderived
from4.3 BSD-Lite (Net/2) and was released in June 1992 by William Jolitz.
FreeBSD(coined by DavidGreenman) 1.0 was releasedinDecember1993, and
FreeBSD1.1wasreleasedinMay1994.Bothversionswerebasedon 4.3 BSD-Lite.
LegalissuesbetweenUCBandNovellrequiredthat 4.3 BSD-Litecodenolonger
beused,sothefinal 4.3 BSD-LitereleasewasmadeinJuly1994( FreeBSD1.1.5.1).
FreeBSDwasthenreinventedbasedon 4.4BSD-Litecode,whichwasincom-
plete.FreeBSD2.0wasreleasedinNovember1994.Laterreleasesincluded2.0.5
inJune1995,2.1.5inAugust1996,2.1.7.1inFebruary1997,2.2.1inApril1997,
2.2.8 in November 1998, 3.0 in October 1998, 3.1 in February 1999, 3.2 in May
1999,3.3inSeptember1999,3.4inDecember1999,3.5inJune2000,4.0inMarch
2000, 4.1inJuly 2000, and4.2 inNovember2000.
The goal of the FreeBSDproject is to provide software that can be used for
any purpose with no strings attached. The idea is that the code will get the
widestpossibleuseandprovidethemostbenefit.Atpresent,itrunsprimarily
onIntelplatforms,althoughAlphaplatformsaresupported.Workisunderway
to portto otherprocessorplatformsas well.
C.2 Design Principles
UNIXwas designed to be a time-sharing system. The standard user interface
(theshell)issimpleand canbereplacedbyanother,ifdesired.Thefilesystem
isamultileveltree,whichallowsuserstocreatetheirownsubdirectories.Each
userdatafile issimplyasequenceof bytes.
Diskfilesand I/Odevicesaretreatedassimilarlyaspossible.Thus,device
dependenciesandpeculiaritiesarekeptinthekernelasmuchaspossible.Even
in the kernel,most of themare confined tothe devicedrivers.
UNIXsupports multiple processes. A process can easily create new pro-
cesses. CPUscheduling is a simple priority algorithm. FreeBSDuses demand"
2,C.2 Design Principles,1130,C.1 UNIX History,"6 Appendix C BSD UNIX
TheUNIXsystem has grown from a personal project of two Bell Labora-
tories employees to an operating system defined by multinational standard-
ization bodies. At the same time, UNIXis an excellent vehicle for academic
study, and we believe it will remain an important part of operating-system
theory and practice. For example, the Tunis operating system, the Xinu oper-
ating system, and the Minix operating system are based on the concepts of
UNIXbutweredevelopedexplicitlyforclassroomstudy.Thereisaplethoraof
ongoing UNIX-related research systems, including Mach, Chorus, Comandos,
and Roisin. The original developers, Ritchie and Thompson, were honored in
1983bytheAssociationforComputingMachineryTuringAwardfortheirwork
onUNIX.
C.1.4 History of FreeBSD
The specific UNIXversion used in this chapter is the Intel version of FreeBSD.
This system implementsmany interestin goperating-systemconcepts, such as
demand paging with clustering, as well as networking. The FreeBSDproject
began in early 1993 to produce a snapshot of 386 BSDto solve problems that
couldnotberesolvedusingtheexistingpatchmechanism.386 BSDwasderived
from4.3 BSD-Lite (Net/2) and was released in June 1992 by William Jolitz.
FreeBSD(coined by DavidGreenman) 1.0 was releasedinDecember1993, and
FreeBSD1.1wasreleasedinMay1994.Bothversionswerebasedon 4.3 BSD-Lite.
LegalissuesbetweenUCBandNovellrequiredthat 4.3 BSD-Litecodenolonger
beused,sothefinal 4.3 BSD-LitereleasewasmadeinJuly1994( FreeBSD1.1.5.1).
FreeBSDwasthenreinventedbasedon 4.4BSD-Litecode,whichwasincom-
plete.FreeBSD2.0wasreleasedinNovember1994.Laterreleasesincluded2.0.5
inJune1995,2.1.5inAugust1996,2.1.7.1inFebruary1997,2.2.1inApril1997,
2.2.8 in November 1998, 3.0 in October 1998, 3.1 in February 1999, 3.2 in May
1999,3.3inSeptember1999,3.4inDecember1999,3.5inJune2000,4.0inMarch
2000, 4.1inJuly 2000, and4.2 inNovember2000.
The goal of the FreeBSDproject is to provide software that can be used for
any purpose with no strings attached. The idea is that the code will get the
widestpossibleuseandprovidethemostbenefit.Atpresent,itrunsprimarily
onIntelplatforms,althoughAlphaplatformsaresupported.Workisunderway
to portto otherprocessorplatformsas well.
C.2 Design Principles
UNIXwas designed to be a time-sharing system. The standard user interface
(theshell)issimpleand canbereplacedbyanother,ifdesired.Thefilesystem
isamultileveltree,whichallowsuserstocreatetheirownsubdirectories.Each
userdatafile issimplyasequenceof bytes.
Diskfilesand I/Odevicesaretreatedassimilarlyaspossible.Thus,device
dependenciesandpeculiaritiesarekeptinthekernelasmuchaspossible.Even
in the kernel,most of themare confined tothe devicedrivers.
UNIXsupports multiple processes. A process can easily create new pro-
cesses. CPUscheduling is a simple priority algorithm. FreeBSDuses demand"
2,C.3 Programmer Interface,1132,C.2 Design Principles,"8 Appendix C BSD UNIX
—required large amounts of code, radically increasing the size of the system.
Forinstance,bothnetworkingandwindowingdoubledthesizeofthesystem.
This patterninturnpointedout thecontinued strengthof UNIX—whenever a
new development occurred in the industry, UNIXcould usually absorb it but
remain UNIX.
C.3 Programmer Interface
Like most operating systems, UNIXconsists of two separable parts: the kernel
and the systems programs. We can view the UNIXoperating system as being
layered,asshowninFigureC.2.Everythingbelowthesystem-callinterfaceand
abovethephysicalhardwareisthe kernel.Thekernelprovidesthefilesystem,
CPUscheduling,memorymanagement, and other operating-systemfunctions
throughsystemcalls.Systemsprogramsusethekernel-supportedsystemcalls
to provideusefulfunctions, suchas compilationandfile manipulation.
System calls define the programmer interface toUNIX. The set of systems
programscommonlyavailabledefinesthe userinterface .Theprogrammerand
userinterfacedefinethe context thatthe kernelmust support.
Most systems programs are written in C, and the UNIXProgrammer’s
Manualpresentsallsystemcallsas Cfunctions.AsystemprogramwritteninC
forFreeBSDonthePentiumcangenerallybemovedtoanAlpha FreeBSDsystem
and simply recompiled, even though the two systems are quite different. The
details of system calls are known only to the compiler. This feature is a major
reason forthe portabilityof UNIXprograms.
System calls for UNIXcan be roughly grouped into three categories: file
manipulation, process control, and information manipulation. In Chapter 2,
welistedafourthcategory,devicemanipulation,butsincedevicesin UNIXare
treated as (special) files, the same system calls support both files and devices
(although thereis anextrasystemcall for settingdeviceparameters).
(the users)
shells and commands
compilers and interpreters
system libraries
system-call interface to the kernel
kernel interface to the hardwarefile system
swapping block I/O 
system
disk and tape driversCPU scheduling
page replacement
demand paging
virtual memorysignals terminal 
handling
character I/O system
terminal drivers
device controllers
disks and tapesmemory controllers
physical memoryterminal controllers
terminals
Figure C.2 4.4BSD layer structure."
3,C.3.1 File Manipulation,1133,C.3 Programmer Interface,"C.3 Programmer Interface 9
C.3.1 File Manipulation
AfileinUNIXis a sequence of bytes. Different programs expect various levels
of structure, but the kernel does not impose a structure on files. For instance,
the convention for text files is lines of ASCIIcharacters separated by a single
newline character (which is the linefeed character in ASCII), but the kernel
knows nothing of thisconvention.
Files are organized in tree-structured directories . Directories are them-
selves files that contain information on how to find other files. A path name
to a file is a text string that identifies a file by specifying a path through the
directory structure to the file. Syntactic ally, it consists of individual file-name
elements separated by the slash character. For example, in /usr/local/font ,t h e
firstslashindicatestherootofthedirectorytree,calledthe rootdirectory .The
nextelement, usr,isasubdirectoryoftheroot, localisasubdirectoryof usr,and
fontis a file or directory in the directory local.W h e t h e r fontis an ordinary file
ora directorycannot be determinedfrom the path-name syntax.
TheUNIXfile system has both absolute path names andrelative path
names. Absolute path names start at the root of the file system and are dis-
tinguished by a slash at the beginning of the path name; /usr/local/font is an
absolute path name. Relative path names start at the currentdirectory ,w h i c h
isanattributeoftheprocessaccessingthepathname.Thus, local/font indicatesa
fileordirectorynamed fontinthedirectory localinthecurrentdirectory,which
mightor mightnot be /usr.
Afi l em a yb ek n o w nb ym o r et h a no n en a m ei no n eo rm o r ed i r e c t o r i e s .
Such multiple names are known as links, and all links are treated equally by
the operating system. FreeBSDalso supports symbolic links ,w h i c ha r efi l e s
containingthepathnameofanotherfile.Thetwokindsoflinksarealsoknown
ashardlinks andsoftlinks .Soft(symbolic)links,unlikehardlinks,maypoint
todirectoriesand maycross file-systemboundaries.
Thefilename “.”inadirectoryisahardlinktothedirectoryitself.Thefile
name “..”isa hardlink totheparentdirectory.Thus, ifthecurrentdirectoryis
/user/jlp/programs, then ../bin/wdf refers to /user/jlp/bin/wdf.
Hardware devices have names in the file system. These device special
filesorspecial files are known to the kernel as device interfaces, but they are
nonetheless accessed by the user by much the same system calls as are other
files.
FigureC.3showsatypical UNIXfilesystem.Theroot( /)normallycontains
a small number of directories as well as /kernel,the binary boot image of the
operating system; /devcontains the device special files, such as /dev/console,
/dev/lp0, /dev/mt0, and so on; and /bincontains the binaries of the essential
UNIXsystems programs. Other binaries may be in /usr/bin(for applications
systems programs, such as text formatters), /usr/compat (for programs from
otheroperatingsystems,suchasLinux),or /usr/local/bin (forsystemsprograms
written at the local site). Library files—such as the C, Pascal, and FORTRAN
subroutinelibraries—arekeptin /lib(or/usr/libor/usr/local/lib ).
The files of users themselves are stored in a separate directory for each
user, typically in /usr.Thus, the user directory for carolwould normally be in
/usr/carol. For a large system,these directoriesmay be further grouped to ease
administration, creating a file structure with /usr/prof/avi and /usr/staff/carol.
Administrative files and programs, such as the password file, are kept in /etc."
3,C.3.2 Process Control,1135,C.3.1 File Manipulation,"C.3 Programmer Interface 11
typesetter are kept in /usr/lib/troff/dev202. All the conventions concerning the
location of specific files and directories have been defined by programmers
andtheirprograms.Theoperating-systemkernelneedsonly /etc/init,which is
usedto initializeterminalprocesses,to beoperable.
System calls for basic file manipulation are creat() ,open(),read(),
write() ,close() ,unlink() ,a n d trunc() .T h e creat() system call, given
a path name, creates an empty file (or truncates an existing one). An existing
fileisopenedbythe open()systemcall,whichtakesapathnameandamode
(such as read, write, or read–write) and returns a small integer, called a file
descriptor . The file descriptor may then be passed to a read()orwrite()
systemcall(alongwithabufferaddressandthenumberofbytestotransfer)to
performdatatransferstoorfromthefile.Afileisclosedwhenitsfiledescriptor
ispassedto the close() systemcall.The trunc() call reducesthelength of a
file to 0.
Afiledescriptorisanindexintoasmalltableofopenfilesforthisprocess.
Descriptors start at 0 and seldom get higher than 6 or 7 for typical programs,
dependingon themaximum number ofsimultaneouslyopen files.
Each read()orwrite() updates the current offset into the file, which is
associated with the file-table entry and is used to determine the position in
the file for the next read()orwrite() .T h e lseek() system call allows the
positiontoberesetexplicitly.Italsoallowsthecreationofsparsefiles(fileswith
“holes ”in them). The dup()anddup2()system calls can be used to produce
a new file descriptor that is a copy of an existing one. The fcntl() system
call can also do that and in addition can examine or set various parameters of
an open file. For example, it can make each succeeding write() to an open
fileappendto the endof that file.Thereisan additionalsystemcall, ioctl() ,
for manipulating deviceparameters.It can set the baud rateof a serialport or
rewind atape, forinstance.
Information about the file (such as its size, protection modes, owner, and
so on) can be obtained by the stat()system call. Several system calls allow
someofthisinformationtobechanged: rename() (changefilename), chmod()
(change the protection mode), and chown() (change the owner and group).
Many of these system calls have variants that apply to file descriptors instead
of file names. The link()system call makes a hard link for an existing file,
creatinganewnameforanexistingfile.Alinkisremovedbythe unlink(())
system call; if it is the last link, the file is deleted. The symlink() system call
makesasymboliclink.
Directories are made by the mkdir() system call and are deleted by
rmdir() .Thecurrent directoryis changed by cd().
Althoughthestandardfilecalls( open()andothers)canbeusedondirecto-
ries, it is inadvisable to do so, since directories have an internal structure that
must be preserved. Instead, another set of system calls is provided to open
a directory, to step through each file entry within the directory, to close the
directory, and to perform other functions; these are opendir() ,readdir() ,
closedir() ,and others.
C.3.2 Process Control
Aprocessis a program in execution. Processes are identified by their process
identifier , which is an integer. Anew process is created by the fork()system"
3,C.3.3 Signals,1137,C.3.2 Process Control,"C.3 Programmer Interface 13
anexecve() as an argument to a loginprocess. The loginprocess collects
the user’s password, encrypts it, and compares the result to an encrypted
stringtakenfromthefile /etc/passwd. Ifthecomparisonissuccessful,theuseris
allowedtologin.The loginprocessexecutesa shell,orcommandinterpreter,
aftersettingthenumeric useridentifier oftheprocesstothatoftheuserlogging
in.(Theshellandtheuseridentifierarefoundin /etc/passwd bytheuser’slogin
name.) It is with this shell that the user ordinarily communicates for the rest
of the login session. The shell itself forks subprocesses for the commands the
usertellsittoexecute.
Theuseridentifierisusedbythekerneltodeterminetheuser’spermissions
for certain system calls, especially those involving file accesses. There is also
agroup identifier , which is used to provide similar privileges to a collection
of users. In FreeBSDa process may be in several groups simultaneously. The
loginprocessputstheshellinallthegroupspermittedtotheuserbythefiles
/etc/passwd and /etc/group.
Twouseridentifiersareusedbythekernel:theeffectiveuseridentifierand
the real user identifier. The effective user identifier is used to determine file
access permissions. If the file of a program being loaded by an execve() has
thesetuidbit set in its inode, the effective user identifier of the process is set
to the user identifier of the owner of the file, whereas the real user identifier
is left as it was. This scheme allows certain processes to have more than
ordinary privileges while still being executable by ordinary users. The setuid
idea was patented by Dennis Ritchie (U .S. Patent 4,135,240) and is one of the
distinctive features of UNIX. Asimilar setgidbit exists for groups. Aprocess
may determine its real and effective user identifier with the getuid() and
geteuid() calls, respectively. The getgid() andgetegid() calls determine
the process’s real and effective group identifier, respectively. The rest of a
pr oc ess’ sgr oupsmayb efoun dw ithth e getgroups() systemcall.
C.3.3 Signals
Signalsare a facility for handling exceptional conditions similar to software
interrupts. There are 20 different signals, each corresponding to a distinct
condition. Asignal may be generated by a keyboard interrupt, by an error in
a process (such as a bad memory reference), or by a number of asynchronous
events(suchastimersorjob-controlsignalsfromtheshell).Almostanysignal
mayalso begeneratedby the kill()systemcall.
Theinterrupt signal,SIGINT,isusedtostopacommandbeforethatcom-
mand completes. It is usually produced by the ˆC character ( ASCII 3). As of
4.2BSD,theimportantkeyboardcharactersaredefinedbyatableforeachtermi-
naland canbe redefinedeasily.The quitsignal,SIGQUIT, isusuallyproduced
bytheˆbscharacter( ASCII28).The quitsignalbothstopsthecurrentlyexecut-
ing program and dumps its current memory image to a file named corein the
currentdirectory.Thecorefilecanbeusedbydebuggers. SIGILLisproducedby
anillegalinstructionand SIGSEGV byanattempttoaddressmemoryoutsideof
thelegalvirtualmemoryspace ofa process.
Arrangements can be made either for most signals to be ignored (to have
no effect) or for a routine in the user process (a signal handler) to be called. A
signalhandlermaysafelydooneoftwoth ingsbeforereturningfromcatching
a signal: call the exit()system call or modify a global variable. One signal"
3,C.3.4 Process Groups,1138,C.3.3 Signals,"14 Appendix C BSD UNIX
(thekillsignal, number 9, SIGKILL) cannot be ignored or caught by a signal
handler. SIGKILLisused,forexample,tokillarunawayprocessthatisignoring
other signalssuch as SIGINTandSIGQUIT.
Signals can be lost. If another signal of the same kind is sent before a
previous signal has been accepted by the process to which it is directed, the
first signal will be overwritten, and only the last signal will be seen by the
process. In other words, a call to the signal handler tells a process that there
hasbeenatleastoneoccurrenceofthesignal.Also,thereisnorelativepriority
among UNIXsignals.Iftwodifferentsignalsaresenttothesameprocessatthe
sametime,we cannot know which onethe processwillreceivefirst.
Signals were originally intended to deal with exceptional events. As is
true of most UNIXfeatures, however, signal use has steadily expanded. 4.1BSD
introduced job control, which uses sign als to start and stop subprocesses on
demand.Thisfacilityallowsoneshelltoco ntrolmultipleprocesses—starting,
stopping, and backgrounding them as the user wishes. The SIGWINCH signal,
inventedbySunMicrosystems,isusedforinformingaprocessthatthewindow
in which output is being displayed has changed size. Signals are also used to
deliverurgentdata fromnetwork connections.
Userswantedmorereliablesignalsandabugfixinaninherentracecondi-
tionintheoldsignalimplementation.Thus, 4.2BSDbroughtwithitarace-free,
reliable,separatelyimplementedsignalc apability.Itallowsindividualsignals
tobeblockedduringcriticalsections,andithas anewsystemcalltoletapro-
cess sleep until interrupted. It is similar to hardware-interrupt functionality.
This capabilityisnow partof the POSIXstandard.
C.3.4 Process Groups
Groups of related processes frequently cooperate to accomplish a common
task. For instance, processes may create, and communicate over, pipes. Such
a set of processes is termed a process group ,o rajob. Signals may be sent to
all processes in a group. Aprocess usually inherits its process group from its
parent,but the setpgrp() systemcall allows a processtochange itsgroup.
Process groups are used by the C shell to control the operation of mul-
tiple jobs. Only one process group may use a terminal device for I/Oat any
time. This foreground job has the attention of the user on that terminal, while
all other nonattached jobs ( background jobs) perform their functions without
userinteraction. Accessto the terminaliscontrolledby process groupsignals.
Each job has a controlling terminal (again, inherited from its parent). If the
process group of the controlling terminal matches the group of a process, that
p r o c e s si si nt h ef o r e g r o u n da n di sa l l o w e dt op e r f o r m I/O. If a nonmatching
(background)processattemptsthesame,a SIGTTINorSIGTTOU signalissentto
its process group. This signal usually causes the process group to freeze until
it is foregrounded by the user, at which point it receives a SIGCONT signal,
indicating that the process can perform the I/O. Similarly, a SIGSTOP may be
sentto theforegroundprocess groupto freezeit.
C.3.5 Information Manipulation
System calls exist to set and return both an interval timer ( getitimer() /
setitimer() ) and the current time ( gettimeofday() /settimeofday() )i n"
3,C.3.5 Information Manipulation,1138,C.3.4 Process Groups,"14 Appendix C BSD UNIX
(thekillsignal, number 9, SIGKILL) cannot be ignored or caught by a signal
handler. SIGKILLisused,forexample,tokillarunawayprocessthatisignoring
other signalssuch as SIGINTandSIGQUIT.
Signals can be lost. If another signal of the same kind is sent before a
previous signal has been accepted by the process to which it is directed, the
first signal will be overwritten, and only the last signal will be seen by the
process. In other words, a call to the signal handler tells a process that there
hasbeenatleastoneoccurrenceofthesignal.Also,thereisnorelativepriority
among UNIXsignals.Iftwodifferentsignalsaresenttothesameprocessatthe
sametime,we cannot know which onethe processwillreceivefirst.
Signals were originally intended to deal with exceptional events. As is
true of most UNIXfeatures, however, signal use has steadily expanded. 4.1BSD
introduced job control, which uses sign als to start and stop subprocesses on
demand.Thisfacilityallowsoneshelltoco ntrolmultipleprocesses—starting,
stopping, and backgrounding them as the user wishes. The SIGWINCH signal,
inventedbySunMicrosystems,isusedforinformingaprocessthatthewindow
in which output is being displayed has changed size. Signals are also used to
deliverurgentdata fromnetwork connections.
Userswantedmorereliablesignalsandabugfixinaninherentracecondi-
tionintheoldsignalimplementation.Thus, 4.2BSDbroughtwithitarace-free,
reliable,separatelyimplementedsignalc apability.Itallowsindividualsignals
tobeblockedduringcriticalsections,andithas anewsystemcalltoletapro-
cess sleep until interrupted. It is similar to hardware-interrupt functionality.
This capabilityisnow partof the POSIXstandard.
C.3.4 Process Groups
Groups of related processes frequently cooperate to accomplish a common
task. For instance, processes may create, and communicate over, pipes. Such
a set of processes is termed a process group ,o rajob. Signals may be sent to
all processes in a group. Aprocess usually inherits its process group from its
parent,but the setpgrp() systemcall allows a processtochange itsgroup.
Process groups are used by the C shell to control the operation of mul-
tiple jobs. Only one process group may use a terminal device for I/Oat any
time. This foreground job has the attention of the user on that terminal, while
all other nonattached jobs ( background jobs) perform their functions without
userinteraction. Accessto the terminaliscontrolledby process groupsignals.
Each job has a controlling terminal (again, inherited from its parent). If the
process group of the controlling terminal matches the group of a process, that
p r o c e s si si nt h ef o r e g r o u n da n di sa l l o w e dt op e r f o r m I/O. If a nonmatching
(background)processattemptsthesame,a SIGTTINorSIGTTOU signalissentto
its process group. This signal usually causes the process group to freeze until
it is foregrounded by the user, at which point it receives a SIGCONT signal,
indicating that the process can perform the I/O. Similarly, a SIGSTOP may be
sentto theforegroundprocess groupto freezeit.
C.3.5 Information Manipulation
System calls exist to set and return both an interval timer ( getitimer() /
setitimer() ) and the current time ( gettimeofday() /settimeofday() )i n"
3,C.3.6 Library Routines,1139,C.3.5 Information Manipulation,"C.4 User Interface 15
microseconds. In addition, processes can ask for their process identifier ( get-
pid()), their group identifier ( getgid() ) ,t h en a m eo ft h em a c h i n eo nw h i c h
theyareexecuting( gethostname() ),and many othervalues.
C.3.6 Library Routines
The system-call interface to UNIXis supported and augmented by a large
collection of library routines and hea der files. The header files provide the
definitionof complex data structures used in system calls. In addition, a large
libraryof functions providesadditionalprogramsupport.
Forexample,the UNIXI/O systemcallsprovideforthereadingandwriting
of blocks of bytes. Some applications may want to read and write only 1 byte
atatime.Althoughpossible,thatwouldrequireasystemcallforeachbyte—a
veryhighoverhead.Instead,asetofstandardlibraryroutines(thestandard I/O
packageaccessedthroughtheheaderfile <stdio.h >)providesanotherinterface,
which reads and writes several thousand bytes at a time using local buffers
and transfers between these buffers (in user memory) when I/Ois desired.
Formatted I/Oisalso supportedby thestandard I/Opackage.
Additional library support is provided for mathematical functions, net-
work access, data conversion, and so on. The FreeBSDkernel supports over
300 system calls; the C program library has over 300 library functions. The
library functions eventually result in system calls where necessary (for exam-
ple,the getchar() libraryroutinewillresultina read()systemcallifthefile
bufferisempty).However,theprogrammergenerallydoesnotneedtodistin-
guishbetweenthebasicsetofkernelsyst emcallsandtheadditionalfunctions
providedby libraryfunctions.
C.4 User Interface
Both the programmer and the user of a UNIXsystem deal mainly with the set
of systems programs that have been written and are available for execution.
Theseprogramsmakethenecessarysystemcallstosupporttheirfunction,but
thesystemcallsthemselvesarecontain edwithintheprogramanddonotneed
tobe obviousto theuser.
The common systems programs can be grouped into several categories;
mostofthemarefileordirectoryoriented.Forexample,thesystemsprograms
tomanipulatedirectoriesare mkdirtocreateanewdirectory, rmdirtoremove
ad i r e c t o r y , cdto change the current directory to another, and pwdto print the
absolutepath name ofthe current(working) directory.
Thelsprogramliststhenamesofthefilesinthecurrentdirectory.Anyof
28 options can ask that properties of the files be displayed also. For example,
the-loption asks for a long listing showing the file name, owner, protection,
dateand timeof creation,and size.The cpprogram createsa newfile that isa
copyofanexistingfile.The mvprogrammovesafilefromoneplacetoanother
in the directory tree. In most cases, th is move simply requires a renaming of
thefile.Ifnecessary,however,thefileiscopiedtothenewlocation,andtheold
copyisdeleted.Afileisdeletedbythe rmprogram(whichmakesan unlink()
systemcall)."
2,C.4 User Interface,1139,C.3 Programmer Interface,"C.4 User Interface 15
microseconds. In addition, processes can ask for their process identifier ( get-
pid()), their group identifier ( getgid() ) ,t h en a m eo ft h em a c h i n eo nw h i c h
theyareexecuting( gethostname() ),and many othervalues.
C.3.6 Library Routines
The system-call interface to UNIXis supported and augmented by a large
collection of library routines and hea der files. The header files provide the
definitionof complex data structures used in system calls. In addition, a large
libraryof functions providesadditionalprogramsupport.
Forexample,the UNIXI/O systemcallsprovideforthereadingandwriting
of blocks of bytes. Some applications may want to read and write only 1 byte
atatime.Althoughpossible,thatwouldrequireasystemcallforeachbyte—a
veryhighoverhead.Instead,asetofstandardlibraryroutines(thestandard I/O
packageaccessedthroughtheheaderfile <stdio.h >)providesanotherinterface,
which reads and writes several thousand bytes at a time using local buffers
and transfers between these buffers (in user memory) when I/Ois desired.
Formatted I/Oisalso supportedby thestandard I/Opackage.
Additional library support is provided for mathematical functions, net-
work access, data conversion, and so on. The FreeBSDkernel supports over
300 system calls; the C program library has over 300 library functions. The
library functions eventually result in system calls where necessary (for exam-
ple,the getchar() libraryroutinewillresultina read()systemcallifthefile
bufferisempty).However,theprogrammergenerallydoesnotneedtodistin-
guishbetweenthebasicsetofkernelsyst emcallsandtheadditionalfunctions
providedby libraryfunctions.
C.4 User Interface
Both the programmer and the user of a UNIXsystem deal mainly with the set
of systems programs that have been written and are available for execution.
Theseprogramsmakethenecessarysystemcallstosupporttheirfunction,but
thesystemcallsthemselvesarecontain edwithintheprogramanddonotneed
tobe obviousto theuser.
The common systems programs can be grouped into several categories;
mostofthemarefileordirectoryoriented.Forexample,thesystemsprograms
tomanipulatedirectoriesare mkdirtocreateanewdirectory, rmdirtoremove
ad i r e c t o r y , cdto change the current directory to another, and pwdto print the
absolutepath name ofthe current(working) directory.
Thelsprogramliststhenamesofthefilesinthecurrentdirectory.Anyof
28 options can ask that properties of the files be displayed also. For example,
the-loption asks for a long listing showing the file name, owner, protection,
dateand timeof creation,and size.The cpprogram createsa newfile that isa
copyofanexistingfile.The mvprogrammovesafilefromoneplacetoanother
in the directory tree. In most cases, th is move simply requires a renaming of
thefile.Ifnecessary,however,thefileiscopiedtothenewlocation,andtheold
copyisdeleted.Afileisdeletedbythe rmprogram(whichmakesan unlink()
systemcall)."
3,C.4.1 Shells and Commands,1140,C.4 User Interface,"16 Appendix C BSD UNIX
Todisplayafileontheterminal,ausercanrun cat.The catprogramtakes
alistoffilesandconcatenatesthem,copyingtheresulttothestandardoutput,
commonly the terminal. On a high-speed cathode-ray tube ( CRT)d i s p l a y ,o f
course, the file may speed by too fast to be read. The moreprogram displays
thefileonescreenatatime,pausinguntiltheusertypesacharactertocontinue
to the next screen. The headprogram displays just the first few lines of a file;
tailshows thelastfew lines.
These are the basic systems programs widely used in UNIX. In addition,
there are a number of editors ( ed,sed,emacs,vi, and so on), compilers (C,
python, FORTRAN , and so on), and text formatters (troff, TEX,s c r i b e ,a n ds o
on).Therearealsoprogramsforsorting( sort)andcomparingfiles( cmp,diff),
lookingforpatterns( grep,awk),sendingmailtootherusers( mail),andmany
other activities.
C.4.1 Shells and Commands
Bothuser-writtenandsystemsprogramsarenormallyexecutedbyacommand
interpreter. The command interpreter in UNIXis a user process like any other.
As noted earlier, it is called a shell—because it surrounds the kernel of the
operating system. Users can write their own shells, and, in fact, several shells
are in general use. The Bourneshell , written by Steve Bourne, is probably the
mostwidelyused—or,atleast,themostwidelyavailable.The Cshell,mo stly
the work of Bill Joy, a founder of Sun Microsystems, is the most popular on
BSDsystems. The Korn shell, by Dave Korn, has become popular because it
combines the featuresof theBourne shellandthe Cshell.
The common shells share much of their command-language syntax. UNIX
is normally an interactive system. The shell indicates its readiness to accept
another command by typing a prompt, and the user types a command on a
singleline.Forinstance, intheline
%ls-l
thepercentsignistheusualCshellprompt,andthe ls -l(typedbytheuser)
is the (long) list-directory command. Commands can take arguments, which
the user types after the command name on the same line, separated by white
space(spaces ortabs).
Although a few commands are built into the shells (such as cd), a typical
command is an executable binary object file. A list of several directories, the
search path , is kept by the shell. For each command, each of the directories
in the search path is searched, in order, for a file of the same name. If a file is
found, it is loaded and executed. The search path can be set by the user. The
directories /binand /usr/binarealmostalwaysinthesearchpath,and atypical
search path on a FreeBSDsystemmight be
( . /usr/avi/bin /usr/local/bin /bin /usr/bin )
Thelscommand’sobjectfileis /bin/ls,andtheshellitselfis /bin/sh(theBourne
shell)or /bin/csh(the Cshell).
Execution of a command is done by a fork()system call followed by an
execve() of the object file. The shell usually then does a wait()to suspend"
3,C.4.2 Standard I/O,1141,C.4.1 Shells and Commands,"C.4 User Interface 17
itsownexecutionuntilthecommandcompletes(FigureC.4).Thereisasimple
syntax (an ampersand [&] at the end of the command line) to indicate that
theshell should notwait for the completionof thecommand. Acommand left
runninginthismannerwhiletheshellcontinuestointerpretfurthercommands
is said to be a background command, or to be running in the background.
Processesforwhich the shell doeswaitaresaidto runinthe foreground .
The C shell in FreeBSDsystems provides a facility called job control (par-
tiallyimplementedinthekernel),asmentionedpreviously.Jobcontrol allows
processesto be movedbetweenthe foreground and the background. The pro-
cesses can be stopped and restarted on v arious conditions, such as a back-
ground job wanting input from the user’s terminal. This scheme allows most
of the control of processes provided by windowing or layering interfaces but
requires no special hardware. Job control is also useful in window systems,
such as the X Window System developed at MIT. Each window is treated as
a terminal, allowing multiple processes to be in the foreground (one per win-
dow) at any one time. Of course, background processes may exist on any of
the windows. The Korn shell also supports job control, and job control (and
processgroups)willlikelybe standardinfutureversionsof UNIX.
C.4.2 Standard I/O
Processes can open files as they like, but most processes expect three file
descriptors(numbers0,1,and2)tobeopenwhentheystart.Thesefiledescrip-
tors are inherited across the fork()(and possibly the execve() )t h a tc r e a t e d
the process. They are known as standard input (0),standard output (1), and
standard error (2). All three are frequently open to the user’s terminal. Thus,
the program can read what the user types by reading standard input, and the
program can send output to the user’s screen by writing to standard output.
Thestandard-errorfiledescriptorisalsoopenforwritingandisusedforerror
output; standard output is used for ordinary output. Most programs can also
accept a file (rather than a terminal) for standard input and standard output.
Theprogramdoesnotcarewhereitsinputiscomingfromandwhereitsoutput
isgoing.This isone of theelegantdesignfeaturesof UNIX.
The common shells have a simple syntax for changing what files are open
for the standard I/Ostreams of a process. Changing a standard file is called
I/Oredirection . The syntax for I/Oredirection is shown in Figure C.5. In this
command meaning of command
% ls > filea direct output of ls to file filea
% pr < filea > fileb
% lpr < fileb
% % make program > & errsinput from filea and output to fileb
input from fileb
save both standard output and
standard error in a file
Figure C.5 Standard /io/ redirection."
3,"C.4.3 Pipelines, Filters, and Shell Scripts",1142,C.4.2 Standard I/O,"18 Appendix C BSD UNIX
example,the lscommandproducesalistingofthenamesoffilesinthecurrent
directory,the prcommandformatsthatlistintopagessuitableforaprinter,and
thelprcommandspoolstheformattedoutputtoaprinter,suchas /dev/lp0.The
subsequentcommandforcesalloutputandallerrormessagestoberedirected
to afile.Without theampersand,errormessagesappearonthe terminal.
C.4.3 Pipelines, Filters, and Shell Scripts
ThefirstthreecommandsofFigureC.5couldhavebeencoalescedintotheone
command
%ls|pr |lpr
Each vertical bar tells the shell to arrange for the output of the preceding
command to be passed as input to the following command. A pipeis used to
carry the data from one process to the other. One process writes into one end
of the pipe,and another processreadsfrom the other end.In the example,the
write end of one pipe would be set up by the shell to be the standard output
ofls,andthereadendofthepipewouldbethestandardinputof pr.Another
pipewould be between prandlpr.
Acommandsuchas prthatpassesitsstandardinputtoitsstandardoutput,
performingsomeprocessingonit,iscalleda filter.Many UNIXcommandscan
beusedasfilters.Complicatedfunctionscanbepiecedtogetheraspipelinesof
common commands. Also, common functions, such as output formatting, do
not need to be built into numerous commands, because the output of almost
any programcan be pipedthrough pr(or someother appropriatefilter).
Both of the common UNIXshells are also programming languages, with
shellvariablesandtheusualhigher-levelprogramming-languagecontrolcon-
structs (loops, conditionals). The execution of a command is analogous to a
subroutine call. A file of shell commands, a shell script , can be executed like
any other command, with the appropriate shell being invoked automatically
toreadit. Shellprogramming thuscan beusedtocombine ordinaryprograms
convenientlyforsophisticatedapplicationswithouttheneedforanyprogram-
ming in conventional languages.
This external user view is commonly thought of as the definition of UNIX,
yet it is the most easily changed definition. Writing a new shell with a quite
different syntax and semantics would greatly change the user view while not
changing the kernel or even the programmer interface. Several menu-driven
and iconic interfaces for UNIXexist, and the X Window System is rapidly
becomingastandard.Theheartof UNIXis,ofcourse,thekernel.Thiskernelis
much more difficult to change than is the user interface, because all programs
depend on the system calls that it provides to remain consistent. Of course,
new system calls can be added to increase functionality, but programs must
thenbemodifiedto usethenewcalls.
C.5 Process Management
A major design problem for operating systems is the representation of pro-
cesses. One substantial difference between UNIXand many other systems is
theeasewithwhichmultipleprocessescanbecreatedandmanipulated.These"
2,C.5 Process Management,1142,C.4 User Interface,"18 Appendix C BSD UNIX
example,the lscommandproducesalistingofthenamesoffilesinthecurrent
directory,the prcommandformatsthatlistintopagessuitableforaprinter,and
thelprcommandspoolstheformattedoutputtoaprinter,suchas /dev/lp0.The
subsequentcommandforcesalloutputandallerrormessagestoberedirected
to afile.Without theampersand,errormessagesappearonthe terminal.
C.4.3 Pipelines, Filters, and Shell Scripts
ThefirstthreecommandsofFigureC.5couldhavebeencoalescedintotheone
command
%ls|pr |lpr
Each vertical bar tells the shell to arrange for the output of the preceding
command to be passed as input to the following command. A pipeis used to
carry the data from one process to the other. One process writes into one end
of the pipe,and another processreadsfrom the other end.In the example,the
write end of one pipe would be set up by the shell to be the standard output
ofls,andthereadendofthepipewouldbethestandardinputof pr.Another
pipewould be between prandlpr.
Acommandsuchas prthatpassesitsstandardinputtoitsstandardoutput,
performingsomeprocessingonit,iscalleda filter.Many UNIXcommandscan
beusedasfilters.Complicatedfunctionscanbepiecedtogetheraspipelinesof
common commands. Also, common functions, such as output formatting, do
not need to be built into numerous commands, because the output of almost
any programcan be pipedthrough pr(or someother appropriatefilter).
Both of the common UNIXshells are also programming languages, with
shellvariablesandtheusualhigher-levelprogramming-languagecontrolcon-
structs (loops, conditionals). The execution of a command is analogous to a
subroutine call. A file of shell commands, a shell script , can be executed like
any other command, with the appropriate shell being invoked automatically
toreadit. Shellprogramming thuscan beusedtocombine ordinaryprograms
convenientlyforsophisticatedapplicationswithouttheneedforanyprogram-
ming in conventional languages.
This external user view is commonly thought of as the definition of UNIX,
yet it is the most easily changed definition. Writing a new shell with a quite
different syntax and semantics would greatly change the user view while not
changing the kernel or even the programmer interface. Several menu-driven
and iconic interfaces for UNIXexist, and the X Window System is rapidly
becomingastandard.Theheartof UNIXis,ofcourse,thekernel.Thiskernelis
much more difficult to change than is the user interface, because all programs
depend on the system calls that it provides to remain consistent. Of course,
new system calls can be added to increase functionality, but programs must
thenbemodifiedto usethenewcalls.
C.5 Process Management
A major design problem for operating systems is the representation of pro-
cesses. One substantial difference between UNIXand many other systems is
theeasewithwhichmultipleprocessescanbecreatedandmanipulated.These"
3,C.5.1 Process Control Blocks,1143,C.5 Process Management,"C.5 Process Management 19
processes are represented in UNIXby various control blocks. No system con-
trolblocks areaccessibleinthevirtualaddressspaceofauserprocess;control
blocks associated with a process are stored in the kernel. The kernel uses the
information in thesecontrol blocks for processcontrol and CPUscheduling.
C.5.1 Process Control Blocks
Themostbasicdatastructureassociatedwithprocessesisthe processstructure .
Aprocessstructurecontainseverythingthatthesystemneedstoknowabouta
processwhentheprocessisswappedout,suchasitsuniqueprocessidentifier,
schedulinginformation(forexample,thepriorityoftheprocess),andpointers
to othercontrol blocks. Thereisan array of processstructureswhose lengthis
defined at system-linking time. The process structures of ready processes are
keptlinkedtogetherbytheschedulerina doublylinkedlist(thereadyqueue),
and there are pointers from each process structure to the process’s parent, to
itsyoungestlivingchild,andtovariouso therrelativesofinterest,suchasalist
ofprocessessharing thesame programcode(text).
Thevirtual address space of a user process is divided into text (program
code), data, and stack segments. The data and stack segments are always in
thesameaddressspace,buttheymaygrowseparately,andusuallyinopposite
directions.Mostfrequently,thestackgrowsdownasthedatagrowuptoward
it.Thetextsegmentissometimes(asonanIntel8086withseparateinstruction
and data space) in an address space different from the data and stack, and it
isusuallyread-only.Thedebuggerputsatextsegmentinread–writemodeto
allowinsertionof breakpoints.
Every process with sharable text (almost all, under FreeBSD)h a sap o i n t e r
from its process structure to a text structure . The text structure records how
many processes are using the text segment, including a pointer into a list of
their process structures, and where the page table for the text segment can be
found on disk when it is swapped. The text structure itself is always resident
in main memory. An array of such structures is allocated at system link time.
The text, data, and stack segments for the processes may be swapped. When
thesegmentsareswappedin, theyarepaged.
Thepage tables record information on the mapping from the process’s
virtual memory to physical memory. The process structure contains pointers
to the page table, for use when the process is resident in main memory, or
the address of the process on the swap device, when the process is swapped.
Thereisnospecialseparatepagetableforasharedtextsegment;everyprocess
sharing thetextsegmenthas entriesfor itspagesintheprocess’s pagetable.
Information about the process needed only when the process is resident
(that is, not swapped out) is kept in the user structure (oru structure ), rather
than in the process structure. This structure is mapped read-only into user
virtual address space, so user processes can read its contents. It is writable
by the kernel. The user structure contains a copy of the process control block,
orPCB, which is kept here for saving the process’s general registers, stack
pointer, program counter, and page-table base registers when the process is
not running. Thereis space to keepsystem-call parameters and return values.
Alluserandgroupidentifiersassociatedwiththeprocess(notjusttheeffective
useridentifierkeptintheprocessstructure)arekepthere.Signals,timers,and
quotas have data structures here. Of more obvious relevance to the ordinary"
3,C.5.2 CPU Scheduling,1145,C.5.1 Process Control Blocks,"C.5 Process Management 21
parent process. Such data structures as are necessary for manipulating pipes
may be kept in registers between the vfork() and the execve() . Files may
be closed in one process without affecti ng the other process, since the kernel
datastructuresinvolveddependontheuserstructure,whichisnotshared.The
parentissuspendedwhenitcalls vfork() untilthechildeithercalls execve()
orterminates,so thatthe parentwillnot change memorythat the child needs.
Whentheparentprocessislarge, vfork() canproducesubstantialsavings
in system CPUtime. However, it is a fairly dangerous system call, since any
memory change occurs in both processes until the execve() occurs. An alter-
nativeistoshareallpagesbyduplicatingthepagetablebuttomarktheentries
of both page tables as copy-on-write . The hardware protection bits are set to
trap any attempt to write in these shared pages. If such a trap occurs, a new
frame is allocated, and the shared page is copied to the new frame. The page
tablesareadjustedtoshowthatthispageisnolongershared(andthereforeno
longerneedsto be write-protected),andexecutioncanresume.
Anexecve() systemcallcreatesnonewprocessoruserstructure.Rather,
thetextanddataoftheprocessarereplaced.Openfilesarepreserved(although
there is a way to specify that certain file descriptors are to be closed on an
execve() ). Most signal-handling properties are preserved, but arrangements
tocallaspecificuserroutineonasignalarecanceled,forobviousreasons.The
processidentifierand mostother propertiesof theprocessareunchanged.
C.5.2 CPU Scheduling
CPUscheduling inUNIXis designed to benefit intera ctive processes. Processes
are given small CPUtime slices by a priority algorithm that reduces to round-
robin schedulingfor CPU-bound jobs.
Everyprocesshas a schedulingpriority associatedwithit;largernumbers
indicatelowerpriority.Processesdoingdisk I/Oorotherimportanttaskshave
priorities less than “pzero ”and cannot be killed by signals. Ordinary user
processeshave positiveprioritiesand thus arelesslikelyto be runthan is any
system process, although user processe s can set precedence over one another
through the nicecommand.
The more CPUtime a process accumulates, the lower (more positive) its
priority becomes, and vice versa. This negative feedback in CPUscheduling
makes it difficult for a single process to take all the CPUtime. Process aging is
employedto preventstarvation.
OlderUNIXsystemsuseda1-secondquantumfortheround-robinschedul-
ing.FreeBSDreschedulesprocessesevery0.1secondandrecomputespriorities
every second. The round-robin scheduling is accomplished by the timeout
mechanism, which tells the clock interr upt driver to call a kernel subroutine
after a specified interval. The subrou tine to be called in this case causes the
rescheduling and then resubmits a timeout to call itself again. The priority
recomputationisalsotimedbyasubroutinethatresubmitsatimeoutforitself.
There is no preemptionof one process by another in the kernel. Aprocess
may relinquish the CPUbecause it is waiting for I/Oor because its time slice
has expired. When a process chooses to relinquish the CPU,i tg o e st o sleep
on anevent. The kernel primitive used for this purpose is called sleep()
(not to be confused with the user-level library routine of the same name).
Sleep() takesanargumentthatis,byconvention,theaddressofakerneldata"
2,C.6 Memory Management,1146,C.5 Process Management,"22 Appendix C BSD UNIX
structure related to an event for which a process is waiting. When the event
occurs,thesystemprocessthatknowsaboutitcalls wakeup() withtheaddress
correspondingtotheevent,and allprocessesthathaddoneasleeponthesame
address are put in the ready queue to be run.
F o re x a m p l e ,ap r o c e s sw a i t i n gf o rd i s k I/Oto complete will sleep on the
addressofthebufferheadercorrespondingtothedatabeingtransferred.When
the interrupt routine for the disk driver notes that the transfer is complete, it
calls wakeup() on the buffer header. The interrupt uses the kernel stack for
whatever process happened to be running at the time, and the wakeup() is
donefrom that systemprocess.
The process that actually does run is chosen by the scheduler. Sleep()
takes a second argument, which is the scheduling priority to be used for this
purpose.Thispriorityargument,iflessthan “pzero, ”alsopreventstheprocess
frombeingawakenedprematurelybysomeexceptionalevent,suchasasignal.
When a signal is generated, it is left pending until the system half of the
affected process next runs. This event usually happens soon, since the signal
normallycausestheprocesstobeawakenediftheprocesshasbeenwaitingfor
someother condition.
No memory is associated with events. The caller of the routine that does
asleep() on an event must be prepared to deal with a premature return,
including thepossibilitythat thereason forwaiting has vanished.
Raceconditions areinvolvedintheeventmechanism.Ifaprocessdecides
(because of checking a flag in memory, for instance) to sleep on an event, and
the event occurs before the process can execute the primitive that does the
sleep() ontheevent,theprocesssleepingmaythensleepforever.Weprevent
this situation by raising the hardware processor priority during the critical
sectionsothatnointerruptscanoccur.Thus,onlytheprocessdesiringtheevent
canrununtilitissleeping.Hardwareprocessorpriorityisusedinthismanner
to protect critical regions throughout the kernel and is the greatest obstacle to
porting UNIXto multiple-processor machines. However, this problem has not
preventedsuch portingfrombeing donerepeatedly.
Many processes, such as text editors, are I/Obound and are, in general,
scheduledmainlyonthebasisofwaitingfor I/O.Experiencesuggeststhatthe
UNIXscheduler performs best with I/O-bound jobs, as can be observed when
several CPU-bound jobs, such as text formatters or language interpreters, are
running.
Whathasbeenreferredtohereas CPUscheduling correspondscloselytothe
short-termscheduling ofChapter3.However,thenegative-feedbackproperty
of the priority scheme provides some long-term scheduling in that it largely
determines the long-term job mix. Medium-term scheduling is done by the
swapping mechanism describedinSectionC.6.
C.6 Memory Management
Much of UNIX’s earlydevelopmentwas doneona PDP-11.ThePDP-11has only
eightsegmentsinitsvirtualaddressspace,andthesizeofeachisatmost8,192
bytes. The larger machines, such as the PDP-11/70 , allow separate instruction
and address spaces, effectively doubling the address space and number of
segments,butthisaddressspaceisstill relativelysmall.Inaddition,thekernel"
2,C.7 File System,1149,C.6 Memory Management,"C.7 File System 25
The amount of memory the process will need is some fraction of that
process’s total virtual size—up to one-half if that process has been swapped
outfor a long time.
C.7 File System
TheUNIXfile system supportstwo main objects: files and directories.Directo-
riesarejustfileswithaspecialformat,sotherepresentationofafileisthebasic
UNIXconcept.
C.7.1 Blocks and Fragments
Mostofthefilesystemistakenupby datablocks ,whichcontainwhateverthe
usershaveputintheirfiles.Let’sconsiderhowthesedatablocksarestoredon
thedisk.
The hardware disk sector is usually 512 bytes. A block size larger than
512 bytes is desirable for speed. However, because UNIXfile systems usually
contain a very large number of small files, much larger blocks would cause
excessiveinternalfragmentation.Thatiswhytheearlier 4.1BSDfilesystemwas
limitedtoa1,024-byte(1- KB)block.The 4.2BSDsolutionistouse twoblocksizes
for files that have no indirect blocks. All the blocks of a file are of a large size
(such as 8 KB) except the last. The last block is an appropriate multiple of a
smaller fragment size (for example, 1,024 KB) to fill out the file. Thus, a file of
size 18,000 bytes would have two 8- KBblocks and one 2- KBfragment (which
wouldnot be filledcompletely).
Theblockandfragmentsizesaresetduringfile-systemcreationaccording
to the intended use of the file system. If many small files are expected, the
fragment sizeshould be small; if repeatedtransfers of large files are expected,
the basic block sizeshould be large.Implementationdetailsforce a maximum
block-to-fragment ratio of 8:1 and a minimum block size of 4 KB,s ot y p i c a l
choices are4,096:512 for theformercase and8,192:1,024 for thelatter.
Suppose data are written to a file in transfer sizes of 1- KBbytes, and the
block and fragment sizes of the file system are 4 KBand 512 bytes. The file
systemwillallocatea1- KBfragmentto contain thedatafromthefirst transfer.
Thenexttransferwillcauseanew2- KBfragmenttobeallocated.Thedatafrom
the original fragment must be copied into this new fragment, followed by the
second1- KBtransfer.Theallocationroutinesattempttofindtherequiredspace
on the disk immediately following the existing fragment so that no copying
is necessary. If they cannot do so, up to seven copies may be required before
the fragment becomes a block. Provisions have been made for programs to
discover the block size for a file so that transfers of that size can be made, to
avoidfragment recopying.
C.7.2 Inodes
Afileisrepresentedbyan inode,whichisarecordthatstoresmostoftheinfor-
mation about a specific file on the disk. (See Figure C.7.) The name inode(pro-
nounced EYE node ) is derived from “index node ”and was originally spelled
“i-node ”; the hyphen fell out of use over the years. The term is sometimes
spelled “In o d e . ”"
3,C.7.1 Blocks and Fragments,1149,C.7 File System,"C.7 File System 25
The amount of memory the process will need is some fraction of that
process’s total virtual size—up to one-half if that process has been swapped
outfor a long time.
C.7 File System
TheUNIXfile system supportstwo main objects: files and directories.Directo-
riesarejustfileswithaspecialformat,sotherepresentationofafileisthebasic
UNIXconcept.
C.7.1 Blocks and Fragments
Mostofthefilesystemistakenupby datablocks ,whichcontainwhateverthe
usershaveputintheirfiles.Let’sconsiderhowthesedatablocksarestoredon
thedisk.
The hardware disk sector is usually 512 bytes. A block size larger than
512 bytes is desirable for speed. However, because UNIXfile systems usually
contain a very large number of small files, much larger blocks would cause
excessiveinternalfragmentation.Thatiswhytheearlier 4.1BSDfilesystemwas
limitedtoa1,024-byte(1- KB)block.The 4.2BSDsolutionistouse twoblocksizes
for files that have no indirect blocks. All the blocks of a file are of a large size
(such as 8 KB) except the last. The last block is an appropriate multiple of a
smaller fragment size (for example, 1,024 KB) to fill out the file. Thus, a file of
size 18,000 bytes would have two 8- KBblocks and one 2- KBfragment (which
wouldnot be filledcompletely).
Theblockandfragmentsizesaresetduringfile-systemcreationaccording
to the intended use of the file system. If many small files are expected, the
fragment sizeshould be small; if repeatedtransfers of large files are expected,
the basic block sizeshould be large.Implementationdetailsforce a maximum
block-to-fragment ratio of 8:1 and a minimum block size of 4 KB,s ot y p i c a l
choices are4,096:512 for theformercase and8,192:1,024 for thelatter.
Suppose data are written to a file in transfer sizes of 1- KBbytes, and the
block and fragment sizes of the file system are 4 KBand 512 bytes. The file
systemwillallocatea1- KBfragmentto contain thedatafromthefirst transfer.
Thenexttransferwillcauseanew2- KBfragmenttobeallocated.Thedatafrom
the original fragment must be copied into this new fragment, followed by the
second1- KBtransfer.Theallocationroutinesattempttofindtherequiredspace
on the disk immediately following the existing fragment so that no copying
is necessary. If they cannot do so, up to seven copies may be required before
the fragment becomes a block. Provisions have been made for programs to
discover the block size for a file so that transfers of that size can be made, to
avoidfragment recopying.
C.7.2 Inodes
Afileisrepresentedbyan inode,whichisarecordthatstoresmostoftheinfor-
mation about a specific file on the disk. (See Figure C.7.) The name inode(pro-
nounced EYE node ) is derived from “index node ”and was originally spelled
“i-node ”; the hyphen fell out of use over the years. The term is sometimes
spelled “In o d e . ”"
3,C.7.2 Inodes,1149,C.7.1 Blocks and Fragments,"C.7 File System 25
The amount of memory the process will need is some fraction of that
process’s total virtual size—up to one-half if that process has been swapped
outfor a long time.
C.7 File System
TheUNIXfile system supportstwo main objects: files and directories.Directo-
riesarejustfileswithaspecialformat,sotherepresentationofafileisthebasic
UNIXconcept.
C.7.1 Blocks and Fragments
Mostofthefilesystemistakenupby datablocks ,whichcontainwhateverthe
usershaveputintheirfiles.Let’sconsiderhowthesedatablocksarestoredon
thedisk.
The hardware disk sector is usually 512 bytes. A block size larger than
512 bytes is desirable for speed. However, because UNIXfile systems usually
contain a very large number of small files, much larger blocks would cause
excessiveinternalfragmentation.Thatiswhytheearlier 4.1BSDfilesystemwas
limitedtoa1,024-byte(1- KB)block.The 4.2BSDsolutionistouse twoblocksizes
for files that have no indirect blocks. All the blocks of a file are of a large size
(such as 8 KB) except the last. The last block is an appropriate multiple of a
smaller fragment size (for example, 1,024 KB) to fill out the file. Thus, a file of
size 18,000 bytes would have two 8- KBblocks and one 2- KBfragment (which
wouldnot be filledcompletely).
Theblockandfragmentsizesaresetduringfile-systemcreationaccording
to the intended use of the file system. If many small files are expected, the
fragment sizeshould be small; if repeatedtransfers of large files are expected,
the basic block sizeshould be large.Implementationdetailsforce a maximum
block-to-fragment ratio of 8:1 and a minimum block size of 4 KB,s ot y p i c a l
choices are4,096:512 for theformercase and8,192:1,024 for thelatter.
Suppose data are written to a file in transfer sizes of 1- KBbytes, and the
block and fragment sizes of the file system are 4 KBand 512 bytes. The file
systemwillallocatea1- KBfragmentto contain thedatafromthefirst transfer.
Thenexttransferwillcauseanew2- KBfragmenttobeallocated.Thedatafrom
the original fragment must be copied into this new fragment, followed by the
second1- KBtransfer.Theallocationroutinesattempttofindtherequiredspace
on the disk immediately following the existing fragment so that no copying
is necessary. If they cannot do so, up to seven copies may be required before
the fragment becomes a block. Provisions have been made for programs to
discover the block size for a file so that transfers of that size can be made, to
avoidfragment recopying.
C.7.2 Inodes
Afileisrepresentedbyan inode,whichisarecordthatstoresmostoftheinfor-
mation about a specific file on the disk. (See Figure C.7.) The name inode(pro-
nounced EYE node ) is derived from “index node ”and was originally spelled
“i-node ”; the hyphen fell out of use over the years. The term is sometimes
spelled “In o d e . ”"
3,C.7.3 Directories,1151,C.7.2 Inodes,"C.7 File System 27
(for seeking backward and forward in a file), the actual maximum file size is
232−1bytes.Two gigabytesis largeenough formost purposes.
C.7.3 Directories
Plain files are not distinguished from directories at this level of implementa-
tion.Directorycontentsarekeptindatablocks,anddirectoriesarerepresented
by an inode in the same way as plain files. Only the inode type field distin-
guishesbetweenplainfilesanddirectories.Plainfilesarenotassumedtohavea
structure,whereasdirectorieshaveaspecificstructure.InVersion7,filenames
werelimitedto14characters,sodirectorieswerealistof16-byteentries:2bytes
foran inode numberand 14 bytesfor a file name.
InFreeBSDfile names are of variable length, up to 255 bytes, so directory
entries are also of variable length. Each entry contains first the length of the
entry, then the file name and the inode n umber. This variable-length entry
makes the directory management and search routines more complex, but it
allows users to choose much moremeaningful names for their files and direc-
tories. The first two names in every directory are “.”and “..”.N e wd i r e c t o r y
entries are added to the directory in the first space available, generally after
theexistingfiles.Alinearsearchisused.
The user refers to a file by a path name, whereas the file system uses the
inode as its definition of a file. Thus, the kernel has to map the supplied user
pathname to aninode.Thedirectoriesareusedfor this mapping.
First, a starting directory is determin ed. As mentioned earlier, if the first
character of the path name is “/,”the starting directory is the root directory.
If the path name starts with any character other than a slash, the starting
directoryis the current directoryof the c urrent process. The starting directory
ischeckedforproperfiletypeandaccesspermissions,andanerrorisreturned
ifnecessary.Theinodeof thestarting directoryisalways available.
The next element of the path name, up to the next “/”or to the end of the
pathname,isafilename.Thestartingdirectoryissearchedforthisname,and
an error is returned if the name is not found. If the path name has yet another
element, the current inode must refer to a directory; an error is returned if it
doesnotorifaccessisdenied.Thisdirectoryissearchedinthesamewayasthe
previousone.Thisprocesscontinuesuntiltheendofthepathnameisreached
andthedesiredinodeisreturned.Thisstep-by-stepprocessisneededbecause
at any directory a mount point (or symbolic link, as discussed below) may be
encountered,causing thetranslationtomoveto adifferentdirectorystructure
forcontinuation.
Hardlinksaresimplydirectoryentrieslikeanyother.Wehandlesymbolic
links for the most part by starting the search over with the path name taken
from the contents of the symbolic link. We prevent infinite loops by counting
the number of symbolic links encountered during a path-name search and
returninganerrorwhena limit(eight)isexceeded.
Nondisk files (such as devices) do not have data blocks allocated on the
disk. The kernel notices these file type s (as indicated in the inode) and calls
appropriatedriversto handle I/Ofor them.
Once the inode is found by, for instance, the open()system call, a file
structure is allocated to point to the inode. The file descriptor given to the
user refers to this file structure. FreeBSDhas adirectory name cache to hold"
3,C.7.4 Mapping a File Descriptor to an Inode,1152,C.7.3 Directories,"28 Appendix C BSD UNIX
user spaceread (4, … )
system space disk spacedata 
blocks
inode 
listin-core 
inode 
listtables of open 
files
(per process)file-structure
tablesync•
•
•
Figure C.8 File-system control blocks.
recentdirectory-to-inodetranslations,whichgreatlyincreasesfile-systemper-
formance.
C.7.4 Mapping a File Descriptor to an Inode
A system call that refers to an open file indicates the file by passing a file
descriptor as an argument. The file descriptor is used by the kernel to index
a table of open files for the current process. Each entry in the table contains
a pointer to a file structure. This file structure in turn points to the inode; see
FigureC.8.Theopenfiletablehasafixedlength,whichissettableonlyatboot
time.Therefore,thereis a fixedlimiton thenumber of concurrently openfiles
ina system.
Theread()andwrite() system calls do not take a position in the file
as an argument. Rather, the kernel keeps a fileoffset ,w h i c hi su p d a t e db ya n
appropriateamountaftereach read()orwrite() accordingtothenumberof
dataactually transferred.The offsetcan besetdirectlyby the lseek() system
call. If the file descriptor indexed an a rray of inode pointers instead of file
pointers,thisoffsetwouldhavetobekeptintheinode.Becausemorethanone
processmayopenthesamefile,andeachsuchprocessneedsitsownoffsetfor
thefile,keepingtheoffsetintheinodeis inappropriate.Thus,thefilestructure
is used to contain the offset. File structures are inherited by the child process
after a fork(), so several processes may share the same offset location for a
file.
Theinodestructure pointedtobythefilestructureisanin-corecopyofthe
inode on the disk.The in-core inode has a few extra fields,such as a reference
countofhowmanyfilestructuresarepointingatit,andthefilestructurehasa
similarreferencecountforhowmanyfiledescriptorsrefertoit.Whenacount
becomeszero,theentryisnolongerneededandmaybereclaimedandreused.
C.7.5 Disk Structures
Thefilesystemthattheuserseesissupportedbydataonamassstoragedevice
—usually, a disk. The user ordinarily knows of only one file system, but this
one logical file system may actually consist of several physicalfile systems,
each on a different device. Because device characteristics differ, each separate"
3,C.7.5 Disk Structures,1152,C.7.4 Mapping a File Descriptor to an Inode,"28 Appendix C BSD UNIX
user spaceread (4, … )
system space disk spacedata 
blocks
inode 
listin-core 
inode 
listtables of open 
files
(per process)file-structure
tablesync•
•
•
Figure C.8 File-system control blocks.
recentdirectory-to-inodetranslations,whichgreatlyincreasesfile-systemper-
formance.
C.7.4 Mapping a File Descriptor to an Inode
A system call that refers to an open file indicates the file by passing a file
descriptor as an argument. The file descriptor is used by the kernel to index
a table of open files for the current process. Each entry in the table contains
a pointer to a file structure. This file structure in turn points to the inode; see
FigureC.8.Theopenfiletablehasafixedlength,whichissettableonlyatboot
time.Therefore,thereis a fixedlimiton thenumber of concurrently openfiles
ina system.
Theread()andwrite() system calls do not take a position in the file
as an argument. Rather, the kernel keeps a fileoffset ,w h i c hi su p d a t e db ya n
appropriateamountaftereach read()orwrite() accordingtothenumberof
dataactually transferred.The offsetcan besetdirectlyby the lseek() system
call. If the file descriptor indexed an a rray of inode pointers instead of file
pointers,thisoffsetwouldhavetobekeptintheinode.Becausemorethanone
processmayopenthesamefile,andeachsuchprocessneedsitsownoffsetfor
thefile,keepingtheoffsetintheinodeis inappropriate.Thus,thefilestructure
is used to contain the offset. File structures are inherited by the child process
after a fork(), so several processes may share the same offset location for a
file.
Theinodestructure pointedtobythefilestructureisanin-corecopyofthe
inode on the disk.The in-core inode has a few extra fields,such as a reference
countofhowmanyfilestructuresarepointingatit,andthefilestructurehasa
similarreferencecountforhowmanyfiledescriptorsrefertoit.Whenacount
becomeszero,theentryisnolongerneededandmaybereclaimedandreused.
C.7.5 Disk Structures
Thefilesystemthattheuserseesissupportedbydataonamassstoragedevice
—usually, a disk. The user ordinarily knows of only one file system, but this
one logical file system may actually consist of several physicalfile systems,
each on a different device. Because device characteristics differ, each separate"
3,C.7.6 Implementations,1154,C.7.5 Disk Structures,"30 Appendix C BSD UNIX
rootfilesystem ,isalwaysavailable.Otherfilesystemsmaybe mounted —that
is,integratedinto thedirectoryhierarchy of the rootfilesystem.
A bit in the inode structure indicates that the inode has a file system
mounted on it. A reference to this file causes the mount table to be searched
to find the device number of the mounted device. The device number is used
to find the inode of the root directory of the mounted file system, and that
inodeisused.Conversely,ifapath-nameelementis “..”andthedirectorybeing
searchedistherootdirectoryofafilesystemthatismounted,themounttable
issearched to find the inode itis mounted on, and that inode is used.
Each file systemis a separate system resourceand representsa set of files.
The first sector on the logical device is the boot block , possibly containing a
primary bootstrap program, which may be used to call a secondary bootstrap
program residing in the next 7.5 KB. A system needs only one partition con-
taining boot-block data, but the system manager may install duplicates via
privileged programs, to allow booting when the primary copy is damaged.
Thesuperblock containsstaticparametersofthefilesystem.Theseparameters
includethetotalsizeofthefilesystem,t heblockandfragmentsizesofthedata
blocks, and assortedparametersthat affect allocationpolicies.
C.7.6 Implementations
The user interface to the file system is simple and well defined, allowing the
implementationofthefilesystemitselfto bechangedwithoutsignificanteffect
on the user. The file system was changed between Version 6 and Version 7 of
3BSD, and again between Version 7 and 4BSD. For Version 7, the size of inodes
doubled, the maximum file and file-system sizes increased, and the details
of free-list handling and superblock information changed. At that time also,
seek()(with a 16-bit offset) became lseek() (with a 32-bit offset), to allow
specificationofoffsetsinlargerfiles,butfewotherchangeswerevisibleoutside
thekernel.
In4.0BSD,thesizeof blocks usedinthefile systemwas increasedfrom512
bytes to 1,024 bytes. Although this incr eased size produced increased internal
fragmentation on the disk, it doubled throughput, due mainly to the greater
number ofdataaccessedoneachdisktransfer.Thisideawaslateradoptedby
SystemV,along witha number of otherideas,devicedrivers,and programs.
4.2BSDadded the Berkeley Fast File System, which increased speed and
was accompanied by new features. Symbolic links required new system calls.
Long file names necessitated new directory system calls to traverse the now-
complex internal directory structure. Finally, truncate() calls were added.
TheFastFileSystemwasasuccessandisnowfoundinmostimplementations
ofUNIX.Itsperformanceismadepossiblebyitslayoutandallocationpolicies,
whichwediscussnext.InSection14.4.4,wediscussedchangesmadeinSun OS
to increasediskthroughput further.
C.7.7 Layout and Allocation Policies
Thekernelusesa <logicaldevicenumber,inodenumber >pairtoidentifyafile.
The logical device number defines the file system involved. The inodes in the
file system are numbered in sequence. In the Version 7 file system, all inodes
are in an array immediately following a single superblock at the beginning of"
3,C.7.7 Layout and Allocation Policies,1154,C.7.6 Implementations,"30 Appendix C BSD UNIX
rootfilesystem ,isalwaysavailable.Otherfilesystemsmaybe mounted —that
is,integratedinto thedirectoryhierarchy of the rootfilesystem.
A bit in the inode structure indicates that the inode has a file system
mounted on it. A reference to this file causes the mount table to be searched
to find the device number of the mounted device. The device number is used
to find the inode of the root directory of the mounted file system, and that
inodeisused.Conversely,ifapath-nameelementis “..”andthedirectorybeing
searchedistherootdirectoryofafilesystemthatismounted,themounttable
issearched to find the inode itis mounted on, and that inode is used.
Each file systemis a separate system resourceand representsa set of files.
The first sector on the logical device is the boot block , possibly containing a
primary bootstrap program, which may be used to call a secondary bootstrap
program residing in the next 7.5 KB. A system needs only one partition con-
taining boot-block data, but the system manager may install duplicates via
privileged programs, to allow booting when the primary copy is damaged.
Thesuperblock containsstaticparametersofthefilesystem.Theseparameters
includethetotalsizeofthefilesystem,t heblockandfragmentsizesofthedata
blocks, and assortedparametersthat affect allocationpolicies.
C.7.6 Implementations
The user interface to the file system is simple and well defined, allowing the
implementationofthefilesystemitselfto bechangedwithoutsignificanteffect
on the user. The file system was changed between Version 6 and Version 7 of
3BSD, and again between Version 7 and 4BSD. For Version 7, the size of inodes
doubled, the maximum file and file-system sizes increased, and the details
of free-list handling and superblock information changed. At that time also,
seek()(with a 16-bit offset) became lseek() (with a 32-bit offset), to allow
specificationofoffsetsinlargerfiles,butfewotherchangeswerevisibleoutside
thekernel.
In4.0BSD,thesizeof blocks usedinthefile systemwas increasedfrom512
bytes to 1,024 bytes. Although this incr eased size produced increased internal
fragmentation on the disk, it doubled throughput, due mainly to the greater
number ofdataaccessedoneachdisktransfer.Thisideawaslateradoptedby
SystemV,along witha number of otherideas,devicedrivers,and programs.
4.2BSDadded the Berkeley Fast File System, which increased speed and
was accompanied by new features. Symbolic links required new system calls.
Long file names necessitated new directory system calls to traverse the now-
complex internal directory structure. Finally, truncate() calls were added.
TheFastFileSystemwasasuccessandisnowfoundinmostimplementations
ofUNIX.Itsperformanceismadepossiblebyitslayoutandallocationpolicies,
whichwediscussnext.InSection14.4.4,wediscussedchangesmadeinSun OS
to increasediskthroughput further.
C.7.7 Layout and Allocation Policies
Thekernelusesa <logicaldevicenumber,inodenumber >pairtoidentifyafile.
The logical device number defines the file system involved. The inodes in the
file system are numbered in sequence. In the Version 7 file system, all inodes
are in an array immediately following a single superblock at the beginning of"
2,C.8 I/O System,1157,C.7 File System,"C.8 I/O System 33
C.8 I/O System
One of the purposes of an operating system is to hide the peculiarities of
specifichardwaredevicesfromtheuser.Forexample,thefilesystempresentsa
simple,consistentstoragefacility(thefile)independentoftheunderlyingdisk
hardware. In UNIX, the peculiarities of I/Odevices are also hidden from the
bulk of the kernel itself by the I/Osystem.T h eI/Osystem consists of a buffer
caching system, general device-driverco de, and driversfor specific hardware
devices.Onlythedevicedriverknowsthepeculiaritiesofaspecificdevice.The
majorpartsof the I/OsystemarediagrammedinFigureC.11.
There are three main kinds of I/OinFreeBSD: block devices, character
devices, and the socket interface. The socket interface, together with its pro-
tocolsand network interfaces,willbedescribedinSectionC.9.1.
Block devices include disks and tapes. Their distinguishing characteristic
is that they are directly addressable in a fixed block size—usually 512 bytes.
Ablock-device driver is required to isolate details of tracks, cylinders, and so
on from the rest of the kernel. Block devices are accessible directly through
appropriatedevicespecialfiles(suchas /dev/rp0),buttheyaremorecommonly
accessedindirectlythroughthefilesystem.Ineithercase,transfersarebuffered
through the blockbuffercache , which has a profound effecton efficiency.
Character devices include terminals and line printers but also include
almost everything else(except network interfaces) that does not use the block
buffer cache. For instance, /dev/mem is an interface to physical main memory,
and /dev/null is a bottomless sink for data and an endless source of end-of-file
markers.Somedevices,suchashigh-speedgraphicsinterfaces,mayhavetheir
own buffers or may always do I/Odirectlyinto the user’s data space;because
they do not use the block buffer cache, they are classed as character devices.
Terminalsandterminal-likedevicesuse C-lists,whicharebufferssmallerthan
those of the block buffercache.
Blockdevicesandcharacterdevicesarethetwomaindeviceclasses.Device
drivers are accessed by one of two arrays of entry points. One array is for
block devices; the other is for character devices. Adevice is distinguished by
a class (block or character) and a device number . The device number consists
oftwo parts.The majordevicenumber isusedtoindexthearray forcharacter
or block devices to find entries into the appropriate device driver. The minor
the hardwaresystem-call interface to the kernel
socket
protocols
network 
interfaceplain file
file 
system
block-device drivercooked 
block 
interfaceraw tty 
interfacecooked TTY
line 
discipline
character-device driverraw 
block 
interface
Figure C.11 4.3 BSD kernel I/O structure."
3,C.8.1 Block Buffer Cache,1158,C.8 I/O System,"34 Appendix C BSD UNIX
devicenumber isinterpretedbythedevicedriveras,forexample,alogicaldisk
partitionor a terminalline.
Adevicedriverisconnectedtotherestofthekernelonlybytheentrypoints
recordedinthearrayforitsclassandbyitsuseofcommonbufferingsystems.
This segregationisimportant for portabilityand for systemconfiguration.
C.8.1 Block Buffer Cache
The block devices, as mentioned, use a block buffer cache. The buffer cache
consists of a number of buffer headers, each of which can point to a piece of
physical memory as well as to a device number and a block number on the
device. The buffer headers for blocks not currently in use are kept in several
linkedlists,one foreach ofthe following:
•Buffersrecentlyused,linkedin LRUorder(the LRUlist)
•Buffersnot recentlyusedor without validcontents (the AGElist)
•EMPTYbufferswithno physicalmemoryassociatedwiththem
Thebuffersintheselistsarealsohashedbydeviceandblocknumberforsearch
efficiency.
Whenablockiswantedfromadevice(aread),thecacheissearched.Ifthe
block is found, it is used, and no I/Otransfer is necessary. If it is not found,
a buffer is chosen from the AGElist or, if that list is empty, the LRUlist. Then
thedevicenumberandblocknumberassociatedwithitareupdated,memory
is found for it if necessary, and the new data are transferred into it from the
device. If there are no empty buffers, the LRUbuffer is written to its device (if
itismodified),andthe bufferis reused.
On a write, if the block in question is already in the buffer cache, the new
dataareputinthebuffer(overwritinganypreviousdata),thebufferheaderis
markedtoindicatethatthebufferhasbeenmodified,andno I/Oisimmediately
necessary.Thedatawillbewrittenwhenthebufferisneededforotherdata.If
the block is not found in the buffer cache, an empty buffer is chosen (as with
a read), and a transfer is done to this buffer. Writes are periodically forced
for dirty buffer blocks to minimize potential file-system inconsistencies after
ac r a s h .
The number of data in a buffer in FreeBSDis variable, up to a maximum
overallfilesystems,usually8 KB.Theminimumsizeisthepaging-clustersize,
usually1,024bytes.Buffersarepage-clusteraligned,andanypageclustermay
bemappedintoonlyonebufferatatime,justasanydiskblockmaybemapped
into only one buffer at a time. The EMPTYlist holds buffer headers, which are
usedifaphysicalmemoryblockof8 KBissplittoholdmultiple,smallerblocks.
Headersareneededfor theseblocks andareretrievedfrom EMPTY.
The number of data in a buffer may grow as a user process writes more
data following those already in the buf fer. When this increase occurs, a new
buffer large enough to hold all the data is allocated, and the original data are
copied into it, followed by the new data. If a buffer shrinks, a buffer is taken"
3,C.8.2 Raw Device Interfaces,1159,C.8.1 Block Buffer Cache,"C.8 I/O System 35
offtheemptyqueue,excesspagesareputinit,andthatbufferisreleasedtobe
writtentodisk.
Some devices, such as magnetic tapes, require that blocks be written in a
certain order. Facilities are therefore provided to force a synchronous write of
buffers to these devices in the correct order. Directory blocks are also written
synchronously,toforestallcrashinconsistencies.Considerthechaosthatcould
occur if many changes were made to a directory but the directory entries
themselveswerenot updated!
Thesizeofthebuffercachecanhaveaprofoundeffectontheperformance
of a system, because, if it is large enough, the percentage of cache hits can be
high and the number of actual I/Otransfers low. FreeBSDoptimizes the buffer
cache by continually adjusting the amount of memory used by programs and
thediskcache.
Someinterestinginteractionsoccuramongthebuffercache,thefilesystem,
and the disk drivers. When data are written to a disk file, they are buffered in
thecache,andthediskdriversortsitsoutputqueueaccordingtodiskaddress.
These two actions allow the disk driver to minimize disk head seeks and to
write data at times optimized for disk rotation. Unless synchronous writes
are required, a process writing to disk simply writes into the buffer cache,
and the system asynchronously writes the data to disk when convenient. The
user process sees very fast writes. When data are read from a disk file, the
blockI/Osystem does some read-ahead; however, writes are much nearer to
asynchronous than are reads.Thus, output to the disk through the file system
isoftenfasterthan isinput forlargetransfers,counter to intuition.
C.8.2 Raw Device Interfaces
Almost every block device also has a character interface, and these are called
rawdeviceinterfaces .Suchaninterfacediffersfromthe blockinterface inthat
theblock buffer cache is bypassed.
Each disk driver maintains a queue of pending transfers. Each record in
the queue specifies whether it is a read or a write and gives a main memory
address for the transfer (usually in 512-byte increments), a device address for
thetransfer(usuallytheaddressofadisksector),andatransfersize(insectors).
It is simpleto map the information from a block buffer to what is requiredfor
thisqueue.
It is almost as simple to map a piece of main memory corresponding to
partofauserprocess’svirtualaddressspace.Thismappingiswhatarawdisk
interface, for instance, does. Unbuffered transfers directly to or from a user’s
virtualaddressspacearethusallowed.Thesizeofthetransferislimitedbythe
physicaldevices,someof which requirean evennumber of bytes.
The kernel accomplishes transfers for swapping and paging simply by
putting the appropriate request on the queue for the appropriate device. No
specialswapping or paging devicedriverisneeded.
The4.2BSDfile-system implementation was actually written and largely
tested as a user process that used a raw disk interface, before the code was
movedintothekernel.Inaninterestingabout-face,theMachoperatingsystem"
3,C.8.3 C-Lists,1160,C.8.2 Raw Device Interfaces,"36 Appendix C BSD UNIX
has no file system per se. File systems can be implemented as user-level tasks
(seeAppendixD).
C.8.3 C-Lists
As mentioned, terminals and terminal-like devices use a character-buffering
system that keeps small blocks of characters (usually 28 bytes) in linked lists
called C-lists. Although all free character buffers are kept in a single free list,
most device drivers that use them limit the number of characters that may be
queuedat onetimefor any giventerminalline.
There are routines to enqueue and dequeue characters for such lists. A
write() systemcall toa terminalenqueuescharacters on a listfor the device.
Aninitialtransferisstarted,andinterr uptscausedequeuingofcharactersand
furthertransfers.
Input is similarly interrupt driven. Terminal drivers typically support two
inputqueues,however,andconversionfromthefirst(rawqueue)totheother
(canonical queue) is triggered when the interrupt routine puts an end-of-line
character on the raw queue. The process doing a read on the device is then
awakened, and its system phase does the conversion. The characters thus put
onthecanonicalqueuearethenavailabletobereturnedtotheuserprocessby
theread.
The device driver can bypass the canonical queue and return characters
directly from the raw queue. This mode of operation is known as raw mode .
Full-screen editors, as well as other programs that need to react to every
keystroke,usethismode.
C.9 Interprocess Communication
Although many tasks can be accomplished in isolatedprocesses,many others
require interprocess communication. Isolated computing systems have long
served for many applications, but networking is increasingly important. Fur-
thermore, with the increasing use of personal workstations, resource sharing
is becoming more common. Interprocess communication has not traditionally
beenoneof UNIX’s strongpoints.
C.9.1 Sockets
The pipe (discussed in Section C.4.3) is the IPCmechanism most characteris-
tic ofUNIX. Apipe permits a reliable unidirectional byte stream between two
processes.Itistraditionallyimplementedasanordinaryfile,withafewexcep-
tions. It has no name in the file system, being created instead by the pipe()
system call. Its size is fixed, and when a process attempts to write to a full
pipe, the process is suspended. Once all data previously written into the pipe
havebeenreadout,writingcontinuesatthebeginningofthefile(pipesarenot
truecircularbuffers).Onebenefitofth esmallsizeofpipes(usually4,096bytes)
is that pipe data are seldom actually written to disk; they usually are kept in
memoryby thenormal block buffercache.
InFreeBSDpipes are implemented as a special case of the socketmecha-
nism. The socket mechanism provides a ge neral interface not only to facilities
suchaspipes,whicharelocaltoonemachine,butalsotonetworkingfacilities."
2,C.9 Interprocess Communication,1160,C.8 I/O System,"36 Appendix C BSD UNIX
has no file system per se. File systems can be implemented as user-level tasks
(seeAppendixD).
C.8.3 C-Lists
As mentioned, terminals and terminal-like devices use a character-buffering
system that keeps small blocks of characters (usually 28 bytes) in linked lists
called C-lists. Although all free character buffers are kept in a single free list,
most device drivers that use them limit the number of characters that may be
queuedat onetimefor any giventerminalline.
There are routines to enqueue and dequeue characters for such lists. A
write() systemcall toa terminalenqueuescharacters on a listfor the device.
Aninitialtransferisstarted,andinterr uptscausedequeuingofcharactersand
furthertransfers.
Input is similarly interrupt driven. Terminal drivers typically support two
inputqueues,however,andconversionfromthefirst(rawqueue)totheother
(canonical queue) is triggered when the interrupt routine puts an end-of-line
character on the raw queue. The process doing a read on the device is then
awakened, and its system phase does the conversion. The characters thus put
onthecanonicalqueuearethenavailabletobereturnedtotheuserprocessby
theread.
The device driver can bypass the canonical queue and return characters
directly from the raw queue. This mode of operation is known as raw mode .
Full-screen editors, as well as other programs that need to react to every
keystroke,usethismode.
C.9 Interprocess Communication
Although many tasks can be accomplished in isolatedprocesses,many others
require interprocess communication. Isolated computing systems have long
served for many applications, but networking is increasingly important. Fur-
thermore, with the increasing use of personal workstations, resource sharing
is becoming more common. Interprocess communication has not traditionally
beenoneof UNIX’s strongpoints.
C.9.1 Sockets
The pipe (discussed in Section C.4.3) is the IPCmechanism most characteris-
tic ofUNIX. Apipe permits a reliable unidirectional byte stream between two
processes.Itistraditionallyimplementedasanordinaryfile,withafewexcep-
tions. It has no name in the file system, being created instead by the pipe()
system call. Its size is fixed, and when a process attempts to write to a full
pipe, the process is suspended. Once all data previously written into the pipe
havebeenreadout,writingcontinuesatthebeginningofthefile(pipesarenot
truecircularbuffers).Onebenefitofth esmallsizeofpipes(usually4,096bytes)
is that pipe data are seldom actually written to disk; they usually are kept in
memoryby thenormal block buffercache.
InFreeBSDpipes are implemented as a special case of the socketmecha-
nism. The socket mechanism provides a ge neral interface not only to facilities
suchaspipes,whicharelocaltoonemachine,butalsotonetworkingfacilities."
3,C.9.1 Sockets,1160,C.9 Interprocess Communication,"36 Appendix C BSD UNIX
has no file system per se. File systems can be implemented as user-level tasks
(seeAppendixD).
C.8.3 C-Lists
As mentioned, terminals and terminal-like devices use a character-buffering
system that keeps small blocks of characters (usually 28 bytes) in linked lists
called C-lists. Although all free character buffers are kept in a single free list,
most device drivers that use them limit the number of characters that may be
queuedat onetimefor any giventerminalline.
There are routines to enqueue and dequeue characters for such lists. A
write() systemcall toa terminalenqueuescharacters on a listfor the device.
Aninitialtransferisstarted,andinterr uptscausedequeuingofcharactersand
furthertransfers.
Input is similarly interrupt driven. Terminal drivers typically support two
inputqueues,however,andconversionfromthefirst(rawqueue)totheother
(canonical queue) is triggered when the interrupt routine puts an end-of-line
character on the raw queue. The process doing a read on the device is then
awakened, and its system phase does the conversion. The characters thus put
onthecanonicalqueuearethenavailabletobereturnedtotheuserprocessby
theread.
The device driver can bypass the canonical queue and return characters
directly from the raw queue. This mode of operation is known as raw mode .
Full-screen editors, as well as other programs that need to react to every
keystroke,usethismode.
C.9 Interprocess Communication
Although many tasks can be accomplished in isolatedprocesses,many others
require interprocess communication. Isolated computing systems have long
served for many applications, but networking is increasingly important. Fur-
thermore, with the increasing use of personal workstations, resource sharing
is becoming more common. Interprocess communication has not traditionally
beenoneof UNIX’s strongpoints.
C.9.1 Sockets
The pipe (discussed in Section C.4.3) is the IPCmechanism most characteris-
tic ofUNIX. Apipe permits a reliable unidirectional byte stream between two
processes.Itistraditionallyimplementedasanordinaryfile,withafewexcep-
tions. It has no name in the file system, being created instead by the pipe()
system call. Its size is fixed, and when a process attempts to write to a full
pipe, the process is suspended. Once all data previously written into the pipe
havebeenreadout,writingcontinuesatthebeginningofthefile(pipesarenot
truecircularbuffers).Onebenefitofth esmallsizeofpipes(usually4,096bytes)
is that pipe data are seldom actually written to disk; they usually are kept in
memoryby thenormal block buffercache.
InFreeBSDpipes are implemented as a special case of the socketmecha-
nism. The socket mechanism provides a ge neral interface not only to facilities
suchaspipes,whicharelocaltoonemachine,butalsotonetworkingfacilities."
3,C.9.2 Network Support,1163,C.9.1 Sockets,"C.9 Interprocess Communication 39
a process for each connection as the connection is made. The server does a
socket() ,bind(),a n d listen() for each service and then does a select()
onallthesocketdescriptors.When select() indicatesactivityonadescriptor,
the server does an accept() on it and forks a process on the new descriptor
returned by accept() ,leavingtheparentprocessto doa select() again.
C.9.2 Network Support
Almost all current UNIXsystems support the UUCPnetwork facilities, which
aremostlyusedoverdial-uptelephonelinestosupportthe UUCPmailnetwork
and the USENETnews network. These are, however, rudimentary networking
facilities; they do not support even re mote login, much less remote proce-
dure calls or distributed file systems. These facilities are almost completely
implementedasuserprocessesand arenot partof theoperatingsystemitself.
FreeBSDsupportsthe DARPAInternetprotocols UDP,TCP,IP,andICMPona
widerangeofEthernet,token-ring,and ARPANET interfaces.Theframeworkin
the kernel to support these protocols is intended to facilitate the implementa-
tionoffurtherprotocols,andallprotocolsareaccessibleviathesocketinterface.
Rob Gurwitz of BBNwrote the first version of the code as an add-on package
for4.1BSD.
The International Standards Organization’s ( ISO) Open System Intercon-
nection ( OSI) Reference Model for networking prescribes seven layers of net-
workprotocolsandstrictmethodsofcommunicationbetweenthem.Animple-
mentationofaprotocolmaycommunicateonlywithapeerentityspeakingthe
same protocol at the same layer or with the protocol–protocol interface of a
protocol inthelayer immediatelyabove or belowinthe same system.The ISO
networking modelisimplementedin FreeBSDReno and 4.4BSD.
TheFreeBSDnetworkingimplementation,andtoacertainextentthesocket
facility, is more oriented toward the ARPANET Reference Model ( ARM). The
ARPANET in its original form served as a proof of concept for many network-
ing ideas, such as packet switching and protocol layering. The ARPANET was
retired in 1988 because the hardware that supported it was no longer state of
the art. Its successors, such as the NSFNET and the Internet, are even larger
andserveascommunicationsutilitiesforresearchersandtest-bedsforInternet
gatewayresearch.The ARMpredatesthe ISOmodel;the ISOmodelwasinlarge
partinspiredby the ARPANET research.
Although the ISOmodel is often interpreted as setting a limit of one pro-
tocol communicating per layer, the ARMallows several protocols in the same
layer.Thereareonly four protocollayersinthe ARM:
•Process/applications. This layer subsumes the application, presentation,
and session layers of the ISOmodel. Such user-level programs as the file-
transfer protocol( FTP) and Telnet(remotelogin) existat thislevel.
•Host–host. This layer corresponds to ISO’s transport and the top part
of its network layers. Both the Transmission Control Protocol ( TCP)a n d
the Internet Protocol ( IP) are in this layer, with TCPon top of IP.TCP
corresponds to an ISOtransport protocol, and IPperforms the addressing
functions of the ISOnetwork layer.
•Network interface. Thislayerspansthelowerpartofthe ISOnetworklayer
and the entire data-link layer. The protocols involved here depend on the"
2,C.10 Summary,1165,C.9 Interprocess Communication,"C.10 Summary 41
support reliable transmission at this level, but most do not. Some networks
providebroadcast addressing,but many donot.
The socket facility and the networking framework use a common set of
memory buffers, or mbufs. These are intermediate in size between the large
buffersusedbytheblock I/OsystemandtheC-listsusedbycharacterdevices.
Anmbufis128byteslong;112bytesmaybeusedfordata,andtherestisused
forpointerstolinkthe mbufintoqueuesandforindicatorsofhowmuchofthe
dataareaisactually inuse.
Data are ordinarily passed between layers—socket–protocol, protocol–
protocol, or protocol–network interface—in mbufs. The ability to pass the
buffers containing the data eliminat es some data copying, but there is still
frequentlyaneedtoremoveoraddprotocolheaders.Itisalsoconvenientand
efficientformanypurposestobeabletoholddatathatoccupyanareathesize
ofthememory-managementpage.Thus,thedataofan mbufmayresidenotin
thembufitself but elsewhere in memory. There is an mbufpage table for this
purpose,as wellasa pool ofpagesdedicatedto mbufuse.
C.10 Summary
The early advantages of UNIXwere that it was written in a high-level lan-
guage, was distributed in source form, and provided powerful operating-
systemprimitivesonaninexpensiveplatform.Theseadvantagesledto UNIX’s
popularity at educational, research, and government institutions and eventu-
ally in the commercial world. This popularity produced many strains of UNIX
withvaryingand improvedfacilities.
UNIXprovides a file system with tree-structured directories. The kernel
supportsfilesasunstructuredsequencesofbytes.Directaccessandsequential
access aresupportedthroughsystemcallsand libraryroutines.
Filesarestoredasanarrayoffixed-sizedatablockswithperhapsatrailing
fragment.Thedatablocksarefoundbypointersintheinode.Directoryentries
pointtoinodes.Diskspaceisallocatedf romcylindergroupstominimizehead
movementand toimproveperformance.
UNIXis a multiprogrammed system. Processes can easily create new pro-
cesseswiththe fork()systemcall. Processescan communicate with pipesor,
moregenerally,sockets.Theymaybegroupedintojobsthatmaybecontrolled
withsignals.
Processes are represented by two structures: the process structure and
the user structure. CPUscheduling is a priority algorithm with dynamically
computed priorities that reduces to round-robin scheduling in the extreme
case.
FreeBSDmemory management uses swapping supported by paging. A
pagedaemon process uses a modified second-chance page-replacement algo-
rithmto keepenoughfreeframestosupportthe executingprocesses.
Pageandfile I/Ousesablockbuffercachetominimizetheamountofactual
I/O.Terminaldevicesusea separatecharacter-buffering system.
Networking support is one of the most important features in FreeBSD.
The socket concept provides the pro gramming mechanism to access other
processes, even across a network. Sockets provide an interface to several sets
ofprotocols."
2,Further Reading,1166,C.10 Summary,"42 Appendix C BSD UNIX
Further Reading
[McKusick et al. (2015)] provides a good general discussion of FreeBSD.A
modern scheduler for FreeBSDis described in [Roberson (2003)]. Locking in
theMultithreaded FreeBSDKernelisdescribedin[Baldwin(2002)].
FreeBSDis described in The FreeBSD Handbook , which can be downloaded
from http://www.freebsd.org .
Bibliography
[Baldwin (2002)] J. Baldwin, “Locking in the Multithreaded FreeBSD Kernel ”,
USENIX BSD (2002).
[McKusick et al. (2015)] M.K.McKusick, G. V.Neville-Neil, and R.N. M.Wat-
son, The Design and Implementation of the FreeBSD UNIX Operating System–Second
Edition, Pearson(2015).
[Roberson (2003)] J. Roberson, “ULE: A Modern Scheduler For FreeBSD ”,Pro-
ceedings of the USENIX BSDCon Conference (2003), pages 17–28."
2,Bibliography,1166,Further Reading,"42 Appendix C BSD UNIX
Further Reading
[McKusick et al. (2015)] provides a good general discussion of FreeBSD.A
modern scheduler for FreeBSDis described in [Roberson (2003)]. Locking in
theMultithreaded FreeBSDKernelisdescribedin[Baldwin(2002)].
FreeBSDis described in The FreeBSD Handbook , which can be downloaded
from http://www.freebsd.org .
Bibliography
[Baldwin (2002)] J. Baldwin, “Locking in the Multithreaded FreeBSD Kernel ”,
USENIX BSD (2002).
[McKusick et al. (2015)] M.K.McKusick, G. V.Neville-Neil, and R.N. M.Wat-
son, The Design and Implementation of the FreeBSD UNIX Operating System–Second
Edition, Pearson(2015).
[Roberson (2003)] J. Roberson, “ULE: A Modern Scheduler For FreeBSD ”,Pro-
ceedings of the USENIX BSDCon Conference (2003), pages 17–28."
1,Appendix D The Mach System,1167,Appendix C BSD UNIX,"DAppendix The
Mach
System
This chapter was firs written in 1991 and has been updated over time but is
no longer modified
In this appendix we examine the Mach operating system. Mach is designed
to incorporate the many recent innovations in operating-system research to
produce a fully functional, technically advanced system. Unlike UNIX,w h i c h
was developed without regard for multiprocessing, Mach incorporates mul-
tiprocessing support throughout. This s upport is exceedingly flexible, accom-
modatingshared-memorysystemsaswellassystemswithnomemoryshared
between processors. Mach is designed to run on computer systems ranging
fromoneprocessortothousandsofprocessors.Inaddition,itiseasilyportedto
manyvariedcomputerarchitectures.AkeygoalofMachistobeadistributed
systemcapable of functioning onheterogeneoushardware.
Althoughmanyexperimentaloperatingsystemsarebeingdesigned,built,
andused,Machsatisfiestheneedsofmos tusersbetterthantheothersbecause
it offers full compatibility with UNIX 4.3 BSD . This compatibility also gives
us a unique opportunity to compare two functionally similar, but internally
dissimilar,operatingsystems.Machand UNIXdifferintheiremphases,so our
Mach discussion does not exactly parallel our UNIXdiscussion. In addition,
we do not include a section on the user interface, because that component is
similartotheuserinterfacein 4.3 BSD.Asyouwillsee,Machprovidestheability
tolayeremulationofotheroperatingsystemsaswell;otheroperatingsystems
canevenrunconcurrently withMach.
D.1 History of the Mach System
MachtracesitsancestrytotheAccentoperatingsystemdevelopedatCarnegie
Mellon University ( CMU). Although Accent pioneered a number of novel
operating-system concepts, its utility was limited by its inability to execute
UNIXapplications and its strong ties to a single hardware architecture, which
made it difficult to port. Mach’s communication system and philosophy
are derived from Accent, but many other significant portions of the system
(for example, the virtual memory system and the management of tasks and
threads) were developed from scratch. An important goal of the Mach effort
was supportformultiprocessors.
1"
2,D.1 History of the Mach System,1167,Appendix D The Mach System,"DAppendix The
Mach
System
This chapter was firs written in 1991 and has been updated over time but is
no longer modified
In this appendix we examine the Mach operating system. Mach is designed
to incorporate the many recent innovations in operating-system research to
produce a fully functional, technically advanced system. Unlike UNIX,w h i c h
was developed without regard for multiprocessing, Mach incorporates mul-
tiprocessing support throughout. This s upport is exceedingly flexible, accom-
modatingshared-memorysystemsaswellassystemswithnomemoryshared
between processors. Mach is designed to run on computer systems ranging
fromoneprocessortothousandsofprocessors.Inaddition,itiseasilyportedto
manyvariedcomputerarchitectures.AkeygoalofMachistobeadistributed
systemcapable of functioning onheterogeneoushardware.
Althoughmanyexperimentaloperatingsystemsarebeingdesigned,built,
andused,Machsatisfiestheneedsofmos tusersbetterthantheothersbecause
it offers full compatibility with UNIX 4.3 BSD . This compatibility also gives
us a unique opportunity to compare two functionally similar, but internally
dissimilar,operatingsystems.Machand UNIXdifferintheiremphases,so our
Mach discussion does not exactly parallel our UNIXdiscussion. In addition,
we do not include a section on the user interface, because that component is
similartotheuserinterfacein 4.3 BSD.Asyouwillsee,Machprovidestheability
tolayeremulationofotheroperatingsystemsaswell;otheroperatingsystems
canevenrunconcurrently withMach.
D.1 History of the Mach System
MachtracesitsancestrytotheAccentoperatingsystemdevelopedatCarnegie
Mellon University ( CMU). Although Accent pioneered a number of novel
operating-system concepts, its utility was limited by its inability to execute
UNIXapplications and its strong ties to a single hardware architecture, which
made it difficult to port. Mach’s communication system and philosophy
are derived from Accent, but many other significant portions of the system
(for example, the virtual memory system and the management of tasks and
threads) were developed from scratch. An important goal of the Mach effort
was supportformultiprocessors.
1"
2,D.2 Design Principles,1169,D.1 History of the Mach System,"D.2 Design Principles 3
operating-system release, and research on Mach continues at CMU,OSF,a n d
elsewhere.
D.2 Design Principles
The Mach operating system was designed to provide basic mechanisms that
mostcurrentoperatingsystemslack.Thegoalistodesignanoperatingsystem
thatisBSD-compatible and,in addition,excelsinthe following areas:
•Supportfordiversearchitectures,includingmultiprocessorswithvarying
degrees of shared memory access: uniform memory access ( UMA), non-
uniformmemoryaccess( NUMA),andnoremotememoryaccess( NORMA)
•Ability to function with varying intercomputer network speeds, from
wide-areanetworkstohigh-speedlocal-areanetworksandtightlycoupled
multiprocessors
•Simplified kernel structure, with a small number of abstractions (in turn,
theseabstractionsaresufficientlygen eraltoallowotheroperatingsystems
to be implementedontopof Mach.)
•Distributed operation, providing network transparency to clients and an
object-orientedorganizationboth internallyand externally
•Integrated memory management and interprocess communication, to
provide efficient communication of large numbers of data as well as
communication-based memorymanagement
•Heterogeneoussystemsupport,tomakeMachwidelyavailableandinter-
operableamong computer systemsfrom multiplevendors
The designersof Mach havebeenheavilyinfluenced by BSD(and by UNIX
ingeneral),whose benefits include
•Asimple programmer interface, with a good set of primitives and a con-
sistentsetof interfacesto systemfacilities
•Easy portabilityto a wideclass of singleprocessors
•Anextensivelibraryof utilitiesandapplications
•The abilityto combine utilitieseasilyviapipes
Of course, the designers also wanted to redress what they saw as the
drawbacks of BSD:
•Akernelthathasbecometherepositoryofmanyredundantfeatures—and
that consequently isdifficultto manage andmodify
•Original design goals that made it difficult to provide support for
multiprocessors, distributed systems, and shared program libraries (for
instance, because the kernel was desi gned for single processors, it has no
provisionsfor locking codeor datathat otherprocessorsmight beusing.)"
2,D.3 System Components,1170,D.2 Design Principles,"4 Appendix D The Mach System
•Toomanyfundamentalabstractions,providingtoomanysimilar,compet-
ing meanswith which to accomplish the sametasks
ThedevelopmentofMachcontinuestobeahugeundertaking.Thebenefits
of such a system are equally large, however. The operating system runs on
many existing single-processor and multiprocessor architectures, and it can
be easily ported to future ones. It makes research easier, because computer
scientists can add featuresvia user-levelcode, insteadof having to write their
own tailor-made operating system. Areas of experimentation include operat-
ingsystems,databases,reliabledistributedsystems,multiprocessorlanguages,
security,anddistributedartificialinte lligence.Initscurrentversion,theMach
systemisusuallyasefficientasothermajorversionsof UNIXwhenperforming
similartasks.
D.3 System Components
To achieve the design goals of Mach, the developers reduced the operating-
system functionality to a small set of basic abstractions, out of which all other
functionalitycanbederived.TheMachapproachistoplaceaslittleaspossible
within the kernel but to make what is there powerful enough that all other
featurescanbe implementedatthe userlevel.
Mach’s design philosophy is to have a si mple, extensible kernel, concen-
tratingoncommunicationfacilities.Forinstance,allrequeststothekernel,and
alldatamovementamongprocesses,arehandledthroughonecommunication
mechanism. Mach is therefore able to provide system-wide protection to its
usersbyprotectingthecommunication mechanism.Optimizingthisonecom-
munication path can result in significant performance gains, and it is simpler
thantryingtooptimizeseveralpaths.Machisextensible,becausemanytradi-
tionally kernel-based functions can be implemented as user-level servers. For
instance, all pagers (including the default pager) can be implemented exter-
nally andcalledby thekernelfor theuser.
Mach is an example of an object-oriented system where the data and the
operations that manipulate that data are encapsulated into an abstract object.
Onlytheoperationsoftheobjectareabletoactontheentitiesdefinedinit.The
detailsofhowtheseoperationsareimplementedarehidden,asaretheinternal
data structures. Thus, a programmer can use an object only by invoking its
defined, exported operations. A programmer can change the internal opera-
tions without changing the interface de finition, so changes and optimizations
do not affect other aspects of system operation. The object-oriented approach
supported by Mach allows objects to reside anywhere in a network of Mach
systems, transparent to the user. The portmechanism, discussed later in this
section,makesall ofthis possible.
Mach’sprimitiveabstractionsaretheheartofthesystemandareasfollows:
•Ataskisanexecutionenvironmentthatprovidesthebasicunitofresource
allocation. It consists of a virtual address space and protected access to
systemresourcesviaports,and itmaycontain one or morethreads.
•Athreadisthebasicunitofexecutionandmustruninthecontextofatask
(which provides the address space). All threads within a task share the"
2,D.4 Process Management,1173,D.3 System Components,"D.4 Process Management 7
Inthesectionsthatfollow,wedetail theoperationofprocessmanagement,
IPC,andmemorymanagement.Then,wedi scussMach’schameleonlikeability
tosupportmultipleoperating-systeminterfaces.
D.4 Process Management
Ataskcanbethoughtofasatraditionalprocessthatdoesnothaveaninstruc-
tion pointer or a register set. A task contains a virtual address space, a set of
port rights, and accounting information. A task is a passive entity that does
nothing unless ithas one ormorethreadsexecutinginit.
D.4.1 Basic Structure
A task containing one thread is similar to a UNIXprocess. Just as a fork()
system call produces a new UNIXprocess, Mach creates a new task by using
fork(). The new task’s memory is a duplicate of the parent’s address space,
asdictatedbythe inheritance attributes oftheparent’smemory.Thenewtask
contains one thread,which is started at the same point as the creating fork()
callintheparent.Threadsand taskscan alsobe suspendedandresumed.
Threads are especially useful in server applications, which are common
inUNIX, since one task can have multiple threads to service multiple requests
to the task. Threads also allow efficient use of parallel computing resources.
Ratherthanhavingoneprocessoneachprocessor,withthecorrespondingper-
formance penalty and operating-system overhead, a task can have its threads
spread among parallel processors. Threads add efficiency to user-level pro-
grams as well. For instance, in UNIX, an entire process must wait when a
page fault occurs or when a system call is executed. In a task with multiple
threads, only the thread that causes the page fault or executes a system call
is delayed; all other threads continue executing. Because Mach has kernel-
supported threads (Chapter 4), the threads have some cost associated with
them.Theymusthavesupportingdatastructuresinthekernel,andmorecom-
plex kernel-scheduling algorithms must be provided. These algorithms and
threadstatesarediscussedinChapter4.
At theuserlevel,threadsmay beinone oftwo states:
•Running. The thread is either executing or waiting to be allocated a pro-
cessor.Athreadisconsideredtoberunningevenifitisblockedwithinthe
kernel(waiting for apagefault to besatisfied,for instance).
•Suspended. The thread is neither executing on a processor nor waiting
to be allocated a processor. Athread can resume its execution only if it is
returnedtothe running state.
These two states are also associated with a task. An operation on a task
affects all threads in a task, so suspending a task involves suspending all the
threads in it. Task and thread suspensions are separate, independent mecha-
nisms, however, so resuming a thread in a suspended task does not resume
thetask.
Machprovidesprimitivesfromwhichthread-synchronizationtoolscanbe
built. This practice is consistent with Mach’s philosophy of providing mini-"
3,D.4.1 Basic Structure,1173,D.4 Process Management,"D.4 Process Management 7
Inthesectionsthatfollow,wedetail theoperationofprocessmanagement,
IPC,andmemorymanagement.Then,wedi scussMach’schameleonlikeability
tosupportmultipleoperating-systeminterfaces.
D.4 Process Management
Ataskcanbethoughtofasatraditionalprocessthatdoesnothaveaninstruc-
tion pointer or a register set. A task contains a virtual address space, a set of
port rights, and accounting information. A task is a passive entity that does
nothing unless ithas one ormorethreadsexecutinginit.
D.4.1 Basic Structure
A task containing one thread is similar to a UNIXprocess. Just as a fork()
system call produces a new UNIXprocess, Mach creates a new task by using
fork(). The new task’s memory is a duplicate of the parent’s address space,
asdictatedbythe inheritance attributes oftheparent’smemory.Thenewtask
contains one thread,which is started at the same point as the creating fork()
callintheparent.Threadsand taskscan alsobe suspendedandresumed.
Threads are especially useful in server applications, which are common
inUNIX, since one task can have multiple threads to service multiple requests
to the task. Threads also allow efficient use of parallel computing resources.
Ratherthanhavingoneprocessoneachprocessor,withthecorrespondingper-
formance penalty and operating-system overhead, a task can have its threads
spread among parallel processors. Threads add efficiency to user-level pro-
grams as well. For instance, in UNIX, an entire process must wait when a
page fault occurs or when a system call is executed. In a task with multiple
threads, only the thread that causes the page fault or executes a system call
is delayed; all other threads continue executing. Because Mach has kernel-
supported threads (Chapter 4), the threads have some cost associated with
them.Theymusthavesupportingdatastructuresinthekernel,andmorecom-
plex kernel-scheduling algorithms must be provided. These algorithms and
threadstatesarediscussedinChapter4.
At theuserlevel,threadsmay beinone oftwo states:
•Running. The thread is either executing or waiting to be allocated a pro-
cessor.Athreadisconsideredtoberunningevenifitisblockedwithinthe
kernel(waiting for apagefault to besatisfied,for instance).
•Suspended. The thread is neither executing on a processor nor waiting
to be allocated a processor. Athread can resume its execution only if it is
returnedtothe running state.
These two states are also associated with a task. An operation on a task
affects all threads in a task, so suspending a task involves suspending all the
threads in it. Task and thread suspensions are separate, independent mecha-
nisms, however, so resuming a thread in a suspended task does not resume
thetask.
Machprovidesprimitivesfromwhichthread-synchronizationtoolscanbe
built. This practice is consistent with Mach’s philosophy of providing mini-"
3,D.4.2 The C Threads Package,1174,D.4.1 Basic Structure,"8 Appendix D The Mach System
mum yet sufficient functionality in the kernel. The Mach IPCfacility can be
used for synchronization, with processe sexchanging messages at rendezvous
points. Thread-level synchronization is provided by calls to start and stop
threads at appropriate times. A suspend count is kept for each thread. This
count allows multiple suspend() calls to be executed on a thread, and only
when an equal number of resume() calls occur is the thread resumed. Unfor-
tunately,thisfeaturehasitsownlimitation.Becauseitisanerrorfora start()
call to be executed before a stop()call (the suspend count would become
negative), these routines cannot be used to synchronize shared data access.
However, wait()andsignal() operations associated with semaphores, and
usedforsynchronization,canbeimplementedviathe IPCcalls.Wediscussthis
methodinSectionD.5.
D.4.2 The C Threads Package
Mach provides low-level but flexible routines instead of polished, large, and
more restrictive functions. Rather than making programmers work at this
low level, Mach provides many higher-level interfaces for programming in C
and other languages. For instance, th e C threads package provides multiple
threadsofcontrol,sharedvariables,mutualexclusionforcriticalsections,and
condition variables for synchronization. In fact, C threads is one of the major
influences on the POSIXPthreads standard, which many operating systems
support. As a result, there are strong similarities between the C threads and
Pthreadsprogramminginterfaces.Theth read-controlroutinesincludecallsto
performthesetasks:
•Createanewthreadwithinatask,givenafunctiontoexecuteandparam-
eters as input. The thread then executes concurrently with the creating
thread,which receivesathreadidentifierwhenthecall returns.
•Destroythecalling thread,and returna valueto thecreating thread.
•Wait for a specific thread to terminate before allowing the calling thread
tocontinue.Thiscallisasynchronizationtool,muchlikethe UNIX wait()
systemcalls.
•Yield use of a processor, signaling that the scheduler can run another
threadatthispoint.Thiscallisalso usefulinthepresenceofapreemptive
scheduler, as it can be used to relinquish the CPUvoluntarily before the
time quantum (or scheduling interval) expires if a thread has no use for
theCPU.
Mutualexclusionisachievedthroughtheuseofspinlocks,asdiscussedin
Chapter6.The routinesassociatedwithmutualexclusionarethese:
•The routine mutex
 alloc() dynamicallycreatesa mutexvariable.
•The routine mutex
 free()deallocates a dynamically created mutex vari-
able.
•The routine mutex
 lock()locks a mutex variable. The executing thread
loopsinaspinlockuntilthelockisattained.Adeadlockresultsifathread
with a lock tries to lock the same mutex variable. Bounded waiting is"
3,D.4.3 The CPU Scheduler,1176,D.4.2 The C Threads Package,"10 Appendix D The Mach System
do{
...
// produce an item into nextp
...
mutex
 lock(mutex);
while(full)
condition
 wait(nonfull, mutex);
...
// add nextp to buffer
...
condition
 signal(nonempty);
mutex
 unlock(mutex);
}while(TRUE);
Figure D.3 The structure of the producer process.
D.4.3 The CPU Scheduler
TheCPUschedulerforathread-basedmultiprocessoroperatingsystemismore
complex than its process-based relatives. There are generally more threads
in a multithreaded system than there are processes in a multitasking system.
Keepingtrackofmultipleprocessorsisalsodifficultandisarelativelynewarea
ofresearch.Machusesasimplepolicyt okeeptheschedulermanageable.Only
threadsarescheduled,sonoknowledgeo ftasksisneededinthescheduler.All
threadscompeteequallyfor resources,including timequanta.
Eachthreadhasanassociatedprioritynumberrangingfrom0through127,
which is based on the exponential average of its usage of the CPU.T h a ti s ,a
thread that recently used the CPUfor a large amount of time has the lowest
do{
mutex
 lock(mutex);
while(empty)
condition
 wait(nonempty, mutex);
...
// remove an item from the buffe to nextc
...
condition
 signal(nonfull);
mutex
 unlock(mutex);
...
// consume the item in nextc
...
}until(FALSE);
Figure D.4 The structure of the consumer process."
3,D.4.4 Exception Handling,1177,D.4.3 The CPU Scheduler,"D.4 Process Management 11
priority. Mach uses the priority to place the thread in one of 32 global run
queues.These queuesare searched inpriorityorder for waiting threadswhen
aprocessorbecomesidle.Machalsokeepsper-processor,orlocal,runqueues.
Alocalrunqueueisusedforthreadsthatareboundtoanindividualprocessor.
Forinstance,adevicedriverforadeviceconnectedtoanindividual CPUmust
runon only that CPU.
Instead of a central dispatcher that assigns threads to processors, each
processor consults the local and global run queues to select the appropriate
next thread to run. Threads in the local run queue have absolute priority over
thoseintheglobalqueues,becauseitisassumedthattheyareperformingsome
chore for the kernel. The run queues—like most other objects in Mach—are
locked when they are modified to avoid simultaneous changes by multiple
processors. To speed dispatching of threads on the global run queue, Mach
maintains alistof idleprocessors.
Additional scheduling difficulties arise from the multiprocessor nature of
Mach. A fixed time quantum is not appropriate because, for instance, there
may be fewer runnable threads than there are available processors. It would
bewastefultointerruptathreadwithacontextswitchtothekernelwhenthat
thread’s quantum runs out, only to have the thread be placed right back in
therunning state.Thus,insteadofusingafixed-lengthquantum,Machvaries
thesizeof thetimequantum inverselywiththe totalnumber of threadsinthe
system. It keeps the time quantum over the entire system constant, however.
Forexample,inasystemwith10processors,11threads,anda100-millisecond
quantum, a context switch needs to occur on each processor only once per
secondto maintainthedesiredquantum.
Ofcourse,complicationsstillexist.Evenrelinquishingthe CPUwhilewait-
ing for a resource is more difficult than it is on traditional operating systems.
First, a thread must issue a call to alert the scheduler that the thread is about
to block. This alert avoids race conditi ons and deadlocks, which could occur
whentheexecutiontakesplaceinamultiprocessorenvironment.Asecondcall
actuallycausesthethreadtobemovedofftherunqueueuntiltheappropriate
event occurs. The scheduler uses many other internal thread states to control
threadexecution.
D.4.4 Exception Handling
Machwasdesignedtoprovideasingle,si mple,consistentexception-handling
system,withsupportforstandardaswellasuser-definedexceptions.Toavoid
redundancyinthekernel,Machuseskernelprimitiveswheneverpossible.For
instance, an exception handler is just another thread in the task in which the
exception occurs. Remote procedure call ( RPC) messages are used to synchro-
nize the execution of the thread causing the exception (the victim)a n dt h a to f
thehandlerandtocommunicateinform ationabouttheexceptionbetweenthe
victimand handler.Mach exceptionsare also usedto emulatethe BSDsignal
package.
Disruptionstonormalprogramexecutioncomeintwovarieties:internally
generated exceptions and external inte rrupts. Interrupts are asynchronously
generateddisruptionsofathreadortask,whereasexceptionsarecausedbythe
occurrenceofunusualconditionsduringathread’sexecution.Mach’sgeneral-
purpose exception facility is used for error detection and debugger support."
2,D.5 Interprocess Communication,1179,D.4 Process Management,"D.5 Interprocess Communication 13
converted to exception RPCs. For tasks and threads that do not make explicit
useoftheMachexception-handlingfacility,thedestinationofthis RPCdefaults
to an in-kernel task. This task has only one purpose: Its thread runs in a
continuous loop, receiving the exception RPCs. For each RPC, it converts the
exceptionintotheappropriatesignal,whichissenttothethreadthatcausedthe
hardwareexception.Itthencompletesthe RPC,clearingtheoriginalexception
condition.Withthecompletionofthe RPC,theinitiatingthreadreenterstherun
state. It immediately sees the signal and executes its signal-handling code. In
this manner, all hardware exceptions begin in a uniform way—as exception
RPCs. Threads not designed to handle such exceptions, however, receive the
exceptions as they would on a standard BSDsystem—as signals. In Mach
3.0, the signal-handling code is moved entirely into a server, but the overall
structureand flow of control issimilarto thoseof Mach 2.5.
D.5 Interprocess Communication
Most commercial operating systems, such as UNIX, provide communication
between processes and between hosts with fixed, global names (or Internet
addresses).Thereisnolocationindepe ndenceoffacilities,becauseanyremote
systemneeding to use a facility must know the name of the system providing
thatfacility.Usually,datainthemessagesareuntypedstreamsofbytes.Mach
simplifies this picture by sending messages between location-independent
ports. The messages contain typed data for ease of interpretation. All BSD
communication methodscanbe implementedwiththis simplifiedsystem.
The two components of Mach IPCare ports and messages. Almost every-
t h i n gi nM a c hi sa no b j e c t ,a n da l lo b j e c t sa r ea d d r e s s e dv i at h e i rc o m m u -
nication ports. Messages are sent to these ports to initiate operations on the
objectsbytheroutinesthatimplementtheobjects.Bydependingononlyports
and messagesfor all communication, Mach deliverslocation independenceof
objectsandsecurityofcommunication.Dataindependenceisprovidedbythe
NetMsgServertask(SectionD.5.3).
Mach ensures security by requiring that message senders and receivers
have rights.Arightconsistsofaportnameandacapability—sendorreceive—
onthatport,andismuchlikeacapabilityinobject-orientedsystems.Onlyone
taskmayhavereceiverightstoanygivenport,butmanytasksmayhavesend
rights. When an object is created, its creator also allocates a port to represent
theobjectandobtainstheaccessrightstothatport.Rightscanbegivenoutby
the creator of the object, including the kernel, and are passed in messages. If
the holder of a receive right sends that right in a message, the receiver of the
message gains the right, and the sender loses it. A task may allocate ports to
allow access to any objects it owns or for communication. The destruction of
eitheraportortheholderofthereceiverightcausestherevocationofallrights
tothat port,and thetasksholding sendrights can be notifiedifdesired.
D.5.1 Ports
Aportisimplementedasaprotected,boundedqueuewithinthekernelofthe
system on which the object resides. If a queue is full, a sender may abort the"
3,D.5.1 Ports,1179,D.5 Interprocess Communication,"D.5 Interprocess Communication 13
converted to exception RPCs. For tasks and threads that do not make explicit
useoftheMachexception-handlingfacility,thedestinationofthis RPCdefaults
to an in-kernel task. This task has only one purpose: Its thread runs in a
continuous loop, receiving the exception RPCs. For each RPC, it converts the
exceptionintotheappropriatesignal,whichissenttothethreadthatcausedthe
hardwareexception.Itthencompletesthe RPC,clearingtheoriginalexception
condition.Withthecompletionofthe RPC,theinitiatingthreadreenterstherun
state. It immediately sees the signal and executes its signal-handling code. In
this manner, all hardware exceptions begin in a uniform way—as exception
RPCs. Threads not designed to handle such exceptions, however, receive the
exceptions as they would on a standard BSDsystem—as signals. In Mach
3.0, the signal-handling code is moved entirely into a server, but the overall
structureand flow of control issimilarto thoseof Mach 2.5.
D.5 Interprocess Communication
Most commercial operating systems, such as UNIX, provide communication
between processes and between hosts with fixed, global names (or Internet
addresses).Thereisnolocationindepe ndenceoffacilities,becauseanyremote
systemneeding to use a facility must know the name of the system providing
thatfacility.Usually,datainthemessagesareuntypedstreamsofbytes.Mach
simplifies this picture by sending messages between location-independent
ports. The messages contain typed data for ease of interpretation. All BSD
communication methodscanbe implementedwiththis simplifiedsystem.
The two components of Mach IPCare ports and messages. Almost every-
t h i n gi nM a c hi sa no b j e c t ,a n da l lo b j e c t sa r ea d d r e s s e dv i at h e i rc o m m u -
nication ports. Messages are sent to these ports to initiate operations on the
objectsbytheroutinesthatimplementtheobjects.Bydependingononlyports
and messagesfor all communication, Mach deliverslocation independenceof
objectsandsecurityofcommunication.Dataindependenceisprovidedbythe
NetMsgServertask(SectionD.5.3).
Mach ensures security by requiring that message senders and receivers
have rights.Arightconsistsofaportnameandacapability—sendorreceive—
onthatport,andismuchlikeacapabilityinobject-orientedsystems.Onlyone
taskmayhavereceiverightstoanygivenport,butmanytasksmayhavesend
rights. When an object is created, its creator also allocates a port to represent
theobjectandobtainstheaccessrightstothatport.Rightscanbegivenoutby
the creator of the object, including the kernel, and are passed in messages. If
the holder of a receive right sends that right in a message, the receiver of the
message gains the right, and the sender loses it. A task may allocate ports to
allow access to any objects it owns or for communication. The destruction of
eitheraportortheholderofthereceiverightcausestherevocationofallrights
tothat port,and thetasksholding sendrights can be notifiedifdesired.
D.5.1 Ports
Aportisimplementedasaprotected,boundedqueuewithinthekernelofthe
system on which the object resides. If a queue is full, a sender may abort the"
3,D.5.2 Messages,1180,D.5.1 Ports,"14 Appendix D The Mach System
send,waitforaslottobecomeavailableinthequeue,orhavethekerneldeliver
themessage.
Severalsystemcalls providethe portwiththefollowing functionalities:
•Allocate a new port in a specified task and give the caller’s task all access
rightsto thenewport.Theport nameis returned.
•Deallocateatask’saccessrightstoapor t.Ifthetaskholdsthereceiveright,
the port is destroyed, and all other tasks with send rights are, potentially,
notified.
•Getthecurrent statusof a task’s port.
•Createabackup port,whichisgiventhereceiverightforaportifthetask
containing thereceiverightrequestsitsdeallocationor terminates.
When a task is created,the kernelcreatesseveralports for it.The function
task
 self()returnsthenameoftheportthatrepresentsthetaskincallstothe
kernel.Forinstance,toallocateanewport,ataskcalls port
 allocate() with
task
 self()as the name of the task that will own the port. Thread creation
results in a similar thread
 self()thread kernel port. This scheme is similar
tothestandardprocess- IDconceptfoundin UNIX.Anotherportisreturnedby
task
 notify() ;thisistheporttowhichthekernelwillsendevent-notification
messages(such as notifications of portterminations).
Portscanalsobecollectedinto port sets .Thisfacilityisusefulifonethread
is to service requests coming in on multiple ports—for example, for multiple
objects. A port may be a member of no more than one port set at a time.
Furthermore,ifaportisinaset,itmaynotbeuseddirectlytoreceivemessages.
Instead,messageswillberoutedtotheportset’squeue.Aportsetmaynotbe
passed in messages, unlike a port. Port sets are objects that serve a purpose
similartothe 4.3 BSD select() systemcall, but theyaremoreefficient.
D.5.2 Messages
A message consists of a fixed-length header and a variable number of typed
data objects. The header contains the destination’s port name, the name of
the reply port to which return messages should be sent, and the length of the
message (Figure D.5). The data in the message (or in-line data) were limited
to less than 8 KBin Mach 2.5 systems, but Mach 3.0 has no limit. Each data
section may be a simple type (numbers or characters), port rights, or pointers
toout-of-linedata.Eachsectionhasanassociatedtype,sothatthereceivercan
unpack the data correctly even if it uses a byte ordering different from that
used by the sender. The kernel also inspects the message for certain types of
data.Forinstance,thekernelmustprocessportinformationwithinamessage,
eitherbytranslatingtheportnameinto aninternalportdatastructureaddress
or by forwardingitfor processingto theNetMsgServer(SectionD.5.3).
The use of pointers in a message provid esthe means to transfer the entire
address space of a task in one single message. The kernel also must process
pointers to out-of-line data, since a pointer to data in the sender’s address
spacewouldbeinvalidinthereceiver’s —especiallyifthesenderandreceiver
reside on differentsystems. Generally,systems send messages by copying the
data from the sender to the receiver. Because this technique can be inefficient,
especiallyforlargemessages,Machtakesadifferentapproach.Thedatarefer-"
3,D.5.3 The NetMsgServer,1181,D.5.2 Messages,"D.5 Interprocess Communication 15
destination port
reply port
size/operation
pure typed data
port rights
out-of-line-data
message control
memory cache object memory cache objectportmessage queueport
message message
  
Figure D.5 Mach messages.
enced by a pointer in a message being sent to a port on the same system are
not copied between the sender and the receiver. Instead, the address map of
the receiving task is modified to inclu de a copy-on-write copy of the pages of
themessage.Thisoperationis muchfasterthanadatacopyandmakesmessage
passingmoreefficient.Inessence,messagepassingisimplementedviavirtual
memorymanagement.
In Version 2.5, this operation was implemented in two phases. A pointer
to a region of memory caused the kernel to map that region into its own
space temporarily, setting the sender’s memory map to copy-on-write mode
to ensure that any modifications did no t affect the original version of the
data. When a message was received at its destination, the kernel moved its
mapping to the receiver’s address space, using a newly allocated region of
virtualmemorywithinthat task.
InVersion3,thisprocesswassimplified.Thekernelcreatesadatastructure
thatwouldbeacopyoftheregionifitwerepartofanaddressmap.Onreceipt,
thisdatastructureisaddedtothereceiver’smapandbecomesacopyaccessible
tothe receiver.
The newly allocated regions in a task do not need to be contiguous with
previous allocations, so Mach virtual memory is said to be sparse, consisting
ofregionsof dataseparatedbyunallocated addresses.Afullmessagetransfer
isshown inFigureD.6.
D.5.3 The NetMsgServer
For a message to be sent between computers, the message’s destination must
be located, and the message must be transmitted to the destination. UNIXtra-
ditionallyleaves these mechanisms to the low-levelnetwork protocols, which
require the use of statically assigned communication endpoints (for example,"
3,D.5.4 Synchronization Through IPC,1184,D.5.3 The NetMsgServer,"18 Appendix D The Mach System
Machkernel,providingmuchmoreefficientinternode IPCformulticomputers
withfastinterconnectionhardware.Forexample,thetime-consumingcopying
of messages between the NetMsgServer and the kernel is eliminated. Use of
theNORMAIPC doesnotprecludeuseoftheNetMsgServer;theNetMsgServer
canstillbeusedtoprovideMach IPCserviceovernetworksthatlinka NORMA
multiprocessor to other computers. In addition to the NORMA IPC ,M a c h3 . 0
also provides support for memory management across a NORMAsystem and
enables a task in such a system to create child tasks on nodes other than its
own. These features support the implementation of a single-system-image
operating system on a NORMA multiprocessor. The multiprocessor behaves
like one large system rather than an assemblage of smaller systems (for both
usersand applications).
D.5.4 Synchronization Through IPC
TheIPCmechanism is extremely flexible and is used throughout Mach. For
example, it may be used for thread synchronization. Aport may be used as a
synchronization variable and may have nmessages sent to it for nresources.
Any thread wishing to use a resource executes a receive call on that port. The
threadwillreceiveamessageiftheresou rceisavailable.Otherwise,itwillwait
ontheportuntilamessageisavailablethere.Toreturnaresourceafteruse,the
threadcansendamessagetotheport.Inthisregard,receivingisequivalentto
thesemaphoreoperation wait(),andsendingisequivalentto signal() .This
methodcanbeusedforsynchronizingse maphoreoperationsamongthreadsin
thesametask,butitcannot beusedforsynchronization amongtasks,because
only one task may have receive rights to a port. For more general-purpose
semaphores,a simpledaemoncanbe writtento implementthesamemethod.
D.6 Memory Management
Given the object-oriented nature of Mach, it is not surprising that a principal
abstractioninMachisthememoryobject.Memoryobjectsareusedtomanage
secondary storage and generally represent files, pipes, or other data that are
mapped into virtual memory for reading and writing (Figure D.8). Memory
objectsmaybebackedbyuser-levelmemorymanagers,whichtaketheplaceof
themoretraditionalkernel-incorpora tedvirtualmemorypagerfoundinother
operatingsystems.Incontrasttothetraditionalapproachofhavingthekernel
manage secondary storage, Mach treats secondary-storage objects (usually
files)asitdoesallotherobjectsinthesystem.Eachobjecthasaportassociated
with it and may be manipulated by messages sent to its port. Memory objects
—unlike the memory-managementroutinesinmonolithic, traditionalkernels
—allow easyexperimentationwithnewmemory-manipulationalgorithms.
D.6.1 Basic Structure
Thevirtualaddressspaceofataskisgenerallysparse,consistingofmanyholes
ofunallocatedspace.Forinstance,ame mory-mappedfileisplacedinsomeset
ofaddresses.Largemessagesarealsotransferredassharedmemorysegments.
For each of these segments, a section of virtual memory address is used to
provide the threads with access to the message. As new items are mapped or"
2,D.6 Memory Management,1184,D.5 Interprocess Communication,"18 Appendix D The Mach System
Machkernel,providingmuchmoreefficientinternode IPCformulticomputers
withfastinterconnectionhardware.Forexample,thetime-consumingcopying
of messages between the NetMsgServer and the kernel is eliminated. Use of
theNORMAIPC doesnotprecludeuseoftheNetMsgServer;theNetMsgServer
canstillbeusedtoprovideMach IPCserviceovernetworksthatlinka NORMA
multiprocessor to other computers. In addition to the NORMA IPC ,M a c h3 . 0
also provides support for memory management across a NORMAsystem and
enables a task in such a system to create child tasks on nodes other than its
own. These features support the implementation of a single-system-image
operating system on a NORMA multiprocessor. The multiprocessor behaves
like one large system rather than an assemblage of smaller systems (for both
usersand applications).
D.5.4 Synchronization Through IPC
TheIPCmechanism is extremely flexible and is used throughout Mach. For
example, it may be used for thread synchronization. Aport may be used as a
synchronization variable and may have nmessages sent to it for nresources.
Any thread wishing to use a resource executes a receive call on that port. The
threadwillreceiveamessageiftheresou rceisavailable.Otherwise,itwillwait
ontheportuntilamessageisavailablethere.Toreturnaresourceafteruse,the
threadcansendamessagetotheport.Inthisregard,receivingisequivalentto
thesemaphoreoperation wait(),andsendingisequivalentto signal() .This
methodcanbeusedforsynchronizingse maphoreoperationsamongthreadsin
thesametask,butitcannot beusedforsynchronization amongtasks,because
only one task may have receive rights to a port. For more general-purpose
semaphores,a simpledaemoncanbe writtento implementthesamemethod.
D.6 Memory Management
Given the object-oriented nature of Mach, it is not surprising that a principal
abstractioninMachisthememoryobject.Memoryobjectsareusedtomanage
secondary storage and generally represent files, pipes, or other data that are
mapped into virtual memory for reading and writing (Figure D.8). Memory
objectsmaybebackedbyuser-levelmemorymanagers,whichtaketheplaceof
themoretraditionalkernel-incorpora tedvirtualmemorypagerfoundinother
operatingsystems.Incontrasttothetraditionalapproachofhavingthekernel
manage secondary storage, Mach treats secondary-storage objects (usually
files)asitdoesallotherobjectsinthesystem.Eachobjecthasaportassociated
with it and may be manipulated by messages sent to its port. Memory objects
—unlike the memory-managementroutinesinmonolithic, traditionalkernels
—allow easyexperimentationwithnewmemory-manipulationalgorithms.
D.6.1 Basic Structure
Thevirtualaddressspaceofataskisgenerallysparse,consistingofmanyholes
ofunallocatedspace.Forinstance,ame mory-mappedfileisplacedinsomeset
ofaddresses.Largemessagesarealsotransferredassharedmemorysegments.
For each of these segments, a section of virtual memory address is used to
provide the threads with access to the message. As new items are mapped or"
3,D.6.1 Basic Structure,1184,D.6 Memory Management,"18 Appendix D The Mach System
Machkernel,providingmuchmoreefficientinternode IPCformulticomputers
withfastinterconnectionhardware.Forexample,thetime-consumingcopying
of messages between the NetMsgServer and the kernel is eliminated. Use of
theNORMAIPC doesnotprecludeuseoftheNetMsgServer;theNetMsgServer
canstillbeusedtoprovideMach IPCserviceovernetworksthatlinka NORMA
multiprocessor to other computers. In addition to the NORMA IPC ,M a c h3 . 0
also provides support for memory management across a NORMAsystem and
enables a task in such a system to create child tasks on nodes other than its
own. These features support the implementation of a single-system-image
operating system on a NORMA multiprocessor. The multiprocessor behaves
like one large system rather than an assemblage of smaller systems (for both
usersand applications).
D.5.4 Synchronization Through IPC
TheIPCmechanism is extremely flexible and is used throughout Mach. For
example, it may be used for thread synchronization. Aport may be used as a
synchronization variable and may have nmessages sent to it for nresources.
Any thread wishing to use a resource executes a receive call on that port. The
threadwillreceiveamessageiftheresou rceisavailable.Otherwise,itwillwait
ontheportuntilamessageisavailablethere.Toreturnaresourceafteruse,the
threadcansendamessagetotheport.Inthisregard,receivingisequivalentto
thesemaphoreoperation wait(),andsendingisequivalentto signal() .This
methodcanbeusedforsynchronizingse maphoreoperationsamongthreadsin
thesametask,butitcannot beusedforsynchronization amongtasks,because
only one task may have receive rights to a port. For more general-purpose
semaphores,a simpledaemoncanbe writtento implementthesamemethod.
D.6 Memory Management
Given the object-oriented nature of Mach, it is not surprising that a principal
abstractioninMachisthememoryobject.Memoryobjectsareusedtomanage
secondary storage and generally represent files, pipes, or other data that are
mapped into virtual memory for reading and writing (Figure D.8). Memory
objectsmaybebackedbyuser-levelmemorymanagers,whichtaketheplaceof
themoretraditionalkernel-incorpora tedvirtualmemorypagerfoundinother
operatingsystems.Incontrasttothetraditionalapproachofhavingthekernel
manage secondary storage, Mach treats secondary-storage objects (usually
files)asitdoesallotherobjectsinthesystem.Eachobjecthasaportassociated
with it and may be manipulated by messages sent to its port. Memory objects
—unlike the memory-managementroutinesinmonolithic, traditionalkernels
—allow easyexperimentationwithnewmemory-manipulationalgorithms.
D.6.1 Basic Structure
Thevirtualaddressspaceofataskisgenerallysparse,consistingofmanyholes
ofunallocatedspace.Forinstance,ame mory-mappedfileisplacedinsomeset
ofaddresses.Largemessagesarealsotransferredassharedmemorysegments.
For each of these segments, a section of virtual memory address is used to
provide the threads with access to the message. As new items are mapped or"
3,D.6.2 User-Level Memory Managers,1186,D.6.1 Basic Structure,"20 Appendix D The Mach System
are also allocated automatically when a task receives a message containing
out-of-line data.
Associated system calls return information about a memory object in a
task’s address space, change the access protection of the object, and specify
howanobjectistobepassedtochildtasksatthetimeoftheircreation(shared,
copy-on-write, ornot present).
D.6.2 User-Level Memory Managers
A secondary-storage object is usually mapped into the virtual address space
of a task. Mach maintains a cache of memory-resident pages of all mapped
objects, as in other virtual memory implementations. However, a page fault
occurringwhenathreadaccessesanonresidentpageisexecutedasamessage
to the object’s port. The concept that a memory object can be created and
serviced by nonkernel tasks (unlike threads, for instance, which are created
and maintained only by the kernel) is important. The end result is that, in the
traditional sense, memory can be paged by user-written memory managers.
When the object is destroyed, it is up to the memory manager to write back
any changed pages to secondary storage. No assumptions are made by Mach
aboutthecontentorimportanceofmemoryobjects,sothememoryobjectsare
independentof the kernel.
In several circumstances, user-level memory managers are insufficient.
For instance, a task allocating a new region of virtual memory might not
have a memory manager assigned to that region, since it does not represent a
secondary-storageobject(butmustbepaged),oramemorymanagermightfail
to perform pageout. Mach itself also needs a memory manager to take care of
itsmemoryneeds.Forthesecases,Machprovidesadefaultmemorymanager.
The Mach 2.5 default memory manager uses the standard file system to store
datathatmustbewrittentodisk,rather thanrequiringaseparateswapspace,
as in4.3 BSD.InMa c h3 .0(a n d OSF/1),the defaultmemorymanager iscapable
of using either files in a standard file system or dedicated disk partitions. The
defaultmemorymanagerhasaninterfacesimilartothatoftheuser-levelones,
but with some extensions to support its role as the memory manager that can
be reliedonto performpageoutwhenuser-levelmanagers failto doso.
Pageout policy is implemented by an internal kernel thread, the pageout
daemon.Apagingalgorithmbasedon FIFOwithsecondchance(Section10.4.5)
is used to select pages for replacement. The selected pages are sent to the
appropriate manager (either user level or default) for actual pageout. Auser-
level manager may be more intelligent than the default manager, and it may
implementadifferentpagingalgorithmsu itabletotheobjectitisbacking(that
is, by selecting some other page and forcibly paging it out). If a user-level
manager fails to reduce the resident set of pages when asked to do so by the
kernel,thedefaultmemorymanagerisinvoked,anditpagesouttheuser-level
managertoreducetheuser-levelmanager’sresidentsetsize.Shouldtheuser-
levelmanagerrecoverfromtheproblemthatpreventeditfromperformingits
own pageouts, it will touch these page s (causing the kernel to page them in
again) and can thenpagethem out asitseesfit.
If a thread needs access to data in a memory object (for instance, a file),
it invokes the vm
map()system call. Included in this system call is a port
that identifies the object and the memory manager that is responsible for the"
3,D.6.3 Shared Memory,1188,D.6.2 User-Level Memory Managers,"22 Appendix D The Mach System
been modified, or any “precious pages ”that the kernel needs to remove from
resident memory (due to page aging, for instance), are sent to the memory
object via memory
 object
 data
 write() .Precious pages are pages that may
nothavebeenmodifiedbutthatcannot bediscardedastheyotherwisewould
be because the memory manager no lon ger retains a copy. The memory man-
agerdeclaresthesepagestobepreciousandexpectsthekerneltoreturnthem
whentheyareremovedfrommemory.Preciouspagessaveunnecessarydupli-
cation and copying of memory.
In the current version, Mach does not allow external memory managers
to affect the page-replacement algorithm directly. Mach does not export the
memory-accessinformationthatwouldbeneededforanexternaltasktoselect
theleastrecentlyusedpage,forinstance.Methodsofprovidingsuchinforma-
tion are currently under investigation. An external memory manager is still
usefulfor a varietyof reasons,however:
•It may reject the kernel’s replacement victim if it knows of a better candi-
date(for instance, MRUpagereplacement).
•It may monitor the memory object it is backing and request pages to be
pagedout beforethe memoryusageinvokesMach’s pageoutdaemon.
•Itisespeciallyimportant inmaintaining consistency of secondarystorage
for threadson multipleprocessors,as weshow inSectionD.6.3.
•It can control the order of operations on secondary storage to enforce
consistencyconstraintsdemandedbydatabasemanagementsystems.For
example, in transaction logging, transactions must be written to a log file
ondiskbeforetheymodifythe databasedata.
•Itcan control mappedfileaccess.
D.6.3 Shared Memory
Mach uses shared memory to reduce the complexity of various system facili-
ties,aswellastoprovidethesefeaturesinanefficientmanner.Sharedmemory
generally provides extremely fast interprocess communication, reduces over-
head in file management, and helps to support multiprocessing and database
management. Mach does not use shared memory for all these traditional
shared-memory roles, however. For instance, all threads in a task share that
task’s memory, so no formal shared-memory facility is needed within a task.
However,Machmuststillprovidetraditionalsharedmemorytosupportother
operating-systemconstructs, such asthe UNIX fork()systemcall.
Itisobviouslydifficultfortasksonmultiplemachinestosharememoryand
tomaintaindataconsistency.Machdoesnottrytosolvethisproblemdirectly;
rather, it provides facilities to allow the problem to be solved. Mach supports
consistent shared memory only when the memory is shared by tasks running
onprocessorsthatsharememory.Aparenttaskisabletodeclarewhichregions
of memory are to be inherited by its children and which are to be readable
–writable. This scheme is different fro m copy-on-write inheritance, in which
each task maintains its own copy of any changed pages. A writable object is
addressedfromeachtask’saddressmap,andallchangesaremadetothesame
copy. The threads within the tasks are responsible for coordinating changes
to memory so that they do not interfere with one another (by writing to the"
2,D.7 Programmer Interface,1189,D.6 Memory Management,"D.7 Programmer Interface 23
same location concurrently). This coordination can be done through normal
synchronization methods:criticalsections ormutual-exclusionlocks.
Forthecaseofmemorysharedamongseparatemachines,Machallowsthe
useof externalmemorymanagers.If asetof unrelatedtasks wishesto sharea
section of memory, the tasks can use the same external memory manager and
access the same secondary-storage areas through it. The implementor of this
systemwouldneedtowritethetasksandtheexternalpager.Thispagercould
be as simple or as complicated as needed. A simple implementation would
allowno readerswhileapagewasbeingwrittento.Anywriteattemptwould
cause the pager to invalidate the page in all tasks currently accessing it. The
pager would then allow the write and would revalidate the readers with the
new version of the page. The readers would simply wait on a page fault until
thepageagainbecameavailable.Machprovidessuchamemorymanager:the
Network Memory Server (NetMemServer). For multicomputers, the NORMA
configuration of Mach 3.0 provides similar support as a standard part of the
kernel. This XMMsubsystem allows multicomputer systems to use external
memory managers that do not incorporate logic for dealing with multiple
kernels. The XMMsubsystem is responsible for ma intaining data consistency
among multiple kernels that share memory and makes these kernels appear
tobea singlekernelto thememorymanager.The XMMsubsystemalsoimple-
ments virtual copy logic for the mapped objects that it manages. This virtual
copylogicincludesbothcopy-on-referenceamongmulticomputerkernelsand
sophisticatedcopy-on-write optimizations.
D.7 Programmer Interface
AprogrammercanworkatseverallevelswithinMach.Thereis,ofcourse,the
system-call level, which, in Mach 2.5, is equivalent to the 4.3 BSDsystem-call
interface. Version 2.5 includes most of 4.3 BSDas one thread in the kernel. A
BSDsystem call traps to the kernel and is serviced by this thread on behalf
of the caller, much as standard BSDw o u l dh a n d l ei t .T h ee m u l a t i o ni sn o t
multithreaded,so ithas limitedefficiency.
Mach 3.0 has moved from the single-server model to support of multiple
servers. It has therefore become a true microkernel without the full features
normallyfoundinakernel.Rather,fullfunctionalitycanbeprovidedviaemu-
lationlibraries,servers,oracombinationofthetwo.Inkeepingwiththedefini-
tionofamicrokernel,theemulationlibrariesandserversrunoutsidethekernel
at user level. In this way, multiple operating systems can run concurrently on
oneMach 3.0kernel.
An emulation library is a set of routin es that lives in a read-only part of a
program’s address space. Any operating-system calls the program makes are
translated into subroutine calls to the library. Single-user operating systems,
such as MS-DOSand the Macintosh operatingsystem,have beenimplemented
solelyasemulationlibraries.Forefficie ncyreasons,theemulationlibrarylives
in the address space of the program needin g its functionality; in theory, how-
ever,itcould be aseparatetask.
Morecomplexoperatingsystemsareemulatedthroughtheuseoflibraries
andoneormoreservers.Systemcallsthatcannotbeimplementedinthelibrary
are redirected to the appropriate server. Servers can be multithreaded for"
2,D.8 Summary,1190,D.7 Programmer Interface,"24 Appendix D The Mach System
improved efficiency; BSDandOSF/1are implemented as single multithreaded
servers. Systems can be decomposed into multiple servers for greater modu-
larity.
Functionally, a system call starts in a task and passes through the kernel
beforebeingredirected,ifappropriate, tothelibraryinthetask’saddressspace
ortoaserver.Althoughthisextratransferofcontroldecreasestheefficiencyof
Mach,thisdecreaseisbalancedtosomeextentbytheabilityofmultiplethreads
to execute BSD-likec o dec o n c u rr en tly .
AtthenexthigherprogramminglevelistheCthreadspackage.Thispack-
ageisarun-timelibrarythatprovidesaClanguageinterfacetothebasicMach
threads primitives. It provides convenient access to these primitives, includ-
ing routines for the forking and joining of threads, mutual exclusion through
mutex variables (Section D.4.2), and synchronization through use of condi-
tion variables. Unfortunately, it is no t appropriate for the C threads package
to be used between systems that share no memory ( NORMAsystems), since it
dependson sharedmemorytoimplementitsconstructs. Thereiscurrentlyno
equivalentofCthreadsfor NORMAsystems.Otherrun-timelibrarieshavebeen
writtenfor Mach, including threadssupportforother languages.
Although the use of primitives makes Mach flexible, it also makes many
programming tasks repetitive. For instance, significant amounts of code are
associated with sending and receivin g messages in each task that uses mes-
sages(which,inMach,ismosttasks).ThedesignersofMachthereforeprovide
aninterfacegenerator(orstubgenerator)called MIG.MIGisessentiallyacom-
pilerthattakesasinputadefinitionoftheinterfacetobeused(declarationsof
variables,types,andprocedures)andgeneratesthe RPCinterfacecodeneeded
to send and receive the messages fitti ng this definition and to connect the
messagestothe sendingand receivingthreads.
D.8 Summary
The Mach operating system is designed to incorporate the many recent inno-
vationsinoperating-systemresearchtoproduceafullyfunctional,technically
advancedoperatingsystem.
TheMachoperatingsystemwasdesignedwiththreecriticalgoalsinmind:
•Emulate 4.3 BSD UNIX so that the executable files from a UNIXsystem can
run correctlyunderMach.
•Haveamodernoperatingsystemthatsupportsmanymemorymodelsand
paralleland distributedcomputing.
•Designa kernelthat issimplerandeasiertomodifythan is 4.3 BSD.
Aswe have shown, Mach iswellon itsway toachieving these goals.
Mach 2.5 includes 4.3 BSDin its kernel, which provides the emulation
neededbutenlargesthekernel.This 4.3 BSDcodehasbeenrewrittentoprovide
the same 4.3functionality but to use the Mach primitives. This change allows
the4.3 BSDsupportcodeto runinuserspaceon aMach 3.0 system."
2,Further Reading,1191,D.8 Summary,"Further Reading 25
Mach uses lightweight processes, in the form of multiple threads of exe-
cution within one task (or address space), to support multiprocessing and
parallel computation. Its extensive use of messages as the only communica-
tion method ensures that protection mechanisms are complete and efficient.
By integrating messages with the virtual memory system, Mach also ensures
thatmessagescanbehandledefficiently.Finally,byhavingthevirtualmemory
systemusemessagestocommunicatewiththedaemonsmanagingthebacking
store,Machprovidesgreatflexibilityinthedesignandimplementationofthese
memory-object-managing tasks.
By providing low-level, or primitive, system calls from which more com-
plexfunctionscanbebuilt,Machreduces thesizeofthekernelwhilepermitting
operating-systememulationattheuserlevel,muchlike IBM’s virtualmachine
systems.
Further Reading
TheAccentoperatingsystemwasdescribedby[RashidandRobertson(1981)].
A historical overview of the progression from an even earlier system, RIG,
through Accent to Mach was given by [Rashid (1986)]. General discussions
concerning theMach modelwereofferedby [Tevanianetal.(1989)].
[Accettaetal.(1986)]presentedanoverviewoftheoriginaldesignofMach.
The Mach scheduler was described in detail by [Tevanian et al. (1987a)] and
[Black (1990)]. An early version of the Mach shared memory and memory-
mappingsystemwas presented[Tevanianetal.(1987b)].
Bibliography
[Accetta et al. (1986)] M .A c c e t t a ,R .B a r o n ,W .B o l o s k y ,D .B .G o l u b ,R .R a s h i d ,
A.Tevanian,andM.Young, “Mach:ANewKernelFoundationfor UNIXDevel-
opment ”,Proceedings of the Summer USENIX Conference (1986), pages93–112.
[Black (1990)] D. L. Black, “Scheduling Support for Concurrency and Paral-
lelism in the Mach Operating System ”,IEEE Computer , Volume 23, Number 5
(1990), pages35–43.
[Rashid (1986)] R. F. Rashid, “From RIG to Accent to Mach: The Evolution of a
NetworkOperatingSystem ”,Proceedings of the ACM/IEEE Computer Society, Fall
Joint Computer Conference (1986), pages1128–1137.
[Rashid and Robertson (1981)] R. Rashid and G. Robertson, “Accent: A Com-
munication-Oriented Network Operating System Kernel ”,Proceedings of the
ACM Symposium on Operating System Principles (1981), pages 64–75.
[Tevanian et al. (1987a)] A. Tevanian, Jr., R. F. Rashid, D. B. Golub, D. L. Black,
E.Cooper,andM.W.Young, “MachThreadsandtheUnixKernel:TheBattlefor
Control ”,Proceedings of the Summer USENIX Conference (1987).
[Tevanian et al. (1987b)] A.T evanian,Jr.,R.F .Rashid,M.W .Y oung,D.B.Golub,
M. R. Thompson, W. Bolosky, and R. Sanzi, “A UNIX Interface for Shared"
2,Bibliography,1191,Further Reading,"Further Reading 25
Mach uses lightweight processes, in the form of multiple threads of exe-
cution within one task (or address space), to support multiprocessing and
parallel computation. Its extensive use of messages as the only communica-
tion method ensures that protection mechanisms are complete and efficient.
By integrating messages with the virtual memory system, Mach also ensures
thatmessagescanbehandledefficiently.Finally,byhavingthevirtualmemory
systemusemessagestocommunicatewiththedaemonsmanagingthebacking
store,Machprovidesgreatflexibilityinthedesignandimplementationofthese
memory-object-managing tasks.
By providing low-level, or primitive, system calls from which more com-
plexfunctionscanbebuilt,Machreduces thesizeofthekernelwhilepermitting
operating-systememulationattheuserlevel,muchlike IBM’s virtualmachine
systems.
Further Reading
TheAccentoperatingsystemwasdescribedby[RashidandRobertson(1981)].
A historical overview of the progression from an even earlier system, RIG,
through Accent to Mach was given by [Rashid (1986)]. General discussions
concerning theMach modelwereofferedby [Tevanianetal.(1989)].
[Accettaetal.(1986)]presentedanoverviewoftheoriginaldesignofMach.
The Mach scheduler was described in detail by [Tevanian et al. (1987a)] and
[Black (1990)]. An early version of the Mach shared memory and memory-
mappingsystemwas presented[Tevanianetal.(1987b)].
Bibliography
[Accetta et al. (1986)] M .A c c e t t a ,R .B a r o n ,W .B o l o s k y ,D .B .G o l u b ,R .R a s h i d ,
A.Tevanian,andM.Young, “Mach:ANewKernelFoundationfor UNIXDevel-
opment ”,Proceedings of the Summer USENIX Conference (1986), pages93–112.
[Black (1990)] D. L. Black, “Scheduling Support for Concurrency and Paral-
lelism in the Mach Operating System ”,IEEE Computer , Volume 23, Number 5
(1990), pages35–43.
[Rashid (1986)] R. F. Rashid, “From RIG to Accent to Mach: The Evolution of a
NetworkOperatingSystem ”,Proceedings of the ACM/IEEE Computer Society, Fall
Joint Computer Conference (1986), pages1128–1137.
[Rashid and Robertson (1981)] R. Rashid and G. Robertson, “Accent: A Com-
munication-Oriented Network Operating System Kernel ”,Proceedings of the
ACM Symposium on Operating System Principles (1981), pages 64–75.
[Tevanian et al. (1987a)] A. Tevanian, Jr., R. F. Rashid, D. B. Golub, D. L. Black,
E.Cooper,andM.W.Young, “MachThreadsandtheUnixKernel:TheBattlefor
Control ”,Proceedings of the Summer USENIX Conference (1987).
[Tevanian et al. (1987b)] A.T evanian,Jr.,R.F .Rashid,M.W .Y oung,D.B.Golub,
M. R. Thompson, W. Bolosky, and R. Sanzi, “A UNIX Interface for Shared"
0,Credits,1193,PART TEN APPENDICES,"Credits
•Figure 1.14: From Hennesy and Patterson, Computer Architecture: A Quan-
titative Approach, Third Edition ,c/circlecopyrt2002,MorganKaufmannPublishers,Fig-
ure5.3,p.394. Reprintedwithpermissionof thepublisher.
•Figure 5.19: From Khanna/Sebree/Zolnowsky, “Realtime Scheduling in
SunOS 5.0, ”Proceedings of Winter USENIX, January 1992, San Francisco,
California.Derivedwith permissionof theauthors.
•Figure5.30 adaptedwithpermissionfrom SunMicrosystems,Inc.
•Figure 10.20: From IBM Systems Journal , Vol. 10, No. 3, c/circlecopyrt1971, Interna-
tional Business Machines Corporation. Reprinted by permission of IBM
Corporation.
•Figure 12.5: Based on a table from Pentium Processor User’s Manual: Archi-
tecture and Programming Manual ,V o l u m e3 , c/circlecopyrt1993.
•Figure 14.8: From Leffler/McKusick/Karels/Quarterman, The Design and
Implementation of the 4.3BSD UNIX Operating System ,c/circlecopyrt1989 by Addison-
Wesley Publishing Co., Inc., Reading, Massachusetts. Figure 7.6, p. 196.
Reprintedwithpermissionof the publisher.
•Figures 19.5, 19.6, and 19.8: From Halsall, Data Communications, Computer
Networks, and Open Systems, Third Edition ,c/circlecopyrt1992, Addison-Wesley Pub-
lishing Co., Inc., Reading, Massachusetts. Figure 1.9, p. 14, Figure 1.10, p.
15, and Figure1.11, p.18.Reprintedwithpermissionof the publisher.
963"
0,Index,1195,Credits,"Index
4-byte pages, 363, 364
32-byte memory, 363, 364
50-percent rule, 359
64-bit computing, 383
A
ABI (application binary interface), 78-79
aborting processes, 342
absolute code, 352
absolute path names, 546
abstract data type (ADT), 277-278
access, 539-541
anonymous,605
controlling, 552-554
direct (relative), 539-541
effectiveaccess time, 397-398
kernelobject,884-885
lightweight directory-access protocol,
607,884
memory,15, 18,19,418-419,498-500
process migrationfor,753
andprotection,551
random-accessdevices, 502
random-accesstime, 450
read, 292
relative, 539-540
RemoteAccess Tool, 625
remotefile, 764-767
security access tokens,662
sequential,539,541
wireless access points, 736
write,292
access control:
discretionary, 684
in Linux, 816-818
MAC address, 745mandatory,684-685
role-based,683-684
access-control lists (ACLs), 552, 555, 826
accessed bits, 437
access mask, 849
access matrix, 675-685
defined, 675
implementationof,679-682
and mandatoryaccess control, 684-685
and revocationofaccess rights, 682-683
and role-basedaccess control, 683-684
access rights, 534, 673, 680, 682-683
accounting, 110, 659, 788
ACG (Arbitrary Code Guard), 827
acknowledgment packet, 748
ACLs,seeaccess-control lists
ACPI (advanced configuratio and power
interface), 516
activation record, 107
active directory, 607, 884
acyclic graphs, 547
acyclic-graph directories, 547-549
additional-reference-bits algorithm,
409-410
additional sense code, 512
additional sense-code qualifie , 512
address(es):
defined, 496
linear,380,382
logical, 353,379
MAC, 745
physical, 354,379
trusted, 638
virtual, 354
address binding, 352-353
address mapping, 456-457
address resolution protocol (ARP), 745
965"
0,Glossary,1237,Index,"G-150-percent rule  A statistical fi  nding that frag-
mentation may result in the loss of 50 percent of 
space.
absolute code  Code with bindings to absolute 
memory addresses.
absolute path name  A path name starting at the 
top of the fi  le system hierarchy. 
abstract data type (ADT)  A programming con-
struct that encapsulates data with a set of functions 
to operate on that data that are independent of any 
specifi  c implementation of the ADT.
access matrix  An abstract model of protection in 
which each row represents a domain, each column 
an object, and each entry a set of access rights.
access right  The ability to execute an operation 
on an object.
access-control list  A list of user names allowed 
to access a fi  le.
acknowledgment packet  In networking, a packet 
sent in response to the successful receipt of a mes-
sage or packet.
activation record  A record created when a func-
tion or subroutine is called; added to the stack by 
the call and removed when the call returns. Con-
tains function parameters, local variables, and the 
return address.
active directory (AD)  The Windows distributed 
information system, which is the Windows imple-
mentation of LDAP .
acyclic graph  In directory structure implemen-
tation, a structure that contains no cycles (loops).
adaptive mutex  A Solaris scheduling feature that 
starts as a standard spinlock and, if the object is 
locked and the lock is not held by a thread run-
ning on a CPU, blocks and sleeps until the lock is 
released.
address space layout randomization (ASLR)  An 
operating system technique to avoid code-injection 
attacks that place memory objects like the stack 
and heap at unpredictable locations.
address windowing extension (AWE)  A Win-
dows mechanism for memory allocation that 
allows developers to directly request free pages of RAM from the memory manager and later commit 
virtual memory on top of those pages.
address-space identifi  er A part of a TLB entry 
that identifi  es the process associated with that 
entry and, if the requesting process doesn’t 
match the ID, causes a TLB miss for address-
space protection.
address-space layout randomization (ASRL)  A 
Windows 7 feature that randomizes process mem-
ory addresses to avoid viruses that jump to specifi  c 
code locations to gain privileges.
admission control  In real-time scheduling, a 
practice whereby the scheduler may not allow a 
process to start if it cannot guarantee that the task 
will be serviced by its deadline. 
advanced confi  guration and power interface 
(ACPI)  Firmware common to PCs and servers 
that manages certain aspects of hardware, includ-
ing power and device information.
advanced encryption standard (AES)  The NIST 
cipher designed to replace DES and triple DES.
advanced local procedure call (ALPC)  In Win-
dows OS, a method used for communication 
between two processes on the same machine. 
advanced technology attachment (ATA)  An older-
generation I/O bus.
advisory fi le-lock mechanism  A fi  le-locking 
system in which the operating system does not 
enforce locking and fi  le access, leaving it to pro-
cesses to implement the details.
AFS (OpenAFS)  A network fi  le system designed 
at Carnegie Mellon University with the goal of 
enabling servers to support as many clients as 
possible.
aging  A solution to scheduling starvation that 
involves gradually increasing the priority of 
threads as they wait for CPU time. 
ahead-of-time (AOT) compilation  A feature of 
the Android RunTime (ART) virtual machine envi-
ronment in which Java applications are compiled 
to native machine code when they are installed on 
a system (rather than just in time, when they are 
executed)."
0,EULA,1278,Glossary,"WILEY END USER LICENSE
AGREEMENT
Go to www.wiley.com/go/eula to access Wiley’s ebook
EULA."
